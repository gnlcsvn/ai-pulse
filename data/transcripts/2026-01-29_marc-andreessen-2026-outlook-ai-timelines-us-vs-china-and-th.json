{
  "metadata": {
    "video_id": "xRh2sVcNXQ8",
    "url": "https://www.youtube.com/watch?v=xRh2sVcNXQ8",
    "title": "Marc Andreessen 2026 Outlook AI Timelines US vs China and The Price of AI",
    "channel": "a16z",
    "upload_date": "2026-01-29",
    "duration": "81m",
    "guests": [
      "Marc Andreessen"
    ],
    "transcribed_date": "2026-02-25",
    "whisper_model": "mlx-community/whisper-large-v3-turbo"
  },
  "language": "en",
  "text": "This new wave of AI companies is growing revenue, like just like actual customer revenue, actual demand translated through to dollars showing up in bank accounts at like an absolutely unprecedented takeoff rate. We're seeing companies grow much faster. I'm very skeptical that the form and shape of the products that people are using today is what they're going to be using in five or 10 years. I think things are going to get much more sophisticated from here. And so I think we probably have a long way to go. These are trillion dollar questions, not answers. But once somebody proves that it's capable, it seems to not be that hard for other people to be able to catch up, even people with far less resources. When a company is confronted with fundamentally open strategic or economic questions, it's often a big problem. Companies like need to answer these questions. And if they get the answers wrong, they're really in trouble. In venture, we can bet on multiple strategies at the same time. We are aggressively investing behind every strategy that we've identified that we think has a plausible chance of working. If you want to understand people, there's basically two ways to understand what people are doing and thinking. One is to ask them, and then the other is to watch them. And what you often see in many areas of human activity, including politics and many different aspects of society, the answers that you get when you ask people are very different than the answers that you get when you watch them. If you run a survey or a poll of what, for example, American voters think about AI, it's just like they're all in a total panic. It's like, oh my God, this is terrible. This is awful. It's going to kill all the jobs, going to ruin everything. If you watch the revealed preferences, they're all using AI. A lot of folks have sent questions ahead of time. And what I've done is kind of curated into a few different sections in an AMA this morning with Mark. So what we thought we'd do is cover four big topics. So AI and what's happening in the markets, policy and regulation, all things A, 16, and Z. And then we've got a fun catch-all, which we're calling sandbox of things if we get to it. So starting first, maybe with the biggest question. We're sitting in the middle of the AI revolution, Mark. What inning do you think we're in and what are you most excited about? Mark Benthien, Ph.D.: First of all, I would say this is the biggest technological revolution of my life. And hopefully I'll see more like this in the next whatever, 30 years. But I mean, this is the big one. And just in terms of order of magnitude, this is clearly bigger than the internet. The comps on this are things like the microprocessor and the steam engine and electricity. So this is a really big one. Mark Benthien, Ph.D.: The wheel. The reason this is so big, I mean, may be obvious to folks at this point, but I'll just go through it quickly. So if you kind of trace all the way back to the 1930s, there's a great book called Rise of the Machines that kind of goes through this. If you trace all the way back to the 1930s, there was actually a debate among the people who actually invented the computer. And it was this sort of debate between whether computer, they kind of understood the theory of computation before they actually built the things. And they had this big debate over whether the computer should be basically built in the image of what at the time were called adding machines or calculating machines. Think of sort of essentially cash registers. IBM is actually the successor company to the National Cash Register Company of America. And that was, of course, the path that the industry took, which was building these kind of hyper-literal mathematical machines that could execute mathematical operations billions of times per second, but of course had no ability to kind of deal with human beings the way humans like to be dealt with. And so couldn't understand human speech, human language, and so forth. And that's the computer industry that got built over the last 80 years. And that's the computer industry that's built all the wealth and financial returns in the computer industry over the last 80 years, across all the generations of computers from mainframes through to smartphones. But they knew at the time, they knew in the 30s, actually, they understood the basic structure of the human brain. They understood they had a theory of sort of human cognition. And actually, they had the theory of neural networks. And so they had this theory that there's actually the first neural network paper, academic paper was published in 1943, you know, which was over 80 years ago, which is extremely amazing. There's an interview, you can read an interview, or you can watch the interview on YouTube with these two authors, McCullough and Pitts. And you can watch an interview, I think, with McCullough on YouTube from like, I don't know, 1946 or something. He was like on TV, you know, in the ancient past. And it's literally like, it's an amazing interview, because it's like him in his beach house, and for some reason, he's not wearing a shirt. And he's like, you know, talking about like this future in which computers are going to be, you know, built on the model of the human brain through neural networks. And that was the path not taken. And basically, what happened was, right, the computers got built in the image of like the adding machine. But the neural network basically didn't happen. But the neural network as an idea continued to be explored in academia, and in sort of advanced research by sort of a rump, you know, movement, that was originally called cybernetics, and then became known as artificial intelligence, basically, for the last 80 years. And essentially, it didn't work. Like, essentially, it was basically decade after decade after decade of excessive optimism, followed by disappointment. When I was in college in the 80s, there had been a famous kind of AI boom bust cycle in the 80s, in venture in Silicon Valley. I mean, it was tiny by modern standards, but at the time was a big deal. And, you know, by the time I got to college in 89, in computer science departments, AI was kind of a backwater field, and everybody kind of assumed that it was never going to happen. But the scientists kept working on it to their credit. And they built up this kind of enormous reservoir of concepts and ideas. And then basically, we all saw what happened with the chat GPT moment. All of a sudden, it sort of crystallized, and it's like, oh, my God, right, it turns out it works. And so, you know, that's the moment we're in now. And then, you know, really significantly, that was what, you know, that was less than three years ago, right? That was the summer of 22. It was the Christmas of 22. And so, we're sort of three years in to, you know, basically what is effectively an 80-year revolution of actually being able to deliver on all the promise that the people on the alternate path, the sort of human cognition model path, you know, kind of saw from the very beginning. And then, you know, the great news with this technology is it's already, it's kind of ultra democratized. You know, the best AI in the world is available on chat GPT or Grok or Gemini or, you know, these other, you know, these other products that you can just use. And you can just kind of see how they work. And, you know, same thing for video, you can see with Sora and video kind of state-of-the-art. With that, you can see with music, you can see, you know, Suno and IDEO and so forth. And so, like, you know, we're basically seeing that happen. And now, and now Silicon Valley is responding with this just like incredible rush of enthusiasm. And, you know, really critically, this gets to the magic of Silicon Valley, which is, you know, Silicon Valley, long since has ceased to be a place where people make Silicon that, you know, that's that not long ago moved out of the, out of California, and then ultimately out of the US, although we're trying to bring it back now. But the great kind of virtue of Silicon Valley over the last, you know, over the last, you know, 80 years of its existence is its ability to kind of recycle talent from previous waves of technology to new waves of technology, and then inspire an entire new generation of talent, you know, to basically come join the, you know, join the project. And so Silicon Valley has this recurring pattern of being able to reallocate capital and talent and build enthusiasm and build critical mass and build funding support and build, you know, human capital and build, you know, everything, enthusiasm, you know, for each new wave of technology. And so, so that's what's happening with AI. You know, I think probably the biggest thing I could just say is like, I'm surprised, I think, essentially on a daily basis of what I'm seeing. And, and, you know, we're, we're in the fortunate position to kind of get to see it from two angles. You know, one is we track the underlying science and, and, and, and kind of research work very carefully. And so I would say like every day, I see a new AI research paper that just like completely floors me of some new capability, or some new discovery, or some new development that I, that I would have never anticipated that I, I'm just like, wow, I, you know, I can't believe this is happening. And then on the other side, of course, you know, we see the flow of all of the new products and all the new startups. And, you know, I would say we're routinely, you know, kind of seeing things that again, kind of have my jaw on the floor. And so, you know, it feels like we, we, we've unlocked this giant Vista. I do think it's going to kind of come in fits and starts. You know, these things are messy processes. You know, you know, this is an industry that kind of routinely gets out over its skis and over promises. And so, you know, there, there, you know, there will certainly be points where it's like, wow, you know, this isn't working as well as people thought, or, you know, wow, this turns out to be too expensive, and the economics don't work or whatever. But, you know, against that, I would just say the capabilities are truly magical. And, by the way, I think that's the experience that consumers are having when they use it. And I think that's the experience that businesses are having for the most part when they, you know, when they're working on their pilots and, and looking at adoption. And then, and then it translates to the underlying numbers. I mean, we're just seeing this new wave of AI companies is growing revenue, like just like actual customer revenue, actual demand, translated through to dollars showing up in bank accounts. You know, at like an absolutely unprecedented takeoff rate, we're seeing companies grow much faster. The key leading AI companies and the companies that have real breakthroughs, and have real very compelling products are growing revenues that, you know, kind of faster than any, any wave I've certainly ever seen before. And so, like, just, just from all that, it kind of feels like it has to be early. Like, it's kind of hard to imagine that we've like, we've topped out in any way, it feels like everything is still developing. I mean, quite frankly, it feels like the products, to me, it feels like the products are still super early. Like, I'm, I'm very skeptical that the form and shape of the products that people are using today is what they're going to be using in five or 10 years. I think, I think things are going to get much more sophisticated from here. And so, I think we probably have a long way to go. Maybe on that, that topic. So, one of the big knocks is, yes, the revenue is immense, but the expenses seem to also be keeping pace. So, like, what are people missing as a part of that discussion and topic? Yeah. So, I just, I'll start with just like core business models, right? And so, you're right, there's basically, this industry basically has two core business models, consumer business model, and the quote unquote enterprise or infrastructure business model. You know, look, on the consumer side, we just live in a very interesting world now where the internet exists and is fully deployed, right? And so, I'll give you an example. Sometimes people ask, it's like, is AI like the internet revolution? It's like, well, a little bit, but like, the thing with the internet was we had to build the internet. Like, we had to actually build the network and we actually had that, you know, and ultimately it involved an enormous amount of fiber in the ground and it involved enormous numbers of like mobile cell towers and, you know, enormous number of, you know, shipments of smartphones and tablets and laptops in order to get people on the internet. Like, there was this like, just like incredible physical lift, you know, to do that. And by the way, people forget how long that took, right? The, you know, the internet itself is a invention of the 1960s, 1970s. The consumer internet, you know, was a new phenomenon in the early 90s. But, you know, we didn't really get broadband to the home until the 2000s. You know, that really didn't start rolling out actually until after the dot-com crash, which is fairly amazing. And then we didn't get mobile broadband until like 2010. And people actually forget the original iPhone dropped in 2007. It didn't have broadband. It was on a narrowband 2G network. It did not have high-speed, like it did not have anything resembling high-speed data. And so it wasn't really until, you know, really about 15 years ago that we even had mobile broadband. So the internet was this massive lift, but the internet got built, right? And smartphones proliferated. And so the point is now you have 5 billion people on planet Earth that are on some version of, you know, mobile broadband internet, right? And, you know, smartphones all over the world are selling for, you know, as little as like 10 bucks. And you have these, you know, amazing projects like GEO and India that are bringing, you know, you know, the sort of the remaining, you know, kind of the remaining population of planet Earth that hasn't been online until now is coming online. So, you know, so we're talking 5 billion, 6 billion, you know, people. And then the consumer, the reason I go through that is the consumer AI products could basically deploy to all of those people basically as quickly as they want to adopt, right? And so sort of the internet's the carrier wave for AI to be able to proliferate at kind of light speed into the broad base of the global population. And that's a, let's just say that's a potential rate of proliferation of a new technology that's just far faster than has ever been possible before. Like, you know, like you couldn't download electricity, right? You couldn't download, you know, you couldn't download indoor plumbing. You know, you couldn't download television, but you can download AI. And this is what we're seeing, which is the AI consumer app, you know, the AI consumer killer applications are growing at an incredible rate. And then they're monetizing really well. And again, you know, I mentioned this already, but like generally speaking, the monetization is very good. By the way, including at higher price points. One of the things I like about the, you know, about watching the AI wave is the AI companies, I think, are more creative on pricing than the SaaS companies, the consumer internet companies were. And so it's, for example, now becoming routine to have 200 or $300 per month tiers for consumer AI, which I think is very positive because I think a lot of companies cap their kind of opportunity by capping their pricing kind of too low. And I think the AI companies are more willing to push that, which I think is good. So anyway, so that, you know, I think that's the reason for, like, I would say, you know, considerable rational optimism for the scope of consumer revenues that we're going to be talking about here. And then on the enterprise side, you know, there the question is basically just, you know, what is intelligence worth, right? And, you know, if you have the ability to like inject more intelligence in your business, and you have the ability to do, you know, even the most prosaic things like raise your customer service scores, you know, increase upsells, you know, or reduce churn, or if you have the ability to, you know, run marketing campaigns more effectively, you know, all of which AI is directly relevant to, like, you know, these are like direct business payoffs, you know, that people are seeing already. And then if you have the opportunity to infuse AI into new products, and all of a sudden, you know, all of a sudden, your car talks to you, and everything in the world kind of lights up and starts to get really smart, you know, what, you know, what's that worth? And again, there, you just, you kind of observe it. And you're like, wow, the leading AI infrastructure companies are growing revenues incredibly quickly. You know, the pull is really tremendous. And so, you know, again, there, it's just, it feels like this just like incredible, you know, product market fit. And the core business model, right, is actually quite interesting. The core business model is basically, is basically tokens by the drink, right? And so it's a sort of tokens of intelligence, you know, per dollar. And oh, and then by the way, this is the other fun thing is, if you look at what's happening with the price of AI, the price of AI is falling much faster than Moore's Law. And when I could go through that in great detail, but basically, like all of the inputs into AI are on a per unit basis, the costs are collapsing. And then as a consequence, there's kind of this hyper deflation of per unit cost. And then that is like driving, you know, just like, you know, a more than corresponding level of demand growth, you know, with elasticity. And so, you know, even there, we're like, it feels like we're just at the very beginning of kind of, you know, figuring out exactly how, you know, expensive or cheap this stuff is getting. I mean, there's just no question tokens by the drink are going to get a lot cheaper from here. That's just going to drive, I think, enormous demand. And then everything in the cost structure is going to get optimized, right? And so, you know, when people talk about like, you know, the chips, or, you know, whatever, you know, kind of the unit input costs for building AI, you know, you now have these like, the losses of blind demand are going to kick in, right? But what's the, you know, in any market that has sort of commodity-like characteristics, you know, the number one cause of a glut is a shortage, and the number one cause of a shortage is a glut, right? And so you have, you know, to the extent you have like shortage of GPUs, or shortage of whatever inference chips, or shortage of, you know, whatever data center space, you know, if you look at just the history of humanity building things in response to demand, you know, if there's a shortage of something that can be physically replicated, it does get replicated. And so there's going to be like just enormous build out of all, I mean, there is, there's just hundreds of billions or at this point, trillions of dollars maybe going into the ground and all these things. And so the per unit cost of the AI companies are going to drop like a rock, you know, over the course of the next decade. And so like, yeah, I mean, the economic questions, of course, are very real. And of course, there's, you know, micro economic questions around all these businesses, but the sort of macro forces have been the least here, I think are very strong. And yeah, I just given the underlying value of this technology to both the consumers and to the enterprise users, and given the just like incredibly aggressive discovery that's happening of all the ways that people can use this in their lives and in their businesses, like, it's just, it's really hard for me to see how it both doesn't grow a lot and generate just enormous revenue. Yeah. And actually, I think it was like two or three weeks ago where AWS was saying like, the GPUs that they've been using, they've been able to extend back to even like seven plus years. So like the shelf life also of the GPUs that they're using is now extending in ways of which they can optimize better than maybe perhaps the last couple of cycles as well. Is that the right way to think about it as well? Yeah, that's right. And then that's one really important question and observation. And then, by the way, that also gets to this other kind of question where there's different theories on it, which is basically big models versus small models. And so a lot of the data, a lot of the data center build is oriented around hosting training and serving the big models, you know, for all the obvious reasons. But there's also the small model revolution is happening at the same time. And if you just kind of track, you know, you can get the various research firms have these charts, you can get but if you just kind of track the capability of the leading edge models over time, what you find is after six or 12 months, there's a small model that's just as capable. And so there's this kind of chase function that's happening, which is the capabilities of the big models are basically being shrunk down and provided at smaller size and then therefore smaller cost, you know, quite quickly. So I'll just give you the most recent example that's just kind of hit over the last two weeks. And again, this is the thing that's just kind of shocking is there's this Chinese company that has a, well, I forget the name of the company, but it's the company that produces the model called Kimi, just spelled K-I-M-I, which is one of the leading open source models out of China. And the new version of Kimi is a reasoning model that is at least according to the benchmark so far, is basically a replication of the reasoning capabilities of GPT-5, right? And the reasoning models of GPT-5 were a big advance over GPT-4. And of course, GPT-5 costs a tremendous amount of money to develop and to serve. And all of a sudden, you know, here we are, whatever, six months later, and you have an open source model called Kimi. And I think, I don't know if they've had, it's either shrunk down to be able to run on either, it's like one MacBook or two MacBooks, right? And so you can all of a sudden, if you have like an application, if you're a business and you want to have a reasoning model of the GPT-5 capable, but you, you know, you're whatever, you're not going to pay the, whatever GPT-5 cost, or you're not going to want to have it be hosted and you want to run it locally, you know, you can do that. And again, that's just like another, just like, it's like another, you know, it's another breakthrough. Like it's just, it's another Tuesday, another huge advance. It's like, oh my God. And then of course, it's like, all right, well, what is OpenAI going to do? Well, obviously they're going to go to GPT-6, right? And, you know, right. And so there's this kind of laddering that's happening where the entire industry is moving forward. The big models are getting more capable, the small models are kind of chasing them. And then, and then the small models provide, you know, a completely different way to deploy, you know, at, at, at, at very low price points. And so, yeah, I think, and, you know, we'll, we'll see what happens. I mean, there, there are some very smart people in the industry who think that ultimately everything only runs in the big models, because obviously the big models are always going to be the smartest. And so therefore you're always, you know, you're always going to want the most intelligent thing, because why would you ever want something that's not the most intelligent thing for any application? You know, the counter argument is just, there's a huge number of tasks that take place in the economy and in the world that don't require Einstein, you know, where, you know, where, you know, 120 IQ person is great. You don't need a, you know, 160 IQ, you know, PhD in, you know, string theory, you just like have somebody who's competent and capable and it's great. And so, you know, I, you know, and I, we've talked about this before. I, I tend to think the AI industry is going to be structured a lot like the computer industry ended up getting structured, which is you're going to have a small handful of basically the equivalent of supercomputers, which are these like giant, you know, kind of, we call God models that are, you know, running in these giant data centers. And then, and then, you know, I, I, I, I'm not like convinced on this, but my, my kind of working assumption is what happens is then you have this cascade down of smaller models, all ultimately all the way, the very small models that run in embedded systems, right. Run on, run on individual chips inside every, you know, physical item in the world. And that, you know, the smartest models will always be at the top, but the volume of models will actually be the smaller models that proliferate out. And right. That's what happened with microchips. It's what happened to computers, which became microchips. And then it's what happened with operating systems and with, with a lot of everything else that we built in software. So, you know, I tend to think that's what will happen. Just quickly on the chip side, again, like chips, you know, if you look at the entire history of the chip industry, shortages become gluts. And you get just, you know, like anytime there's a giant profit pool in a, in a new chip category, you know, somebody has a lead for a while and kind of gets, you know, let's say the, the, the, the profits appropriate to what we, what we call robust market share. But in time, what happens, right, is that, that draws competition. And of course, you know, that, that, that's happening right now. So NVIDIA is, you know, NVIDIA is an absolutely fantastic company, fully deserves the position that they're in, fully deserves the profits that they're generating, but they're now so valuable generating so many profits that it's the bat signal of all time to the rest of the chip industry to figure out how to advance the state of the art in AI chips. And that's, by the way, and that's already happening, right? And so you've got other major companies like AMD coming at them, and then you've got really significantly, you've got the hyperscalers building their own chips. And so, you know, a bunch of the big, a bunch of those kind of big tech companies are building their own chips. And of course, then the Chinese are building their own chips as well. And so it's just, it's like pretty likely in five years that, that, you know, AI chips will be, you know, cheap and plentiful, at least in comparison to the situation today, which again, I think will, you know, will tend to be extremely positive for the economics of the kinds of companies that we invest in. Yep. And the startups are also starting to go after new chip design as well, which is exciting. Yeah. Well, that's the other thing is, yeah, you have these disruptive startups. And actually that, just for a moment on the chips, we're not really big investors in chips, because it's kind of a big, it's kind of a big company thing, but it's a little bit of historical happenstance that AI is running on quote unquote GPUs, you know, which in GPU stands for graphical processing unit. So, and basically just for people who haven't tracked this, there were basically two kinds of chips that made the personal computer happen, the so-called CPU central processing unit, which classically was the Intel x86 chip. It's kind of the brain of the computer. And then there was this other kind of chip called the GPU or graphical processing unit that was the sort of second chip in every PC that does all the graphics. And, you know, and this is graphics, like, you know, 3D graphics for gaming or for CAD cam or for, you know, anything else, you know, Photoshop or for anything that involves, you know, lots of visuals. And so the kind of canonical architecture for a personal computer was a CPU and a GPU, by the way, same thing for smartphones. But by the way, and over time, you know, these have kind of merged. And so like a lot of CPUs now have GPU capability built in, actually, a lot of GPUs now have CPU capability built in. So this, you know, this has gotten fuzzy over time, but like that, that was like the classic breakdown. But the fact that that was the classic breakdown, you know, kind of meant that while Intel had a, you know, monopoly for a long time on CPUs, there was this other market of GPUs, which NVIDIA, you know, basically fought the GPU wars for 30 years and came out the winner, like what was the best company in the space. But it was like a hyper competitive market for graphics processors. It was actually not that high margin. It was actually not that big. And then basically, it just, it turned out that there were two other forms of computation that were incredibly valuable that happened to be massively parallel in how they operate, which happened to be very good fits for the GPU architecture. And those two basically highly lucrative additional applications were cryptocurrency, starting about, you know, 15 years ago, and then AI, starting about, you know, whatever, four years ago. And so, and NVIDIA, like I would say, very cleverly set itself up with an architecture that works very well for this. But it's also just a little bit of a twist of fate, that it just turns out that if AI is the killer app, it just turns out that the GPU architecture is the best legacy architecture is devoted to it. I go through that to say, like, if you were designing AI chips from scratch today, you wouldn't build a full GPU, you would build dedicated AI chips that were much more straight, much more specifically adapted to AI, and would have, I think would just be much more economically efficient. And, you know, Jen, to your point, there are startups that are actually building entirely new kinds of chips oriented specifically for AI. And, you know, we'll have to see what happens there. You know, it's hard to build a new chip company from scratch. You know, it's possible that one or more of those startups makes it on their own. And some of them are, you know, doing very well. It's also possible, of course, that they get bought, you know, by big companies that have the ability to scale them. And so, you know, we'll see exactly how that unfolds. And of course, we'll also, by the way, see, you know, the Koreans are going to play here, for sure. The Japanese are going to play. And then, you know, the Chinese in a major way, as well. And, you know, they have their own, you know, native chip ecosystem that they're building up. And so there are going to be many choices of AI chips in the future. And it's going to be, you know, that'll be a giant battle. That'll be a giant battle that we observe very carefully, and that we make sure that our companies basically are able to take full advantage of. Well, while on the topic of international, you mentioned Kimi earlier. So it seems like some of the best open source models today are from China. Should this be worrisome to folks? How are you thinking and talking about this topic with folks in DC? I know you were just there last week. How much of this is a concern for US companies, particularly just having seen the rise of China do unnatural things in solar markets, car markets. Are they kind of flooding the ecosystem so that they could eventually kind of take share and increasingly own the ecosystem? Yeah. So, you know, a couple of things. So one is, you know, you want to start these discussions by just kind of saying, like, you know, look, there's vigorous debate in the US and around the world of, like, you know, how much are we in a new Cold War with China? You know, and exactly like how hostile, you know, should we view them? And it's very tempting, by the way, it's very tempting, and I think it's a very good case to be made that we're in, like, a new Cold War that's, you know, that in a lot of ways is like the US versus USSR in the 20th century. You know, it is, the counterargument would be, it is more complicated than that because the US and the USSR were never really intertwined from a trade standpoint. And a big part of that, quite frankly, was the USSR never really made anything that anybody else needed, I guess, other than weapons. But like, you know, the USSR's primary exports were literally, like, you know, literally, like, wheat and oil. Whereas, of course, China exports just a tremendous number of physical things, right? Including, like, a huge part of, like, the entire supply chain of parts that basically go into everything that American manufacturers, you know, kind of make, right? And so by the time a US, you know, whatever, by the time an American company brings a toy to market, right? Or a, you know, or a car, or anything, or a computer, or a smartphone, or whatever, like, it's got a lot of componentry in it that was made in China. So there is a much tighter interlinkage between the American and Chinese economies than there was the American and Soviet economies. And, you know, maybe, you know, Adam Smith or whatever might say, you know, that's good news for peace, and that, you know, both countries need each other. By the way, the other part of that argument is that the Chinese, basically, the Chinese, you know, the Chinese governance model is based on high employment. You know, because, you know, if, you know, at least all the geopolitical people say, if China ended up with, like, 25% or 50% unemployment, that would cause civil unrest, which is the one thing that the CCP doesn't want. And so the corresponding part of the trade pressure is China needs the American export market. You know, the American consumer is like a third of the global economy, a third of global consumer demand. And so, you know, China needs the US export market, or it has high, all of a sudden, a lot of its factories would go kind of instantly bankrupt, and, you know, would cause mass unemployment and unrest in China. So, so anyway, like, you know, we, there is this complicated, it's a complicated, intertwined relationship. Having said that, you know, the mood in DC, basically, for the last 10 years, on a bipartisan basis, has been that we need to take, we, the US need to take China more seriously as a geopolitical foe. And, you know, under, under, under that school of thought, there's sort of, there's sort of, you know, there's, there's the military dimension, which is, you know, this sort of, you know, the, the, the risk of some kind of war in the South China Sea, the risk of some kind of war around, around Taiwan. And so that, you know, that, that has everybody in Washington on high alert. You know, there's also this, this economic question around the kind of de-industrialization of the US, the potential re-industrialization, and what that means about, you know, dependence on China. And then, and then there's, and then there's this, this, this AI question. And the AI question is an economic question, but it's also like a geopolitical question, which is, okay, you know, basically AI is essentially only being built in the US and in China. You know, the rest of the world either, you know, can't build it or doesn't want to, which, which we could talk about. So it's basically US versus China. And then AI is going to proliferate all over the world. And is it going to be American AI that proliferates all over the world? Or is it going to be Chinese AI that proliferates all over the world? And so, and I would say just generally across party lines in DC, this, you know, the, the things I just went through are kind of how they look at it. And the Chinese are in the game. And so the, you know, the Chinese are in the game for sure, you know, with software, you know, DeepSeq, you know, was kind of the big, you know, kind of fired the starting gun of the software race. And now you've got, I think it's, I think you've got four, it's like a DeepSeq, which is a deep, so DeepSeq is an AI model from actually a hedge fund in China. It's a little bit, kind of took a lot of people by surprise. And then Quinn is the model from Alibaba. Kimmy is from another startup, oh, called Moonshot. The company's called Moonshot. And then there's, you know, and then, you know, there's also Tencent and Baidu and ByteDance, you know, that are all primary, you know, companies doing a lot of work in AI. And so, you know, there's somewhere between three to six, you know, kind of primary AI companies. And then there's, you know, tremendous numbers of startups. And so, you know, they're in the race on, on, you know, they're in the race on, on, on software. They are, you know, working to catch up on chips. They're not there yet, but they're working incredibly hard to catch up. And just as an example of that, you know, the, at least the common understanding, you know, in the US is that the reason you haven't seen the new version of DeepSeq yet is that basically the Chinese government has instructed them to build it only on Chinese chips as a, as a motivator to get the Chinese chip ecosystem up and running. And then the main chip company there is Huawei, although there could be more in the future. And then there's, you know, so, so, so, so there's that, and then, and then there's everything to follow, which is basically AI in kind of robotic form, right? And so there's this basically global technological economic robotics competition that's kicking off. And, you know, China kind of starts out ahead on robotics, because they're just ahead on so many of the, so many of the components that go into robots, because the, you know, the sort of, like I said, this, the kind of entire supply chain of like electromechanical things, you know, basically moved from the US to China 30 years ago, and it's never come back. So, so, so that's kind of the, the, the, the DC lens on it. And I would say, you know, DC is watching it, you know, quite carefully. Yeah, the, the, the big kind of supernova moment this year was the DeepSeq release. The DeepSeq release was surprising on a number of fronts. One was just how good it was. And again, along this line of it took the capability set that we're running in large models in the cloud and kind of shrunk it onto a, you know, into, into a, into a sort of a, a reduced size, you know, a smaller version of sort of equivalent capabilities that you could run on small amounts of local hardware. And so, there was that. And then it was also a surprise that it was released as open source, and particularly open source from China, because China, China does not have a long history of open source. And then it was also a surprise that it actually came from a hedge fund. So, it didn't come from a big, you know, sort of university research lab. It didn't come from a, you know, from a big tech company. It came from a hedge fund. And it, it, like, as far as we can tell, it basically is this somewhat idiosyncratic situation where you just have this incredibly successful quant hedge fund with all these, you know, super geniuses. And the, the founder of that hedge fund, you know, basically decided to build AI. And, you know, at least externally, indications are this was a surprise to even the Chinese government. It's, it's impossible to prove, you know, what the Chinese government was surprised by or not. But, you know, there's at least the atmospherics are that this was not exactly planned. This was not a national champion tech company at the time that DeepSeq was released. It was a, it sort of came out of left field, which by the way, is very encouraging for the field that it was possible for somebody to do that kind of who was unknown, right? Because it kind of means that maybe you don't need all these, you know, super genius, superstar researchers, maybe actually smart kids can just build this stuff, which I think is, is the direction things are headed. And so that kicked off, I would say like this kind of, I don't know, copycats the wrong word, but that, that was sort of, it feels like the success of DeepSeq and the success of DeepSeq from China as open source kind of kicked off a sort of trend in China of releasing these open source models. You know, look, the cynics, you know, in DC would say, you know, yeah, like they're dumping, right? They're obviously dumping, they're, they're trying to, you know, they see that the West has this opportunity to build this China industry. You know, they're trying to commoditize it right out of the gate. You know, there's probably something to that. You know, the Chinese industrial economy does have a history of, you know, sort of, let's say subsidized production that leads to selling, you know, selling things below cost in some cases. But I think also it's like, I think that's almost too cynical of a view also, because it's just like, all right, wow, like they're really in the race, like open source, closed source, whatever, like that, you know, they're actually really in the race. You know, we, we've talked in the past, I think on, on LP calls about, you know, these policy fights that, you know, we've been having in DC for the last two years. And, you know, there was a big, pretty, pretty big push within the US government, or, you know, two years ago to basically, you know, restrict, you know, or outright ban, you know, a lot of AI. And, you know, it's very easy for a country that is the only game in town to have those conversations. It's quite another thing if you're actually in a foot race with China. And so I think actually, the policy landscape in DC has, I would say, has improved dramatically, as a consequence of sort of an awareness now that this is actually a two horse race, not a one horse race. For sure. Yeah, actually, on the point, I'll jump ahead here to policy and regulation, just because it seems like the current stance on, on 50 different set of AI laws by state seems like a catastrophic way to, to put us effectively with a, or one of our, our hands tied behind our, our back here in terms of the, the AI race. What's the state of plan that, are folks recognizing that that would be catastrophic for progress and development? Where do most people at least stand on that topic today? Yeah, so it's a little bit complicated. So, I'll rewind to say like two years ago, I was very worried about like really ruin this federal, federal legislation on AI. And there was, there was, we, you know, we engaged, you know, kind of very heavily at that point, which we talked about in the past. And I think the good news on that is, I think the risk of that sitting here today is very low. I, there's very little mood in DC on either side of the aisle to really, you know, essentially there's very little, there's very little interest in doing anything that would prevent us from beating China. So, so, you know, on the federal side, things are much better now. There, there will, there will be issues in their attentions in the system, but like things are looking, looking pretty good. That has translated, Jen, to your point, that's translated a lot of the attention to the states. And basically what's happened is, you know, under our system of federalism, you know, the states get to pass their own laws on a lot of things. And so, yeah, basically, you know, a lot of, you know, and, you know, with these things, it's always a combination. A lot of well-meaning people are trying to figure out what to do at the state level. And then of course, there's a lot of opportunism where AI is just the hot topic. And so if you're a, you know, aggressive up and coming state legislator or whatever in some state, and you want to run for governor and then president, you know, you want to kind of attach yourself to the heat. And so there's like a political motivation to do state level stuff. Yeah. And sitting here today, like we're tracking on the order of 1200 bills across the 50 states. And by the way, not just the blue states, also the red states. And so, you know, I've, you know, for the last like five years or whatever, I spent a lot of time complaining about, you know, kind of what democratic politicians are threatening to do to tech. There's also a lot of Republicans, like Republicans are not a block on this. And there are quite a few like local Republican officials in different states that also, I think have, you know, let's say, you know, misinformed or ill-advised views and are trying to put together, put out bad bills. You know, it's a little bit weird that this is happening and that, you know, the federal government does have regulation of interstate commerce. And, you know, technology, AI kind of by definition is interstate. Like, you know, there's, there's no AI company that just operates in California or just operates in, you know, Colorado or Texas. You know, AI, of all technologies, AI is obviously something that's the sort of national in scope. You know, it's sort of obvious that the federal government should be the regulator, not the states. But the federal government needs to assert itself, needs to step in. There was actually an attempt to do that. There was a, there was an attempt to add a moratorium, a state level AI regulation that basically would reserve the right of the federal government to regulate AI and sort of prevent the states from moving forward with these bills. That was, I think, part of the negotiation for the quote, one big, beautiful bill. And then that, that there was a deal behind that and that deal kind of blew up at the, at the last minute. And that moratorium didn't happen. And, and, you know, in fairness, the critics of that moratorium, it probably was, was, it was probably too much of a stretch. Oh, it was, I'm sorry, it was definitely too much of a stretch to get enough support to pass, but it was also probably too much of a stretch in terms of restricting the states from certain kinds of regulation that they really should be able to do. So, so it just, it didn't quite come together. There's a very active, we're having very active discussions in DC right now about kind of the next, you know, the kind of the next turn on that. You know, the administration is, I would say the administration is very supportive of, of the idea of, of the federal government being in charge of this as part of it being an actual, you know, 50 state issue and, and, and an issue of national importance. And then, you know, I'd say most, most Congress people on both sides of the aisle, you know, kind of get this. So we just, we kind of have to figure out a way to, you know, to land this, but, but I think that'll happen. Some of the state level bills are wild. The, the Colorado passed a very draconian regulation bill last year and against like serious objections from the local startup ecosystem in, in, in and around Denver and Boulder. And actually, they're, they're now actually trying to reverse their way out of that bill, you know, a year later. But maybe hear some of the nuance of it, like the algorithmic discrimination and like how to admit it, like what were some of the, the extreme versions of what they had proposed? Yeah. So the really draconian one was the, the one that we really fought hard was the one in California, which was called SB 1047. And it wasn't, it, it was basically, it was modeled basically after the, it was called the EU AI Act. So the European Union's AI Act. Okay. And this is the backdrop to all the US stuff, which is the EU passed this bill called the AI Act. I don't know, whatever, two years ago. And it basically has killed AI development in, well, it's actually killed AI development in Europe to a large extent. And then it even, it is so draconian that even, even big American companies like Apple and Meta are not launching leading edge AI capabilities in their products in Europe. Like that, that's how, that's how like draconian that bill was. And it's, it's sort of a classic, it's a classic kind of European thing where they like, you know, like they just thought that, you know, they, they have this kind of view that it's just like, well, you know, we, if we can't be the leader, they literally say this, by the way, if we can't be the leaders in innovation, at least you can be the leaders in regulation. And, and, and then they pass this like incredibly, you know, kind of ruinous self harm, you know, kind of thing. And then, you know, a few years pass and they're like, oh my God, what have we done? And so they're, you know, they're kind of going through their own version of that. Yeah. By the way, you know, I, I, you know, when I talk about Europe, I tend to be very dark about the whole thing. I will tell you the darkest people I know about Europe are the European entrepreneurs who moved to the US, are just like absolutely furious about what's happening in, in, in Europe on this stuff. But, but even there, like it's, it's so bad in Europe, like they, they shot themselves in the foot so badly that there's actually a process now at the EU to try to unwind that. They're trying to unwind the GDPR. So anyway, for people tracking Europe, Mario Draghi is the former, I guess, prime minister of Italy, did this thing about a year ago called the Draghi report, which is the report on European competitiveness. And he kind of outlined kind of in great detail, all the ways that Europe was holding itself back. And part of it was over regulation areas like AI. So, so they're trying to reverse out of that or making gestures, you know, we'll, we'll see what happens. In the middle of all that, California sort of inexplicably decided to basically copycat the EU AI Act and try to apply it to California, which might strike you as completely insane, to which I would say, yes, welcome to California. And, you know, it was this basically this like Sacramento political dynamic, that kind of got, got, got crazy. It would have, you know, completely killed, you know, AI development in California. Unfortunately, our governor vetoed it at the last minute. It did pass both houses, the legislature that he vetoed at the last minute. It, Jen, to your point, it would have done for, it would have done a whole bunch of things that were ruinously bad. But one of the things that would have done is it would have assigned downstream liability to open source developers. And so, you know, we talked about, you know, the Chinese open source thing. Okay. So you got Chinese out there with open source. Now you're gonna have American companies that have open source AI. And by the way, you're also gonna have American academics and just like independent people in their nights and weekends developing open source, you know, which is a key way that all this technology proliferates. And so this, this law would have assigned downstream liability to any misuse of open source to the original developer of the open source. And so, you know, you're an independent developer, or you're an academic, or you're a startup, you develop and release an AI model. The AI model works fine. The day you release it, it's great. But like five years later, it gets built into a nuclear power plant. And then there's a meltdown of the nuclear power plant. And then somebody says, oh, it's the fault of the AI. The legal liability for the nuclear meltdown or for anything, any other practical real world thing that would follow in the out years would then be assigned back to that open source developer. Of course, this is completely insane. It would completely kill open source. It would completely kill startups doing open source. It would completely kill academic research, like in its entirety, you know, anything in the field. And so, you know, like, that's the level of playing with fire, you know, kind of that these state level politicians have become enamored with. Like I said, I think the good news is the feds understand this, I suspect that this is going to get resolved, but it does need to get resolved. Because, you know, just as a country, it just doesn't make any sense to let the states kind of operate suicidally like this. And so that's what we're doing. You know, we talk about this, we call this our little tech agenda. We're extremely focused on the freedom of startups to innovate. We are not trying to argue, you know, many, many other issues. We operate in a completely bipartisan fashion. We have extensive support, you know, on both sides of the aisle and for both sides of the aisle. So it's a truly bipartisan effort, very policy-based, and, you know, I think very much aligned with the interests of the country broadly. And so that is what we're doing. And then the other question we get, we get actually, you know, in some cases from LPs, but in a lot of cases actually from employees, is like, okay, why us, right? Like, you know, with any sort of, you know, policy question like this, there's always this collective action question, which is this like, you know, tragedy of the commons, which is, in theory, like everybody, every venture firm, every tech company, whatever, should be weighing in on these things. In practice, what happens is most of them just simply don't. And so at some point, it falls on somebody's shoulders to fight these things. And Ben and I just basically concluded that the stakes here were just way too high. You know, if we're going to be the industry leader, we just have to take responsibility for our own destiny. You know, for better or for worse, I think that's the cost of doing business for being the leader in the field right now. Before we get off the topic of AI, I want to go back to one question that was submitted. And so do you think usage-based or utility is the right way to price an AI compared to seats? Ah, that is a fantastic question. So this is one of these giant, this is in my list of what I call the trillion dollar questions, where, you know, depending on how this is answered, will drive, you know, trillions of dollars in market value. So, yeah, so usage-based pricing, it's actually fairly amazing. If you think about this from a startup standpoint, from a venture standpoint, it's actually fairly amazing what's happened. And I'm trying, I'm not really talking about this in public, because I don't really, I guess I don't want it to stop. I think it's actually quite amazing. Which is, you have these technology companies, you know, these big tech companies with these incredible R&D capabilities that are building these big models, these big AI models with this incredible, you know, new kind of intelligence. And then it turns out that they were already in a war, they were already in the cloud war, right? And so they were already in the war for kind of cloud services. And this is like AWS versus Azure versus Google Cloud, you know, and then all these other cloud efforts. And so what actually happened was they sort of, like, there's an alternate universe in which they basically just kept all of their magic AI secret and captive and just used it in their own business, or used it to just compete with more companies, you know, in more categories. But instead, what they've done is they've basically, you know, if I've commoditized is too strong a word, but they have proliferated their magic new technology through their cloud business, which is this business that just has these like incredible scale, you know, kind of kind of components to it, you know, and sort of this hyper competition between the providers and these, you know, these, these prices that come down very fast. And so you've got like the most magic new technology in the world. And then it's basically being served up by those companies in as a cloud business, and made made basically available to everybody on the planet to just click and use and for like relatively small amounts of money. And then on a usage basis, which means usage is great for startups, because it means you can start easily, right? You know, the, you know, there's very, you know, there's basically no fixed cost for a startup building an AI app, they don't have giant fixed costs, because they can just tap into the open AI or Anthropic or Google or Microsoft or whatever, you know, cloud, you know, tokens by the drink, you know, intelligence tokens by the drink offering and just get going. And so it's kind of this, from this, from the startup standpoint, it's like this marvelous thing, where like the most magical thing in the world is available by the drink. You know, it's absolutely amazing. And you know, that model, you know, by the way, that model is working in those companies are happy, and they're growing really fast. And they're, you know, happily reporting massive cloud revenue growth, and you know, they're happy with the margins and so forth. And so, you know, I think generally, it's working. And those businesses are, I think, likely to get much larger. And so I think, you know, generally, that's going to work. But, but to the question like, that doesn't mean that the optimal pricing model for, for example, all of the applications should be tokens by the drink. And in fact, very much, I think, not the case. You know, we spend a lot of time working, we actually have, you know, dedicated, you know, experts on pricing in our firm, we spend a lot of time with our companies working on pricing, because it's, you know, it's really this magical art and science that a lot of companies don't take don't take seriously enough. So we spend a lot of time with our companies on this. And of course, you know, a core principle of pricing is you don't want to price by cost. If you can avoid it, you want to price by value, right? Like you want to price, you have price where you're getting a percentage of the business value of, you know, especially when you're selling to businesses, you want to price as a percentage of the business value that you're getting. And so, so you do have some AI startups that are that are pricing by the drink for certain things that they're doing, but you have many others that are exploring other pricing models. You know, some that are just like replications of SaaS pricing models, but you also have other companies that are exploring pricing models, for example, of, well, if the AI can actually do the job of a coder, or the AI could do the job of a doctor or a nurse or a radiologist or a lawyer or a paralegal, right, or whatever, or a teacher, you know, basically, can you price by value and can you get a percentage of the value of what otherwise would have been literally a person? You know, or by the way, equivalently, can you price by marginal productivity? So if you can take a human doctor and make them much more productive because you give them AI, you know, can you price as a percentage of kind of the productivity uplift, you know, from the symbiotic relationship between the human being and the AI? And so, I think what we see in startup land is like a lot of experimentation happening on these pricing models. And I think, again, I think that's like super healthy. You know, I was in this little speech on this, it's like high prices are really underappreciated. High prices are often a favor to the customer. It's actually really funny. A lot of like the naive view on pricing is the lower the price, the better is for the customer. The more sophisticated way of looking at it is higher prices are often good for the customer because a higher price means that the vendor can make the product better, faster, right? Like you can actually, companies with higher prices, higher margins can actually invest more in R&D and they can actually make the product better. And, you know, most people who buy things aren't just looking for the cheapest price. They want something that's really, that's going to work really well. And so often high prices, you know, the customer doesn't ever say this. It'll never show up in a survey. But the high price can actually be a gift to the customer because it can make the vendor better, can make the product better and ultimately make the customer better off. And so I'm very encouraged by the degree to which the AI entrepreneurs are willing to run these experiments. And I, you know, we'll have to see where it pans out. But at least so far, I feel, I feel good about the, the, you know, at least the attitude in the industry about it. Awesome. I actually, as you were going through it, I had probably 10 more follow-up questions, but I'm actually going to go back to a topic you had briefly, the trillion dollar questions, will open source or closed source win? Feels like we've come out on this, this debate or where do you, where do you put that? No, I think this is still open. I think this is still open. Yeah. It's still very open. You know, like the, the, the closed source models keep getting better. By the way, if you, generally, if you just like take the temperature of the people working at the big labs who work on the big proprietary models, like generally what they'll tell you is progress is continuing at a very rapid pace. You know, there's, there's this, you know, there's this periodic concern that kind of shows up on online, which is, or in the, in the market, which is like, you know, maybe the capabilities, these models are topping out. And, you know, there's certain, there's, there's certain areas in which, you know, there's, there's, you know, people are working, but like the people working at the big labs are like, oh no, we have like 800 new ideas. Like we have tons of new ideas. We have tons of new ways of doing things. We, we might need to find new ways to scale, but like, we, we have a lot of ideas on how to do that. We know a lot of ways to make these things better. And, you know, we're basically making new discoveries all the time. So like I would say, you know, generally the people working at, like across all the big labs are, are pretty optimistic. And so like, I, I think the big models are going to continue to get better, you know, very quickly here and then, you know, overall and then the open source models continue to get better. And like I said, you know, you know, every, every, every, I don't know, every month or something, there's like another big release of like something like this, give me thing, where it's just like, wow, like, you know, that's amazing. And, you know, wow, they really like shrunk that down and got that capability on a very small form factor. And so, yeah, that's the case. And then, you know, maybe just the third kind of thing to bring up is the other really nice benefit of open source is that open source is the thing that's easy to learn from. Right. And so if you're a, you know, computer science, if you're a computer science professor who wants to teach a class on, on CS, on AI, or if you're a computer science student that's trying to learn about it, or if you're just like a normal engineer in a normal company trying to learn this new thing, or just somebody in your, you know, by the way, somebody in your basement at night with a startup idea, you know, the existence of these, of these state-of-the-art open source models is amazing, because that's the education that you need. Like they actually, these open source models actually show you how to do everything. Right. And so like, and what that's leading to, right, is the proliferation of the knowledge about how to build AI is like expanding very fast. Again, as compared to a counterfactual world in which it was all basically bottled up in two or three big companies. And so, you know, the open source thing is also just proliferating knowledge. And then that knowledge is generating a lot of new people. And so I, you know, you know, say, as you guys have all seen sitting here today, AI researchers are at an enormous premium. You know, AI researchers today are getting paid more than professional athletes. Right. Like, you know, and that's right. That's the supply demand imbalance. There aren't enough of them to go around. But, you know, again, shortages create gluts. The number of smart people in the world who are coming up to speed very quickly on how to build these things. I mean, some of the best AI people in the world are like 22, 23, 24. Like, you know, kind of by definition, they haven't been in the field that long. You know, they can't have been experts their whole lives. Right. So, you know, they kind of have to have come up to speed over the course of the last four or five years. And if they've been able to do that, then there's going to be a lot more in the future that are going to do that. And so just the sort of spread of the level of expertise on this technology is happening now very quickly. So, yeah, I mean, I think it's still, like I said, I think it's still a race. And by the way, you know, look, the long-term answer may well just be both. You know, like I said, if you believe my pyramid industry structure, then there will certainly be a large business of whatever is the smartest thing, almost regardless of how much it costs. But there will also be this just giant volume market of smaller models everywhere, which is what we're also seeing. Yep. Yep. Another question you had posed at that point in time was, will incumbents versus startups win? And at that point in time, I think there was a mixed bag of where the incumbents were approaching AI. I think that's radically changed in the last two years. And then on the counter example, the blossoming of startups increasingly now may be migrating into the incumbent category, just how big they've become since that time. You want to take that question and give your assessment of where the state of the world is? Yeah. So, I mean, look, you know, big companies that are definitely, you know, playing hard, you know, Google's playing hard, Meta's playing hard, Amazon, Microsoft, you know, there's a bunch of these companies that are, you know, that are kind of in there, you know, very aggressively. And then you've got these, you know, what we call the new incumbents like Anthropic and OpenAI. But you also have like, you know, even in the last two years, you've had this birth of all of a sudden, like brand new companies that are almost instant incumbents. And you could say XAI is one of those. Mistral, by the way, Mistral is the great outlier to my Europe thing from earlier, like Mistral is actually doing very well, Mistral is sort of the European kind of, you know, French national European continental, you know, kind of AI champion. Sort of the, you know, the exception that proves the rule. But, you know, there's a bunch of these now that are like, you know, doing quite well and are kind of becoming new incumbents. And then of course, there's tons of startups, by the way, there's and then there's there's actual foundation model startups, right. And so, you know, we funded, you know, we funded Ilya Suskiver out of OpenAI to do a new foundation model company. We funded Mira Mirati also out of OpenAI. We funded Fei-Fei Li out of Stanford to do a world model foundation model company. And so, you know, there, you know, there are new swings all, you know, all early, but very promising for to kind of build, you know, new incumbents quickly. And so, you know, that's all happening. And then, and then, you know, and then on top of that, there's just this giant explosion of AI application companies, right. And so there's basically companies that then usually startups that basically take the technology and then, you know, field it in a specific domain, whether that's law or medicine or education or, you know, creativity or whatever. But again, here, it's just like, it's amazing kind of how, how sophisticated things are getting very quickly. So, I'll just talk about the application companies for a moment. So like an application company, like classic examples, like a cursor is like an application company. So they take the core AI capability, which they purchased by the drink from, you know, Anthropic or OpenAI or Google, you know, tokens by the drink. And then they, they, they build a code, basically a code editor, what we used to call an IDE integrated development environment, or basically like a software creation system. So they build like an AI coding system on top of the Anthropic or OpenAI or whatever, you know, kind of, kind of big models. So until then, and the, the, the critique of those companies in the industry has been, oh, those are what are called, called GPT wrappers. It's kind of the pejorative. And the idea basically being as well, they're not actually like, they're not actually doing anything that's going to preserve value because the, the actual, the, the whole point of what they're doing is they're surfacing AI, but it's not their AI, the AI that's being surfaced is from somebody else. And so these are kind of these paths, pass through shell things that ultimately won't have value. It actually turns out what's happening is kind of the opposite of that, which is the, the leading AI application companies like cursor. I mean, first of all, what they're discovering is they're not just using a single AI model. They're actually, they actually, as these products get more sophisticated, they actually end up using many different kinds of models that are kind of custom tailored to the specific aspects of how these products work. And so they may start out using one model, but they end up using a dozen models. And then in the fullness of time, it might be 50 or 100 different models for different aspects of the product, A, and then B, they end up building a lot of their own models. And so they, they, a lot of these, the leading edge application companies are actually backward integrating and actually building their own AI models because, because they have the deepest understanding of their domain. They're able to build the model that's best suited to that. And then by the way, also AI open source, they're also able to pick up and run on open source models. And so if they don't like the economics of buying intelligence, you know, by the drink from a, from a, from a cloud service provider, you know, they can pick up one of these open source models and implement it instead, which, you know, which these companies are also doing. And so the, the best, the best of the AI application companies are actually, they are actually full-fledged deep technology companies actually building their own AI. And so that, you know, that's, I think... All models though, right, Mark? When you think about God models versus small models, as you were describing that, but that would be small. Would you categorize that as a small? Well, some of them, I mean, we should, I will let them, I will let them announce, you know, whatever they're doing, whenever it's appropriate, but some of them are now also doing big model development. And again, this, this is also part of what, this is also part of learning just the last two years. Well, so like, here's a big learning just from the last two years, which is very interesting, which is two years ago or three years ago, for sure, you would have said, wow, open AI is like way out ahead. And like, it's probably going to be impossible for anybody to catch up. And then it's like, okay, well, Anthropic caught up. And so, but you know, they came out of open AI. And so they had all the secrets, you know, whatever. And so knew how to do it. And so, okay, they caught up, but surely nobody can catch up after them. And then very quickly after that, there were a raft of other companies that caught up very fast. And, and XAI is maybe the best example of that, which is like, you know, XAI, you know, Elon's company, XAI is the company name, Grok is the consumer product version of it. XAI basically caught up to, you know, state of the art open AI Anthropic level in, in like less than 12 months from a standing start. Right. And so, and again, that, that kind of argues against any kind of permanent lead, right. By, by any one incumbent, that's just going to basically be able to lock the entire market down. Like if you can catch up like that. And then, and then as we, as we discussed the, you know, the, the China part is all new in the last year, right. The deep seek, this, the deep seek moment, I think was in January or February of this year. Right. So less than 12 months ago. And so, and now you've got like four Chinese companies that have effectively caught up. And so, you know, so it's like, all right. I mean, you know, again, this is, these are, these are trillion dollar questions, not answers, but it's just like, wow. Okay. Like it's, it's one of these things where once somebody proves that it's capable, it seems to not be that hard for other people to be able to catch up even people with far less resources. And so, you know, I don't know what that does. Maybe it makes you slightly more skeptical in the long run economics of, of the big players. On the other hand, maybe it makes you like more bullish about the startup ecosystem. It certainly should make you more bullish about startup application companies, right. Being able to do interesting things, which is why we're so excited about that. You know, it should make you probably, you know, a bit more excited about, about certainly about China. Yeah. On the other hand, the Chinese competition, putting pressure on the American system to not screw itself up is very positive. So it should probably make you a little bit more bullish on the U.S. And so I, yeah, I think, you know, these are, yeah, these are, yeah, these are our live dynamics. And I think we still need more time to pass before we know the exact answer. I should say this sometimes, cause sometimes I don't, sometimes I freak people out when I say these are open questions. When a company is confronted with fundamentally open strategic or economic questions, it's often a big problem because a company needs to have a strategy and the strategy needs to be very specific. And a company has to make like very specific concrete choices about where it like deploys investment dollars and personnel. And like the strategy has to be like logical and coherent or the company kind of collapses into chaos. And so like companies like need to answer these questions and if they get the answers wrong, they're really in trouble. Venture, we have our issues in venture, but a huge advantage that we have is we don't have to, we can bet on multiple strategies at the same time. Right. And we are doing this. So we are betting on big models and small models and proprietary models and open source models, right. And, you know, and foundation models and applications, right. And consumer and enterprise. And so the portfolio approach, the nature of it is like we we are aggressively basically we are aggressively investing behind every strategy that we've identified that we think has a plausible chance of working, even when that those even when that's contradictory to another strategy that we're investing in. And one is just like the world's messy and probably a bunch of things are going to work. And so like there's not going to be clean yes or no answers to a bunch of this. Like a lot of the answers to this, I think are just going to be and answers. But the other is like if one of these strategies doesn't work, like, you know, we're not we're not trying to hedge per se, but, you know, we're going to have representation in the portfolio of the alternate strategy. And so we're going to have multiple ways to win. So anyway, that's that's the goal. That's the theory of why we are, you know, kind of taking the approach in the space that we're taking. And that's why I have a big smile on my face when I say that there are these big open questions because I think that actually works to our advantage. It's a good segue to A16Z questions because we've gotten a few in so far and we have a few that were send ins ahead as well. So I'll start one with the with the broad topic. What is something you and Ben disagree and commit on? Ben Bauer, Ph.D.: Disagree and commit. You know, we agree. I mean, we, as Ben and I was going to say, you know, we're an old married couple, so we argue constantly, but we've been... We're the romance of dead. Ben Bauer, Ph.D.: The romance of long dead. Yes, yes, yes, yes. The fire has long since gone out. Ben Bauer, Ph.D.: But yes, yes, we're in the park squabbling all the time. So, yeah, I mean, so look, we debate everything. We argue about everything. That said, like, you know, one of the things that's made our partnership work is like we do tend to come to the same conclusion. Like each of us is open to being persuaded by the other one. And so we end up coming, you know, we end up coming to the same conclusion most of the time. So I would say there aren't like, there aren't, I was going to say, specifically sitting here today, there are like zero issues where I'm sitting here and I'm like, I can't believe, you know, I just, I can't believe I'm, you know, I'm putting up with this crazy thing on his, on his part that he's doing that I really disagree with, but I feel like I have to commit to, or I don't think vice versa. And so, so we don't have any of those. You know, quite honestly, the biggest thing I say, the biggest thing that I, that he and I, the biggest thing that he and I discuss is this, by the way, this is not, this is not the most important thing we're doing, but it is a topic since somebody asked the question. The biggest thing he and I discuss where I, I don't know, maybe I'm always like second guessing myself, or I never quite know where I should come out on it, that he and I talked about a lot is just like basically the public footprint of the company. So like our presence, our presence in the, our presence in the world in terms of like public statements, controversy, you know, how we vocalize and express our views on things. And I would just say there like, you know, there's a real, there's a tension, there's a real, it's, you know, maybe obvious, but like a very important tension. Like generally speaking, the more out there we are, and the more outspoken we are, and the more controversial we are, the better for the, better for the business in the sense of the entrepreneurs love it. The founders want to work with, it was very clear at this point, the founders want to work with people who basically are brave and controversial and take controversial stands and articulate things clearly. And they want that for a bunch of reasons. One is because it's a demonstration of courage, which they appreciate. But the other is because it, it teaches them who we are before they even meet us. And, and, and that has just proven to be just like this incredible competitive advantage. You know, long term LPs will know, like, this is why we started with a very active marketing strategy from the very beginning. And like, it completely worked. Like the whole thing was, if we're able to broadcast our message, and we're able to basically be very clear in what we believe, even to the point where it's controversial, like, the best founders in the world are going to understand us before they even walk in the door. Right? And they're going to, they're going to know us even before they've met us, as opposed to everybody else in venture, at least at the time, that was basically just like keeping everything quiet, where they, you know, the founder just has no idea who these people are and what they believe. And so that, that like worked incredibly well, it continues to work incredibly well. It's, by the way, it's, you know, it's generally true across the industry. It's, it's, it's like generally the case. On the other hand, there are externalities to being, you know, publicly visible and, and, and, and to being controversial on many fronts. We are, I would say this, we are, we're very much, we're trying very hard to thread this needle. So like, we're, we're not backing off of generally being a company that does a lot of outbound. We, you know, we, Eric Tornberg and the team that he's built, you know, that we've talked to you guys about in the past, you know, is, I, is already off to the races. You know, we're, we're gonna, you know, we're tripling down on the idea of basically being the leaders and articulating the tech and business issues that matter. You know, the, you know, the issues for sure that people need to be able to understand. And that's proven to be very effective. By the way, a fair amount of our cons are actually aimed at Washington. Because again, it's like, if you're a policymaker in Washington, and you're sitting there 3000, 3000 miles away, and your entire information source is like East Coast newspapers that hate Silicon Valley, like that's bad. And so, you know, our ability to like broadcast, you know, inform points of view on technology, we just, we meet people in DC all the time, who say, yeah, I, you know, most of what I know about this topic, I learned from you guys, because I listened to the podcast, I read the articles, I watched the YouTube channel. And so, you know, we're, we're going to continue to do that. And so we, you know, over, over, over, overall, we have a, you know, we're, we're kind of on our front foot on that stuff. But yeah, he and I do, he and I do go back and forth a bit on exactly how, yeah, how many third rail topics should we touch? And how frequently, and I would say, we're, we're, we're trying to, we're trying to moderate that. As Elizabeth Taylor said, as long as I spell our name right, it's oftentimes could be good in most scenarios, particularly when it comes to little tech, WS. And also, I think embedded in that question is probably some degree of the relationship that you and Ben have, which is now going on 30 plus years at this point. So much so that, that Mark has become one person representing both. Some people refer to Mark as Andreessen Horowitz. No, lost the mark, have combined just into one person. Yes. That's the result of 30 plus years working together. Okay. So it's been two years since you've reorganized around AI, launched AD. What do you think you got most right? And in hindsight, is there anything that you underestimated or missed in that decisioning process? No, I mean, look, we've made, we've made plenty of mistakes. I think those were, I think those were the right calls. I mean, AI was, like I said, like, you know, the whole theory, back up, the whole theory of venture, the whole theory of venture that we've had from the beginning is, that, you know, many people before us have had as well. That's very correct. I think is, both theories like the money adventure has made when there's like a fundamental architecture shift, like when there's like a fundamental change in the technology landscape. And that's been true for, you know, adventure basically forever. And the reason is because if you have a fundamental change in technology, then you have this period of creativity in which you can have basically aggressive, you know, very aggressive kind of people, you know, kind of start these new companies and they have this kind of shot to kind of come in and you kind of win categories before big companies can respond. If there's no fundamental change in technology, it's very hard to make startups work because the big companies just end up doing everything. And so venture kind of, you know, sort of lives or dies on the basis of these waves, of these transitions. And so there's always this question. I mean, I would just say the best venture capital firms in history, I think, are the ones that were the most aggressive at being able to navigate from wave to wave, right? And look, I was a beneficiary of this when I came to Silicon Valley in 1994. You know, there was no venture firm in 1994 that was like the internet venture capital firm, like it just didn't exist. But there were a set of venture capital firms at the time, you know, at the time, our firm Kleiner Perkins that said, oh, this is a new architecture, this is a new technology change. It seems totally crazy. Everybody says you can't make money on it, whatever, whatever, these kids are nuts, but like, we're going to make those bets. And so they were willing to invest. And by the way, you know, KP in the 90s invested not only in us, but also in Amazon and then Google and like, you know, company after company after company. They invested in at home, which basically made home broadband work. You know, they invested in a fleet of companies. And they were a venture capital firm that had started in the 1970s, around really around what was at the time called mini computers, which was like, you know, three generations of technology back. And they had navigated from wave to wave. And, you know, the same thing is true for Sequoia. The same thing's true for basically any successful venture firm has been a business for, you know, 30 or 40 or 50 years. And so I think in this business, like of all businesses, like you just you need you need to get onto the new thing. You know, it was, I mean, quite honestly, it was, I think, pretty amazing that most of the venture ecosystem just decided to sit crypto out. And the number of VCs that we talked to between call it, you know, the release of the Bitcoin white paper in 2009 to the beginning of the crypto war in 2021, who just basically said, oh, we're not going to do crypto. It was fairly, it's like, I don't know, I never quite know what to do with a VC who says, oh, there's a new wave of technology, and I'm very deliberately not going to participate in it. And I'm always like, like, is that not the job? Right? Like, so, so, so, like, I was fairly amazed by the VCs that didn't make the jump to crypto. You know, they looked briefly smart during the crypto wars, I would say, of the last, you know, three or four years. And I think they probably look maybe a little bit less smart now. You know, AI is another one of these where there are certain firms that are jumping all over it. And there are certain firms that are just kind of sitting back and letting it happen. And, and by the way, there were certain firms that never made it to the internet. I mean, there were, there were firms that were very well known in the 80s, and very successful that just like did not make the jump to the internet, and basically just petered out. And so anyway, long winded way of saying, I think, I think in this business of all businesses, you have to jump, you have to jump on the new wave. And I think we got the magnitude of it, of it, right, that this is like a fundamental, fundamental transformation inside the firm. You know, AD is, you know, AD is doing great. AD itself, I believe, is also a beneficiary of AI, right, because in two ways, one is a lot of the kinds of products that AD companies build themselves benefit from AI. And then also, AI is a driver of demand in other sectors of AD, like, like energy and materials. And so, I, you know, I think that that generally is very consistent, and, you know, is working well. By the way, you know, crypto is back, back to being a, you know, I would say, an exciting industry as a consequence of all the policy changes. And then, and then there's even going to be, I think, intersections, I think there's actually going to be quite a few intersections between AI and crypto. And then, and then, you know, biotech also, bio and healthcare, I think, are obviously going to be transformed by AI, both on the healthcare side and on the actual drug discovery side. And, you know, and that's underway. And so anyway, so like the, the individual efforts in the firm feel good, and suitable for the time, the inner, the interactions between the teams, and the kind, the hybrid ideas, you know, the companies that are coming at these things from multiple angles, you know, feels really good. You know, maybe the corollary question is like, you know, what do we feel like we're missing right now? And I think the answer is really not, like, I don't, I don't think like right now, we're not missing a vertical. Like, I don't, like, as of right now, like, there's not like a specific vertical of like, I don't know, whatever that, like, where we just like, oh, we just need, you know, we need the equivalent of a new, of a new unit or the equivalent of a new, you know, new fund or whatever. I don't, I don't see that at the moment. I think it's more executing extremely well in the verticals that we have in front of us. And, and then, you know, being the best possible partner to the, to the portfolio companies. Yeah, actually, on the point of AD, because AI is creating, and there's a lot of talk around AI taking jobs, et cetera, ironically enough, the jobs in AD sectors have never been more in demand in the physical world related to energy, related, obviously, to data center build-out, et cetera. So like the, the pendulum, it seems like also is, is swinging from just an accelerant standpoint from, from a society point of view. You talked about the importance of society also needing to be ready for tech adoption. Like, have you seen that accelerating of recently? What's your sentiment of, of how to actually increase that just to also make sure the convergence of adoption also falls in line with, with how quickly tech is, is actually being implemented? Yeah. So, you know, look, we've talked about this before, but, um, you know, for a very long time, tech was just not a very relevant, look, if you go back over like whatever, 300 years, like there's just like recurring waves of like total panic and freak out caused by new technology, or even you go back 500 years, you go back to the printing press, you know, which basically was hand in hand with the, the sort of creation of product, Protestantism, which really changed things. Um, and then, um, you know, you go, you go back to, um, you know, there, there were just always kind of, you know, continuous panics there, you know, there have been, there have been multiple waves of automation panics for the last 200 years. You know, a lot of the foundational panic under Marxism was basically a fear of, of, of, of, of, of the elimination of jobs through the application of automation. Um, uh, you know, a lot of the same arguments you heard today about like, AI is going to centralize all the wealth and a handful of a few people and everybody else is going to be poor and immiserated like that. That basically is what Marx used to say, um, which I think was by the way wrong then and is wrong now, which we could talk about, but, um, you know, and then even like in the 1960s, there was this whole panic around, around AI, um, uh, replacing all the jobs. There was this, there's this great, uh, it's long, long forgotten, but it was a big deal at the time during the Johnson administration. You read these AI pause letters today, you know, the, this one that just came out a few weeks ago, that Prince Harry, uh, uh, headlined of all people. Um, and, um, uh, uh, you know, he takes about AI is going to ruin everything. And it's like, and then it says that 1964, there was basically a group of like the leading lights in academia, science and, uh, you know, um, kind of public affairs that there was this thing called the triple committee, uh, the committee for the triple revolution. If you do a Google search on, uh, it's like committee for the triple revolution, Johnson white house or whatever, you'll, you'll, this thing will pop up. Um, and, you know, it was, it was a very similar kind of manifesto of like, we need to stop the march of technology today or we're going to ruin everything. Um, and, and then, you know, even in the course of the last 20 years, there was like a big, panic around, um, uh, actually outsourcing in the two thousands was going to take all the jobs. And then it was actually, it was actually robots weirdly enough in the 2010s, which is amazing because robots didn't even work in the 2010s and they kind of, you know, still don't. Um, but, uh, you know, there's a panic around that and now there's kind of whatever level of AI panic. Um, and so like, you know, like I would just say like, look, the, you know, the way I would describe it is, you know, we in Silicon Valley have always wanted the work that we do to matter. Um, you know, we spend most of our time quite honestly with people telling us that everything that we're doing is stupid and won't work. Um, like that's the default position. Um, you know, and then basically that flips at some point into panic about how it's going to ruin everything. Um, you know, it's, it's easy sitting out here to be cynical about that. Um, especially when you kind of see the patterns over time, I, you know, my view is we need to be actually very respectful of that and we need to be very aware of that. And, and basically that we, you know, I use the metaphor where the doctor caught the bus, like we always wanted to work on things that matter. We are working on things that matter. Uh, people in the rest of society actually really do care about these things. Um, and, you know, it's our responsibility to think that all through very carefully and to do a good job, um, you know, both not just building the technology, but also explaining it. You know, look, I, you know, I think we have a real obligation to, uh, you know, to really explain ourselves and engage on these issues. Um, in terms of how to measure how it's going, you know, it's, it's sort of the classic social science question, um, uh, which is like, okay, if you want to understand basically, you know, patterns of people, there's basically two ways to understand what people are doing and thinking. Um, one is to ask them and then, and then the other is to watch them. Um, and like every social, every social scientist, like every sociologist will, will, will, will, will tell you this, which basically is you can, you can ask people, right. And, and the way you do that, right. And it's like, you know, surveys, focus groups, polls, um, you know, what they think. Um, uh, but then, but then you can watch them and you can do what's, you know, called reveal preferences or just observe behavior, because you can actually watch their behavior. And, and what you often see in many areas of human activity, including politics and many different aspects of society and culture over time is the answers that you get when you ask people are very different than the answers that you get when you watch them. Um, and, and the reason is because like, I mean, you could have a bunch of theories as to why this is the Marxists claim that people have false consciousness. The, the, the, the somewhat, the explanation I believe is just people have opinions on all kinds of things, particularly when they're in a context where they get to express themselves. Um, and they'll have a tendency to kind of express themselves in very heated ways. And then if you just watch their behavior, they're often a lot calmer, um, and a lot more measured and a lot more rational in what they do. And so the AI that's playing out on AI right now, which is if you pull, if you run a survey or a poll of what, for example, American voters think about AI, it's just like, they're all in a total panic. It's like, oh my God, this is terrible. This is awful. It's going to kill all the jobs, going to ruin everything. The whole thing. If you watch the revealed preferences, they're all using AI. So they're like, they're downloading the apps. They're using ChatGPT in their job. They're, you know, having an argument. You see this online all the time now. I'm having an argument with my boyfriend or girlfriend. I don't understand what's happening. I take the text exchange. I cut and paste it into ChatGPT and I have ChatGPT explain to me what my partner is thinking and tell me how I should answer. So that he's, you know, he or she is not mad at me anymore. Right? So, or like, you know, I have this thing, you know, I have a skin condition and doctors, you know, and I take a photo and I'm finally like learning about my own health or I use it in my job. Like I, you know, I had to get this report ready for Monday morning and I ran out of time and like, you know, ChatGPT really saved my bacon. And so people in their daily lives are, I would, you know, just, you just look at the, just look at the data. It's just like, they are not only using this technology, they love this technology and they love it and they're adopting as fast as they possibly can. And so I, I tend to think we're going to pick with the public discussion. This is going to ping pong back and forth for a while, because there is this divergence between what people are saying, what people are doing. But, but I do think that the, what people are doing part is, is obviously the part, the part ultimately that wins. And, and I think this, by the way, I think this technology is going to be exactly the same as every other one, which is the thing that's going to happen here is this is just going to proliferate really broadly. It's going to freak everybody out. And then, you know, 20 years from now, everybody's going to be like, oh, thank God, we've got it. Like, wouldn't life be miserable if we didn't have this? And, or, you know, five years from now or one year from now, you know, people are going to reach that conclusion. So I'm, I'm very optimistic about where this lands. It's just that, you know, there will be turbulence along the way. I'm, I'm smiling because I also witnessed that in the wild. Literally late last week, I was on the plane. The guy next to me was talking to his chat to me. I could see him and he was like, help me draft an escalation letter to United for the delay on this flight. I was like, sir, you are on the flight right now. Like, at least wait until it's over. It was very good though. I'm sure he had a great email crafted as a, as a part of that. So, okay. I'm going to switch gears to a few fun questions that, that were sent in, that is intended to be a lightning round. So, so what, what is something you've changed your mind on recently? Bonus points. If it was someone younger than you. I mean, it's like every day. It's just like, it's just a constant, you know, it's, it's almost all like what's in the realm of the possible. I, I'm, I'm terrible at specific examples. So I don't, I don't have one like ready at hand, but like, like I said, it's just, it's, it's always. Yeah, no, it's, it's often somebody showing up. It's either something somebody writes or something somebody says. And yeah, it's almost all, yeah, it's very frequently somebody who's very young. And yeah, it's just like, I would say it's, it's a, it's a routine experience. Good way to stay young. Awesome. Do you plan, speaking of young, do you plan to be cryogenically frozen? Not with current, not with current cryogenic technology. The, the, the, the track record of that is not great. And the stories are somewhat horrifying, but you know, we'll see. We'll see. We still got some time. Sure. How do you stay grounded when your influence itself may distort reality around you? Yeah. So I was just saying the good news, you know, I would say the good news on several. I mean, so one is look, the concern is real. And it's hard for me to start for me to talk about with sort of my Midwestern, you know, kind of, you know, Midwesterns, we, we either are very humble or we, we're really good at faking it. But, you know, it's hard to talk about, but requires some introspection. But yeah, I mean, look, the reality warping effect is definitely real. By the way, there is a very big advantage to the reality warping effect, which is being able to get people to do what you want them to do. So that, you know, there is, there is another side to it. But it, you know, it is a concern in terms of like having an actual accurate understanding of what's happening. I guess I'd say two things. I would say one is, you know, I mean, one is just, you know, my partners, I think are quite, you know, including Ben, are quite forthright in telling me when I'm wrong. But, you know, more generally, like, we're just, we're, we are very exposed to reality. And so, and this, and again, you know, you mentioned, I don't know, it's a way to stay young or make sure their hair never grows back or whatever. It's just like, you know, we run these experiments, you know, because we make these decisions about whether to invest or not invest, and we work with these companies and all their things. And like, you know, reality kicks in quickly. You know, the delusions don't last very long in this business, because like, you know, these, these things either work or they don't. And, you know, you have these like long, elaborate, you know, discussions about, you know, theories on this and that and the other thing. And then reality just like completely smacks you square in the face, you know, like you idiot, right? You know, like, you know, what were you, you like, you know, this is like the, you know, the ultimate frustration of business, which is also very motivating, which is the number of times that you think that you've applied superior analysis, and then you've either invested or not invested based on that analysis. And it turns out it was just your analysis was just completely wrong. Right. And, you know, you just like completely overrated your ability to epistemically, you know, kind of analyze these things, you just, you know, basically inflicted harm. Like, I always, you know, question is always, you know, it's sort of, you know, any activity that we do, is it value add or is it actually value subtract? Right. And I think in this business of all businesses, it's kind of like that. And that applies to all of my own contributions as well. So, so there is that. And then, and then I would say, you know, maybe the final thing is just like, I do have the entire internet ready to tell me that I'm an idiot. So that also doesn't hurt. And it does on a regular basis. Amy Quinton, Ph.D.: On the point of your alluding to earlier about decisions on investing in companies, my favorite line, I think it was from the Cheeky Pint interview that you did, was, you know, when you invest in a company, it doesn't go well, at least it goes bankrupt. Right? If it does, if it does well, and it does fantastically well, you hear about it every single fucking day. For the rest of your life. Yeah. For the next, for the next 30 years. Reality smacking you in the face saying, you fool. You had it. It's literally, it's literally, you had it in your office. All you had to do is say yes. And by the way, and this is the thing, like every great VC, like if you, this is, this is the stories that, you know, the VCs tell each other. Every great VC basically has this history of like, my God, I had, it was in my office. The thing was in my office and I said no. And if I had just said yes. And so it's, yeah, it's very hard to, yes, the constant reminders in the Wall Street Journal and on CNBC every day that you made a giant mistake. Yes. Very good. Very good for the, for the old humility factor. Yeah. Very humbling. Helps you stay grounded all the time. Last question. Do you plan to go to Mars if, and when that opportunity presents itself? Probably not. I think I might. Mike's subliminal Zoom background wasn't sending you the positive vibes. This is what it could. Well, I'm not even willing to leave California. I'm barely willing to leave my house. So yeah, maybe by, maybe by VR. Yeah. And then we'll see what happens. I mean, look, having said that, I think Elon's going to pull it off. And so I think, you know, I don't know. I don't know, you know, I don't want to predict, this is not a prediction, but I, you know, I would not be surprised if within a decade there's routine trips back and forth. Um, so, uh, yeah, we may, uh, this, this may actually become a practical question. And, and by the way, I do know a lot of people who are probably going to go. Myself included. Put me on that trip. Oh, fantastic. The flights around the world have prepared me for the six month journey to Mars. So I will be just fine. Okay.",
  "segments": [
    {
      "id": 0,
      "start": 0.0,
      "end": 4.72,
      "text": "This new wave of AI companies is growing revenue, like just like actual customer revenue, actual"
    },
    {
      "id": 1,
      "start": 4.72,
      "end": 9.28,
      "text": "demand translated through to dollars showing up in bank accounts at like an absolutely unprecedented"
    },
    {
      "id": 2,
      "start": 9.28,
      "end": 13.76,
      "text": "takeoff rate. We're seeing companies grow much faster. I'm very skeptical that the form and"
    },
    {
      "id": 3,
      "start": 13.76,
      "end": 16.56,
      "text": "shape of the products that people are using today is what they're going to be using in five or 10"
    },
    {
      "id": 4,
      "start": 16.56,
      "end": 19.92,
      "text": "years. I think things are going to get much more sophisticated from here. And so I think we probably"
    },
    {
      "id": 5,
      "start": 19.92,
      "end": 24.0,
      "text": "have a long way to go. These are trillion dollar questions, not answers. But once somebody proves"
    },
    {
      "id": 6,
      "start": 24.0,
      "end": 28.240000000000002,
      "text": "that it's capable, it seems to not be that hard for other people to be able to catch up, even"
    },
    {
      "id": 7,
      "start": 28.24,
      "end": 33.199999999999996,
      "text": "people with far less resources. When a company is confronted with fundamentally open strategic or"
    },
    {
      "id": 8,
      "start": 33.199999999999996,
      "end": 37.839999999999996,
      "text": "economic questions, it's often a big problem. Companies like need to answer these questions."
    },
    {
      "id": 9,
      "start": 37.839999999999996,
      "end": 41.599999999999994,
      "text": "And if they get the answers wrong, they're really in trouble. In venture, we can bet on multiple"
    },
    {
      "id": 10,
      "start": 41.599999999999994,
      "end": 45.599999999999994,
      "text": "strategies at the same time. We are aggressively investing behind every strategy that we've"
    },
    {
      "id": 11,
      "start": 45.599999999999994,
      "end": 49.2,
      "text": "identified that we think has a plausible chance of working. If you want to understand people,"
    },
    {
      "id": 12,
      "start": 49.2,
      "end": 53.36,
      "text": "there's basically two ways to understand what people are doing and thinking. One is to ask them,"
    },
    {
      "id": 13,
      "start": 53.36,
      "end": 57.36,
      "text": "and then the other is to watch them. And what you often see in many areas of human activity,"
    },
    {
      "id": 14,
      "start": 57.36,
      "end": 61.6,
      "text": "including politics and many different aspects of society, the answers that you get when you ask"
    },
    {
      "id": 15,
      "start": 61.6,
      "end": 65.28,
      "text": "people are very different than the answers that you get when you watch them. If you run a survey or a"
    },
    {
      "id": 16,
      "start": 65.28,
      "end": 70.0,
      "text": "poll of what, for example, American voters think about AI, it's just like they're all in a total panic."
    },
    {
      "id": 17,
      "start": 70.0,
      "end": 72.64,
      "text": "It's like, oh my God, this is terrible. This is awful. It's going to kill all the jobs,"
    },
    {
      "id": 18,
      "start": 72.64,
      "end": 76.32,
      "text": "going to ruin everything. If you watch the revealed preferences, they're all using AI."
    },
    {
      "id": 19,
      "start": 82.16,
      "end": 86.24,
      "text": "A lot of folks have sent questions ahead of time. And what I've done is kind of curated into a few"
    },
    {
      "id": 20,
      "start": 86.24,
      "end": 92.08,
      "text": "different sections in an AMA this morning with Mark. So what we thought we'd do is cover four"
    },
    {
      "id": 21,
      "start": 92.08,
      "end": 97.03999999999999,
      "text": "big topics. So AI and what's happening in the markets, policy and regulation, all things A,"
    },
    {
      "id": 22,
      "start": 97.03999999999999,
      "end": 102.63999999999999,
      "text": "16, and Z. And then we've got a fun catch-all, which we're calling sandbox of things if we get to it."
    },
    {
      "id": 23,
      "start": 102.63999999999999,
      "end": 107.44,
      "text": "So starting first, maybe with the biggest question. We're sitting in the middle of the AI revolution,"
    },
    {
      "id": 24,
      "start": 107.44,
      "end": 110.47999999999999,
      "text": "Mark. What inning do you think we're in and what are you most excited about?"
    },
    {
      "id": 25,
      "start": 110.48,
      "end": 114.64,
      "text": "Mark Benthien, Ph.D.: First of all, I would say this is the biggest technological revolution of my life."
    },
    {
      "id": 26,
      "start": 115.52000000000001,
      "end": 120.48,
      "text": "And hopefully I'll see more like this in the next whatever, 30 years. But I mean, this is the big"
    },
    {
      "id": 27,
      "start": 120.48,
      "end": 126.88,
      "text": "one. And just in terms of order of magnitude, this is clearly bigger than the internet. The comps on"
    },
    {
      "id": 28,
      "start": 126.88,
      "end": 132.48000000000002,
      "text": "this are things like the microprocessor and the steam engine and electricity. So this is a really big one."
    },
    {
      "id": 29,
      "start": 132.48,
      "end": 138.88,
      "text": "Mark Benthien, Ph.D.: The wheel. The reason this is so big, I mean, may be obvious to folks at this"
    },
    {
      "id": 30,
      "start": 138.88,
      "end": 144.23999999999998,
      "text": "point, but I'll just go through it quickly. So if you kind of trace all the way back to the 1930s,"
    },
    {
      "id": 31,
      "start": 144.23999999999998,
      "end": 147.67999999999998,
      "text": "there's a great book called Rise of the Machines that kind of goes through this. If you trace all"
    },
    {
      "id": 32,
      "start": 147.67999999999998,
      "end": 151.04,
      "text": "the way back to the 1930s, there was actually a debate among the people who actually invented the"
    },
    {
      "id": 33,
      "start": 151.04,
      "end": 155.76,
      "text": "computer. And it was this sort of debate between whether computer, they kind of understood the"
    },
    {
      "id": 34,
      "start": 155.76,
      "end": 161.83999999999997,
      "text": "theory of computation before they actually built the things. And they had this big debate over whether"
    },
    {
      "id": 35,
      "start": 161.84,
      "end": 165.28,
      "text": "the computer should be basically built in the image of what at the time were called adding"
    },
    {
      "id": 36,
      "start": 165.28,
      "end": 171.28,
      "text": "machines or calculating machines. Think of sort of essentially cash registers. IBM is actually the"
    },
    {
      "id": 37,
      "start": 171.28,
      "end": 177.12,
      "text": "successor company to the National Cash Register Company of America. And that was, of course, the"
    },
    {
      "id": 38,
      "start": 177.12,
      "end": 182.16,
      "text": "path that the industry took, which was building these kind of hyper-literal mathematical machines"
    },
    {
      "id": 39,
      "start": 182.16,
      "end": 186.56,
      "text": "that could execute mathematical operations billions of times per second, but of course had no ability to"
    },
    {
      "id": 40,
      "start": 186.56,
      "end": 190.64000000000001,
      "text": "kind of deal with human beings the way humans like to be dealt with. And so couldn't understand"
    },
    {
      "id": 41,
      "start": 190.64,
      "end": 195.35999999999999,
      "text": "human speech, human language, and so forth. And that's the computer industry that got built over"
    },
    {
      "id": 42,
      "start": 195.35999999999999,
      "end": 200.0,
      "text": "the last 80 years. And that's the computer industry that's built all the wealth and financial returns"
    },
    {
      "id": 43,
      "start": 200.0,
      "end": 204.88,
      "text": "in the computer industry over the last 80 years, across all the generations of computers from mainframes"
    },
    {
      "id": 44,
      "start": 204.88,
      "end": 209.6,
      "text": "through to smartphones. But they knew at the time, they knew in the 30s, actually, they understood the"
    },
    {
      "id": 45,
      "start": 209.6,
      "end": 213.2,
      "text": "basic structure of the human brain. They understood they had a theory of sort of human cognition."
    },
    {
      "id": 46,
      "start": 214.0,
      "end": 217.83999999999997,
      "text": "And actually, they had the theory of neural networks. And so they had this theory that"
    },
    {
      "id": 47,
      "start": 217.84,
      "end": 223.68,
      "text": "there's actually the first neural network paper, academic paper was published in 1943,"
    },
    {
      "id": 48,
      "start": 223.68,
      "end": 229.28,
      "text": "you know, which was over 80 years ago, which is extremely amazing. There's an interview,"
    },
    {
      "id": 49,
      "start": 229.28,
      "end": 232.8,
      "text": "you can read an interview, or you can watch the interview on YouTube with these two authors,"
    },
    {
      "id": 50,
      "start": 232.8,
      "end": 236.4,
      "text": "McCullough and Pitts. And you can watch an interview, I think, with McCullough on YouTube"
    },
    {
      "id": 51,
      "start": 236.4,
      "end": 241.68,
      "text": "from like, I don't know, 1946 or something. He was like on TV, you know, in the ancient past. And"
    },
    {
      "id": 52,
      "start": 241.68,
      "end": 244.64000000000001,
      "text": "it's literally like, it's an amazing interview, because it's like him in his beach house, and for some"
    },
    {
      "id": 53,
      "start": 244.64,
      "end": 248.88,
      "text": "reason, he's not wearing a shirt. And he's like, you know, talking about like this future in which"
    },
    {
      "id": 54,
      "start": 248.88,
      "end": 252.64,
      "text": "computers are going to be, you know, built on the model of the human brain through neural networks."
    },
    {
      "id": 55,
      "start": 254.23999999999998,
      "end": 258.15999999999997,
      "text": "And that was the path not taken. And basically, what happened was, right, the computers got built"
    },
    {
      "id": 56,
      "start": 258.15999999999997,
      "end": 263.2,
      "text": "in the image of like the adding machine. But the neural network basically didn't happen. But the neural"
    },
    {
      "id": 57,
      "start": 263.2,
      "end": 268.56,
      "text": "network as an idea continued to be explored in academia, and in sort of advanced research by sort of"
    },
    {
      "id": 58,
      "start": 268.56,
      "end": 273.03999999999996,
      "text": "a rump, you know, movement, that was originally called cybernetics, and then became known as artificial"
    },
    {
      "id": 59,
      "start": 273.04,
      "end": 277.92,
      "text": "intelligence, basically, for the last 80 years. And essentially, it didn't work. Like, essentially,"
    },
    {
      "id": 60,
      "start": 277.92,
      "end": 283.04,
      "text": "it was basically decade after decade after decade of excessive optimism, followed by disappointment."
    },
    {
      "id": 61,
      "start": 283.04,
      "end": 288.40000000000003,
      "text": "When I was in college in the 80s, there had been a famous kind of AI boom bust cycle in the 80s,"
    },
    {
      "id": 62,
      "start": 288.40000000000003,
      "end": 293.76,
      "text": "in venture in Silicon Valley. I mean, it was tiny by modern standards, but at the time was a big deal."
    },
    {
      "id": 63,
      "start": 294.48,
      "end": 299.44,
      "text": "And, you know, by the time I got to college in 89, in computer science departments, AI was kind of a"
    },
    {
      "id": 64,
      "start": 299.44,
      "end": 303.2,
      "text": "backwater field, and everybody kind of assumed that it was never going to happen. But the scientists"
    },
    {
      "id": 65,
      "start": 303.2,
      "end": 307.6,
      "text": "kept working on it to their credit. And they built up this kind of enormous reservoir of concepts and"
    },
    {
      "id": 66,
      "start": 307.6,
      "end": 313.12,
      "text": "ideas. And then basically, we all saw what happened with the chat GPT moment. All of a sudden, it sort"
    },
    {
      "id": 67,
      "start": 313.12,
      "end": 318.15999999999997,
      "text": "of crystallized, and it's like, oh, my God, right, it turns out it works. And so, you know, that's the"
    },
    {
      "id": 68,
      "start": 318.15999999999997,
      "end": 321.28,
      "text": "moment we're in now. And then, you know, really significantly, that was what, you know, that was less"
    },
    {
      "id": 69,
      "start": 321.28,
      "end": 325.36,
      "text": "than three years ago, right? That was the summer of 22. It was the Christmas of 22. And so,"
    },
    {
      "id": 70,
      "start": 325.36,
      "end": 333.6,
      "text": "we're sort of three years in to, you know, basically what is effectively an 80-year revolution"
    },
    {
      "id": 71,
      "start": 334.64,
      "end": 339.28000000000003,
      "text": "of actually being able to deliver on all the promise that the people on the alternate path,"
    },
    {
      "id": 72,
      "start": 339.28000000000003,
      "end": 343.12,
      "text": "the sort of human cognition model path, you know, kind of saw from the very beginning. And then,"
    },
    {
      "id": 73,
      "start": 343.12,
      "end": 347.76,
      "text": "you know, the great news with this technology is it's already, it's kind of ultra democratized."
    },
    {
      "id": 74,
      "start": 347.76,
      "end": 352.56,
      "text": "You know, the best AI in the world is available on chat GPT or Grok or Gemini or, you know, these other,"
    },
    {
      "id": 75,
      "start": 352.56,
      "end": 356.88,
      "text": "you know, these other products that you can just use. And you can just kind of see how they work."
    },
    {
      "id": 76,
      "start": 356.88,
      "end": 360.24,
      "text": "And, you know, same thing for video, you can see with Sora and video kind of state-of-the-art."
    },
    {
      "id": 77,
      "start": 361.12,
      "end": 364.64,
      "text": "With that, you can see with music, you can see, you know, Suno and IDEO and so forth."
    },
    {
      "id": 78,
      "start": 365.84000000000003,
      "end": 370.08,
      "text": "And so, like, you know, we're basically seeing that happen. And now, and now Silicon Valley is"
    },
    {
      "id": 79,
      "start": 370.08,
      "end": 375.28,
      "text": "responding with this just like incredible rush of enthusiasm. And, you know, really critically,"
    },
    {
      "id": 80,
      "start": 375.28,
      "end": 379.84000000000003,
      "text": "this gets to the magic of Silicon Valley, which is, you know, Silicon Valley, long since has ceased to"
    },
    {
      "id": 81,
      "start": 379.84,
      "end": 383.67999999999995,
      "text": "be a place where people make Silicon that, you know, that's that not long ago moved out of the,"
    },
    {
      "id": 82,
      "start": 383.67999999999995,
      "end": 387.35999999999996,
      "text": "out of California, and then ultimately out of the US, although we're trying to bring it back now."
    },
    {
      "id": 83,
      "start": 388.47999999999996,
      "end": 392.64,
      "text": "But the great kind of virtue of Silicon Valley over the last, you know, over the last, you know,"
    },
    {
      "id": 84,
      "start": 392.64,
      "end": 397.91999999999996,
      "text": "80 years of its existence is its ability to kind of recycle talent from previous waves of technology"
    },
    {
      "id": 85,
      "start": 397.91999999999996,
      "end": 402.0,
      "text": "to new waves of technology, and then inspire an entire new generation of talent, you know,"
    },
    {
      "id": 86,
      "start": 402.0,
      "end": 406.47999999999996,
      "text": "to basically come join the, you know, join the project. And so Silicon Valley has this recurring"
    },
    {
      "id": 87,
      "start": 406.48,
      "end": 410.40000000000003,
      "text": "pattern of being able to reallocate capital and talent and build enthusiasm and build critical mass"
    },
    {
      "id": 88,
      "start": 410.40000000000003,
      "end": 413.92,
      "text": "and build funding support and build, you know, human capital and build, you know, everything,"
    },
    {
      "id": 89,
      "start": 413.92,
      "end": 419.12,
      "text": "enthusiasm, you know, for each new wave of technology. And so, so that's what's happening with AI."
    },
    {
      "id": 90,
      "start": 420.72,
      "end": 424.24,
      "text": "You know, I think probably the biggest thing I could just say is like, I'm surprised, I think,"
    },
    {
      "id": 91,
      "start": 424.24,
      "end": 429.76,
      "text": "essentially on a daily basis of what I'm seeing. And, and, you know, we're, we're in the fortunate"
    },
    {
      "id": 92,
      "start": 429.76,
      "end": 434.48,
      "text": "position to kind of get to see it from two angles. You know, one is we track the underlying science"
    },
    {
      "id": 93,
      "start": 434.48,
      "end": 438.32,
      "text": "and, and, and, and kind of research work very carefully. And so I would say like every day,"
    },
    {
      "id": 94,
      "start": 438.32,
      "end": 443.12,
      "text": "I see a new AI research paper that just like completely floors me of some new capability,"
    },
    {
      "id": 95,
      "start": 443.12,
      "end": 447.76,
      "text": "or some new discovery, or some new development that I, that I would have never anticipated that I,"
    },
    {
      "id": 96,
      "start": 447.76,
      "end": 451.68,
      "text": "I'm just like, wow, I, you know, I can't believe this is happening. And then on the other side,"
    },
    {
      "id": 97,
      "start": 451.68,
      "end": 456.32,
      "text": "of course, you know, we see the flow of all of the new products and all the new startups. And,"
    },
    {
      "id": 98,
      "start": 456.32,
      "end": 460.40000000000003,
      "text": "you know, I would say we're routinely, you know, kind of seeing things that again,"
    },
    {
      "id": 99,
      "start": 460.4,
      "end": 465.52,
      "text": "kind of have my jaw on the floor. And so, you know, it feels like we, we, we've unlocked this"
    },
    {
      "id": 100,
      "start": 465.52,
      "end": 471.03999999999996,
      "text": "giant Vista. I do think it's going to kind of come in fits and starts. You know, these things are"
    },
    {
      "id": 101,
      "start": 471.03999999999996,
      "end": 475.59999999999997,
      "text": "messy processes. You know, you know, this is an industry that kind of routinely gets out over"
    },
    {
      "id": 102,
      "start": 475.59999999999997,
      "end": 479.91999999999996,
      "text": "its skis and over promises. And so, you know, there, there, you know, there will certainly be"
    },
    {
      "id": 103,
      "start": 479.91999999999996,
      "end": 483.03999999999996,
      "text": "points where it's like, wow, you know, this isn't working as well as people thought, or, you know,"
    },
    {
      "id": 104,
      "start": 483.03999999999996,
      "end": 486.4,
      "text": "wow, this turns out to be too expensive, and the economics don't work or whatever. But,"
    },
    {
      "id": 105,
      "start": 486.4,
      "end": 489.52,
      "text": "you know, against that, I would just say the capabilities are truly magical. And,"
    },
    {
      "id": 106,
      "start": 489.52,
      "end": 492.71999999999997,
      "text": "by the way, I think that's the experience that consumers are having when they use it. And I think"
    },
    {
      "id": 107,
      "start": 492.71999999999997,
      "end": 496.64,
      "text": "that's the experience that businesses are having for the most part when they, you know, when they're"
    },
    {
      "id": 108,
      "start": 496.64,
      "end": 500.79999999999995,
      "text": "working on their pilots and, and looking at adoption. And then, and then it translates to"
    },
    {
      "id": 109,
      "start": 500.79999999999995,
      "end": 505.28,
      "text": "the underlying numbers. I mean, we're just seeing this new wave of AI companies is growing revenue,"
    },
    {
      "id": 110,
      "start": 505.28,
      "end": 510.4,
      "text": "like just like actual customer revenue, actual demand, translated through to dollars showing up in"
    },
    {
      "id": 111,
      "start": 510.4,
      "end": 515.04,
      "text": "bank accounts. You know, at like an absolutely unprecedented takeoff rate, we're seeing companies grow much"
    },
    {
      "id": 112,
      "start": 515.04,
      "end": 520.9599999999999,
      "text": "faster. The key leading AI companies and the companies that have real breakthroughs, and have"
    },
    {
      "id": 113,
      "start": 520.9599999999999,
      "end": 524.88,
      "text": "real very compelling products are growing revenues that, you know, kind of faster than any, any wave"
    },
    {
      "id": 114,
      "start": 524.88,
      "end": 529.4399999999999,
      "text": "I've certainly ever seen before. And so, like, just, just from all that, it kind of feels like it has to"
    },
    {
      "id": 115,
      "start": 529.4399999999999,
      "end": 534.7199999999999,
      "text": "be early. Like, it's kind of hard to imagine that we've like, we've topped out in any way, it feels like"
    },
    {
      "id": 116,
      "start": 534.7199999999999,
      "end": 538.3199999999999,
      "text": "everything is still developing. I mean, quite frankly, it feels like the products, to me, it feels like the"
    },
    {
      "id": 117,
      "start": 538.32,
      "end": 543.6,
      "text": "products are still super early. Like, I'm, I'm very skeptical that the form and shape of the products"
    },
    {
      "id": 118,
      "start": 543.6,
      "end": 546.48,
      "text": "that people are using today is what they're going to be using in five or 10 years. I think, I think"
    },
    {
      "id": 119,
      "start": 546.48,
      "end": 550.32,
      "text": "things are going to get much more sophisticated from here. And so, I think we probably have a long"
    },
    {
      "id": 120,
      "start": 550.32,
      "end": 555.44,
      "text": "way to go. Maybe on that, that topic. So, one of the big knocks is, yes, the revenue is immense, but"
    },
    {
      "id": 121,
      "start": 555.44,
      "end": 561.0400000000001,
      "text": "the expenses seem to also be keeping pace. So, like, what are people missing as a part of that discussion and"
    },
    {
      "id": 122,
      "start": 561.0400000000001,
      "end": 565.6,
      "text": "topic? Yeah. So, I just, I'll start with just like core business models, right? And so, you're right,"
    },
    {
      "id": 123,
      "start": 565.6,
      "end": 569.36,
      "text": "there's basically, this industry basically has two core business models, consumer business model,"
    },
    {
      "id": 124,
      "start": 569.36,
      "end": 574.96,
      "text": "and the quote unquote enterprise or infrastructure business model. You know, look, on the consumer side,"
    },
    {
      "id": 125,
      "start": 574.96,
      "end": 579.0400000000001,
      "text": "we just live in a very interesting world now where the internet exists and is fully deployed,"
    },
    {
      "id": 126,
      "start": 579.0400000000001,
      "end": 583.52,
      "text": "right? And so, I'll give you an example. Sometimes people ask, it's like, is AI like the internet"
    },
    {
      "id": 127,
      "start": 583.52,
      "end": 586.96,
      "text": "revolution? It's like, well, a little bit, but like, the thing with the internet was we had to build"
    },
    {
      "id": 128,
      "start": 586.96,
      "end": 592.32,
      "text": "the internet. Like, we had to actually build the network and we actually had that, you know, and"
    },
    {
      "id": 129,
      "start": 592.32,
      "end": 595.2,
      "text": "ultimately it involved an enormous amount of fiber in the ground and it involved"
    },
    {
      "id": 130,
      "start": 595.2,
      "end": 598.48,
      "text": "enormous numbers of like mobile cell towers and, you know, enormous number of, you know,"
    },
    {
      "id": 131,
      "start": 598.48,
      "end": 603.5200000000001,
      "text": "shipments of smartphones and tablets and laptops in order to get people on the internet. Like,"
    },
    {
      "id": 132,
      "start": 603.5200000000001,
      "end": 608.08,
      "text": "there was this like, just like incredible physical lift, you know, to do that. And by the way,"
    },
    {
      "id": 133,
      "start": 608.08,
      "end": 612.8000000000001,
      "text": "people forget how long that took, right? The, you know, the internet itself is a invention of the"
    },
    {
      "id": 134,
      "start": 612.8000000000001,
      "end": 619.44,
      "text": "1960s, 1970s. The consumer internet, you know, was a new phenomenon in the early 90s. But, you know,"
    },
    {
      "id": 135,
      "start": 619.44,
      "end": 623.6,
      "text": "we didn't really get broadband to the home until the 2000s. You know, that really didn't start rolling out"
    },
    {
      "id": 136,
      "start": 623.6,
      "end": 627.28,
      "text": "actually until after the dot-com crash, which is fairly amazing. And then we didn't get mobile"
    },
    {
      "id": 137,
      "start": 627.28,
      "end": 632.96,
      "text": "broadband until like 2010. And people actually forget the original iPhone dropped in 2007. It"
    },
    {
      "id": 138,
      "start": 632.96,
      "end": 639.84,
      "text": "didn't have broadband. It was on a narrowband 2G network. It did not have high-speed, like it did"
    },
    {
      "id": 139,
      "start": 639.84,
      "end": 644.4,
      "text": "not have anything resembling high-speed data. And so it wasn't really until, you know, really about 15"
    },
    {
      "id": 140,
      "start": 644.4,
      "end": 649.36,
      "text": "years ago that we even had mobile broadband. So the internet was this massive lift, but the internet got"
    },
    {
      "id": 141,
      "start": 649.36,
      "end": 653.76,
      "text": "built, right? And smartphones proliferated. And so the point is now you have 5 billion people on"
    },
    {
      "id": 142,
      "start": 653.76,
      "end": 658.5600000000001,
      "text": "planet Earth that are on some version of, you know, mobile broadband internet, right? And, you know,"
    },
    {
      "id": 143,
      "start": 658.5600000000001,
      "end": 663.28,
      "text": "smartphones all over the world are selling for, you know, as little as like 10 bucks. And you have these,"
    },
    {
      "id": 144,
      "start": 663.28,
      "end": 666.96,
      "text": "you know, amazing projects like GEO and India that are bringing, you know, you know, the sort of the"
    },
    {
      "id": 145,
      "start": 666.96,
      "end": 671.04,
      "text": "remaining, you know, kind of the remaining population of planet Earth that hasn't been online until now is"
    },
    {
      "id": 146,
      "start": 671.04,
      "end": 676.24,
      "text": "coming online. So, you know, so we're talking 5 billion, 6 billion, you know, people. And then the"
    },
    {
      "id": 147,
      "start": 676.24,
      "end": 679.92,
      "text": "consumer, the reason I go through that is the consumer AI products could basically deploy to all"
    },
    {
      "id": 148,
      "start": 679.92,
      "end": 685.36,
      "text": "of those people basically as quickly as they want to adopt, right? And so sort of the internet's the"
    },
    {
      "id": 149,
      "start": 685.36,
      "end": 690.72,
      "text": "carrier wave for AI to be able to proliferate at kind of light speed into the broad base of the global"
    },
    {
      "id": 150,
      "start": 690.72,
      "end": 695.2,
      "text": "population. And that's a, let's just say that's a potential rate of proliferation of a new technology"
    },
    {
      "id": 151,
      "start": 695.2,
      "end": 700.08,
      "text": "that's just far faster than has ever been possible before. Like, you know, like you couldn't download"
    },
    {
      "id": 152,
      "start": 700.08,
      "end": 705.44,
      "text": "electricity, right? You couldn't download, you know, you couldn't download indoor plumbing. You know,"
    },
    {
      "id": 153,
      "start": 705.44,
      "end": 709.5200000000001,
      "text": "you couldn't download television, but you can download AI. And this is what we're seeing,"
    },
    {
      "id": 154,
      "start": 709.5200000000001,
      "end": 713.7600000000001,
      "text": "which is the AI consumer app, you know, the AI consumer killer applications are growing at an"
    },
    {
      "id": 155,
      "start": 713.7600000000001,
      "end": 719.9200000000001,
      "text": "incredible rate. And then they're monetizing really well. And again, you know, I mentioned this"
    },
    {
      "id": 156,
      "start": 719.9200000000001,
      "end": 724.08,
      "text": "already, but like generally speaking, the monetization is very good. By the way, including"
    },
    {
      "id": 157,
      "start": 724.08,
      "end": 728.8800000000001,
      "text": "at higher price points. One of the things I like about the, you know, about watching the AI wave is"
    },
    {
      "id": 158,
      "start": 728.8800000000001,
      "end": 732.96,
      "text": "the AI companies, I think, are more creative on pricing than the SaaS companies, the consumer internet"
    },
    {
      "id": 159,
      "start": 732.96,
      "end": 737.2800000000001,
      "text": "companies were. And so it's, for example, now becoming routine to have 200 or $300 per month"
    },
    {
      "id": 160,
      "start": 737.2800000000001,
      "end": 743.44,
      "text": "tiers for consumer AI, which I think is very positive because I think a lot of companies"
    },
    {
      "id": 161,
      "start": 743.44,
      "end": 747.84,
      "text": "cap their kind of opportunity by capping their pricing kind of too low. And I think the AI companies"
    },
    {
      "id": 162,
      "start": 747.84,
      "end": 752.1600000000001,
      "text": "are more willing to push that, which I think is good. So anyway, so that, you know, I think that's"
    },
    {
      "id": 163,
      "start": 752.1600000000001,
      "end": 756.4000000000001,
      "text": "the reason for, like, I would say, you know, considerable rational optimism for the scope of consumer"
    },
    {
      "id": 164,
      "start": 756.4000000000001,
      "end": 760.24,
      "text": "revenues that we're going to be talking about here. And then on the enterprise side, you know,"
    },
    {
      "id": 165,
      "start": 760.24,
      "end": 765.6,
      "text": "there the question is basically just, you know, what is intelligence worth, right? And, you know,"
    },
    {
      "id": 166,
      "start": 765.6,
      "end": 769.04,
      "text": "if you have the ability to like inject more intelligence in your business, and you have"
    },
    {
      "id": 167,
      "start": 769.04,
      "end": 772.72,
      "text": "the ability to do, you know, even the most prosaic things like raise your customer service scores,"
    },
    {
      "id": 168,
      "start": 773.36,
      "end": 778.08,
      "text": "you know, increase upsells, you know, or reduce churn, or if you have the ability to, you know,"
    },
    {
      "id": 169,
      "start": 778.08,
      "end": 782.32,
      "text": "run marketing campaigns more effectively, you know, all of which AI is directly relevant to,"
    },
    {
      "id": 170,
      "start": 782.32,
      "end": 786.08,
      "text": "like, you know, these are like direct business payoffs, you know, that people are seeing already."
    },
    {
      "id": 171,
      "start": 786.8000000000001,
      "end": 790.48,
      "text": "And then if you have the opportunity to infuse AI into new products, and all of a sudden, you know,"
    },
    {
      "id": 172,
      "start": 790.48,
      "end": 794.5600000000001,
      "text": "all of a sudden, your car talks to you, and everything in the world kind of lights up and"
    },
    {
      "id": 173,
      "start": 794.5600000000001,
      "end": 798.5600000000001,
      "text": "starts to get really smart, you know, what, you know, what's that worth? And again, there, you just,"
    },
    {
      "id": 174,
      "start": 798.5600000000001,
      "end": 802.5600000000001,
      "text": "you kind of observe it. And you're like, wow, the leading AI infrastructure companies are growing"
    },
    {
      "id": 175,
      "start": 802.5600000000001,
      "end": 808.1600000000001,
      "text": "revenues incredibly quickly. You know, the pull is really tremendous. And so, you know, again,"
    },
    {
      "id": 176,
      "start": 808.1600000000001,
      "end": 813.5200000000001,
      "text": "there, it's just, it feels like this just like incredible, you know, product market fit. And the core"
    },
    {
      "id": 177,
      "start": 813.52,
      "end": 818.16,
      "text": "business model, right, is actually quite interesting. The core business model is basically,"
    },
    {
      "id": 178,
      "start": 818.16,
      "end": 822.8,
      "text": "is basically tokens by the drink, right? And so it's a sort of tokens of intelligence, you know,"
    },
    {
      "id": 179,
      "start": 822.8,
      "end": 826.56,
      "text": "per dollar. And oh, and then by the way, this is the other fun thing is, if you look at what's"
    },
    {
      "id": 180,
      "start": 826.56,
      "end": 833.36,
      "text": "happening with the price of AI, the price of AI is falling much faster than Moore's Law. And when I"
    },
    {
      "id": 181,
      "start": 833.36,
      "end": 837.76,
      "text": "could go through that in great detail, but basically, like all of the inputs into AI are on a per unit"
    },
    {
      "id": 182,
      "start": 837.76,
      "end": 843.04,
      "text": "basis, the costs are collapsing. And then as a consequence, there's kind of this hyper deflation"
    },
    {
      "id": 183,
      "start": 843.04,
      "end": 847.4399999999999,
      "text": "of per unit cost. And then that is like driving, you know, just like, you know, a more than"
    },
    {
      "id": 184,
      "start": 847.4399999999999,
      "end": 852.72,
      "text": "corresponding level of demand growth, you know, with elasticity. And so, you know, even there,"
    },
    {
      "id": 185,
      "start": 852.72,
      "end": 857.04,
      "text": "we're like, it feels like we're just at the very beginning of kind of, you know, figuring out exactly"
    },
    {
      "id": 186,
      "start": 857.04,
      "end": 860.8,
      "text": "how, you know, expensive or cheap this stuff is getting. I mean, there's just no question tokens by the"
    },
    {
      "id": 187,
      "start": 860.8,
      "end": 864.72,
      "text": "drink are going to get a lot cheaper from here. That's just going to drive, I think, enormous demand."
    },
    {
      "id": 188,
      "start": 864.72,
      "end": 870.24,
      "text": "And then everything in the cost structure is going to get optimized, right? And so, you know, when"
    },
    {
      "id": 189,
      "start": 870.24,
      "end": 874.32,
      "text": "people talk about like, you know, the chips, or, you know, whatever, you know, kind of the unit input"
    },
    {
      "id": 190,
      "start": 874.32,
      "end": 880.48,
      "text": "costs for building AI, you know, you now have these like, the losses of blind demand are going to kick"
    },
    {
      "id": 191,
      "start": 880.48,
      "end": 884.96,
      "text": "in, right? But what's the, you know, in any market that has sort of commodity-like characteristics,"
    },
    {
      "id": 192,
      "start": 884.96,
      "end": 889.28,
      "text": "you know, the number one cause of a glut is a shortage, and the number one cause of a shortage is"
    },
    {
      "id": 193,
      "start": 889.28,
      "end": 894.4,
      "text": "a glut, right? And so you have, you know, to the extent you have like shortage of GPUs,"
    },
    {
      "id": 194,
      "start": 894.4,
      "end": 898.24,
      "text": "or shortage of whatever inference chips, or shortage of, you know, whatever data center space,"
    },
    {
      "id": 195,
      "start": 898.24,
      "end": 902.88,
      "text": "you know, if you look at just the history of humanity building things in response to demand,"
    },
    {
      "id": 196,
      "start": 902.88,
      "end": 907.1999999999999,
      "text": "you know, if there's a shortage of something that can be physically replicated, it does get replicated."
    },
    {
      "id": 197,
      "start": 908.16,
      "end": 911.1999999999999,
      "text": "And so there's going to be like just enormous build out of all, I mean, there is, there's just"
    },
    {
      "id": 198,
      "start": 911.1999999999999,
      "end": 914.3199999999999,
      "text": "hundreds of billions or at this point, trillions of dollars maybe going into the ground"
    },
    {
      "id": 199,
      "start": 915.04,
      "end": 918.96,
      "text": "and all these things. And so the per unit cost of the AI companies are going to drop like a rock,"
    },
    {
      "id": 200,
      "start": 918.96,
      "end": 925.52,
      "text": "you know, over the course of the next decade. And so like, yeah, I mean, the economic questions,"
    },
    {
      "id": 201,
      "start": 925.52,
      "end": 929.2,
      "text": "of course, are very real. And of course, there's, you know, micro economic questions around all these"
    },
    {
      "id": 202,
      "start": 929.2,
      "end": 932.5600000000001,
      "text": "businesses, but the sort of macro forces have been the least here, I think are very strong."
    },
    {
      "id": 203,
      "start": 933.44,
      "end": 939.76,
      "text": "And yeah, I just given the underlying value of this technology to both the consumers and to the"
    },
    {
      "id": 204,
      "start": 939.76,
      "end": 945.0400000000001,
      "text": "enterprise users, and given the just like incredibly aggressive discovery that's happening of all the"
    },
    {
      "id": 205,
      "start": 945.04,
      "end": 948.24,
      "text": "ways that people can use this in their lives and in their businesses, like, it's just, it's really"
    },
    {
      "id": 206,
      "start": 948.24,
      "end": 951.4399999999999,
      "text": "hard for me to see how it both doesn't grow a lot and generate just enormous revenue."
    },
    {
      "id": 207,
      "start": 951.4399999999999,
      "end": 955.76,
      "text": "Yeah. And actually, I think it was like two or three weeks ago where AWS was saying like,"
    },
    {
      "id": 208,
      "start": 955.76,
      "end": 959.5999999999999,
      "text": "the GPUs that they've been using, they've been able to extend back to even like seven plus years."
    },
    {
      "id": 209,
      "start": 959.5999999999999,
      "end": 965.68,
      "text": "So like the shelf life also of the GPUs that they're using is now extending in ways of which they"
    },
    {
      "id": 210,
      "start": 965.68,
      "end": 971.92,
      "text": "can optimize better than maybe perhaps the last couple of cycles as well. Is that the right way to think about it as well?"
    },
    {
      "id": 211,
      "start": 971.92,
      "end": 977.04,
      "text": "Yeah, that's right. And then that's one really important question and observation. And then,"
    },
    {
      "id": 212,
      "start": 977.04,
      "end": 981.68,
      "text": "by the way, that also gets to this other kind of question where there's different theories on it,"
    },
    {
      "id": 213,
      "start": 981.68,
      "end": 986.7199999999999,
      "text": "which is basically big models versus small models. And so a lot of the data, a lot of the data center"
    },
    {
      "id": 214,
      "start": 986.7199999999999,
      "end": 992.56,
      "text": "build is oriented around hosting training and serving the big models, you know, for all the obvious"
    },
    {
      "id": 215,
      "start": 992.56,
      "end": 998.0,
      "text": "reasons. But there's also the small model revolution is happening at the same time. And if you just kind"
    },
    {
      "id": 216,
      "start": 998.0,
      "end": 1001.68,
      "text": "of track, you know, you can get the various research firms have these charts, you can get"
    },
    {
      "id": 217,
      "start": 1002.24,
      "end": 1006.16,
      "text": "but if you just kind of track the capability of the leading edge models over time, what you find"
    },
    {
      "id": 218,
      "start": 1006.16,
      "end": 1011.28,
      "text": "is after six or 12 months, there's a small model that's just as capable. And so there's this kind"
    },
    {
      "id": 219,
      "start": 1011.28,
      "end": 1015.8399999999999,
      "text": "of chase function that's happening, which is the capabilities of the big models are basically being"
    },
    {
      "id": 220,
      "start": 1015.8399999999999,
      "end": 1021.8399999999999,
      "text": "shrunk down and provided at smaller size and then therefore smaller cost, you know, quite quickly."
    },
    {
      "id": 221,
      "start": 1021.8399999999999,
      "end": 1025.12,
      "text": "So I'll just give you the most recent example that's just kind of hit over the last two weeks. And again,"
    },
    {
      "id": 222,
      "start": 1025.12,
      "end": 1029.36,
      "text": "this is the thing that's just kind of shocking is there's this Chinese company that has a,"
    },
    {
      "id": 223,
      "start": 1029.36,
      "end": 1033.76,
      "text": "well, I forget the name of the company, but it's the company that produces the model called Kimi,"
    },
    {
      "id": 224,
      "start": 1033.76,
      "end": 1037.04,
      "text": "just spelled K-I-M-I, which is one of the leading open source models out of China."
    },
    {
      "id": 225,
      "start": 1037.04,
      "end": 1043.12,
      "text": "And the new version of Kimi is a reasoning model that is at least according to the benchmark so far,"
    },
    {
      "id": 226,
      "start": 1043.12,
      "end": 1048.1599999999999,
      "text": "is basically a replication of the reasoning capabilities of GPT-5, right? And the reasoning"
    },
    {
      "id": 227,
      "start": 1048.1599999999999,
      "end": 1053.04,
      "text": "models of GPT-5 were a big advance over GPT-4. And of course, GPT-5 costs a tremendous amount of money"
    },
    {
      "id": 228,
      "start": 1053.04,
      "end": 1056.6399999999999,
      "text": "to develop and to serve. And all of a sudden, you know, here we are, whatever, six months later,"
    },
    {
      "id": 229,
      "start": 1056.64,
      "end": 1060.0800000000002,
      "text": "and you have an open source model called Kimi. And I think, I don't know if they've had,"
    },
    {
      "id": 230,
      "start": 1060.0800000000002,
      "end": 1063.2800000000002,
      "text": "it's either shrunk down to be able to run on either, it's like one MacBook or two MacBooks,"
    },
    {
      "id": 231,
      "start": 1064.4,
      "end": 1069.0400000000002,
      "text": "right? And so you can all of a sudden, if you have like an application, if you're a business and you"
    },
    {
      "id": 232,
      "start": 1069.0400000000002,
      "end": 1073.0400000000002,
      "text": "want to have a reasoning model of the GPT-5 capable, but you, you know, you're whatever,"
    },
    {
      "id": 233,
      "start": 1073.0400000000002,
      "end": 1076.88,
      "text": "you're not going to pay the, whatever GPT-5 cost, or you're not going to want to have it be hosted"
    },
    {
      "id": 234,
      "start": 1076.88,
      "end": 1081.76,
      "text": "and you want to run it locally, you know, you can do that. And again, that's just like another,"
    },
    {
      "id": 235,
      "start": 1081.76,
      "end": 1085.68,
      "text": "just like, it's like another, you know, it's another breakthrough. Like it's just, it's another"
    },
    {
      "id": 236,
      "start": 1085.68,
      "end": 1088.8799999999999,
      "text": "Tuesday, another huge advance. It's like, oh my God. And then of course, it's like, all right,"
    },
    {
      "id": 237,
      "start": 1088.8799999999999,
      "end": 1093.04,
      "text": "well, what is OpenAI going to do? Well, obviously they're going to go to GPT-6, right? And, you know,"
    },
    {
      "id": 238,
      "start": 1093.44,
      "end": 1097.28,
      "text": "right. And so there's this kind of laddering that's happening where the entire industry is"
    },
    {
      "id": 239,
      "start": 1097.28,
      "end": 1100.8799999999999,
      "text": "moving forward. The big models are getting more capable, the small models are kind of chasing them."
    },
    {
      "id": 240,
      "start": 1102.4,
      "end": 1105.44,
      "text": "And then, and then the small models provide, you know, a completely different way to deploy,"
    },
    {
      "id": 241,
      "start": 1106.0,
      "end": 1111.44,
      "text": "you know, at, at, at, at very low price points. And so, yeah, I think, and, you know,"
    },
    {
      "id": 242,
      "start": 1111.44,
      "end": 1114.16,
      "text": "we'll, we'll see what happens. I mean, there, there are some very smart people in the industry"
    },
    {
      "id": 243,
      "start": 1114.16,
      "end": 1117.28,
      "text": "who think that ultimately everything only runs in the big models, because obviously the big models"
    },
    {
      "id": 244,
      "start": 1117.28,
      "end": 1120.0800000000002,
      "text": "are always going to be the smartest. And so therefore you're always, you know, you're always"
    },
    {
      "id": 245,
      "start": 1120.0800000000002,
      "end": 1122.8,
      "text": "going to want the most intelligent thing, because why would you ever want something that's not the"
    },
    {
      "id": 246,
      "start": 1122.8,
      "end": 1126.48,
      "text": "most intelligent thing for any application? You know, the counter argument is just, there's a"
    },
    {
      "id": 247,
      "start": 1126.48,
      "end": 1130.56,
      "text": "huge number of tasks that take place in the economy and in the world that don't require Einstein,"
    },
    {
      "id": 248,
      "start": 1130.56,
      "end": 1134.56,
      "text": "you know, where, you know, where, you know, 120 IQ person is great. You don't need a, you know,"
    },
    {
      "id": 249,
      "start": 1134.56,
      "end": 1138.88,
      "text": "160 IQ, you know, PhD in, you know, string theory, you just like have somebody who's"
    },
    {
      "id": 250,
      "start": 1138.88,
      "end": 1143.3600000000001,
      "text": "competent and capable and it's great. And so, you know, I, you know, and I, we've talked about this"
    },
    {
      "id": 251,
      "start": 1143.3600000000001,
      "end": 1147.0400000000002,
      "text": "before. I, I tend to think the AI industry is going to be structured a lot like the computer"
    },
    {
      "id": 252,
      "start": 1147.0400000000002,
      "end": 1150.88,
      "text": "industry ended up getting structured, which is you're going to have a small handful of basically"
    },
    {
      "id": 253,
      "start": 1150.88,
      "end": 1154.8000000000002,
      "text": "the equivalent of supercomputers, which are these like giant, you know, kind of, we call God models"
    },
    {
      "id": 254,
      "start": 1154.8000000000002,
      "end": 1160.0800000000002,
      "text": "that are, you know, running in these giant data centers. And then, and then, you know, I, I, I, I'm not"
    },
    {
      "id": 255,
      "start": 1160.0800000000002,
      "end": 1163.44,
      "text": "like convinced on this, but my, my kind of working assumption is what happens is then you have this"
    },
    {
      "id": 256,
      "start": 1163.44,
      "end": 1168.3200000000002,
      "text": "cascade down of smaller models, all ultimately all the way, the very small models that run in embedded"
    },
    {
      "id": 257,
      "start": 1168.32,
      "end": 1172.32,
      "text": "systems, right. Run on, run on individual chips inside every, you know, physical item in the world."
    },
    {
      "id": 258,
      "start": 1173.4399999999998,
      "end": 1177.4399999999998,
      "text": "And that, you know, the smartest models will always be at the top, but the volume of models"
    },
    {
      "id": 259,
      "start": 1177.4399999999998,
      "end": 1181.12,
      "text": "will actually be the smaller models that proliferate out. And right. That's what happened with microchips."
    },
    {
      "id": 260,
      "start": 1181.12,
      "end": 1184.3999999999999,
      "text": "It's what happened to computers, which became microchips. And then it's what happened with"
    },
    {
      "id": 261,
      "start": 1184.3999999999999,
      "end": 1187.28,
      "text": "operating systems and with, with a lot of everything else that we built in software."
    },
    {
      "id": 262,
      "start": 1188.32,
      "end": 1193.6799999999998,
      "text": "So, you know, I tend to think that's what will happen. Just quickly on the chip side, again, like"
    },
    {
      "id": 263,
      "start": 1193.68,
      "end": 1199.92,
      "text": "chips, you know, if you look at the entire history of the chip industry, shortages become gluts. And"
    },
    {
      "id": 264,
      "start": 1199.92,
      "end": 1204.96,
      "text": "you get just, you know, like anytime there's a giant profit pool in a, in a new chip category,"
    },
    {
      "id": 265,
      "start": 1205.52,
      "end": 1209.8400000000001,
      "text": "you know, somebody has a lead for a while and kind of gets, you know, let's say the, the, the,"
    },
    {
      "id": 266,
      "start": 1209.8400000000001,
      "end": 1215.3600000000001,
      "text": "the profits appropriate to what we, what we call robust market share. But in time, what happens,"
    },
    {
      "id": 267,
      "start": 1215.3600000000001,
      "end": 1219.1200000000001,
      "text": "right, is that, that draws competition. And of course, you know, that, that, that's happening right now."
    },
    {
      "id": 268,
      "start": 1219.12,
      "end": 1222.9599999999998,
      "text": "So NVIDIA is, you know, NVIDIA is an absolutely fantastic company, fully deserves the position"
    },
    {
      "id": 269,
      "start": 1222.9599999999998,
      "end": 1226.4799999999998,
      "text": "that they're in, fully deserves the profits that they're generating, but they're now so valuable"
    },
    {
      "id": 270,
      "start": 1226.4799999999998,
      "end": 1230.0,
      "text": "generating so many profits that it's the bat signal of all time to the rest of the chip industry to"
    },
    {
      "id": 271,
      "start": 1230.0,
      "end": 1233.9199999999998,
      "text": "figure out how to advance the state of the art in AI chips. And that's, by the way, and that's"
    },
    {
      "id": 272,
      "start": 1233.9199999999998,
      "end": 1237.4399999999998,
      "text": "already happening, right? And so you've got other major companies like AMD coming at them, and then"
    },
    {
      "id": 273,
      "start": 1237.4399999999998,
      "end": 1242.2399999999998,
      "text": "you've got really significantly, you've got the hyperscalers building their own chips. And so, you know,"
    },
    {
      "id": 274,
      "start": 1242.2399999999998,
      "end": 1245.9199999999998,
      "text": "a bunch of the big, a bunch of those kind of big tech companies are building their own chips. And of course,"
    },
    {
      "id": 275,
      "start": 1245.92,
      "end": 1249.92,
      "text": "then the Chinese are building their own chips as well. And so it's just, it's like pretty likely"
    },
    {
      "id": 276,
      "start": 1249.92,
      "end": 1254.16,
      "text": "in five years that, that, you know, AI chips will be, you know, cheap and plentiful, at least in"
    },
    {
      "id": 277,
      "start": 1254.16,
      "end": 1258.64,
      "text": "comparison to the situation today, which again, I think will, you know, will tend to be extremely"
    },
    {
      "id": 278,
      "start": 1258.64,
      "end": 1261.1200000000001,
      "text": "positive for the economics of the kinds of companies that we invest in."
    },
    {
      "id": 279,
      "start": 1261.1200000000001,
      "end": 1266.72,
      "text": "Yep. And the startups are also starting to go after new chip design as well, which is exciting."
    },
    {
      "id": 280,
      "start": 1266.72,
      "end": 1269.68,
      "text": "Yeah. Well, that's the other thing is, yeah, you have these disruptive startups. And actually that,"
    },
    {
      "id": 281,
      "start": 1269.68,
      "end": 1273.04,
      "text": "just for a moment on the chips, we're not really big investors in chips, because it's kind of a big,"
    },
    {
      "id": 282,
      "start": 1273.04,
      "end": 1277.68,
      "text": "it's kind of a big company thing, but it's a little bit of historical happenstance that AI is"
    },
    {
      "id": 283,
      "start": 1277.68,
      "end": 1282.3999999999999,
      "text": "running on quote unquote GPUs, you know, which in GPU stands for graphical processing unit. So,"
    },
    {
      "id": 284,
      "start": 1283.44,
      "end": 1287.28,
      "text": "and basically just for people who haven't tracked this, there were basically two kinds of chips that"
    },
    {
      "id": 285,
      "start": 1287.28,
      "end": 1291.76,
      "text": "made the personal computer happen, the so-called CPU central processing unit, which classically was"
    },
    {
      "id": 286,
      "start": 1291.76,
      "end": 1296.6399999999999,
      "text": "the Intel x86 chip. It's kind of the brain of the computer. And then there was this other kind of chip"
    },
    {
      "id": 287,
      "start": 1296.6399999999999,
      "end": 1301.84,
      "text": "called the GPU or graphical processing unit that was the sort of second chip in every PC that does all the graphics."
    },
    {
      "id": 288,
      "start": 1303.04,
      "end": 1306.8,
      "text": "And, you know, and this is graphics, like, you know, 3D graphics for gaming or for CAD cam or for,"
    },
    {
      "id": 289,
      "start": 1306.8,
      "end": 1310.8,
      "text": "you know, anything else, you know, Photoshop or for anything that involves, you know, lots of visuals."
    },
    {
      "id": 290,
      "start": 1310.8,
      "end": 1315.84,
      "text": "And so the kind of canonical architecture for a personal computer was a CPU and a GPU,"
    },
    {
      "id": 291,
      "start": 1315.84,
      "end": 1319.92,
      "text": "by the way, same thing for smartphones. But by the way, and over time, you know, these have kind of"
    },
    {
      "id": 292,
      "start": 1319.92,
      "end": 1324.1599999999999,
      "text": "merged. And so like a lot of CPUs now have GPU capability built in, actually, a lot of GPUs now have"
    },
    {
      "id": 293,
      "start": 1324.1599999999999,
      "end": 1328.1599999999999,
      "text": "CPU capability built in. So this, you know, this has gotten fuzzy over time, but like that, that was like the"
    },
    {
      "id": 294,
      "start": 1328.16,
      "end": 1331.8400000000001,
      "text": "classic breakdown. But the fact that that was the classic breakdown, you know, kind of meant that"
    },
    {
      "id": 295,
      "start": 1331.8400000000001,
      "end": 1337.28,
      "text": "while Intel had a, you know, monopoly for a long time on CPUs, there was this other market of GPUs,"
    },
    {
      "id": 296,
      "start": 1337.28,
      "end": 1342.64,
      "text": "which NVIDIA, you know, basically fought the GPU wars for 30 years and came out the winner, like what"
    },
    {
      "id": 297,
      "start": 1342.64,
      "end": 1346.96,
      "text": "was the best company in the space. But it was like a hyper competitive market for graphics processors."
    },
    {
      "id": 298,
      "start": 1346.96,
      "end": 1350.24,
      "text": "It was actually not that high margin. It was actually not that big. And then basically,"
    },
    {
      "id": 299,
      "start": 1350.8,
      "end": 1356.4,
      "text": "it just, it turned out that there were two other forms of computation that were incredibly valuable"
    },
    {
      "id": 300,
      "start": 1356.4,
      "end": 1361.84,
      "text": "that happened to be massively parallel in how they operate, which happened to be very good fits"
    },
    {
      "id": 301,
      "start": 1361.84,
      "end": 1366.4,
      "text": "for the GPU architecture. And those two basically highly lucrative additional applications were"
    },
    {
      "id": 302,
      "start": 1366.4,
      "end": 1370.8,
      "text": "cryptocurrency, starting about, you know, 15 years ago, and then AI, starting about, you know,"
    },
    {
      "id": 303,
      "start": 1370.8,
      "end": 1378.16,
      "text": "whatever, four years ago. And so, and NVIDIA, like I would say, very cleverly set itself up with an"
    },
    {
      "id": 304,
      "start": 1378.16,
      "end": 1382.0800000000002,
      "text": "architecture that works very well for this. But it's also just a little bit of a twist of fate,"
    },
    {
      "id": 305,
      "start": 1382.0800000000002,
      "end": 1386.0800000000002,
      "text": "that it just turns out that if AI is the killer app, it just turns out that the GPU architecture"
    },
    {
      "id": 306,
      "start": 1386.0800000000002,
      "end": 1390.64,
      "text": "is the best legacy architecture is devoted to it. I go through that to say, like, if you were designing"
    },
    {
      "id": 307,
      "start": 1390.64,
      "end": 1395.3600000000001,
      "text": "AI chips from scratch today, you wouldn't build a full GPU, you would build dedicated AI chips that"
    },
    {
      "id": 308,
      "start": 1395.3600000000001,
      "end": 1400.3200000000002,
      "text": "were much more straight, much more specifically adapted to AI, and would have, I think would just be"
    },
    {
      "id": 309,
      "start": 1400.3200000000002,
      "end": 1404.64,
      "text": "much more economically efficient. And, you know, Jen, to your point, there are startups that are"
    },
    {
      "id": 310,
      "start": 1404.64,
      "end": 1409.5200000000002,
      "text": "actually building entirely new kinds of chips oriented specifically for AI. And, you know,"
    },
    {
      "id": 311,
      "start": 1409.5200000000002,
      "end": 1412.96,
      "text": "we'll have to see what happens there. You know, it's hard to build a new chip company from scratch."
    },
    {
      "id": 312,
      "start": 1413.5200000000002,
      "end": 1416.0800000000002,
      "text": "You know, it's possible that one or more of those startups makes it on their own."
    },
    {
      "id": 313,
      "start": 1416.96,
      "end": 1420.64,
      "text": "And some of them are, you know, doing very well. It's also possible, of course, that they get bought,"
    },
    {
      "id": 314,
      "start": 1421.2800000000002,
      "end": 1426.96,
      "text": "you know, by big companies that have the ability to scale them. And so, you know, we'll see exactly"
    },
    {
      "id": 315,
      "start": 1426.96,
      "end": 1432.16,
      "text": "how that unfolds. And of course, we'll also, by the way, see, you know, the Koreans are going to play here,"
    },
    {
      "id": 316,
      "start": 1432.16,
      "end": 1437.1200000000001,
      "text": "for sure. The Japanese are going to play. And then, you know, the Chinese in a major way,"
    },
    {
      "id": 317,
      "start": 1437.8400000000001,
      "end": 1441.28,
      "text": "as well. And, you know, they have their own, you know, native chip ecosystem that they're building up."
    },
    {
      "id": 318,
      "start": 1441.28,
      "end": 1446.64,
      "text": "And so there are going to be many choices of AI chips in the future. And it's going to be, you"
    },
    {
      "id": 319,
      "start": 1446.64,
      "end": 1450.16,
      "text": "know, that'll be a giant battle. That'll be a giant battle that we observe very carefully,"
    },
    {
      "id": 320,
      "start": 1450.72,
      "end": 1454.4,
      "text": "and that we make sure that our companies basically are able to take full advantage of."
    },
    {
      "id": 321,
      "start": 1454.4,
      "end": 1460.72,
      "text": "Well, while on the topic of international, you mentioned Kimi earlier. So it seems like some"
    },
    {
      "id": 322,
      "start": 1460.72,
      "end": 1465.76,
      "text": "of the best open source models today are from China. Should this be worrisome to folks? How"
    },
    {
      "id": 323,
      "start": 1465.76,
      "end": 1470.88,
      "text": "are you thinking and talking about this topic with folks in DC? I know you were just there last week."
    },
    {
      "id": 324,
      "start": 1471.44,
      "end": 1478.4,
      "text": "How much of this is a concern for US companies, particularly just having seen the rise of China"
    },
    {
      "id": 325,
      "start": 1478.4,
      "end": 1485.6000000000001,
      "text": "do unnatural things in solar markets, car markets. Are they kind of flooding the ecosystem so that"
    },
    {
      "id": 326,
      "start": 1485.6000000000001,
      "end": 1490.3200000000002,
      "text": "they could eventually kind of take share and increasingly own the ecosystem?"
    },
    {
      "id": 327,
      "start": 1490.3200000000002,
      "end": 1495.3600000000001,
      "text": "Yeah. So, you know, a couple of things. So one is, you know, you want to start these discussions by"
    },
    {
      "id": 328,
      "start": 1495.3600000000001,
      "end": 1499.1200000000001,
      "text": "just kind of saying, like, you know, look, there's vigorous debate in the US and around the world of,"
    },
    {
      "id": 329,
      "start": 1499.1200000000001,
      "end": 1503.2800000000002,
      "text": "like, you know, how much are we in a new Cold War with China? You know, and exactly like how hostile,"
    },
    {
      "id": 330,
      "start": 1503.2800000000002,
      "end": 1507.0400000000002,
      "text": "you know, should we view them? And it's very tempting, by the way, it's very tempting,"
    },
    {
      "id": 331,
      "start": 1507.04,
      "end": 1510.1599999999999,
      "text": "and I think it's a very good case to be made that we're in, like, a new Cold War that's,"
    },
    {
      "id": 332,
      "start": 1510.1599999999999,
      "end": 1514.6399999999999,
      "text": "you know, that in a lot of ways is like the US versus USSR in the 20th century."
    },
    {
      "id": 333,
      "start": 1515.28,
      "end": 1519.28,
      "text": "You know, it is, the counterargument would be, it is more complicated than that because the US"
    },
    {
      "id": 334,
      "start": 1519.28,
      "end": 1523.6,
      "text": "and the USSR were never really intertwined from a trade standpoint. And a big part of that,"
    },
    {
      "id": 335,
      "start": 1523.6,
      "end": 1528.08,
      "text": "quite frankly, was the USSR never really made anything that anybody else needed,"
    },
    {
      "id": 336,
      "start": 1528.08,
      "end": 1532.6399999999999,
      "text": "I guess, other than weapons. But like, you know, the USSR's primary exports were literally,"
    },
    {
      "id": 337,
      "start": 1532.6399999999999,
      "end": 1536.72,
      "text": "like, you know, literally, like, wheat and oil. Whereas, of course,"
    },
    {
      "id": 338,
      "start": 1536.72,
      "end": 1542.32,
      "text": "China exports just a tremendous number of physical things, right? Including, like,"
    },
    {
      "id": 339,
      "start": 1542.32,
      "end": 1545.76,
      "text": "a huge part of, like, the entire supply chain of parts that basically go into everything that"
    },
    {
      "id": 340,
      "start": 1545.76,
      "end": 1550.56,
      "text": "American manufacturers, you know, kind of make, right? And so by the time a US, you know, whatever,"
    },
    {
      "id": 341,
      "start": 1550.56,
      "end": 1554.48,
      "text": "by the time an American company brings a toy to market, right? Or a, you know, or a car,"
    },
    {
      "id": 342,
      "start": 1555.44,
      "end": 1559.04,
      "text": "or anything, or a computer, or a smartphone, or whatever, like, it's got a lot of componentry in it"
    },
    {
      "id": 343,
      "start": 1559.04,
      "end": 1564.24,
      "text": "that was made in China. So there is a much tighter interlinkage between the American and Chinese"
    },
    {
      "id": 344,
      "start": 1564.24,
      "end": 1568.88,
      "text": "economies than there was the American and Soviet economies. And, you know, maybe, you know, Adam"
    },
    {
      "id": 345,
      "start": 1568.88,
      "end": 1571.84,
      "text": "Smith or whatever might say, you know, that's good news for peace, and that, you know, both countries"
    },
    {
      "id": 346,
      "start": 1571.84,
      "end": 1575.52,
      "text": "need each other. By the way, the other part of that argument is that the Chinese, basically,"
    },
    {
      "id": 347,
      "start": 1575.52,
      "end": 1580.24,
      "text": "the Chinese, you know, the Chinese governance model is based on high employment. You know, because,"
    },
    {
      "id": 348,
      "start": 1580.24,
      "end": 1583.68,
      "text": "you know, if, you know, at least all the geopolitical people say, if China ended up with,"
    },
    {
      "id": 349,
      "start": 1583.68,
      "end": 1587.36,
      "text": "like, 25% or 50% unemployment, that would cause civil unrest, which is the one thing that the"
    },
    {
      "id": 350,
      "start": 1587.92,
      "end": 1593.04,
      "text": "CCP doesn't want. And so the corresponding part of the trade pressure is China needs the American export market."
    },
    {
      "id": 351,
      "start": 1593.04,
      "end": 1597.12,
      "text": "You know, the American consumer is like a third of the global economy, a third of global consumer"
    },
    {
      "id": 352,
      "start": 1597.12,
      "end": 1602.24,
      "text": "demand. And so, you know, China needs the US export market, or it has high, all of a sudden, a lot of"
    },
    {
      "id": 353,
      "start": 1602.24,
      "end": 1605.52,
      "text": "its factories would go kind of instantly bankrupt, and, you know, would cause mass unemployment and"
    },
    {
      "id": 354,
      "start": 1605.52,
      "end": 1610.24,
      "text": "unrest in China. So, so anyway, like, you know, we, there is this complicated, it's a complicated,"
    },
    {
      "id": 355,
      "start": 1610.24,
      "end": 1616.72,
      "text": "intertwined relationship. Having said that, you know, the mood in DC, basically, for the last 10 years,"
    },
    {
      "id": 356,
      "start": 1616.72,
      "end": 1621.92,
      "text": "on a bipartisan basis, has been that we need to take, we, the US need to take China more seriously as a"
    },
    {
      "id": 357,
      "start": 1621.92,
      "end": 1626.64,
      "text": "geopolitical foe. And, you know, under, under, under that school of thought, there's sort of,"
    },
    {
      "id": 358,
      "start": 1626.64,
      "end": 1630.48,
      "text": "there's sort of, you know, there's, there's the military dimension, which is, you know, this sort"
    },
    {
      "id": 359,
      "start": 1630.48,
      "end": 1634.0,
      "text": "of, you know, the, the, the risk of some kind of war in the South China Sea, the risk of some kind"
    },
    {
      "id": 360,
      "start": 1634.0,
      "end": 1638.96,
      "text": "of war around, around Taiwan. And so that, you know, that, that has everybody in Washington on high alert."
    },
    {
      "id": 361,
      "start": 1638.96,
      "end": 1643.52,
      "text": "You know, there's also this, this economic question around the kind of de-industrialization of the US,"
    },
    {
      "id": 362,
      "start": 1643.52,
      "end": 1647.1200000000001,
      "text": "the potential re-industrialization, and what that means about, you know, dependence on China."
    },
    {
      "id": 363,
      "start": 1647.12,
      "end": 1652.32,
      "text": "And then, and then there's, and then there's this, this, this AI question. And the AI question is an"
    },
    {
      "id": 364,
      "start": 1652.32,
      "end": 1656.9599999999998,
      "text": "economic question, but it's also like a geopolitical question, which is, okay, you know, basically AI is"
    },
    {
      "id": 365,
      "start": 1656.9599999999998,
      "end": 1661.4399999999998,
      "text": "essentially only being built in the US and in China. You know, the rest of the world either, you know,"
    },
    {
      "id": 366,
      "start": 1662.3999999999999,
      "end": 1666.6399999999999,
      "text": "can't build it or doesn't want to, which, which we could talk about. So it's basically US versus China."
    },
    {
      "id": 367,
      "start": 1667.6,
      "end": 1671.6799999999998,
      "text": "And then AI is going to proliferate all over the world. And is it going to be American AI that proliferates"
    },
    {
      "id": 368,
      "start": 1671.6799999999998,
      "end": 1675.28,
      "text": "all over the world? Or is it going to be Chinese AI that proliferates all over the world? And so,"
    },
    {
      "id": 369,
      "start": 1675.28,
      "end": 1680.24,
      "text": "and I would say just generally across party lines in DC, this, you know, the, the things I just went"
    },
    {
      "id": 370,
      "start": 1680.24,
      "end": 1685.6,
      "text": "through are kind of how they look at it. And the Chinese are in the game. And so the, you know,"
    },
    {
      "id": 371,
      "start": 1685.6,
      "end": 1689.36,
      "text": "the Chinese are in the game for sure, you know, with software, you know, DeepSeq, you know, was kind"
    },
    {
      "id": 372,
      "start": 1689.36,
      "end": 1693.04,
      "text": "of the big, you know, kind of fired the starting gun of the software race. And now you've got,"
    },
    {
      "id": 373,
      "start": 1693.04,
      "end": 1698.16,
      "text": "I think it's, I think you've got four, it's like a DeepSeq, which is a deep, so DeepSeq is an AI"
    },
    {
      "id": 374,
      "start": 1698.16,
      "end": 1704.3999999999999,
      "text": "model from actually a hedge fund in China. It's a little bit, kind of took a lot of people by surprise."
    },
    {
      "id": 375,
      "start": 1704.4,
      "end": 1708.96,
      "text": "And then Quinn is the model from Alibaba. Kimmy is from another startup, oh, called Moonshot."
    },
    {
      "id": 376,
      "start": 1708.96,
      "end": 1713.92,
      "text": "The company's called Moonshot. And then there's, you know, and then, you know, there's also Tencent"
    },
    {
      "id": 377,
      "start": 1713.92,
      "end": 1719.0400000000002,
      "text": "and Baidu and ByteDance, you know, that are all primary, you know, companies doing a lot of work in"
    },
    {
      "id": 378,
      "start": 1719.0400000000002,
      "end": 1723.52,
      "text": "AI. And so, you know, there's somewhere between three to six, you know, kind of primary AI companies."
    },
    {
      "id": 379,
      "start": 1723.52,
      "end": 1728.0,
      "text": "And then there's, you know, tremendous numbers of startups. And so, you know, they're in the race on,"
    },
    {
      "id": 380,
      "start": 1728.0,
      "end": 1732.96,
      "text": "on, you know, they're in the race on, on, on software. They are, you know, working to catch"
    },
    {
      "id": 381,
      "start": 1732.96,
      "end": 1736.4,
      "text": "up on chips. They're not there yet, but they're working incredibly hard to catch up. And just as"
    },
    {
      "id": 382,
      "start": 1736.4,
      "end": 1741.28,
      "text": "an example of that, you know, the, at least the common understanding, you know, in the US is that"
    },
    {
      "id": 383,
      "start": 1741.28,
      "end": 1744.8,
      "text": "the reason you haven't seen the new version of DeepSeq yet is that basically the Chinese government"
    },
    {
      "id": 384,
      "start": 1744.8,
      "end": 1749.44,
      "text": "has instructed them to build it only on Chinese chips as a, as a motivator to get the Chinese chip"
    },
    {
      "id": 385,
      "start": 1749.44,
      "end": 1754.4,
      "text": "ecosystem up and running. And then the main chip company there is Huawei, although there could be more in"
    },
    {
      "id": 386,
      "start": 1754.4,
      "end": 1759.6000000000001,
      "text": "the future. And then there's, you know, so, so, so, so there's that, and then, and then there's"
    },
    {
      "id": 387,
      "start": 1759.6000000000001,
      "end": 1764.3200000000002,
      "text": "everything to follow, which is basically AI in kind of robotic form, right? And so there's this"
    },
    {
      "id": 388,
      "start": 1764.3200000000002,
      "end": 1770.48,
      "text": "basically global technological economic robotics competition that's kicking off. And, you know,"
    },
    {
      "id": 389,
      "start": 1770.48,
      "end": 1774.3200000000002,
      "text": "China kind of starts out ahead on robotics, because they're just ahead on so many of the,"
    },
    {
      "id": 390,
      "start": 1774.3200000000002,
      "end": 1778.48,
      "text": "so many of the components that go into robots, because the, you know, the sort of, like I said,"
    },
    {
      "id": 391,
      "start": 1778.48,
      "end": 1782.8000000000002,
      "text": "this, the kind of entire supply chain of like electromechanical things, you know, basically moved from the"
    },
    {
      "id": 392,
      "start": 1782.8,
      "end": 1787.9199999999998,
      "text": "US to China 30 years ago, and it's never come back. So, so, so that's kind of the, the, the,"
    },
    {
      "id": 393,
      "start": 1787.9199999999998,
      "end": 1792.24,
      "text": "the DC lens on it. And I would say, you know, DC is watching it, you know, quite carefully."
    },
    {
      "id": 394,
      "start": 1792.24,
      "end": 1798.6399999999999,
      "text": "Yeah, the, the, the big kind of supernova moment this year was the DeepSeq release. The DeepSeq"
    },
    {
      "id": 395,
      "start": 1798.6399999999999,
      "end": 1803.9199999999998,
      "text": "release was surprising on a number of fronts. One was just how good it was. And again, along this line"
    },
    {
      "id": 396,
      "start": 1803.9199999999998,
      "end": 1808.24,
      "text": "of it took the capability set that we're running in large models in the cloud and kind of shrunk it"
    },
    {
      "id": 397,
      "start": 1808.24,
      "end": 1815.68,
      "text": "onto a, you know, into, into a, into a sort of a, a reduced size, you know, a smaller version"
    },
    {
      "id": 398,
      "start": 1815.68,
      "end": 1819.92,
      "text": "of sort of equivalent capabilities that you could run on small amounts of local hardware. And so,"
    },
    {
      "id": 399,
      "start": 1819.92,
      "end": 1823.92,
      "text": "there was that. And then it was also a surprise that it was released as open source, and particularly"
    },
    {
      "id": 400,
      "start": 1823.92,
      "end": 1827.44,
      "text": "open source from China, because China, China does not have a long history of open source."
    },
    {
      "id": 401,
      "start": 1828.56,
      "end": 1834.64,
      "text": "And then it was also a surprise that it actually came from a hedge fund. So, it didn't come from a big,"
    },
    {
      "id": 402,
      "start": 1834.64,
      "end": 1838.4,
      "text": "you know, sort of university research lab. It didn't come from a, you know, from a big tech"
    },
    {
      "id": 403,
      "start": 1838.4,
      "end": 1843.5200000000002,
      "text": "company. It came from a hedge fund. And it, it, like, as far as we can tell, it basically is this"
    },
    {
      "id": 404,
      "start": 1843.5200000000002,
      "end": 1847.5200000000002,
      "text": "somewhat idiosyncratic situation where you just have this incredibly successful quant hedge fund"
    },
    {
      "id": 405,
      "start": 1847.5200000000002,
      "end": 1851.1200000000001,
      "text": "with all these, you know, super geniuses. And the, the founder of that hedge fund, you know,"
    },
    {
      "id": 406,
      "start": 1851.1200000000001,
      "end": 1856.16,
      "text": "basically decided to build AI. And, you know, at least externally, indications are this was a surprise"
    },
    {
      "id": 407,
      "start": 1856.16,
      "end": 1859.92,
      "text": "to even the Chinese government. It's, it's impossible to prove, you know, what the Chinese"
    },
    {
      "id": 408,
      "start": 1859.92,
      "end": 1863.76,
      "text": "government was surprised by or not. But, you know, there's at least the atmospherics are that this was not"
    },
    {
      "id": 409,
      "start": 1863.76,
      "end": 1867.92,
      "text": "exactly planned. This was not a national champion tech company at the time that DeepSeq was released."
    },
    {
      "id": 410,
      "start": 1867.92,
      "end": 1872.0,
      "text": "It was a, it sort of came out of left field, which by the way, is very encouraging for the field that"
    },
    {
      "id": 411,
      "start": 1872.0,
      "end": 1875.6,
      "text": "it was possible for somebody to do that kind of who was unknown, right? Because it kind of means that"
    },
    {
      "id": 412,
      "start": 1875.6,
      "end": 1879.6,
      "text": "maybe you don't need all these, you know, super genius, superstar researchers, maybe actually smart"
    },
    {
      "id": 413,
      "start": 1879.6,
      "end": 1884.24,
      "text": "kids can just build this stuff, which I think is, is the direction things are headed. And so that"
    },
    {
      "id": 414,
      "start": 1884.24,
      "end": 1888.72,
      "text": "kicked off, I would say like this kind of, I don't know, copycats the wrong word, but that, that was sort of,"
    },
    {
      "id": 415,
      "start": 1888.72,
      "end": 1893.12,
      "text": "it feels like the success of DeepSeq and the success of DeepSeq from China as open source kind of"
    },
    {
      "id": 416,
      "start": 1893.12,
      "end": 1898.08,
      "text": "kicked off a sort of trend in China of releasing these open source models. You know, look, the"
    },
    {
      "id": 417,
      "start": 1898.08,
      "end": 1903.36,
      "text": "cynics, you know, in DC would say, you know, yeah, like they're dumping, right? They're obviously"
    },
    {
      "id": 418,
      "start": 1903.36,
      "end": 1906.3999999999999,
      "text": "dumping, they're, they're trying to, you know, they see that the West has this opportunity to build this"
    },
    {
      "id": 419,
      "start": 1906.3999999999999,
      "end": 1909.6,
      "text": "China industry. You know, they're trying to commoditize it right out of the gate. You know,"
    },
    {
      "id": 420,
      "start": 1909.6,
      "end": 1914.7199999999998,
      "text": "there's probably something to that. You know, the Chinese industrial economy does have a history of,"
    },
    {
      "id": 421,
      "start": 1914.7199999999998,
      "end": 1918.7199999999998,
      "text": "you know, sort of, let's say subsidized production that leads to selling, you know, selling things"
    },
    {
      "id": 422,
      "start": 1918.72,
      "end": 1924.8,
      "text": "below cost in some cases. But I think also it's like, I think that's almost too cynical of a view"
    },
    {
      "id": 423,
      "start": 1924.8,
      "end": 1928.0,
      "text": "also, because it's just like, all right, wow, like they're really in the race, like open source,"
    },
    {
      "id": 424,
      "start": 1928.0,
      "end": 1931.76,
      "text": "closed source, whatever, like that, you know, they're actually really in the race. You know,"
    },
    {
      "id": 425,
      "start": 1931.76,
      "end": 1936.24,
      "text": "we, we've talked in the past, I think on, on LP calls about, you know, these policy fights that,"
    },
    {
      "id": 426,
      "start": 1936.24,
      "end": 1938.8,
      "text": "you know, we've been having in DC for the last two years. And, you know, there was a big,"
    },
    {
      "id": 427,
      "start": 1938.8,
      "end": 1942.96,
      "text": "pretty, pretty big push within the US government, or, you know, two years ago to basically, you know,"
    },
    {
      "id": 428,
      "start": 1942.96,
      "end": 1948.64,
      "text": "restrict, you know, or outright ban, you know, a lot of AI. And, you know, it's very easy for a"
    },
    {
      "id": 429,
      "start": 1948.64,
      "end": 1952.4,
      "text": "country that is the only game in town to have those conversations. It's quite another thing if"
    },
    {
      "id": 430,
      "start": 1952.4,
      "end": 1958.48,
      "text": "you're actually in a foot race with China. And so I think actually, the policy landscape in DC has,"
    },
    {
      "id": 431,
      "start": 1958.48,
      "end": 1963.04,
      "text": "I would say, has improved dramatically, as a consequence of sort of an awareness now that"
    },
    {
      "id": 432,
      "start": 1963.04,
      "end": 1965.04,
      "text": "this is actually a two horse race, not a one horse race."
    },
    {
      "id": 433,
      "start": 1965.04,
      "end": 1969.04,
      "text": "For sure. Yeah, actually, on the point, I'll jump ahead here to policy and regulation,"
    },
    {
      "id": 434,
      "start": 1969.04,
      "end": 1976.8799999999999,
      "text": "just because it seems like the current stance on, on 50 different set of AI laws by state seems like"
    },
    {
      "id": 435,
      "start": 1976.8799999999999,
      "end": 1984.3999999999999,
      "text": "a catastrophic way to, to put us effectively with a, or one of our, our hands tied behind our,"
    },
    {
      "id": 436,
      "start": 1984.3999999999999,
      "end": 1990.32,
      "text": "our back here in terms of the, the AI race. What's the state of plan that, are folks recognizing that"
    },
    {
      "id": 437,
      "start": 1990.32,
      "end": 1994.8,
      "text": "that would be catastrophic for progress and development? Where do most people at least stand"
    },
    {
      "id": 438,
      "start": 1994.8,
      "end": 1998.3999999999999,
      "text": "on that topic today? Yeah, so it's a little bit complicated. So,"
    },
    {
      "id": 439,
      "start": 1998.4,
      "end": 2002.16,
      "text": "I'll rewind to say like two years ago, I was very worried about like really ruin this federal,"
    },
    {
      "id": 440,
      "start": 2002.16,
      "end": 2005.76,
      "text": "federal legislation on AI. And there was, there was, we, you know, we engaged, you know, kind of very"
    },
    {
      "id": 441,
      "start": 2005.76,
      "end": 2008.96,
      "text": "heavily at that point, which we talked about in the past. And I think the good news on that is,"
    },
    {
      "id": 442,
      "start": 2008.96,
      "end": 2013.92,
      "text": "I think the risk of that sitting here today is very low. I, there's very little mood in DC on either"
    },
    {
      "id": 443,
      "start": 2013.92,
      "end": 2018.64,
      "text": "side of the aisle to really, you know, essentially there's very little, there's very little interest"
    },
    {
      "id": 444,
      "start": 2018.64,
      "end": 2025.2,
      "text": "in doing anything that would prevent us from beating China. So, so, you know, on the federal side,"
    },
    {
      "id": 445,
      "start": 2025.2,
      "end": 2028.0,
      "text": "things are much better now. There, there will, there will be issues in their attentions in the"
    },
    {
      "id": 446,
      "start": 2028.0,
      "end": 2033.52,
      "text": "system, but like things are looking, looking pretty good. That has translated, Jen, to your point,"
    },
    {
      "id": 447,
      "start": 2033.52,
      "end": 2036.48,
      "text": "that's translated a lot of the attention to the states. And basically what's happened is,"
    },
    {
      "id": 448,
      "start": 2036.48,
      "end": 2040.56,
      "text": "you know, under our system of federalism, you know, the states get to pass their own laws on a lot of"
    },
    {
      "id": 449,
      "start": 2040.56,
      "end": 2045.3600000000001,
      "text": "things. And so, yeah, basically, you know, a lot of, you know, and, you know, with these things,"
    },
    {
      "id": 450,
      "start": 2045.3600000000001,
      "end": 2048.2400000000002,
      "text": "it's always a combination. A lot of well-meaning people are trying to figure out what to do at the"
    },
    {
      "id": 451,
      "start": 2048.2400000000002,
      "end": 2052.08,
      "text": "state level. And then of course, there's a lot of opportunism where AI is just the hot topic."
    },
    {
      "id": 452,
      "start": 2052.08,
      "end": 2055.7599999999998,
      "text": "And so if you're a, you know, aggressive up and coming state legislator or whatever in some state,"
    },
    {
      "id": 453,
      "start": 2055.7599999999998,
      "end": 2058.3199999999997,
      "text": "and you want to run for governor and then president, you know, you want to kind of attach"
    },
    {
      "id": 454,
      "start": 2058.3199999999997,
      "end": 2062.56,
      "text": "yourself to the heat. And so there's like a political motivation to do state level stuff."
    },
    {
      "id": 455,
      "start": 2063.52,
      "end": 2067.84,
      "text": "Yeah. And sitting here today, like we're tracking on the order of 1200 bills across the 50 states."
    },
    {
      "id": 456,
      "start": 2067.84,
      "end": 2073.12,
      "text": "And by the way, not just the blue states, also the red states. And so, you know, I've, you know,"
    },
    {
      "id": 457,
      "start": 2073.12,
      "end": 2076.3199999999997,
      "text": "for the last like five years or whatever, I spent a lot of time complaining about, you know,"
    },
    {
      "id": 458,
      "start": 2076.3199999999997,
      "end": 2080.0,
      "text": "kind of what democratic politicians are threatening to do to tech. There's also a lot of Republicans,"
    },
    {
      "id": 459,
      "start": 2080.0,
      "end": 2084.16,
      "text": "like Republicans are not a block on this. And there are quite a few like local Republican"
    },
    {
      "id": 460,
      "start": 2084.16,
      "end": 2088.0,
      "text": "officials in different states that also, I think have, you know, let's say, you know,"
    },
    {
      "id": 461,
      "start": 2088.0,
      "end": 2092.72,
      "text": "misinformed or ill-advised views and are trying to put together, put out bad bills."
    },
    {
      "id": 462,
      "start": 2094.16,
      "end": 2097.6,
      "text": "You know, it's a little bit weird that this is happening and that, you know,"
    },
    {
      "id": 463,
      "start": 2097.6,
      "end": 2102.16,
      "text": "the federal government does have regulation of interstate commerce. And, you know, technology,"
    },
    {
      "id": 464,
      "start": 2102.16,
      "end": 2106.48,
      "text": "AI kind of by definition is interstate. Like, you know, there's, there's no AI company that just"
    },
    {
      "id": 465,
      "start": 2106.48,
      "end": 2112.56,
      "text": "operates in California or just operates in, you know, Colorado or Texas. You know, AI,"
    },
    {
      "id": 466,
      "start": 2112.56,
      "end": 2116.96,
      "text": "of all technologies, AI is obviously something that's the sort of national in scope. You know,"
    },
    {
      "id": 467,
      "start": 2116.96,
      "end": 2122.0,
      "text": "it's sort of obvious that the federal government should be the regulator, not the states. But the"
    },
    {
      "id": 468,
      "start": 2122.0,
      "end": 2126.32,
      "text": "federal government needs to assert itself, needs to step in. There was actually an attempt to do that."
    },
    {
      "id": 469,
      "start": 2126.32,
      "end": 2131.92,
      "text": "There was a, there was an attempt to add a moratorium, a state level AI regulation that basically would"
    },
    {
      "id": 470,
      "start": 2132.72,
      "end": 2136.16,
      "text": "reserve the right of the federal government to regulate AI and sort of prevent the states from moving"
    },
    {
      "id": 471,
      "start": 2136.16,
      "end": 2140.0,
      "text": "forward with these bills. That was, I think, part of the negotiation for the quote, one big,"
    },
    {
      "id": 472,
      "start": 2140.0,
      "end": 2143.8399999999997,
      "text": "beautiful bill. And then that, that there was a deal behind that and that deal kind of blew up at"
    },
    {
      "id": 473,
      "start": 2143.8399999999997,
      "end": 2147.6,
      "text": "the, at the last minute. And that moratorium didn't happen. And, and, you know, in fairness,"
    },
    {
      "id": 474,
      "start": 2147.6,
      "end": 2151.92,
      "text": "the critics of that moratorium, it probably was, was, it was probably too much of a stretch."
    },
    {
      "id": 475,
      "start": 2151.92,
      "end": 2155.2,
      "text": "Oh, it was, I'm sorry, it was definitely too much of a stretch to get enough support to pass,"
    },
    {
      "id": 476,
      "start": 2155.2,
      "end": 2158.72,
      "text": "but it was also probably too much of a stretch in terms of restricting the states from certain kinds"
    },
    {
      "id": 477,
      "start": 2158.72,
      "end": 2162.64,
      "text": "of regulation that they really should be able to do. So, so it just, it didn't quite come together."
    },
    {
      "id": 478,
      "start": 2162.64,
      "end": 2166.08,
      "text": "There's a very active, we're having very active discussions in DC right now about"
    },
    {
      "id": 479,
      "start": 2166.16,
      "end": 2170.48,
      "text": "kind of the next, you know, the kind of the next turn on that. You know, the administration is,"
    },
    {
      "id": 480,
      "start": 2170.48,
      "end": 2173.8399999999997,
      "text": "I would say the administration is very supportive of, of the idea of, of the federal government being"
    },
    {
      "id": 481,
      "start": 2173.8399999999997,
      "end": 2179.68,
      "text": "in charge of this as part of it being an actual, you know, 50 state issue and, and, and an issue"
    },
    {
      "id": 482,
      "start": 2179.68,
      "end": 2184.56,
      "text": "of national importance. And then, you know, I'd say most, most Congress people on both sides of the"
    },
    {
      "id": 483,
      "start": 2184.56,
      "end": 2188.56,
      "text": "aisle, you know, kind of get this. So we just, we kind of have to figure out a way to, you know,"
    },
    {
      "id": 484,
      "start": 2188.56,
      "end": 2194.08,
      "text": "to land this, but, but I think that'll happen. Some of the state level bills are wild. The,"
    },
    {
      "id": 485,
      "start": 2194.08,
      "end": 2202.88,
      "text": "the Colorado passed a very draconian regulation bill last year and against like serious objections"
    },
    {
      "id": 486,
      "start": 2202.88,
      "end": 2207.2799999999997,
      "text": "from the local startup ecosystem in, in, in and around Denver and Boulder. And actually,"
    },
    {
      "id": 487,
      "start": 2207.2799999999997,
      "end": 2210.7999999999997,
      "text": "they're, they're now actually trying to reverse their way out of that bill, you know, a year later."
    },
    {
      "id": 488,
      "start": 2210.7999999999997,
      "end": 2214.7999999999997,
      "text": "But maybe hear some of the nuance of it, like the algorithmic discrimination and like how to"
    },
    {
      "id": 489,
      "start": 2214.7999999999997,
      "end": 2218.56,
      "text": "admit it, like what were some of the, the extreme versions of what they had proposed?"
    },
    {
      "id": 490,
      "start": 2218.56,
      "end": 2222.4,
      "text": "Yeah. So the really draconian one was the, the one that we really fought hard was the one in"
    },
    {
      "id": 491,
      "start": 2222.4,
      "end": 2227.2,
      "text": "California, which was called SB 1047. And it wasn't, it, it was basically, it was modeled basically"
    },
    {
      "id": 492,
      "start": 2227.2,
      "end": 2231.92,
      "text": "after the, it was called the EU AI Act. So the European Union's AI Act. Okay. And this is the"
    },
    {
      "id": 493,
      "start": 2231.92,
      "end": 2235.84,
      "text": "backdrop to all the US stuff, which is the EU passed this bill called the AI Act. I don't know,"
    },
    {
      "id": 494,
      "start": 2235.84,
      "end": 2239.68,
      "text": "whatever, two years ago. And it basically has killed AI development in, well, it's actually killed"
    },
    {
      "id": 495,
      "start": 2239.68,
      "end": 2246.16,
      "text": "AI development in Europe to a large extent. And then it even, it is so draconian that even, even big"
    },
    {
      "id": 496,
      "start": 2246.16,
      "end": 2250.0,
      "text": "American companies like Apple and Meta are not launching leading edge AI capabilities in their"
    },
    {
      "id": 497,
      "start": 2250.0,
      "end": 2253.8399999999997,
      "text": "products in Europe. Like that, that's how, that's how like draconian that bill was. And it's, it's"
    },
    {
      "id": 498,
      "start": 2253.8399999999997,
      "end": 2258.64,
      "text": "sort of a classic, it's a classic kind of European thing where they like, you know, like they just"
    },
    {
      "id": 499,
      "start": 2258.64,
      "end": 2262.3199999999997,
      "text": "thought that, you know, they, they have this kind of view that it's just like, well, you know, we, if we"
    },
    {
      "id": 500,
      "start": 2262.3199999999997,
      "end": 2265.52,
      "text": "can't be the leader, they literally say this, by the way, if we can't be the leaders in innovation, at least"
    },
    {
      "id": 501,
      "start": 2265.52,
      "end": 2270.24,
      "text": "you can be the leaders in regulation. And, and, and then they pass this like incredibly, you know,"
    },
    {
      "id": 502,
      "start": 2270.24,
      "end": 2276.0,
      "text": "kind of ruinous self harm, you know, kind of thing. And then, you know, a few years pass and they're like, oh my God,"
    },
    {
      "id": 503,
      "start": 2276.0,
      "end": 2279.04,
      "text": "what have we done? And so they're, you know, they're kind of going through their own version of that."
    },
    {
      "id": 504,
      "start": 2279.04,
      "end": 2284.24,
      "text": "Yeah. By the way, you know, I, I, you know, when I talk about Europe, I tend to be very dark about"
    },
    {
      "id": 505,
      "start": 2284.24,
      "end": 2287.44,
      "text": "the whole thing. I will tell you the darkest people I know about Europe are the European entrepreneurs"
    },
    {
      "id": 506,
      "start": 2287.44,
      "end": 2293.2,
      "text": "who moved to the US, are just like absolutely furious about what's happening in, in, in Europe"
    },
    {
      "id": 507,
      "start": 2293.2,
      "end": 2297.76,
      "text": "on this stuff. But, but even there, like it's, it's so bad in Europe, like they, they shot themselves"
    },
    {
      "id": 508,
      "start": 2297.76,
      "end": 2301.76,
      "text": "in the foot so badly that there's actually a process now at the EU to try to unwind that. They're"
    },
    {
      "id": 509,
      "start": 2301.76,
      "end": 2308.1600000000003,
      "text": "trying to unwind the GDPR. So anyway, for people tracking Europe, Mario Draghi is the former, I"
    },
    {
      "id": 510,
      "start": 2308.1600000000003,
      "end": 2311.36,
      "text": "guess, prime minister of Italy, did this thing about a year ago called the Draghi report, which"
    },
    {
      "id": 511,
      "start": 2311.36,
      "end": 2315.1200000000003,
      "text": "is the report on European competitiveness. And he kind of outlined kind of in great detail,"
    },
    {
      "id": 512,
      "start": 2315.1200000000003,
      "end": 2318.7200000000003,
      "text": "all the ways that Europe was holding itself back. And part of it was over regulation areas like AI."
    },
    {
      "id": 513,
      "start": 2318.7200000000003,
      "end": 2323.28,
      "text": "So, so they're trying to reverse out of that or making gestures, you know, we'll, we'll see what"
    },
    {
      "id": 514,
      "start": 2323.28,
      "end": 2330.7200000000003,
      "text": "happens. In the middle of all that, California sort of inexplicably decided to basically copycat the EU"
    },
    {
      "id": 515,
      "start": 2330.72,
      "end": 2335.4399999999996,
      "text": "AI Act and try to apply it to California, which might strike you as completely insane, to which"
    },
    {
      "id": 516,
      "start": 2335.4399999999996,
      "end": 2340.72,
      "text": "I would say, yes, welcome to California. And, you know, it was this basically this like"
    },
    {
      "id": 517,
      "start": 2340.72,
      "end": 2345.9199999999996,
      "text": "Sacramento political dynamic, that kind of got, got, got crazy. It would have, you know, completely"
    },
    {
      "id": 518,
      "start": 2345.9199999999996,
      "end": 2351.04,
      "text": "killed, you know, AI development in California. Unfortunately, our governor vetoed it at the last"
    },
    {
      "id": 519,
      "start": 2351.04,
      "end": 2356.0,
      "text": "minute. It did pass both houses, the legislature that he vetoed at the last minute. It, Jen, to your"
    },
    {
      "id": 520,
      "start": 2356.0,
      "end": 2360.24,
      "text": "point, it would have done for, it would have done a whole bunch of things that were ruinously bad."
    },
    {
      "id": 521,
      "start": 2360.24,
      "end": 2363.3599999999997,
      "text": "But one of the things that would have done is it would have assigned downstream liability"
    },
    {
      "id": 522,
      "start": 2364.56,
      "end": 2369.6,
      "text": "to open source developers. And so, you know, we talked about, you know, the Chinese open source"
    },
    {
      "id": 523,
      "start": 2369.6,
      "end": 2372.24,
      "text": "thing. Okay. So you got Chinese out there with open source. Now you're gonna have American companies"
    },
    {
      "id": 524,
      "start": 2372.24,
      "end": 2376.24,
      "text": "that have open source AI. And by the way, you're also gonna have American academics and just like"
    },
    {
      "id": 525,
      "start": 2376.24,
      "end": 2380.56,
      "text": "independent people in their nights and weekends developing open source, you know, which is a key"
    },
    {
      "id": 526,
      "start": 2380.56,
      "end": 2384.64,
      "text": "way that all this technology proliferates. And so this, this law would have assigned downstream"
    },
    {
      "id": 527,
      "start": 2384.64,
      "end": 2388.0,
      "text": "liability to any misuse of open source to the original developer of the open source."
    },
    {
      "id": 528,
      "start": 2388.0,
      "end": 2392.88,
      "text": "And so, you know, you're an independent developer, or you're an academic, or you're a startup, you"
    },
    {
      "id": 529,
      "start": 2392.88,
      "end": 2397.12,
      "text": "develop and release an AI model. The AI model works fine. The day you release it, it's great. But like"
    },
    {
      "id": 530,
      "start": 2397.12,
      "end": 2400.48,
      "text": "five years later, it gets built into a nuclear power plant. And then there's a meltdown of the"
    },
    {
      "id": 531,
      "start": 2400.48,
      "end": 2407.2,
      "text": "nuclear power plant. And then somebody says, oh, it's the fault of the AI. The legal liability for"
    },
    {
      "id": 532,
      "start": 2407.2,
      "end": 2411.84,
      "text": "the nuclear meltdown or for anything, any other practical real world thing that would follow in the"
    },
    {
      "id": 533,
      "start": 2411.84,
      "end": 2416.16,
      "text": "out years would then be assigned back to that open source developer. Of course, this is completely insane. It would"
    },
    {
      "id": 534,
      "start": 2416.16,
      "end": 2420.16,
      "text": "completely kill open source. It would completely kill startups doing open source. It would completely"
    },
    {
      "id": 535,
      "start": 2420.16,
      "end": 2425.7599999999998,
      "text": "kill academic research, like in its entirety, you know, anything in the field. And so, you know,"
    },
    {
      "id": 536,
      "start": 2425.7599999999998,
      "end": 2429.92,
      "text": "like, that's the level of playing with fire, you know, kind of that these state level politicians have"
    },
    {
      "id": 537,
      "start": 2429.92,
      "end": 2434.72,
      "text": "become enamored with. Like I said, I think the good news is the feds understand this, I suspect that this"
    },
    {
      "id": 538,
      "start": 2434.72,
      "end": 2439.12,
      "text": "is going to get resolved, but it does need to get resolved. Because, you know, just as a country, it just"
    },
    {
      "id": 539,
      "start": 2439.12,
      "end": 2445.04,
      "text": "doesn't make any sense to let the states kind of operate suicidally like this. And so that's what"
    },
    {
      "id": 540,
      "start": 2445.04,
      "end": 2449.2799999999997,
      "text": "we're doing. You know, we talk about this, we call this our little tech agenda. We're extremely focused"
    },
    {
      "id": 541,
      "start": 2449.2799999999997,
      "end": 2454.56,
      "text": "on the freedom of startups to innovate. We are not trying to argue, you know, many, many other issues."
    },
    {
      "id": 542,
      "start": 2454.56,
      "end": 2459.44,
      "text": "We operate in a completely bipartisan fashion. We have extensive support, you know, on both sides of"
    },
    {
      "id": 543,
      "start": 2459.44,
      "end": 2465.52,
      "text": "the aisle and for both sides of the aisle. So it's a truly bipartisan effort, very policy-based, and,"
    },
    {
      "id": 544,
      "start": 2465.52,
      "end": 2471.04,
      "text": "you know, I think very much aligned with the interests of the country broadly. And so that is"
    },
    {
      "id": 545,
      "start": 2471.04,
      "end": 2474.8,
      "text": "what we're doing. And then the other question we get, we get actually, you know, in some cases from"
    },
    {
      "id": 546,
      "start": 2474.8,
      "end": 2479.6,
      "text": "LPs, but in a lot of cases actually from employees, is like, okay, why us, right? Like, you know,"
    },
    {
      "id": 547,
      "start": 2481.6,
      "end": 2484.72,
      "text": "with any sort of, you know, policy question like this, there's always this collective action question,"
    },
    {
      "id": 548,
      "start": 2484.72,
      "end": 2488.64,
      "text": "which is this like, you know, tragedy of the commons, which is, in theory, like everybody,"
    },
    {
      "id": 549,
      "start": 2488.64,
      "end": 2492.0,
      "text": "every venture firm, every tech company, whatever, should be weighing in on these things. In practice,"
    },
    {
      "id": 550,
      "start": 2492.0,
      "end": 2496.56,
      "text": "what happens is most of them just simply don't. And so at some point, it falls on somebody's"
    },
    {
      "id": 551,
      "start": 2496.56,
      "end": 2501.12,
      "text": "shoulders to fight these things. And Ben and I just basically concluded that the stakes here were"
    },
    {
      "id": 552,
      "start": 2501.12,
      "end": 2504.88,
      "text": "just way too high. You know, if we're going to be the industry leader, we just have to take"
    },
    {
      "id": 553,
      "start": 2504.88,
      "end": 2509.2,
      "text": "responsibility for our own destiny. You know, for better or for worse, I think that's the cost of"
    },
    {
      "id": 554,
      "start": 2509.2,
      "end": 2513.52,
      "text": "doing business for being the leader in the field right now. Before we get off the topic of AI, I want"
    },
    {
      "id": 555,
      "start": 2513.52,
      "end": 2518.16,
      "text": "to go back to one question that was submitted. And so do you think usage-based or utility is the right"
    },
    {
      "id": 556,
      "start": 2518.16,
      "end": 2524.3199999999997,
      "text": "way to price an AI compared to seats? Ah, that is a fantastic question. So this is one of these giant,"
    },
    {
      "id": 557,
      "start": 2524.3199999999997,
      "end": 2528.08,
      "text": "this is in my list of what I call the trillion dollar questions, where, you know, depending on"
    },
    {
      "id": 558,
      "start": 2528.08,
      "end": 2531.52,
      "text": "how this is answered, will drive, you know, trillions of dollars in market value. So, yeah,"
    },
    {
      "id": 559,
      "start": 2531.52,
      "end": 2537.3599999999997,
      "text": "so usage-based pricing, it's actually fairly amazing. If you think about this from a startup"
    },
    {
      "id": 560,
      "start": 2537.3599999999997,
      "end": 2540.96,
      "text": "standpoint, from a venture standpoint, it's actually fairly amazing what's happened. And I'm trying,"
    },
    {
      "id": 561,
      "start": 2540.96,
      "end": 2544.64,
      "text": "I'm not really talking about this in public, because I don't really, I guess I don't want it to stop."
    },
    {
      "id": 562,
      "start": 2544.64,
      "end": 2549.7599999999998,
      "text": "I think it's actually quite amazing. Which is, you have these technology companies, you know,"
    },
    {
      "id": 563,
      "start": 2549.7599999999998,
      "end": 2553.68,
      "text": "these big tech companies with these incredible R&D capabilities that are building these big models,"
    },
    {
      "id": 564,
      "start": 2553.68,
      "end": 2559.2799999999997,
      "text": "these big AI models with this incredible, you know, new kind of intelligence. And then it turns"
    },
    {
      "id": 565,
      "start": 2559.2799999999997,
      "end": 2563.12,
      "text": "out that they were already in a war, they were already in the cloud war, right? And so they were"
    },
    {
      "id": 566,
      "start": 2563.12,
      "end": 2568.24,
      "text": "already in the war for kind of cloud services. And this is like AWS versus Azure versus Google Cloud,"
    },
    {
      "id": 567,
      "start": 2569.3599999999997,
      "end": 2574.3199999999997,
      "text": "you know, and then all these other cloud efforts. And so what actually happened was they sort of,"
    },
    {
      "id": 568,
      "start": 2574.32,
      "end": 2579.52,
      "text": "like, there's an alternate universe in which they basically just kept all of their magic AI secret"
    },
    {
      "id": 569,
      "start": 2579.52,
      "end": 2584.48,
      "text": "and captive and just used it in their own business, or used it to just compete with more companies,"
    },
    {
      "id": 570,
      "start": 2584.96,
      "end": 2589.28,
      "text": "you know, in more categories. But instead, what they've done is they've basically, you know,"
    },
    {
      "id": 571,
      "start": 2589.28,
      "end": 2594.8,
      "text": "if I've commoditized is too strong a word, but they have proliferated their magic new technology"
    },
    {
      "id": 572,
      "start": 2594.8,
      "end": 2599.6800000000003,
      "text": "through their cloud business, which is this business that just has these like incredible scale,"
    },
    {
      "id": 573,
      "start": 2599.68,
      "end": 2603.7599999999998,
      "text": "you know, kind of kind of components to it, you know, and sort of this hyper competition between"
    },
    {
      "id": 574,
      "start": 2603.7599999999998,
      "end": 2608.16,
      "text": "the providers and these, you know, these, these prices that come down very fast. And so you've got"
    },
    {
      "id": 575,
      "start": 2608.16,
      "end": 2611.52,
      "text": "like the most magic new technology in the world. And then it's basically being served up by those"
    },
    {
      "id": 576,
      "start": 2611.52,
      "end": 2616.8799999999997,
      "text": "companies in as a cloud business, and made made basically available to everybody on the planet to"
    },
    {
      "id": 577,
      "start": 2616.8799999999997,
      "end": 2621.9199999999996,
      "text": "just click and use and for like relatively small amounts of money. And then on a usage basis,"
    },
    {
      "id": 578,
      "start": 2621.9199999999996,
      "end": 2625.68,
      "text": "which means usage is great for startups, because it means you can start easily, right? You know,"
    },
    {
      "id": 579,
      "start": 2625.68,
      "end": 2629.3599999999997,
      "text": "the, you know, there's very, you know, there's basically no fixed cost for a startup building"
    },
    {
      "id": 580,
      "start": 2629.3599999999997,
      "end": 2633.04,
      "text": "an AI app, they don't have giant fixed costs, because they can just tap into the open AI or"
    },
    {
      "id": 581,
      "start": 2633.04,
      "end": 2636.8799999999997,
      "text": "Anthropic or Google or Microsoft or whatever, you know, cloud, you know, tokens by the drink,"
    },
    {
      "id": 582,
      "start": 2636.8799999999997,
      "end": 2641.2799999999997,
      "text": "you know, intelligence tokens by the drink offering and just get going. And so it's kind of this,"
    },
    {
      "id": 583,
      "start": 2641.9199999999996,
      "end": 2644.64,
      "text": "from this, from the startup standpoint, it's like this marvelous thing, where like the most"
    },
    {
      "id": 584,
      "start": 2644.64,
      "end": 2648.0,
      "text": "magical thing in the world is available by the drink. You know, it's absolutely amazing."
    },
    {
      "id": 585,
      "start": 2650.7999999999997,
      "end": 2653.52,
      "text": "And you know, that model, you know, by the way, that model is working in those companies are"
    },
    {
      "id": 586,
      "start": 2653.52,
      "end": 2656.8,
      "text": "happy, and they're growing really fast. And they're, you know, happily reporting massive cloud"
    },
    {
      "id": 587,
      "start": 2656.8,
      "end": 2660.16,
      "text": "revenue growth, and you know, they're happy with the margins and so forth. And so, you know,"
    },
    {
      "id": 588,
      "start": 2660.16,
      "end": 2664.8,
      "text": "I think generally, it's working. And those businesses are, I think, likely to get much larger."
    },
    {
      "id": 589,
      "start": 2664.8,
      "end": 2668.48,
      "text": "And so I think, you know, generally, that's going to work. But, but to the question like,"
    },
    {
      "id": 590,
      "start": 2668.48,
      "end": 2673.2,
      "text": "that doesn't mean that the optimal pricing model for, for example, all of the applications should be"
    },
    {
      "id": 591,
      "start": 2673.2,
      "end": 2678.32,
      "text": "tokens by the drink. And in fact, very much, I think, not the case. You know, we spend a lot of time"
    },
    {
      "id": 592,
      "start": 2678.32,
      "end": 2681.7599999999998,
      "text": "working, we actually have, you know, dedicated, you know, experts on pricing in our firm,"
    },
    {
      "id": 593,
      "start": 2681.76,
      "end": 2684.8,
      "text": "we spend a lot of time with our companies working on pricing, because it's, you know,"
    },
    {
      "id": 594,
      "start": 2684.8,
      "end": 2688.32,
      "text": "it's really this magical art and science that a lot of companies don't take don't take seriously"
    },
    {
      "id": 595,
      "start": 2688.32,
      "end": 2691.36,
      "text": "enough. So we spend a lot of time with our companies on this. And of course, you know,"
    },
    {
      "id": 596,
      "start": 2692.0,
      "end": 2695.92,
      "text": "a core principle of pricing is you don't want to price by cost. If you can avoid it, you want to"
    },
    {
      "id": 597,
      "start": 2695.92,
      "end": 2699.92,
      "text": "price by value, right? Like you want to price, you have price where you're getting a percentage of"
    },
    {
      "id": 598,
      "start": 2699.92,
      "end": 2704.0,
      "text": "the business value of, you know, especially when you're selling to businesses, you want to price"
    },
    {
      "id": 599,
      "start": 2704.0,
      "end": 2708.32,
      "text": "as a percentage of the business value that you're getting. And so, so you do have some AI"
    },
    {
      "id": 600,
      "start": 2708.32,
      "end": 2710.96,
      "text": "startups that are that are pricing by the drink for certain things that they're doing,"
    },
    {
      "id": 601,
      "start": 2710.96,
      "end": 2715.52,
      "text": "but you have many others that are exploring other pricing models. You know, some that are just like"
    },
    {
      "id": 602,
      "start": 2715.52,
      "end": 2719.12,
      "text": "replications of SaaS pricing models, but you also have other companies that are exploring pricing"
    },
    {
      "id": 603,
      "start": 2719.12,
      "end": 2724.48,
      "text": "models, for example, of, well, if the AI can actually do the job of a coder, or the AI could"
    },
    {
      "id": 604,
      "start": 2724.48,
      "end": 2730.48,
      "text": "do the job of a doctor or a nurse or a radiologist or a lawyer or a paralegal, right, or whatever,"
    },
    {
      "id": 605,
      "start": 2730.48,
      "end": 2736.4,
      "text": "or a teacher, you know, basically, can you price by value and can you get a percentage of the value of"
    },
    {
      "id": 606,
      "start": 2736.4,
      "end": 2743.52,
      "text": "what otherwise would have been literally a person? You know, or by the way, equivalently,"
    },
    {
      "id": 607,
      "start": 2743.52,
      "end": 2747.2000000000003,
      "text": "can you price by marginal productivity? So if you can take a human doctor and make them much more"
    },
    {
      "id": 608,
      "start": 2747.2000000000003,
      "end": 2750.96,
      "text": "productive because you give them AI, you know, can you price as a percentage of kind of the productivity"
    },
    {
      "id": 609,
      "start": 2750.96,
      "end": 2759.44,
      "text": "uplift, you know, from the symbiotic relationship between the human being and the AI? And so, I think"
    },
    {
      "id": 610,
      "start": 2759.44,
      "end": 2763.92,
      "text": "what we see in startup land is like a lot of experimentation happening on these pricing models."
    },
    {
      "id": 611,
      "start": 2763.92,
      "end": 2769.44,
      "text": "And I think, again, I think that's like super healthy. You know, I was in this little speech"
    },
    {
      "id": 612,
      "start": 2769.44,
      "end": 2772.48,
      "text": "on this, it's like high prices are really underappreciated. High prices are often a favor"
    },
    {
      "id": 613,
      "start": 2772.48,
      "end": 2776.88,
      "text": "to the customer. It's actually really funny. A lot of like the naive view on pricing is the lower the"
    },
    {
      "id": 614,
      "start": 2776.88,
      "end": 2780.16,
      "text": "price, the better is for the customer. The more sophisticated way of looking at it is higher prices"
    },
    {
      "id": 615,
      "start": 2780.16,
      "end": 2783.36,
      "text": "are often good for the customer because a higher price means that the vendor can make the product"
    },
    {
      "id": 616,
      "start": 2783.36,
      "end": 2788.6400000000003,
      "text": "better, faster, right? Like you can actually, companies with higher prices, higher margins can"
    },
    {
      "id": 617,
      "start": 2788.6400000000003,
      "end": 2793.04,
      "text": "actually invest more in R&D and they can actually make the product better. And, you know, most people"
    },
    {
      "id": 618,
      "start": 2793.04,
      "end": 2796.48,
      "text": "who buy things aren't just looking for the cheapest price. They want something that's really, that's"
    },
    {
      "id": 619,
      "start": 2796.48,
      "end": 2801.84,
      "text": "going to work really well. And so often high prices, you know, the customer doesn't ever say this."
    },
    {
      "id": 620,
      "start": 2801.84,
      "end": 2806.48,
      "text": "It'll never show up in a survey. But the high price can actually be a gift to the customer because"
    },
    {
      "id": 621,
      "start": 2806.48,
      "end": 2809.6800000000003,
      "text": "it can make the vendor better, can make the product better and ultimately make the customer better off."
    },
    {
      "id": 622,
      "start": 2809.68,
      "end": 2814.16,
      "text": "And so I'm very encouraged by the degree to which the AI entrepreneurs are willing to run these"
    },
    {
      "id": 623,
      "start": 2814.16,
      "end": 2817.3599999999997,
      "text": "experiments. And I, you know, we'll have to see where it pans out. But at least so far, I feel,"
    },
    {
      "id": 624,
      "start": 2817.3599999999997,
      "end": 2820.48,
      "text": "I feel good about the, the, you know, at least the attitude in the industry about it."
    },
    {
      "id": 625,
      "start": 2820.48,
      "end": 2824.64,
      "text": "Awesome. I actually, as you were going through it, I had probably 10 more follow-up questions,"
    },
    {
      "id": 626,
      "start": 2824.64,
      "end": 2830.16,
      "text": "but I'm actually going to go back to a topic you had briefly, the trillion dollar questions,"
    },
    {
      "id": 627,
      "start": 2830.16,
      "end": 2835.9199999999996,
      "text": "will open source or closed source win? Feels like we've come out on this, this debate or where do you,"
    },
    {
      "id": 628,
      "start": 2835.9199999999996,
      "end": 2836.72,
      "text": "where do you put that?"
    },
    {
      "id": 629,
      "start": 2836.72,
      "end": 2839.6,
      "text": "No, I think this is still open. I think this is still open."
    },
    {
      "id": 630,
      "start": 2839.6,
      "end": 2843.36,
      "text": "Yeah. It's still very open. You know, like the, the, the closed source models keep getting better."
    },
    {
      "id": 631,
      "start": 2843.36,
      "end": 2843.36,
      "text": ""
    },
    {
      "id": 632,
      "start": 2843.36,
      "end": 2849.12,
      "text": "By the way, if you, generally, if you just like take the temperature of the people working at the big"
    },
    {
      "id": 633,
      "start": 2849.12,
      "end": 2852.7999999999997,
      "text": "labs who work on the big proprietary models, like generally what they'll tell you is progress is"
    },
    {
      "id": 634,
      "start": 2852.7999999999997,
      "end": 2856.96,
      "text": "continuing at a very rapid pace. You know, there's, there's this, you know, there's this periodic"
    },
    {
      "id": 635,
      "start": 2856.96,
      "end": 2860.4,
      "text": "concern that kind of shows up on online, which is, or in the, in the market, which is like, you know,"
    },
    {
      "id": 636,
      "start": 2860.4,
      "end": 2864.16,
      "text": "maybe the capabilities, these models are topping out. And, you know, there's certain, there's,"
    },
    {
      "id": 637,
      "start": 2864.16,
      "end": 2868.08,
      "text": "there's certain areas in which, you know, there's, there's, you know, people are working, but like the people"
    },
    {
      "id": 638,
      "start": 2868.08,
      "end": 2872.08,
      "text": "working at the big labs are like, oh no, we have like 800 new ideas. Like we have tons of new ideas."
    },
    {
      "id": 639,
      "start": 2872.08,
      "end": 2875.92,
      "text": "We have tons of new ways of doing things. We, we might need to find new ways to scale, but like,"
    },
    {
      "id": 640,
      "start": 2875.92,
      "end": 2879.52,
      "text": "we, we have a lot of ideas on how to do that. We know a lot of ways to make these things better."
    },
    {
      "id": 641,
      "start": 2879.52,
      "end": 2882.56,
      "text": "And, you know, we're basically making new discoveries all the time. So like I would say,"
    },
    {
      "id": 642,
      "start": 2882.56,
      "end": 2886.64,
      "text": "you know, generally the people working at, like across all the big labs are, are pretty optimistic."
    },
    {
      "id": 643,
      "start": 2886.64,
      "end": 2890.64,
      "text": "And so like, I, I think the big models are going to continue to get better, you know,"
    },
    {
      "id": 644,
      "start": 2890.64,
      "end": 2895.2799999999997,
      "text": "very quickly here and then, you know, overall and then the open source models continue to get better."
    },
    {
      "id": 645,
      "start": 2895.2799999999997,
      "end": 2898.64,
      "text": "And like I said, you know, you know, every, every, every, I don't know, every month or something,"
    },
    {
      "id": 646,
      "start": 2898.64,
      "end": 2902.3199999999997,
      "text": "there's like another big release of like something like this, give me thing, where it's just like,"
    },
    {
      "id": 647,
      "start": 2902.3199999999997,
      "end": 2905.68,
      "text": "wow, like, you know, that's amazing. And, you know, wow, they really like shrunk that down and got"
    },
    {
      "id": 648,
      "start": 2905.68,
      "end": 2911.52,
      "text": "that capability on a very small form factor. And so, yeah, that's the case. And then, you know,"
    },
    {
      "id": 649,
      "start": 2911.52,
      "end": 2916.96,
      "text": "maybe just the third kind of thing to bring up is the other really nice benefit of open source is"
    },
    {
      "id": 650,
      "start": 2916.96,
      "end": 2922.56,
      "text": "that open source is the thing that's easy to learn from. Right. And so if you're a, you know,"
    },
    {
      "id": 651,
      "start": 2922.56,
      "end": 2926.4,
      "text": "computer science, if you're a computer science professor who wants to teach a class on, on CS,"
    },
    {
      "id": 652,
      "start": 2926.4,
      "end": 2930.24,
      "text": "on AI, or if you're a computer science student that's trying to learn about it, or if you're just"
    },
    {
      "id": 653,
      "start": 2930.24,
      "end": 2935.84,
      "text": "like a normal engineer in a normal company trying to learn this new thing, or just somebody in your,"
    },
    {
      "id": 654,
      "start": 2935.84,
      "end": 2938.56,
      "text": "you know, by the way, somebody in your basement at night with a startup idea,"
    },
    {
      "id": 655,
      "start": 2938.56,
      "end": 2942.32,
      "text": "you know, the existence of these, of these state-of-the-art open source models is amazing,"
    },
    {
      "id": 656,
      "start": 2942.32,
      "end": 2946.24,
      "text": "because that's the education that you need. Like they actually, these open source models actually"
    },
    {
      "id": 657,
      "start": 2946.24,
      "end": 2952.24,
      "text": "show you how to do everything. Right. And so like, and what that's leading to, right, is the"
    },
    {
      "id": 658,
      "start": 2952.24,
      "end": 2957.2799999999997,
      "text": "proliferation of the knowledge about how to build AI is like expanding very fast. Again, as compared"
    },
    {
      "id": 659,
      "start": 2957.2799999999997,
      "end": 2961.2,
      "text": "to a counterfactual world in which it was all basically bottled up in two or three big companies."
    },
    {
      "id": 660,
      "start": 2961.2,
      "end": 2965.12,
      "text": "And so, you know, the open source thing is also just proliferating knowledge. And then that"
    },
    {
      "id": 661,
      "start": 2965.12,
      "end": 2969.8399999999997,
      "text": "knowledge is generating a lot of new people. And so I, you know, you know, say, as you guys have"
    },
    {
      "id": 662,
      "start": 2969.8399999999997,
      "end": 2974.72,
      "text": "all seen sitting here today, AI researchers are at an enormous premium. You know, AI researchers today"
    },
    {
      "id": 663,
      "start": 2974.72,
      "end": 2979.3599999999997,
      "text": "are getting paid more than professional athletes. Right. Like, you know, and that's right. That's the"
    },
    {
      "id": 664,
      "start": 2979.3599999999997,
      "end": 2984.0,
      "text": "supply demand imbalance. There aren't enough of them to go around. But, you know, again, shortages create"
    },
    {
      "id": 665,
      "start": 2984.0,
      "end": 2990.08,
      "text": "gluts. The number of smart people in the world who are coming up to speed very quickly on how to build"
    },
    {
      "id": 666,
      "start": 2990.08,
      "end": 2995.04,
      "text": "these things. I mean, some of the best AI people in the world are like 22, 23, 24. Like, you know,"
    },
    {
      "id": 667,
      "start": 2995.04,
      "end": 2998.96,
      "text": "kind of by definition, they haven't been in the field that long. You know, they can't have been"
    },
    {
      "id": 668,
      "start": 2998.96,
      "end": 3002.96,
      "text": "experts their whole lives. Right. So, you know, they kind of have to have come up to speed over"
    },
    {
      "id": 669,
      "start": 3002.96,
      "end": 3007.2,
      "text": "the course of the last four or five years. And if they've been able to do that, then there's going"
    },
    {
      "id": 670,
      "start": 3007.2,
      "end": 3011.6,
      "text": "to be a lot more in the future that are going to do that. And so just the sort of spread of the"
    },
    {
      "id": 671,
      "start": 3011.6,
      "end": 3016.64,
      "text": "level of expertise on this technology is happening now very quickly. So, yeah, I mean, I think it's still,"
    },
    {
      "id": 672,
      "start": 3016.64,
      "end": 3020.72,
      "text": "like I said, I think it's still a race. And by the way, you know, look, the long-term answer may"
    },
    {
      "id": 673,
      "start": 3020.72,
      "end": 3025.6,
      "text": "well just be both. You know, like I said, if you believe my pyramid industry structure,"
    },
    {
      "id": 674,
      "start": 3025.6,
      "end": 3030.72,
      "text": "then there will certainly be a large business of whatever is the smartest thing, almost regardless"
    },
    {
      "id": 675,
      "start": 3030.72,
      "end": 3036.4,
      "text": "of how much it costs. But there will also be this just giant volume market of smaller models"
    },
    {
      "id": 676,
      "start": 3036.4,
      "end": 3041.52,
      "text": "everywhere, which is what we're also seeing. Yep. Yep. Another question you had posed at that"
    },
    {
      "id": 677,
      "start": 3041.52,
      "end": 3045.68,
      "text": "point in time was, will incumbents versus startups win? And at that point in time, I think there was a"
    },
    {
      "id": 678,
      "start": 3045.68,
      "end": 3051.12,
      "text": "mixed bag of where the incumbents were approaching AI. I think that's radically changed in the last"
    },
    {
      "id": 679,
      "start": 3051.12,
      "end": 3058.24,
      "text": "two years. And then on the counter example, the blossoming of startups increasingly now may be"
    },
    {
      "id": 680,
      "start": 3058.24,
      "end": 3062.7999999999997,
      "text": "migrating into the incumbent category, just how big they've become since that time. You want to take"
    },
    {
      "id": 681,
      "start": 3062.7999999999997,
      "end": 3066.96,
      "text": "that question and give your assessment of where the state of the world is?"
    },
    {
      "id": 682,
      "start": 3066.96,
      "end": 3070.7999999999997,
      "text": "Yeah. So, I mean, look, you know, big companies that are definitely, you know, playing hard, you know,"
    },
    {
      "id": 683,
      "start": 3070.8,
      "end": 3076.0,
      "text": "Google's playing hard, Meta's playing hard, Amazon, Microsoft, you know, there's a bunch of these"
    },
    {
      "id": 684,
      "start": 3076.0,
      "end": 3079.76,
      "text": "companies that are, you know, that are kind of in there, you know, very aggressively. And then you've"
    },
    {
      "id": 685,
      "start": 3079.76,
      "end": 3085.44,
      "text": "got these, you know, what we call the new incumbents like Anthropic and OpenAI. But you also have like,"
    },
    {
      "id": 686,
      "start": 3085.44,
      "end": 3088.4,
      "text": "you know, even in the last two years, you've had this birth of all of a sudden, like brand new"
    },
    {
      "id": 687,
      "start": 3088.4,
      "end": 3093.92,
      "text": "companies that are almost instant incumbents. And you could say XAI is one of those. Mistral, by the way,"
    },
    {
      "id": 688,
      "start": 3093.92,
      "end": 3098.0800000000004,
      "text": "Mistral is the great outlier to my Europe thing from earlier, like Mistral is actually doing very well,"
    },
    {
      "id": 689,
      "start": 3098.08,
      "end": 3103.36,
      "text": "Mistral is sort of the European kind of, you know, French national European continental, you know,"
    },
    {
      "id": 690,
      "start": 3103.36,
      "end": 3108.4,
      "text": "kind of AI champion. Sort of the, you know, the exception that proves the rule. But, you know,"
    },
    {
      "id": 691,
      "start": 3108.4,
      "end": 3111.52,
      "text": "there's a bunch of these now that are like, you know, doing quite well and are kind of becoming new"
    },
    {
      "id": 692,
      "start": 3111.52,
      "end": 3115.04,
      "text": "incumbents. And then of course, there's tons of startups, by the way, there's and then there's"
    },
    {
      "id": 693,
      "start": 3115.04,
      "end": 3119.04,
      "text": "there's actual foundation model startups, right. And so, you know, we funded, you know, we funded"
    },
    {
      "id": 694,
      "start": 3119.04,
      "end": 3124.16,
      "text": "Ilya Suskiver out of OpenAI to do a new foundation model company. We funded Mira Mirati also out of OpenAI."
    },
    {
      "id": 695,
      "start": 3124.16,
      "end": 3128.0,
      "text": "We funded Fei-Fei Li out of Stanford to do a world model foundation model company. And so,"
    },
    {
      "id": 696,
      "start": 3128.0,
      "end": 3132.24,
      "text": "you know, there, you know, there are new swings all, you know, all early, but very promising"
    },
    {
      "id": 697,
      "start": 3133.12,
      "end": 3137.6,
      "text": "for to kind of build, you know, new incumbents quickly. And so, you know, that's all happening."
    },
    {
      "id": 698,
      "start": 3137.6,
      "end": 3141.04,
      "text": "And then, and then, you know, and then on top of that, there's just this giant explosion of AI"
    },
    {
      "id": 699,
      "start": 3141.04,
      "end": 3145.28,
      "text": "application companies, right. And so there's basically companies that then usually startups"
    },
    {
      "id": 700,
      "start": 3145.28,
      "end": 3149.84,
      "text": "that basically take the technology and then, you know, field it in a specific domain, whether that's law"
    },
    {
      "id": 701,
      "start": 3149.84,
      "end": 3157.44,
      "text": "or medicine or education or, you know, creativity or whatever. But again, here, it's just like,"
    },
    {
      "id": 702,
      "start": 3157.44,
      "end": 3162.4,
      "text": "it's amazing kind of how, how sophisticated things are getting very quickly. So,"
    },
    {
      "id": 703,
      "start": 3163.52,
      "end": 3166.6400000000003,
      "text": "I'll just talk about the application companies for a moment. So like an application company,"
    },
    {
      "id": 704,
      "start": 3166.6400000000003,
      "end": 3170.56,
      "text": "like classic examples, like a cursor is like an application company. So they take the core AI"
    },
    {
      "id": 705,
      "start": 3170.56,
      "end": 3174.8,
      "text": "capability, which they purchased by the drink from, you know, Anthropic or OpenAI or Google,"
    },
    {
      "id": 706,
      "start": 3174.8,
      "end": 3179.92,
      "text": "you know, tokens by the drink. And then they, they, they build a code, basically a code editor,"
    },
    {
      "id": 707,
      "start": 3179.92,
      "end": 3185.2000000000003,
      "text": "what we used to call an IDE integrated development environment, or basically like a software creation"
    },
    {
      "id": 708,
      "start": 3185.2000000000003,
      "end": 3191.44,
      "text": "system. So they build like an AI coding system on top of the Anthropic or OpenAI or whatever,"
    },
    {
      "id": 709,
      "start": 3191.44,
      "end": 3194.96,
      "text": "you know, kind of, kind of big models. So until then, and the, the, the critique of those companies"
    },
    {
      "id": 710,
      "start": 3194.96,
      "end": 3199.04,
      "text": "in the industry has been, oh, those are what are called, called GPT wrappers. It's kind of the pejorative."
    },
    {
      "id": 711,
      "start": 3199.04,
      "end": 3202.7200000000003,
      "text": "And the idea basically being as well, they're not actually like, they're not actually doing anything"
    },
    {
      "id": 712,
      "start": 3202.72,
      "end": 3206.64,
      "text": "that's going to preserve value because the, the actual, the, the whole point of what they're"
    },
    {
      "id": 713,
      "start": 3206.64,
      "end": 3210.72,
      "text": "doing is they're surfacing AI, but it's not their AI, the AI that's being surfaced is from somebody"
    },
    {
      "id": 714,
      "start": 3210.72,
      "end": 3214.3199999999997,
      "text": "else. And so these are kind of these paths, pass through shell things that ultimately won't have"
    },
    {
      "id": 715,
      "start": 3214.3199999999997,
      "end": 3218.3199999999997,
      "text": "value. It actually turns out what's happening is kind of the opposite of that, which is the,"
    },
    {
      "id": 716,
      "start": 3218.3199999999997,
      "end": 3223.52,
      "text": "the leading AI application companies like cursor. I mean, first of all, what they're discovering is"
    },
    {
      "id": 717,
      "start": 3223.52,
      "end": 3227.2799999999997,
      "text": "they're not just using a single AI model. They're actually, they actually, as these products get more"
    },
    {
      "id": 718,
      "start": 3227.2799999999997,
      "end": 3231.2799999999997,
      "text": "sophisticated, they actually end up using many different kinds of models that are kind of custom"
    },
    {
      "id": 719,
      "start": 3231.28,
      "end": 3236.0,
      "text": "tailored to the specific aspects of how these products work. And so they may start out using"
    },
    {
      "id": 720,
      "start": 3236.0,
      "end": 3239.28,
      "text": "one model, but they end up using a dozen models. And then in the fullness of time, it might be 50 or"
    },
    {
      "id": 721,
      "start": 3239.28,
      "end": 3243.44,
      "text": "100 different models for different aspects of the product, A, and then B, they end up building a lot"
    },
    {
      "id": 722,
      "start": 3243.44,
      "end": 3248.32,
      "text": "of their own models. And so they, they, a lot of these, the leading edge application companies are"
    },
    {
      "id": 723,
      "start": 3248.32,
      "end": 3252.1600000000003,
      "text": "actually backward integrating and actually building their own AI models because, because they have the"
    },
    {
      "id": 724,
      "start": 3252.1600000000003,
      "end": 3255.52,
      "text": "deepest understanding of their domain. They're able to build the model that's best suited to that."
    },
    {
      "id": 725,
      "start": 3256.48,
      "end": 3261.2000000000003,
      "text": "And then by the way, also AI open source, they're also able to pick up and run on open source models."
    },
    {
      "id": 726,
      "start": 3262.16,
      "end": 3266.96,
      "text": "And so if they don't like the economics of buying intelligence, you know, by the drink from a,"
    },
    {
      "id": 727,
      "start": 3266.96,
      "end": 3270.48,
      "text": "from a, from a cloud service provider, you know, they can pick up one of these open source models"
    },
    {
      "id": 728,
      "start": 3270.48,
      "end": 3274.8799999999997,
      "text": "and implement it instead, which, you know, which these companies are also doing. And so the, the best,"
    },
    {
      "id": 729,
      "start": 3274.8799999999997,
      "end": 3278.72,
      "text": "the best of the AI application companies are actually, they are actually full-fledged deep"
    },
    {
      "id": 730,
      "start": 3278.72,
      "end": 3283.12,
      "text": "technology companies actually building their own AI. And so that, you know, that's, I think..."
    },
    {
      "id": 731,
      "start": 3283.12,
      "end": 3286.56,
      "text": "All models though, right, Mark? When you think about God models versus small models,"
    },
    {
      "id": 732,
      "start": 3286.56,
      "end": 3289.6,
      "text": "as you were describing that, but that would be small. Would you categorize that as a small?"
    },
    {
      "id": 733,
      "start": 3289.6,
      "end": 3293.12,
      "text": "Well, some of them, I mean, we should, I will let them, I will let them announce, you know,"
    },
    {
      "id": 734,
      "start": 3293.12,
      "end": 3296.4,
      "text": "whatever they're doing, whenever it's appropriate, but some of them are now also doing big model"
    },
    {
      "id": 735,
      "start": 3296.4,
      "end": 3300.7999999999997,
      "text": "development. And again, this, this is also part of what, this is also part of learning just the"
    },
    {
      "id": 736,
      "start": 3300.7999999999997,
      "end": 3304.7999999999997,
      "text": "last two years. Well, so like, here's a big learning just from the last two years, which is very"
    },
    {
      "id": 737,
      "start": 3304.7999999999997,
      "end": 3307.6,
      "text": "interesting, which is two years ago or three years ago, for sure, you would have said, wow,"
    },
    {
      "id": 738,
      "start": 3307.6,
      "end": 3312.08,
      "text": "open AI is like way out ahead. And like, it's probably going to be impossible for anybody to catch up."
    },
    {
      "id": 739,
      "start": 3312.08,
      "end": 3314.88,
      "text": "And then it's like, okay, well, Anthropic caught up. And so, but you know, they came out of"
    },
    {
      "id": 740,
      "start": 3314.88,
      "end": 3318.32,
      "text": "open AI. And so they had all the secrets, you know, whatever. And so knew how to do it. And so,"
    },
    {
      "id": 741,
      "start": 3318.32,
      "end": 3322.32,
      "text": "okay, they caught up, but surely nobody can catch up after them. And then very quickly after that,"
    },
    {
      "id": 742,
      "start": 3322.32,
      "end": 3326.32,
      "text": "there were a raft of other companies that caught up very fast. And, and XAI is maybe the best"
    },
    {
      "id": 743,
      "start": 3326.32,
      "end": 3331.6,
      "text": "example of that, which is like, you know, XAI, you know, Elon's company, XAI is the company name,"
    },
    {
      "id": 744,
      "start": 3331.6,
      "end": 3336.4,
      "text": "Grok is the consumer product version of it. XAI basically caught up to, you know, state of the art"
    },
    {
      "id": 745,
      "start": 3336.4,
      "end": 3340.7200000000003,
      "text": "open AI Anthropic level in, in like less than 12 months from a standing start. Right. And so,"
    },
    {
      "id": 746,
      "start": 3340.72,
      "end": 3345.9199999999996,
      "text": "and again, that, that kind of argues against any kind of permanent lead, right. By, by any one"
    },
    {
      "id": 747,
      "start": 3345.9199999999996,
      "end": 3349.6,
      "text": "incumbent, that's just going to basically be able to lock the entire market down. Like if you can catch"
    },
    {
      "id": 748,
      "start": 3349.6,
      "end": 3353.2,
      "text": "up like that. And then, and then as we, as we discussed the, you know, the, the China part is"
    },
    {
      "id": 749,
      "start": 3353.2,
      "end": 3358.0,
      "text": "all new in the last year, right. The deep seek, this, the deep seek moment, I think was in January"
    },
    {
      "id": 750,
      "start": 3358.0,
      "end": 3363.12,
      "text": "or February of this year. Right. So less than 12 months ago. And so, and now you've got like four"
    },
    {
      "id": 751,
      "start": 3363.12,
      "end": 3366.9599999999996,
      "text": "Chinese companies that have effectively caught up. And so, you know, so it's like, all right. I mean,"
    },
    {
      "id": 752,
      "start": 3366.96,
      "end": 3370.64,
      "text": "you know, again, this is, these are, these are trillion dollar questions, not answers, but it's"
    },
    {
      "id": 753,
      "start": 3370.64,
      "end": 3375.44,
      "text": "just like, wow. Okay. Like it's, it's one of these things where once somebody proves that it's capable,"
    },
    {
      "id": 754,
      "start": 3375.44,
      "end": 3379.68,
      "text": "it seems to not be that hard for other people to be able to catch up even people with far less"
    },
    {
      "id": 755,
      "start": 3379.68,
      "end": 3384.32,
      "text": "resources. And so, you know, I don't know what that does. Maybe it makes you slightly more skeptical"
    },
    {
      "id": 756,
      "start": 3384.32,
      "end": 3388.64,
      "text": "in the long run economics of, of the big players. On the other hand, maybe it makes you like more"
    },
    {
      "id": 757,
      "start": 3388.64,
      "end": 3393.52,
      "text": "bullish about the startup ecosystem. It certainly should make you more bullish about startup application"
    },
    {
      "id": 758,
      "start": 3393.52,
      "end": 3396.8,
      "text": "companies, right. Being able to do interesting things, which is why we're so excited about"
    },
    {
      "id": 759,
      "start": 3396.8,
      "end": 3401.6000000000004,
      "text": "that. You know, it should make you probably, you know, a bit more excited about, about certainly"
    },
    {
      "id": 760,
      "start": 3401.6000000000004,
      "end": 3407.6000000000004,
      "text": "about China. Yeah. On the other hand, the Chinese competition, putting pressure on the American"
    },
    {
      "id": 761,
      "start": 3407.6000000000004,
      "end": 3410.6400000000003,
      "text": "system to not screw itself up is very positive. So it should probably make you a little bit more"
    },
    {
      "id": 762,
      "start": 3410.6400000000003,
      "end": 3415.76,
      "text": "bullish on the U.S. And so I, yeah, I think, you know, these are, yeah, these are, yeah, these are"
    },
    {
      "id": 763,
      "start": 3415.76,
      "end": 3419.52,
      "text": "our live dynamics. And I think we still need more time to pass before we know the exact answer."
    },
    {
      "id": 764,
      "start": 3419.52,
      "end": 3422.8,
      "text": "I should say this sometimes, cause sometimes I don't, sometimes I freak people out when I say these are"
    },
    {
      "id": 765,
      "start": 3422.8,
      "end": 3429.04,
      "text": "open questions. When a company is confronted with fundamentally open strategic or economic"
    },
    {
      "id": 766,
      "start": 3429.04,
      "end": 3434.4,
      "text": "questions, it's often a big problem because a company needs to have a strategy and the strategy"
    },
    {
      "id": 767,
      "start": 3434.4,
      "end": 3440.32,
      "text": "needs to be very specific. And a company has to make like very specific concrete choices about where"
    },
    {
      "id": 768,
      "start": 3440.32,
      "end": 3444.0,
      "text": "it like deploys investment dollars and personnel. And like the strategy has to be like logical and"
    },
    {
      "id": 769,
      "start": 3444.0,
      "end": 3448.8,
      "text": "coherent or the company kind of collapses into chaos. And so like companies like need to answer these"
    },
    {
      "id": 770,
      "start": 3448.8,
      "end": 3454.6400000000003,
      "text": "questions and if they get the answers wrong, they're really in trouble. Venture, we have our issues in"
    },
    {
      "id": 771,
      "start": 3454.6400000000003,
      "end": 3459.28,
      "text": "venture, but a huge advantage that we have is we don't have to, we can bet on multiple strategies at"
    },
    {
      "id": 772,
      "start": 3459.28,
      "end": 3464.2400000000002,
      "text": "the same time. Right. And we are doing this. So we are betting on big models and small models and"
    },
    {
      "id": 773,
      "start": 3464.2400000000002,
      "end": 3469.76,
      "text": "proprietary models and open source models, right. And, you know, and foundation models and applications,"
    },
    {
      "id": 774,
      "start": 3469.76,
      "end": 3474.5600000000004,
      "text": "right. And consumer and enterprise. And so the portfolio approach, the nature of it is like we"
    },
    {
      "id": 775,
      "start": 3474.56,
      "end": 3480.4,
      "text": "we are aggressively basically we are aggressively investing behind every strategy that we've"
    },
    {
      "id": 776,
      "start": 3480.4,
      "end": 3484.48,
      "text": "identified that we think has a plausible chance of working, even when that those even when that's"
    },
    {
      "id": 777,
      "start": 3484.48,
      "end": 3488.16,
      "text": "contradictory to another strategy that we're investing in. And one is just like the world's"
    },
    {
      "id": 778,
      "start": 3488.16,
      "end": 3491.52,
      "text": "messy and probably a bunch of things are going to work. And so like there's not going to be clean yes"
    },
    {
      "id": 779,
      "start": 3491.52,
      "end": 3494.7999999999997,
      "text": "or no answers to a bunch of this. Like a lot of the answers to this, I think are just going to be"
    },
    {
      "id": 780,
      "start": 3494.7999999999997,
      "end": 3499.04,
      "text": "and answers. But the other is like if one of these strategies doesn't work, like, you know, we're not"
    },
    {
      "id": 781,
      "start": 3499.04,
      "end": 3503.6,
      "text": "we're not trying to hedge per se, but, you know, we're going to have representation in the portfolio of the"
    },
    {
      "id": 782,
      "start": 3503.6,
      "end": 3507.68,
      "text": "alternate strategy. And so we're going to have multiple ways to win. So anyway, that's that's"
    },
    {
      "id": 783,
      "start": 3507.68,
      "end": 3512.16,
      "text": "the goal. That's the theory of why we are, you know, kind of taking the approach in the space that"
    },
    {
      "id": 784,
      "start": 3512.16,
      "end": 3516.4,
      "text": "we're taking. And that's why I have a big smile on my face when I say that there are these big open"
    },
    {
      "id": 785,
      "start": 3516.4,
      "end": 3522.16,
      "text": "questions because I think that actually works to our advantage. It's a good segue to A16Z questions"
    },
    {
      "id": 786,
      "start": 3522.16,
      "end": 3528.72,
      "text": "because we've gotten a few in so far and we have a few that were send ins ahead as well. So I'll start"
    },
    {
      "id": 787,
      "start": 3528.72,
      "end": 3533.2799999999997,
      "text": "one with the with the broad topic. What is something you and Ben disagree and commit on?"
    },
    {
      "id": 788,
      "start": 3533.2799999999997,
      "end": 3539.6,
      "text": "Ben Bauer, Ph.D.: Disagree and commit. You know, we agree. I mean, we, as Ben and I was going to say,"
    },
    {
      "id": 789,
      "start": 3539.6,
      "end": 3542.8799999999997,
      "text": "you know, we're an old married couple, so we argue constantly, but we've been..."
    },
    {
      "id": 790,
      "start": 3542.8799999999997,
      "end": 3544.56,
      "text": "We're the romance of dead."
    },
    {
      "id": 791,
      "start": 3544.56,
      "end": 3549.6,
      "text": "Ben Bauer, Ph.D.: The romance of long dead. Yes, yes, yes, yes. The fire has long since gone out."
    },
    {
      "id": 792,
      "start": 3549.6,
      "end": 3560.56,
      "text": "Ben Bauer, Ph.D.: But yes, yes, we're in the park squabbling all the time. So, yeah, I mean, so look,"
    },
    {
      "id": 793,
      "start": 3560.56,
      "end": 3563.7599999999998,
      "text": "we debate everything. We argue about everything. That said, like, you know, one of the things that's"
    },
    {
      "id": 794,
      "start": 3563.7599999999998,
      "end": 3567.52,
      "text": "made our partnership work is like we do tend to come to the same conclusion. Like each of us is"
    },
    {
      "id": 795,
      "start": 3567.52,
      "end": 3571.04,
      "text": "open to being persuaded by the other one. And so we end up coming, you know, we end up coming to the same"
    },
    {
      "id": 796,
      "start": 3571.04,
      "end": 3575.68,
      "text": "conclusion most of the time. So I would say there aren't like, there aren't, I was going to say,"
    },
    {
      "id": 797,
      "start": 3575.68,
      "end": 3579.04,
      "text": "specifically sitting here today, there are like zero issues where I'm sitting here and I'm like,"
    },
    {
      "id": 798,
      "start": 3579.04,
      "end": 3582.4,
      "text": "I can't believe, you know, I just, I can't believe I'm, you know, I'm putting up with this crazy thing"
    },
    {
      "id": 799,
      "start": 3582.4,
      "end": 3586.88,
      "text": "on his, on his part that he's doing that I really disagree with, but I feel like I have to commit to,"
    },
    {
      "id": 800,
      "start": 3586.88,
      "end": 3592.16,
      "text": "or I don't think vice versa. And so, so we don't have any of those. You know, quite honestly,"
    },
    {
      "id": 801,
      "start": 3592.16,
      "end": 3597.2,
      "text": "the biggest thing I say, the biggest thing that I, that he and I, the biggest thing that he and I"
    },
    {
      "id": 802,
      "start": 3597.2,
      "end": 3601.36,
      "text": "discuss is this, by the way, this is not, this is not the most important thing we're doing, but it is"
    },
    {
      "id": 803,
      "start": 3601.36,
      "end": 3605.6,
      "text": "a topic since somebody asked the question. The biggest thing he and I discuss where I, I don't know,"
    },
    {
      "id": 804,
      "start": 3605.6,
      "end": 3608.88,
      "text": "maybe I'm always like second guessing myself, or I never quite know where I should come out on"
    },
    {
      "id": 805,
      "start": 3608.88,
      "end": 3613.36,
      "text": "it, that he and I talked about a lot is just like basically the public footprint of the company."
    },
    {
      "id": 806,
      "start": 3614.56,
      "end": 3618.88,
      "text": "So like our presence, our presence in the, our presence in the world in terms of like public"
    },
    {
      "id": 807,
      "start": 3618.88,
      "end": 3626.88,
      "text": "statements, controversy, you know, how we vocalize and express our views on things. And I would just"
    },
    {
      "id": 808,
      "start": 3626.88,
      "end": 3630.1600000000003,
      "text": "say there like, you know, there's a real, there's a tension, there's a real, it's, you know, maybe"
    },
    {
      "id": 809,
      "start": 3630.1600000000003,
      "end": 3634.6400000000003,
      "text": "obvious, but like a very important tension. Like generally speaking, the more out there we are,"
    },
    {
      "id": 810,
      "start": 3634.64,
      "end": 3637.7599999999998,
      "text": "and the more outspoken we are, and the more controversial we are, the better for the,"
    },
    {
      "id": 811,
      "start": 3638.24,
      "end": 3640.4,
      "text": "better for the business in the sense of the entrepreneurs love it."
    },
    {
      "id": 812,
      "start": 3642.8799999999997,
      "end": 3647.3599999999997,
      "text": "The founders want to work with, it was very clear at this point, the founders want to work with"
    },
    {
      "id": 813,
      "start": 3648.64,
      "end": 3654.24,
      "text": "people who basically are brave and controversial and take controversial stands and articulate things"
    },
    {
      "id": 814,
      "start": 3654.24,
      "end": 3657.12,
      "text": "clearly. And they want that for a bunch of reasons. One is because it's a demonstration of"
    },
    {
      "id": 815,
      "start": 3657.12,
      "end": 3661.6,
      "text": "courage, which they appreciate. But the other is because it, it teaches them who we are before they"
    },
    {
      "id": 816,
      "start": 3661.6,
      "end": 3666.96,
      "text": "even meet us. And, and, and that has just proven to be just like this incredible competitive advantage."
    },
    {
      "id": 817,
      "start": 3666.96,
      "end": 3670.7999999999997,
      "text": "You know, long term LPs will know, like, this is why we started with a very active marketing"
    },
    {
      "id": 818,
      "start": 3670.7999999999997,
      "end": 3674.4,
      "text": "strategy from the very beginning. And like, it completely worked. Like the whole thing was,"
    },
    {
      "id": 819,
      "start": 3674.4,
      "end": 3679.04,
      "text": "if we're able to broadcast our message, and we're able to basically be very clear in what we believe,"
    },
    {
      "id": 820,
      "start": 3679.04,
      "end": 3682.3199999999997,
      "text": "even to the point where it's controversial, like, the best founders in the world are going to"
    },
    {
      "id": 821,
      "start": 3682.3199999999997,
      "end": 3685.92,
      "text": "understand us before they even walk in the door. Right? And they're going to, they're going to know us"
    },
    {
      "id": 822,
      "start": 3685.92,
      "end": 3689.2,
      "text": "even before they've met us, as opposed to everybody else in venture, at least at the time,"
    },
    {
      "id": 823,
      "start": 3689.2,
      "end": 3693.8399999999997,
      "text": "that was basically just like keeping everything quiet, where they, you know, the founder just has"
    },
    {
      "id": 824,
      "start": 3693.8399999999997,
      "end": 3697.04,
      "text": "no idea who these people are and what they believe. And so that, that like worked incredibly well,"
    },
    {
      "id": 825,
      "start": 3697.04,
      "end": 3701.8399999999997,
      "text": "it continues to work incredibly well. It's, by the way, it's, you know, it's generally true across"
    },
    {
      "id": 826,
      "start": 3701.8399999999997,
      "end": 3706.0,
      "text": "the industry. It's, it's, it's like generally the case. On the other hand, there are externalities to"
    },
    {
      "id": 827,
      "start": 3706.0,
      "end": 3712.56,
      "text": "being, you know, publicly visible and, and, and, and to being controversial on many fronts. We are,"
    },
    {
      "id": 828,
      "start": 3712.56,
      "end": 3715.68,
      "text": "I would say this, we are, we're very much, we're trying very hard to thread this needle. So like,"
    },
    {
      "id": 829,
      "start": 3715.68,
      "end": 3719.6,
      "text": "we're, we're not backing off of generally being a company that does a lot of outbound. We, you know,"
    },
    {
      "id": 830,
      "start": 3719.6,
      "end": 3722.96,
      "text": "we, Eric Tornberg and the team that he's built, you know, that we've talked to you guys about in"
    },
    {
      "id": 831,
      "start": 3722.96,
      "end": 3727.3599999999997,
      "text": "the past, you know, is, I, is already off to the races. You know, we're, we're gonna, you know,"
    },
    {
      "id": 832,
      "start": 3727.3599999999997,
      "end": 3731.2799999999997,
      "text": "we're tripling down on the idea of basically being the leaders and articulating the tech and business"
    },
    {
      "id": 833,
      "start": 3731.2799999999997,
      "end": 3734.7999999999997,
      "text": "issues that matter. You know, the, you know, the issues for sure that people need to be able to"
    },
    {
      "id": 834,
      "start": 3734.7999999999997,
      "end": 3739.9199999999996,
      "text": "understand. And that's proven to be very effective. By the way, a fair amount of our cons are actually"
    },
    {
      "id": 835,
      "start": 3739.9199999999996,
      "end": 3744.7999999999997,
      "text": "aimed at Washington. Because again, it's like, if you're a policymaker in Washington,"
    },
    {
      "id": 836,
      "start": 3744.8,
      "end": 3749.44,
      "text": "and you're sitting there 3000, 3000 miles away, and your entire information source is like East"
    },
    {
      "id": 837,
      "start": 3749.44,
      "end": 3754.4,
      "text": "Coast newspapers that hate Silicon Valley, like that's bad. And so, you know, our ability to like"
    },
    {
      "id": 838,
      "start": 3754.4,
      "end": 3758.88,
      "text": "broadcast, you know, inform points of view on technology, we just, we meet people in DC all"
    },
    {
      "id": 839,
      "start": 3758.88,
      "end": 3762.7200000000003,
      "text": "the time, who say, yeah, I, you know, most of what I know about this topic, I learned from you guys,"
    },
    {
      "id": 840,
      "start": 3762.7200000000003,
      "end": 3766.32,
      "text": "because I listened to the podcast, I read the articles, I watched the YouTube channel. And so,"
    },
    {
      "id": 841,
      "start": 3766.32,
      "end": 3769.44,
      "text": "you know, we're, we're going to continue to do that. And so we, you know, over, over, over,"
    },
    {
      "id": 842,
      "start": 3769.44,
      "end": 3772.48,
      "text": "overall, we have a, you know, we're, we're kind of on our front foot on that stuff. But yeah,"
    },
    {
      "id": 843,
      "start": 3772.48,
      "end": 3776.8,
      "text": "he and I do, he and I do go back and forth a bit on exactly how, yeah, how many third rail topics"
    },
    {
      "id": 844,
      "start": 3776.8,
      "end": 3781.52,
      "text": "should we touch? And how frequently, and I would say, we're, we're, we're trying to,"
    },
    {
      "id": 845,
      "start": 3781.52,
      "end": 3785.52,
      "text": "we're trying to moderate that. As Elizabeth Taylor said, as long as I spell our name right,"
    },
    {
      "id": 846,
      "start": 3786.96,
      "end": 3791.84,
      "text": "it's oftentimes could be good in most scenarios, particularly when it comes to little tech,"
    },
    {
      "id": 847,
      "start": 3791.84,
      "end": 3799.6,
      "text": "WS. And also, I think embedded in that question is probably some degree of the relationship that you"
    },
    {
      "id": 848,
      "start": 3799.6,
      "end": 3804.48,
      "text": "and Ben have, which is now going on 30 plus years at this point. So much so that, that Mark has become"
    },
    {
      "id": 849,
      "start": 3805.68,
      "end": 3811.6,
      "text": "one person representing both. Some people refer to Mark as Andreessen Horowitz. No, lost the mark,"
    },
    {
      "id": 850,
      "start": 3811.6,
      "end": 3815.36,
      "text": "have combined just into one person. Yes."
    },
    {
      "id": 851,
      "start": 3815.36,
      "end": 3820.32,
      "text": "That's the result of 30 plus years working together. Okay. So it's been two years since"
    },
    {
      "id": 852,
      "start": 3820.32,
      "end": 3825.6800000000003,
      "text": "you've reorganized around AI, launched AD. What do you think you got most right? And in hindsight,"
    },
    {
      "id": 853,
      "start": 3825.6800000000003,
      "end": 3829.76,
      "text": "is there anything that you underestimated or missed in that decisioning process?"
    },
    {
      "id": 854,
      "start": 3829.76,
      "end": 3833.6800000000003,
      "text": "No, I mean, look, we've made, we've made plenty of mistakes. I think those were,"
    },
    {
      "id": 855,
      "start": 3833.6800000000003,
      "end": 3838.1600000000003,
      "text": "I think those were the right calls. I mean, AI was, like I said, like, you know, the whole theory,"
    },
    {
      "id": 856,
      "start": 3838.1600000000003,
      "end": 3842.2400000000002,
      "text": "back up, the whole theory of venture, the whole theory of venture that we've had from the beginning is,"
    },
    {
      "id": 857,
      "start": 3842.24,
      "end": 3846.56,
      "text": "that, you know, many people before us have had as well. That's very correct. I think is,"
    },
    {
      "id": 858,
      "start": 3846.56,
      "end": 3850.64,
      "text": "both theories like the money adventure has made when there's like a fundamental architecture shift,"
    },
    {
      "id": 859,
      "start": 3850.64,
      "end": 3855.2799999999997,
      "text": "like when there's like a fundamental change in the technology landscape. And that's been true for,"
    },
    {
      "id": 860,
      "start": 3855.2799999999997,
      "end": 3860.24,
      "text": "you know, adventure basically forever. And the reason is because if you have a fundamental change"
    },
    {
      "id": 861,
      "start": 3860.24,
      "end": 3864.4799999999996,
      "text": "in technology, then you have this period of creativity in which you can have basically aggressive,"
    },
    {
      "id": 862,
      "start": 3864.4799999999996,
      "end": 3868.08,
      "text": "you know, very aggressive kind of people, you know, kind of start these new companies and they have"
    },
    {
      "id": 863,
      "start": 3868.08,
      "end": 3872.3199999999997,
      "text": "this kind of shot to kind of come in and you kind of win categories before big companies can respond."
    },
    {
      "id": 864,
      "start": 3873.2799999999997,
      "end": 3876.88,
      "text": "If there's no fundamental change in technology, it's very hard to make startups work because the big"
    },
    {
      "id": 865,
      "start": 3876.88,
      "end": 3881.7599999999998,
      "text": "companies just end up doing everything. And so venture kind of, you know, sort of lives or dies"
    },
    {
      "id": 866,
      "start": 3881.7599999999998,
      "end": 3889.7599999999998,
      "text": "on the basis of these waves, of these transitions. And so there's always this question. I mean,"
    },
    {
      "id": 867,
      "start": 3889.7599999999998,
      "end": 3894.24,
      "text": "I would just say the best venture capital firms in history, I think, are the ones that were the most"
    },
    {
      "id": 868,
      "start": 3894.24,
      "end": 3898.9599999999996,
      "text": "aggressive at being able to navigate from wave to wave, right? And look, I was a beneficiary of this"
    },
    {
      "id": 869,
      "start": 3898.9599999999996,
      "end": 3903.7599999999998,
      "text": "when I came to Silicon Valley in 1994. You know, there was no venture firm in 1994 that was like"
    },
    {
      "id": 870,
      "start": 3903.7599999999998,
      "end": 3908.3999999999996,
      "text": "the internet venture capital firm, like it just didn't exist. But there were a set of venture"
    },
    {
      "id": 871,
      "start": 3908.3999999999996,
      "end": 3912.8799999999997,
      "text": "capital firms at the time, you know, at the time, our firm Kleiner Perkins that said, oh, this is a new"
    },
    {
      "id": 872,
      "start": 3912.8799999999997,
      "end": 3917.2,
      "text": "architecture, this is a new technology change. It seems totally crazy. Everybody says you can't make"
    },
    {
      "id": 873,
      "start": 3917.2,
      "end": 3921.04,
      "text": "money on it, whatever, whatever, these kids are nuts, but like, we're going to make those bets."
    },
    {
      "id": 874,
      "start": 3921.04,
      "end": 3926.48,
      "text": "And so they were willing to invest. And by the way, you know, KP in the 90s invested not only in us,"
    },
    {
      "id": 875,
      "start": 3926.48,
      "end": 3930.72,
      "text": "but also in Amazon and then Google and like, you know, company after company after company. They"
    },
    {
      "id": 876,
      "start": 3930.72,
      "end": 3935.2,
      "text": "invested in at home, which basically made home broadband work. You know, they invested in a"
    },
    {
      "id": 877,
      "start": 3935.2,
      "end": 3939.36,
      "text": "fleet of companies. And they were a venture capital firm that had started in the 1970s,"
    },
    {
      "id": 878,
      "start": 3939.36,
      "end": 3942.8,
      "text": "around really around what was at the time called mini computers, which was like, you know, three"
    },
    {
      "id": 879,
      "start": 3942.8,
      "end": 3948.32,
      "text": "generations of technology back. And they had navigated from wave to wave. And, you know, the same thing"
    },
    {
      "id": 880,
      "start": 3948.32,
      "end": 3951.6000000000004,
      "text": "is true for Sequoia. The same thing's true for basically any successful venture firm has been"
    },
    {
      "id": 881,
      "start": 3951.6000000000004,
      "end": 3956.56,
      "text": "a business for, you know, 30 or 40 or 50 years. And so I think in this business, like of all"
    },
    {
      "id": 882,
      "start": 3956.56,
      "end": 3961.92,
      "text": "businesses, like you just you need you need to get onto the new thing. You know, it was, I mean,"
    },
    {
      "id": 883,
      "start": 3961.92,
      "end": 3967.04,
      "text": "quite honestly, it was, I think, pretty amazing that most of the venture ecosystem just decided to sit"
    },
    {
      "id": 884,
      "start": 3967.04,
      "end": 3973.92,
      "text": "crypto out. And the number of VCs that we talked to between call it, you know, the release of the"
    },
    {
      "id": 885,
      "start": 3973.92,
      "end": 3978.56,
      "text": "Bitcoin white paper in 2009 to the beginning of the crypto war in 2021, who just basically said,"
    },
    {
      "id": 886,
      "start": 3978.56,
      "end": 3983.04,
      "text": "oh, we're not going to do crypto. It was fairly, it's like, I don't know, I never quite know what"
    },
    {
      "id": 887,
      "start": 3983.04,
      "end": 3986.0,
      "text": "to do with a VC who says, oh, there's a new wave of technology, and I'm very deliberately not going"
    },
    {
      "id": 888,
      "start": 3986.0,
      "end": 3992.64,
      "text": "to participate in it. And I'm always like, like, is that not the job? Right? Like, so, so, so, like,"
    },
    {
      "id": 889,
      "start": 3992.64,
      "end": 3997.6,
      "text": "I was fairly amazed by the VCs that didn't make the jump to crypto. You know, they looked briefly"
    },
    {
      "id": 890,
      "start": 3997.6,
      "end": 4001.52,
      "text": "smart during the crypto wars, I would say, of the last, you know, three or four years. And I think they"
    },
    {
      "id": 891,
      "start": 4001.52,
      "end": 4006.32,
      "text": "probably look maybe a little bit less smart now. You know, AI is another one of these where there"
    },
    {
      "id": 892,
      "start": 4006.32,
      "end": 4009.28,
      "text": "are certain firms that are jumping all over it. And there are certain firms that are just kind of"
    },
    {
      "id": 893,
      "start": 4009.28,
      "end": 4014.16,
      "text": "sitting back and letting it happen. And, and by the way, there were certain firms that never made"
    },
    {
      "id": 894,
      "start": 4014.16,
      "end": 4017.28,
      "text": "it to the internet. I mean, there were, there were firms that were very well known in the 80s,"
    },
    {
      "id": 895,
      "start": 4017.28,
      "end": 4021.52,
      "text": "and very successful that just like did not make the jump to the internet, and basically just petered"
    },
    {
      "id": 896,
      "start": 4021.52,
      "end": 4024.88,
      "text": "out. And so anyway, long winded way of saying, I think, I think in this business of all businesses,"
    },
    {
      "id": 897,
      "start": 4024.88,
      "end": 4028.8,
      "text": "you have to jump, you have to jump on the new wave. And I think we got the magnitude of it,"
    },
    {
      "id": 898,
      "start": 4028.8,
      "end": 4031.76,
      "text": "of it, right, that this is like a fundamental, fundamental transformation inside the firm."
    },
    {
      "id": 899,
      "start": 4032.48,
      "end": 4038.2400000000002,
      "text": "You know, AD is, you know, AD is doing great. AD itself, I believe, is also a beneficiary of AI,"
    },
    {
      "id": 900,
      "start": 4039.2000000000003,
      "end": 4044.2400000000002,
      "text": "right, because in two ways, one is a lot of the kinds of products that AD companies build themselves"
    },
    {
      "id": 901,
      "start": 4044.2400000000002,
      "end": 4049.36,
      "text": "benefit from AI. And then also, AI is a driver of demand in other sectors of AD, like, like energy"
    },
    {
      "id": 902,
      "start": 4049.36,
      "end": 4055.04,
      "text": "and materials. And so, I, you know, I think that that generally is very consistent, and, you know,"
    },
    {
      "id": 903,
      "start": 4055.04,
      "end": 4060.8,
      "text": "is working well. By the way, you know, crypto is back, back to being a, you know, I would say,"
    },
    {
      "id": 904,
      "start": 4060.8,
      "end": 4065.04,
      "text": "an exciting industry as a consequence of all the policy changes. And then, and then there's even"
    },
    {
      "id": 905,
      "start": 4065.04,
      "end": 4068.08,
      "text": "going to be, I think, intersections, I think there's actually going to be quite a few intersections"
    },
    {
      "id": 906,
      "start": 4068.08,
      "end": 4073.84,
      "text": "between AI and crypto. And then, and then, you know, biotech also, bio and healthcare, I think,"
    },
    {
      "id": 907,
      "start": 4073.84,
      "end": 4077.52,
      "text": "are obviously going to be transformed by AI, both on the healthcare side and on the actual drug"
    },
    {
      "id": 908,
      "start": 4077.52,
      "end": 4082.32,
      "text": "discovery side. And, you know, and that's underway. And so anyway, so like the, the individual efforts"
    },
    {
      "id": 909,
      "start": 4082.32,
      "end": 4087.2000000000003,
      "text": "in the firm feel good, and suitable for the time, the inner, the interactions between the teams,"
    },
    {
      "id": 910,
      "start": 4087.2000000000003,
      "end": 4091.76,
      "text": "and the kind, the hybrid ideas, you know, the companies that are coming at these things from"
    },
    {
      "id": 911,
      "start": 4091.76,
      "end": 4096.8,
      "text": "multiple angles, you know, feels really good. You know, maybe the corollary question is like,"
    },
    {
      "id": 912,
      "start": 4096.8,
      "end": 4100.8,
      "text": "you know, what do we feel like we're missing right now? And I think the answer is really not,"
    },
    {
      "id": 913,
      "start": 4100.8,
      "end": 4104.96,
      "text": "like, I don't, I don't think like right now, we're not missing a vertical. Like, I don't, like,"
    },
    {
      "id": 914,
      "start": 4104.96,
      "end": 4108.8,
      "text": "as of right now, like, there's not like a specific vertical of like, I don't know, whatever that,"
    },
    {
      "id": 915,
      "start": 4108.8,
      "end": 4111.52,
      "text": "like, where we just like, oh, we just need, you know, we need the equivalent of a new,"
    },
    {
      "id": 916,
      "start": 4111.52,
      "end": 4114.64,
      "text": "of a new unit or the equivalent of a new, you know, new fund or whatever. I don't,"
    },
    {
      "id": 917,
      "start": 4114.64,
      "end": 4118.320000000001,
      "text": "I don't see that at the moment. I think it's more executing extremely well in the verticals that we"
    },
    {
      "id": 918,
      "start": 4118.320000000001,
      "end": 4122.0,
      "text": "have in front of us. And, and then, you know, being the best possible partner to the, to the"
    },
    {
      "id": 919,
      "start": 4122.0,
      "end": 4130.240000000001,
      "text": "portfolio companies. Yeah, actually, on the point of AD, because AI is creating, and there's a lot of"
    },
    {
      "id": 920,
      "start": 4130.240000000001,
      "end": 4136.8,
      "text": "talk around AI taking jobs, et cetera, ironically enough, the jobs in AD sectors have never been more"
    },
    {
      "id": 921,
      "start": 4136.8,
      "end": 4141.280000000001,
      "text": "in demand in the physical world related to energy, related, obviously, to data center build-out,"
    },
    {
      "id": 922,
      "start": 4141.28,
      "end": 4146.08,
      "text": "et cetera. So like the, the pendulum, it seems like also is, is swinging from just an accelerant"
    },
    {
      "id": 923,
      "start": 4146.08,
      "end": 4152.08,
      "text": "standpoint from, from a society point of view. You talked about the importance of society also"
    },
    {
      "id": 924,
      "start": 4152.08,
      "end": 4156.4,
      "text": "needing to be ready for tech adoption. Like, have you seen that accelerating of recently? What's your"
    },
    {
      "id": 925,
      "start": 4156.4,
      "end": 4164.08,
      "text": "sentiment of, of how to actually increase that just to also make sure the convergence of adoption also"
    },
    {
      "id": 926,
      "start": 4164.08,
      "end": 4167.12,
      "text": "falls in line with, with how quickly tech is, is actually being implemented?"
    },
    {
      "id": 927,
      "start": 4167.12,
      "end": 4172.08,
      "text": "Yeah. So, you know, look, we've talked about this before, but, um, you know, for a very long time,"
    },
    {
      "id": 928,
      "start": 4172.08,
      "end": 4178.5599999999995,
      "text": "tech was just not a very relevant, look, if you go back over like whatever, 300 years, like there's"
    },
    {
      "id": 929,
      "start": 4178.5599999999995,
      "end": 4183.2,
      "text": "just like recurring waves of like total panic and freak out caused by new technology, or even you go"
    },
    {
      "id": 930,
      "start": 4183.2,
      "end": 4186.88,
      "text": "back 500 years, you go back to the printing press, you know, which basically was hand in hand with the,"
    },
    {
      "id": 931,
      "start": 4186.88,
      "end": 4191.76,
      "text": "the sort of creation of product, Protestantism, which really changed things. Um, and then, um, you know,"
    },
    {
      "id": 932,
      "start": 4191.76,
      "end": 4195.360000000001,
      "text": "you go, you go back to, um, you know, there, there were just always kind of, you know, continuous"
    },
    {
      "id": 933,
      "start": 4195.360000000001,
      "end": 4198.56,
      "text": "panics there, you know, there have been, there have been multiple waves of automation panics for the"
    },
    {
      "id": 934,
      "start": 4198.56,
      "end": 4203.12,
      "text": "last 200 years. You know, a lot of the foundational panic under Marxism was basically a fear of, of,"
    },
    {
      "id": 935,
      "start": 4203.12,
      "end": 4208.72,
      "text": "of, of, of, of the elimination of jobs through the application of automation. Um, uh, you know,"
    },
    {
      "id": 936,
      "start": 4208.72,
      "end": 4211.6,
      "text": "a lot of the same arguments you heard today about like, AI is going to centralize all the wealth and"
    },
    {
      "id": 937,
      "start": 4211.6,
      "end": 4215.04,
      "text": "a handful of a few people and everybody else is going to be poor and immiserated like that. That"
    },
    {
      "id": 938,
      "start": 4215.04,
      "end": 4220.4,
      "text": "basically is what Marx used to say, um, which I think was by the way wrong then and is wrong now,"
    },
    {
      "id": 939,
      "start": 4220.4,
      "end": 4224.32,
      "text": "which we could talk about, but, um, you know, and then even like in the 1960s, there was this whole"
    },
    {
      "id": 940,
      "start": 4224.32,
      "end": 4229.5199999999995,
      "text": "panic around, around AI, um, uh, replacing all the jobs. There was this, there's this great, uh, it's"
    },
    {
      "id": 941,
      "start": 4229.5199999999995,
      "end": 4232.56,
      "text": "long, long forgotten, but it was a big deal at the time during the Johnson administration."
    },
    {
      "id": 942,
      "start": 4233.36,
      "end": 4236.72,
      "text": "You read these AI pause letters today, you know, the, this one that just came out a few weeks ago,"
    },
    {
      "id": 943,
      "start": 4236.72,
      "end": 4243.76,
      "text": "that Prince Harry, uh, uh, headlined of all people. Um, and, um, uh, uh, you know, he takes about AI is"
    },
    {
      "id": 944,
      "start": 4243.76,
      "end": 4248.320000000001,
      "text": "going to ruin everything. And it's like, and then it says that 1964, there was basically a group of"
    },
    {
      "id": 945,
      "start": 4248.320000000001,
      "end": 4254.16,
      "text": "like the leading lights in academia, science and, uh, you know, um, kind of public affairs that there"
    },
    {
      "id": 946,
      "start": 4254.16,
      "end": 4257.6,
      "text": "was this thing called the triple committee, uh, the committee for the triple revolution. If you do"
    },
    {
      "id": 947,
      "start": 4257.6,
      "end": 4261.84,
      "text": "a Google search on, uh, it's like committee for the triple revolution, Johnson white house or whatever,"
    },
    {
      "id": 948,
      "start": 4261.84,
      "end": 4266.0,
      "text": "you'll, you'll, this thing will pop up. Um, and, you know, it was, it was a very similar kind of"
    },
    {
      "id": 949,
      "start": 4266.0,
      "end": 4269.360000000001,
      "text": "manifesto of like, we need to stop the march of technology today or we're going to ruin everything."
    },
    {
      "id": 950,
      "start": 4269.92,
      "end": 4273.68,
      "text": "Um, and, and then, you know, even in the course of the last 20 years, there was like a big,"
    },
    {
      "id": 951,
      "start": 4273.76,
      "end": 4277.92,
      "text": "panic around, um, uh, actually outsourcing in the two thousands was going to take all the jobs."
    },
    {
      "id": 952,
      "start": 4277.92,
      "end": 4281.92,
      "text": "And then it was actually, it was actually robots weirdly enough in the 2010s, which is amazing"
    },
    {
      "id": 953,
      "start": 4281.92,
      "end": 4284.56,
      "text": "because robots didn't even work in the 2010s and they kind of, you know, still don't."
    },
    {
      "id": 954,
      "start": 4285.2,
      "end": 4289.360000000001,
      "text": "Um, but, uh, you know, there's a panic around that and now there's kind of whatever level of AI panic."
    },
    {
      "id": 955,
      "start": 4289.360000000001,
      "end": 4293.280000000001,
      "text": "Um, and so like, you know, like I would just say like, look, the, you know, the way I would describe"
    },
    {
      "id": 956,
      "start": 4293.280000000001,
      "end": 4297.4400000000005,
      "text": "it is, you know, we in Silicon Valley have always wanted the work that we do to matter."
    },
    {
      "id": 957,
      "start": 4297.4400000000005,
      "end": 4301.6,
      "text": "Um, you know, we spend most of our time quite honestly with people telling us that everything that"
    },
    {
      "id": 958,
      "start": 4301.6,
      "end": 4303.68,
      "text": "we're doing is stupid and won't work."
    },
    {
      "id": 959,
      "start": 4303.68,
      "end": 4305.04,
      "text": "Um, like that's the default position."
    },
    {
      "id": 960,
      "start": 4305.68,
      "end": 4309.68,
      "text": "Um, you know, and then basically that flips at some point into panic about how it's going to ruin"
    },
    {
      "id": 961,
      "start": 4309.68,
      "end": 4310.08,
      "text": "everything."
    },
    {
      "id": 962,
      "start": 4310.08,
      "end": 4314.0,
      "text": "Um, you know, it's, it's easy sitting out here to be cynical about that."
    },
    {
      "id": 963,
      "start": 4314.160000000001,
      "end": 4318.88,
      "text": "Um, especially when you kind of see the patterns over time, I, you know, my view is we need to be"
    },
    {
      "id": 964,
      "start": 4318.88,
      "end": 4321.360000000001,
      "text": "actually very respectful of that and we need to be very aware of that."
    },
    {
      "id": 965,
      "start": 4321.360000000001,
      "end": 4325.280000000001,
      "text": "And, and basically that we, you know, I use the metaphor where the doctor caught the bus,"
    },
    {
      "id": 966,
      "start": 4325.280000000001,
      "end": 4326.88,
      "text": "like we always wanted to work on things that matter."
    },
    {
      "id": 967,
      "start": 4326.88,
      "end": 4328.08,
      "text": "We are working on things that matter."
    },
    {
      "id": 968,
      "start": 4328.08,
      "end": 4332.24,
      "text": "Uh, people in the rest of society actually really do care about these things."
    },
    {
      "id": 969,
      "start": 4332.24,
      "end": 4335.76,
      "text": "Um, and, you know, it's our responsibility to think that all through very carefully and to"
    },
    {
      "id": 970,
      "start": 4335.76,
      "end": 4339.4400000000005,
      "text": "do a good job, um, you know, both not just building the technology, but also explaining it."
    },
    {
      "id": 971,
      "start": 4339.4400000000005,
      "end": 4342.56,
      "text": "You know, look, I, you know, I think we have a real obligation to, uh, you know, to really"
    },
    {
      "id": 972,
      "start": 4342.56,
      "end": 4344.4800000000005,
      "text": "explain ourselves and engage on these issues."
    },
    {
      "id": 973,
      "start": 4344.4800000000005,
      "end": 4348.56,
      "text": "Um, in terms of how to measure how it's going, you know, it's, it's sort of the classic social"
    },
    {
      "id": 974,
      "start": 4348.56,
      "end": 4353.04,
      "text": "science question, um, uh, which is like, okay, if you want to understand basically,"
    },
    {
      "id": 975,
      "start": 4353.84,
      "end": 4357.76,
      "text": "you know, patterns of people, there's basically two ways to understand what people are doing"
    },
    {
      "id": 976,
      "start": 4357.76,
      "end": 4358.24,
      "text": "and thinking."
    },
    {
      "id": 977,
      "start": 4358.8,
      "end": 4362.24,
      "text": "Um, one is to ask them and then, and then the other is to watch them."
    },
    {
      "id": 978,
      "start": 4362.24,
      "end": 4366.56,
      "text": "Um, and like every social, every social scientist, like every sociologist will, will, will, will,"
    },
    {
      "id": 979,
      "start": 4366.56,
      "end": 4370.16,
      "text": "will tell you this, which basically is you can, you can ask people, right."
    },
    {
      "id": 980,
      "start": 4370.16,
      "end": 4371.44,
      "text": "And, and the way you do that, right."
    },
    {
      "id": 981,
      "start": 4371.44,
      "end": 4375.5199999999995,
      "text": "And it's like, you know, surveys, focus groups, polls, um, you know, what they think."
    },
    {
      "id": 982,
      "start": 4375.5199999999995,
      "end": 4378.56,
      "text": "Um, uh, but then, but then you can watch them and you can do what's, you know,"
    },
    {
      "id": 983,
      "start": 4378.56,
      "end": 4382.24,
      "text": "called reveal preferences or just observe behavior, because you can actually watch their behavior."
    },
    {
      "id": 984,
      "start": 4382.24,
      "end": 4386.0,
      "text": "And, and what you often see in many areas of human activity, including politics and"
    },
    {
      "id": 985,
      "start": 4386.0,
      "end": 4390.0,
      "text": "many different aspects of society and culture over time is the answers that you get when you"
    },
    {
      "id": 986,
      "start": 4390.0,
      "end": 4392.48,
      "text": "ask people are very different than the answers that you get when you watch them."
    },
    {
      "id": 987,
      "start": 4393.12,
      "end": 4397.84,
      "text": "Um, and, and the reason is because like, I mean, you could have a bunch of theories as to why this"
    },
    {
      "id": 988,
      "start": 4397.84,
      "end": 4400.32,
      "text": "is the Marxists claim that people have false consciousness."
    },
    {
      "id": 989,
      "start": 4400.88,
      "end": 4404.4,
      "text": "The, the, the, the somewhat, the explanation I believe is just people have opinions on all kinds"
    },
    {
      "id": 990,
      "start": 4404.4,
      "end": 4407.04,
      "text": "of things, particularly when they're in a context where they get to express themselves."
    },
    {
      "id": 991,
      "start": 4407.599999999999,
      "end": 4410.8,
      "text": "Um, and they'll have a tendency to kind of express themselves in very heated ways."
    },
    {
      "id": 992,
      "start": 4410.8,
      "end": 4414.88,
      "text": "And then if you just watch their behavior, they're often a lot calmer, um, and a lot more"
    },
    {
      "id": 993,
      "start": 4414.88,
      "end": 4416.72,
      "text": "measured and a lot more rational in what they do."
    },
    {
      "id": 994,
      "start": 4416.72,
      "end": 4421.52,
      "text": "And so the AI that's playing out on AI right now, which is if you pull, if you run a survey"
    },
    {
      "id": 995,
      "start": 4421.52,
      "end": 4425.92,
      "text": "or a poll of what, for example, American voters think about AI, it's just like, they're all in"
    },
    {
      "id": 996,
      "start": 4425.92,
      "end": 4426.56,
      "text": "a total panic."
    },
    {
      "id": 997,
      "start": 4426.56,
      "end": 4427.84,
      "text": "It's like, oh my God, this is terrible."
    },
    {
      "id": 998,
      "start": 4427.84,
      "end": 4428.320000000001,
      "text": "This is awful."
    },
    {
      "id": 999,
      "start": 4428.320000000001,
      "end": 4430.400000000001,
      "text": "It's going to kill all the jobs, going to ruin everything."
    },
    {
      "id": 1000,
      "start": 4430.400000000001,
      "end": 4431.28,
      "text": "The whole thing."
    },
    {
      "id": 1001,
      "start": 4431.28,
      "end": 4434.08,
      "text": "If you watch the revealed preferences, they're all using AI."
    },
    {
      "id": 1002,
      "start": 4435.12,
      "end": 4437.759999999999,
      "text": "So they're like, they're downloading the apps."
    },
    {
      "id": 1003,
      "start": 4438.639999999999,
      "end": 4440.32,
      "text": "They're using ChatGPT in their job."
    },
    {
      "id": 1004,
      "start": 4440.96,
      "end": 4443.36,
      "text": "They're, you know, having an argument."
    },
    {
      "id": 1005,
      "start": 4443.36,
      "end": 4444.5599999999995,
      "text": "You see this online all the time now."
    },
    {
      "id": 1006,
      "start": 4444.5599999999995,
      "end": 4446.32,
      "text": "I'm having an argument with my boyfriend or girlfriend."
    },
    {
      "id": 1007,
      "start": 4446.32,
      "end": 4447.36,
      "text": "I don't understand what's happening."
    },
    {
      "id": 1008,
      "start": 4447.36,
      "end": 4448.88,
      "text": "I take the text exchange."
    },
    {
      "id": 1009,
      "start": 4448.88,
      "end": 4452.96,
      "text": "I cut and paste it into ChatGPT and I have ChatGPT explain to me what my partner is thinking"
    },
    {
      "id": 1010,
      "start": 4452.96,
      "end": 4454.4,
      "text": "and tell me how I should answer."
    },
    {
      "id": 1011,
      "start": 4454.4,
      "end": 4456.24,
      "text": "So that he's, you know, he or she is not mad at me anymore."
    },
    {
      "id": 1012,
      "start": 4456.24,
      "end": 4456.4,
      "text": "Right?"
    },
    {
      "id": 1013,
      "start": 4456.4,
      "end": 4461.04,
      "text": "So, or like, you know, I have this thing, you know, I have a skin condition and doctors, you"
    },
    {
      "id": 1014,
      "start": 4461.04,
      "end": 4466.24,
      "text": "know, and I take a photo and I'm finally like learning about my own health or I use it in my"
    },
    {
      "id": 1015,
      "start": 4466.24,
      "end": 4466.5599999999995,
      "text": "job."
    },
    {
      "id": 1016,
      "start": 4466.5599999999995,
      "end": 4469.679999999999,
      "text": "Like I, you know, I had to get this report ready for Monday morning and I ran out of time"
    },
    {
      "id": 1017,
      "start": 4469.679999999999,
      "end": 4471.759999999999,
      "text": "and like, you know, ChatGPT really saved my bacon."
    },
    {
      "id": 1018,
      "start": 4472.719999999999,
      "end": 4477.5199999999995,
      "text": "And so people in their daily lives are, I would, you know, just, you just look at the, just look"
    },
    {
      "id": 1019,
      "start": 4477.5199999999995,
      "end": 4478.24,
      "text": "at the data."
    },
    {
      "id": 1020,
      "start": 4478.24,
      "end": 4482.4,
      "text": "It's just like, they are not only using this technology, they love this technology and they"
    },
    {
      "id": 1021,
      "start": 4482.4,
      "end": 4484.32,
      "text": "love it and they're adopting as fast as they possibly can."
    },
    {
      "id": 1022,
      "start": 4484.32,
      "end": 4487.44,
      "text": "And so I, I tend to think we're going to pick with the public discussion."
    },
    {
      "id": 1023,
      "start": 4487.44,
      "end": 4490.5599999999995,
      "text": "This is going to ping pong back and forth for a while, because there is this divergence between"
    },
    {
      "id": 1024,
      "start": 4490.5599999999995,
      "end": 4491.84,
      "text": "what people are saying, what people are doing."
    },
    {
      "id": 1025,
      "start": 4492.48,
      "end": 4496.5599999999995,
      "text": "But, but I do think that the, what people are doing part is, is obviously the part, the part"
    },
    {
      "id": 1026,
      "start": 4496.5599999999995,
      "end": 4497.28,
      "text": "ultimately that wins."
    },
    {
      "id": 1027,
      "start": 4497.28,
      "end": 4500.639999999999,
      "text": "And, and I think this, by the way, I think this technology is going to be exactly the same as"
    },
    {
      "id": 1028,
      "start": 4500.639999999999,
      "end": 4503.759999999999,
      "text": "every other one, which is the thing that's going to happen here is this is just going to"
    },
    {
      "id": 1029,
      "start": 4503.759999999999,
      "end": 4504.799999999999,
      "text": "proliferate really broadly."
    },
    {
      "id": 1030,
      "start": 4504.799999999999,
      "end": 4505.92,
      "text": "It's going to freak everybody out."
    },
    {
      "id": 1031,
      "start": 4505.92,
      "end": 4509.759999999999,
      "text": "And then, you know, 20 years from now, everybody's going to be like, oh, thank God, we've got it."
    },
    {
      "id": 1032,
      "start": 4509.759999999999,
      "end": 4511.759999999999,
      "text": "Like, wouldn't life be miserable if we didn't have this?"
    },
    {
      "id": 1033,
      "start": 4511.76,
      "end": 4516.24,
      "text": "And, or, you know, five years from now or one year from now, you know, people are going to"
    },
    {
      "id": 1034,
      "start": 4516.24,
      "end": 4517.280000000001,
      "text": "reach that conclusion."
    },
    {
      "id": 1035,
      "start": 4517.280000000001,
      "end": 4520.56,
      "text": "So I'm, I'm very optimistic about where this lands."
    },
    {
      "id": 1036,
      "start": 4520.56,
      "end": 4522.320000000001,
      "text": "It's just that, you know, there will be turbulence along the way."
    },
    {
      "id": 1037,
      "start": 4522.320000000001,
      "end": 4524.96,
      "text": "I'm, I'm smiling because I also witnessed that in the wild."
    },
    {
      "id": 1038,
      "start": 4524.96,
      "end": 4526.96,
      "text": "Literally late last week, I was on the plane."
    },
    {
      "id": 1039,
      "start": 4526.96,
      "end": 4529.4400000000005,
      "text": "The guy next to me was talking to his chat to me."
    },
    {
      "id": 1040,
      "start": 4529.4400000000005,
      "end": 4534.24,
      "text": "I could see him and he was like, help me draft an escalation letter to United for the delay"
    },
    {
      "id": 1041,
      "start": 4534.24,
      "end": 4534.8,
      "text": "on this flight."
    },
    {
      "id": 1042,
      "start": 4534.8,
      "end": 4536.72,
      "text": "I was like, sir, you are on the flight right now."
    },
    {
      "id": 1043,
      "start": 4536.72,
      "end": 4538.24,
      "text": "Like, at least wait until it's over."
    },
    {
      "id": 1044,
      "start": 4541.92,
      "end": 4542.64,
      "text": "It was very good though."
    },
    {
      "id": 1045,
      "start": 4542.64,
      "end": 4545.12,
      "text": "I'm sure he had a great email crafted as a, as a part of that."
    },
    {
      "id": 1046,
      "start": 4546.88,
      "end": 4547.52,
      "text": "So, okay."
    },
    {
      "id": 1047,
      "start": 4547.52,
      "end": 4550.8,
      "text": "I'm going to switch gears to a few fun questions that, that were sent in,"
    },
    {
      "id": 1048,
      "start": 4551.4400000000005,
      "end": 4553.360000000001,
      "text": "that is intended to be a lightning round."
    },
    {
      "id": 1049,
      "start": 4553.360000000001,
      "end": 4556.72,
      "text": "So, so what, what is something you've changed your mind on recently?"
    },
    {
      "id": 1050,
      "start": 4556.72,
      "end": 4557.360000000001,
      "text": "Bonus points."
    },
    {
      "id": 1051,
      "start": 4557.360000000001,
      "end": 4558.4800000000005,
      "text": "If it was someone younger than you."
    },
    {
      "id": 1052,
      "start": 4558.48,
      "end": 4560.24,
      "text": "I mean, it's like every day."
    },
    {
      "id": 1053,
      "start": 4561.04,
      "end": 4565.28,
      "text": "It's just like, it's just a constant, you know, it's, it's almost all like what's in"
    },
    {
      "id": 1054,
      "start": 4565.28,
      "end": 4566.24,
      "text": "the realm of the possible."
    },
    {
      "id": 1055,
      "start": 4566.24,
      "end": 4568.32,
      "text": "I, I'm, I'm terrible at specific examples."
    },
    {
      "id": 1056,
      "start": 4568.32,
      "end": 4571.28,
      "text": "So I don't, I don't have one like ready at hand, but like, like I said, it's just, it's,"
    },
    {
      "id": 1057,
      "start": 4571.28,
      "end": 4571.919999999999,
      "text": "it's always."
    },
    {
      "id": 1058,
      "start": 4572.48,
      "end": 4574.32,
      "text": "Yeah, no, it's, it's often somebody showing up."
    },
    {
      "id": 1059,
      "start": 4574.32,
      "end": 4576.4,
      "text": "It's either something somebody writes or something somebody says."
    },
    {
      "id": 1060,
      "start": 4577.44,
      "end": 4580.16,
      "text": "And yeah, it's almost all, yeah, it's very frequently somebody who's very young."
    },
    {
      "id": 1061,
      "start": 4580.959999999999,
      "end": 4584.0,
      "text": "And yeah, it's just like, I would say it's, it's a, it's a routine experience."
    },
    {
      "id": 1062,
      "start": 4584.0,
      "end": 4585.599999999999,
      "text": "Good way to stay young."
    },
    {
      "id": 1063,
      "start": 4585.6,
      "end": 4586.4800000000005,
      "text": "Awesome."
    },
    {
      "id": 1064,
      "start": 4586.4800000000005,
      "end": 4590.56,
      "text": "Do you plan, speaking of young, do you plan to be cryogenically frozen?"
    },
    {
      "id": 1065,
      "start": 4590.56,
      "end": 4595.84,
      "text": "Not with current, not with current cryogenic technology."
    },
    {
      "id": 1066,
      "start": 4595.84,
      "end": 4599.4400000000005,
      "text": "The, the, the, the track record of that is not great."
    },
    {
      "id": 1067,
      "start": 4600.56,
      "end": 4603.76,
      "text": "And the stories are somewhat horrifying, but you know, we'll see."
    },
    {
      "id": 1068,
      "start": 4604.320000000001,
      "end": 4604.72,
      "text": "We'll see."
    },
    {
      "id": 1069,
      "start": 4604.72,
      "end": 4606.0,
      "text": "We still got some time."
    },
    {
      "id": 1070,
      "start": 4606.0,
      "end": 4606.56,
      "text": "Sure."
    },
    {
      "id": 1071,
      "start": 4608.0,
      "end": 4612.160000000001,
      "text": "How do you stay grounded when your influence itself may distort reality around you?"
    },
    {
      "id": 1072,
      "start": 4612.160000000001,
      "end": 4613.4400000000005,
      "text": "Yeah."
    },
    {
      "id": 1073,
      "start": 4613.44,
      "end": 4617.679999999999,
      "text": "So I was just saying the good news, you know, I would say the good news on several."
    },
    {
      "id": 1074,
      "start": 4617.679999999999,
      "end": 4619.599999999999,
      "text": "I mean, so one is look, the concern is real."
    },
    {
      "id": 1075,
      "start": 4620.24,
      "end": 4623.919999999999,
      "text": "And it's hard for me to start for me to talk about with sort of my Midwestern, you know, kind of,"
    },
    {
      "id": 1076,
      "start": 4623.919999999999,
      "end": 4627.759999999999,
      "text": "you know, Midwesterns, we, we either are very humble or we, we're really good at faking it."
    },
    {
      "id": 1077,
      "start": 4627.759999999999,
      "end": 4631.759999999999,
      "text": "But, you know, it's hard to talk about, but requires some introspection."
    },
    {
      "id": 1078,
      "start": 4631.759999999999,
      "end": 4634.16,
      "text": "But yeah, I mean, look, the reality warping effect is definitely real."
    },
    {
      "id": 1079,
      "start": 4634.799999999999,
      "end": 4638.639999999999,
      "text": "By the way, there is a very big advantage to the reality warping effect, which is being able"
    },
    {
      "id": 1080,
      "start": 4638.64,
      "end": 4644.160000000001,
      "text": "to get people to do what you want them to do. So that, you know, there is, there is another side"
    },
    {
      "id": 1081,
      "start": 4644.160000000001,
      "end": 4648.88,
      "text": "to it. But it, you know, it is a concern in terms of like having an actual accurate"
    },
    {
      "id": 1082,
      "start": 4648.88,
      "end": 4652.88,
      "text": "understanding of what's happening. I guess I'd say two things. I would say one is, you know,"
    },
    {
      "id": 1083,
      "start": 4652.88,
      "end": 4656.0,
      "text": "I mean, one is just, you know, my partners, I think are quite, you know, including Ben,"
    },
    {
      "id": 1084,
      "start": 4656.0,
      "end": 4659.76,
      "text": "are quite forthright in telling me when I'm wrong. But, you know, more generally, like,"
    },
    {
      "id": 1085,
      "start": 4659.76,
      "end": 4664.08,
      "text": "we're just, we're, we are very exposed to reality. And so, and this, and again, you know,"
    },
    {
      "id": 1086,
      "start": 4664.08,
      "end": 4667.68,
      "text": "you mentioned, I don't know, it's a way to stay young or make sure their hair never grows back or"
    },
    {
      "id": 1087,
      "start": 4667.68,
      "end": 4671.28,
      "text": "whatever. It's just like, you know, we run these experiments, you know, because we make these"
    },
    {
      "id": 1088,
      "start": 4671.28,
      "end": 4674.08,
      "text": "decisions about whether to invest or not invest, and we work with these companies and all their"
    },
    {
      "id": 1089,
      "start": 4674.08,
      "end": 4679.12,
      "text": "things. And like, you know, reality kicks in quickly. You know, the delusions don't last very"
    },
    {
      "id": 1090,
      "start": 4679.12,
      "end": 4682.72,
      "text": "long in this business, because like, you know, these, these things either work or they don't."
    },
    {
      "id": 1091,
      "start": 4683.68,
      "end": 4687.2,
      "text": "And, you know, you have these like long, elaborate, you know, discussions about, you know,"
    },
    {
      "id": 1092,
      "start": 4687.2,
      "end": 4690.32,
      "text": "theories on this and that and the other thing. And then reality just like completely smacks you"
    },
    {
      "id": 1093,
      "start": 4690.32,
      "end": 4694.719999999999,
      "text": "square in the face, you know, like you idiot, right? You know, like, you know, what were you,"
    },
    {
      "id": 1094,
      "start": 4694.719999999999,
      "end": 4698.16,
      "text": "you like, you know, this is like the, you know, the ultimate frustration of business,"
    },
    {
      "id": 1095,
      "start": 4698.16,
      "end": 4701.679999999999,
      "text": "which is also very motivating, which is the number of times that you think that you've applied superior"
    },
    {
      "id": 1096,
      "start": 4701.679999999999,
      "end": 4705.44,
      "text": "analysis, and then you've either invested or not invested based on that analysis. And it turns out"
    },
    {
      "id": 1097,
      "start": 4705.44,
      "end": 4710.0,
      "text": "it was just your analysis was just completely wrong. Right. And, you know, you just like completely"
    },
    {
      "id": 1098,
      "start": 4710.0,
      "end": 4713.36,
      "text": "overrated your ability to epistemically, you know, kind of analyze these things, you just,"
    },
    {
      "id": 1099,
      "start": 4713.36,
      "end": 4717.36,
      "text": "you know, basically inflicted harm. Like, I always, you know, question is always, you know,"
    },
    {
      "id": 1100,
      "start": 4717.36,
      "end": 4721.839999999999,
      "text": "it's sort of, you know, any activity that we do, is it value add or is it actually value subtract?"
    },
    {
      "id": 1101,
      "start": 4721.839999999999,
      "end": 4726.0,
      "text": "Right. And I think in this business of all businesses, it's kind of like that. And that"
    },
    {
      "id": 1102,
      "start": 4726.0,
      "end": 4730.639999999999,
      "text": "applies to all of my own contributions as well. So, so there is that. And then, and then I would say,"
    },
    {
      "id": 1103,
      "start": 4730.639999999999,
      "end": 4733.92,
      "text": "you know, maybe the final thing is just like, I do have the entire internet ready to tell me that"
    },
    {
      "id": 1104,
      "start": 4733.92,
      "end": 4741.599999999999,
      "text": "I'm an idiot. So that also doesn't hurt. And it does on a regular basis."
    },
    {
      "id": 1105,
      "start": 4741.6,
      "end": 4748.64,
      "text": "Amy Quinton, Ph.D.: On the point of your alluding to earlier about decisions on investing in companies,"
    },
    {
      "id": 1106,
      "start": 4748.64,
      "end": 4754.08,
      "text": "my favorite line, I think it was from the Cheeky Pint interview that you did, was, you know,"
    },
    {
      "id": 1107,
      "start": 4754.08,
      "end": 4758.240000000001,
      "text": "when you invest in a company, it doesn't go well, at least it goes bankrupt. Right? If it does,"
    },
    {
      "id": 1108,
      "start": 4758.96,
      "end": 4762.96,
      "text": "if it does well, and it does fantastically well, you hear about it every single fucking day."
    },
    {
      "id": 1109,
      "start": 4762.96,
      "end": 4766.96,
      "text": "For the rest of your life. Yeah. For the next, for the next 30 years."
    },
    {
      "id": 1110,
      "start": 4769.12,
      "end": 4774.16,
      "text": "Reality smacking you in the face saying, you fool. You had it. It's literally, it's literally,"
    },
    {
      "id": 1111,
      "start": 4774.16,
      "end": 4779.2,
      "text": "you had it in your office. All you had to do is say yes. And by the way, and this is the thing,"
    },
    {
      "id": 1112,
      "start": 4779.2,
      "end": 4783.68,
      "text": "like every great VC, like if you, this is, this is the stories that, you know, the VCs tell each"
    },
    {
      "id": 1113,
      "start": 4783.68,
      "end": 4788.56,
      "text": "other. Every great VC basically has this history of like, my God, I had, it was in my office. The thing"
    },
    {
      "id": 1114,
      "start": 4788.56,
      "end": 4794.240000000001,
      "text": "was in my office and I said no. And if I had just said yes. And so it's, yeah, it's very hard to,"
    },
    {
      "id": 1115,
      "start": 4794.240000000001,
      "end": 4797.6,
      "text": "yes, the constant reminders in the Wall Street Journal and on CNBC every day that you made a"
    },
    {
      "id": 1116,
      "start": 4797.6,
      "end": 4801.76,
      "text": "giant mistake. Yes. Very good. Very good for the, for the old humility factor."
    },
    {
      "id": 1117,
      "start": 4801.76,
      "end": 4808.240000000001,
      "text": "Yeah. Very humbling. Helps you stay grounded all the time. Last question. Do you plan to go to Mars"
    },
    {
      "id": 1118,
      "start": 4808.240000000001,
      "end": 4813.4400000000005,
      "text": "if, and when that opportunity presents itself? Probably not."
    },
    {
      "id": 1119,
      "start": 4813.44,
      "end": 4818.24,
      "text": "I think I might. Mike's subliminal Zoom background wasn't"
    },
    {
      "id": 1120,
      "start": 4819.04,
      "end": 4821.12,
      "text": "sending you the positive vibes. This is what it could."
    },
    {
      "id": 1121,
      "start": 4821.12,
      "end": 4822.879999999999,
      "text": "Well, I'm not even willing to leave California."
    },
    {
      "id": 1122,
      "start": 4826.639999999999,
      "end": 4831.839999999999,
      "text": "I'm barely willing to leave my house. So yeah, maybe by, maybe by VR."
    },
    {
      "id": 1123,
      "start": 4831.839999999999,
      "end": 4834.799999999999,
      "text": "Yeah. And then we'll see what happens. I mean,"
    },
    {
      "id": 1124,
      "start": 4834.799999999999,
      "end": 4839.12,
      "text": "look, having said that, I think Elon's going to pull it off. And so I think, you know, I don't know."
    },
    {
      "id": 1125,
      "start": 4839.12,
      "end": 4841.839999999999,
      "text": "I don't know, you know, I don't want to predict, this is not a prediction, but I, you know,"
    },
    {
      "id": 1126,
      "start": 4841.84,
      "end": 4844.4800000000005,
      "text": "I would not be surprised if within a decade there's routine trips back and forth."
    },
    {
      "id": 1127,
      "start": 4845.2,
      "end": 4849.92,
      "text": "Um, so, uh, yeah, we may, uh, this, this may actually become a practical question. And,"
    },
    {
      "id": 1128,
      "start": 4849.92,
      "end": 4851.84,
      "text": "and by the way, I do know a lot of people who are probably going to go."
    },
    {
      "id": 1129,
      "start": 4851.84,
      "end": 4854.8,
      "text": "Myself included. Put me on that trip."
    },
    {
      "id": 1130,
      "start": 4854.8,
      "end": 4855.4400000000005,
      "text": "Oh, fantastic."
    },
    {
      "id": 1131,
      "start": 4856.96,
      "end": 4869.84,
      "text": "The flights around the world have prepared me for the six month journey to Mars. So I will be just fine."
    },
    {
      "id": 1132,
      "start": 4871.84,
      "end": 4873.88,
      "text": "Okay."
    },
    {
      "id": 1133,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1134,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1135,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1136,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1137,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1138,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1139,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1140,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1141,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1142,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1143,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1144,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1145,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1146,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1147,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1148,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1149,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1150,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1151,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1152,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1153,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1154,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1155,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1156,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1157,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1158,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1159,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1160,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1161,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1162,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1163,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1164,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1165,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1166,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1167,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1168,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1169,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1170,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1171,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1172,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1173,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1174,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1175,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1176,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1177,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1178,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1179,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1180,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1181,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1182,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1183,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1184,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1185,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1186,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1187,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1188,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    },
    {
      "id": 1189,
      "start": 4873.88,
      "end": 4873.88,
      "text": ""
    }
  ]
}