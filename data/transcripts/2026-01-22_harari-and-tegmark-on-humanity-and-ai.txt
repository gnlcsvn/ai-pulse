I'm actually so excited about this fireside chat because a lot of people have been thinking about super intelligence and AI And I could not be more happy to speak to Yuval Noah Harari and Max Tegmark To both of you We're gonna have a good conversation over the next 30 minutes to try and understand super intelligence now super intelligence Means different things to different people even the big ones that are trying to build it have different timelines and different definitions So what does super intelligence you don't mean to you? hmm that It can make a million dollars on its own that it's an agent that you release To the financial system for instance and it can do everything including open and manage its own bank account and it can make a million dollars Then it's super intelligence and then you can have millions of those taking over the financial system. I Mean I wish we'd hear Ken react to that because he's made a couple of millions and maybe he's worried about it max. What does it mean to you? So let's build up to it like a layer cake first. What's artificial intelligence? It's just non biological intelligence What's intelligence? For those of us who are researching and building artificial intelligence, but a bit we simply define intelligence as the ability to accomplish goals The more difficult the goals the more intelligent the more diverse the goals are the more broad the intelligence is and and super intelligence Was originally defined in the book called super intelligence as an artificial intelligence which is just vastly Better than humans at any cognitive processes. So practically it would mean It can do every job much better than us by definition and in fact It would pretty quickly figure out how to improve itself and be able to be smarter than all of humanity combined So Elon Musk thinks you know we could have AGI this year if you speak to Demis Hassabis He thinks it's like five ten years away. Who's right? I Don't know. I mean, but it's a very very short time time however you look at it and if it is coming then humanity is completely unprepared for it I hope it takes longer because it means we have longer to prepare But this is a very very short time frame anyway I mean just to put into context I mean is this bigger and different than the industrial revolution? It's bigger than anything I mean because it's not a tool it's an agent I mean every previous invention in human history was a tool Whether it's the printing press whether it's atom bomb whether it's an airplane It's a tool in our hand we decide what to do with it Here we are creating an agent that can make decisions by itself. It doesn't wait for us to decide It can invent ideas by itself. It's introducing a different species Non-organic species to plant earth Which is presumably by the claims of these people more intelligent than us? You look at the history of humanity and the history of biology It usually doesn't end well for the less intelligent species when the more intelligent species comes along We were getting laughed, but I would be worried. Should we not worry? You should be worried. Dark humor is a good way to cope Yeah, you know and The actual definition we talked about of course means that it's a new species if you have robots that are both vastly Smarter than us and also every bit as agile as us they can do everything we can do they can make robot factories and make new robots They can reproduce in other words. They check all the boxes on the species definition and This is very accepted stuff in Silicon Valley You can go read Sam Altman's blog called the merge which he wrote 11 years ago where he says homo sapiens is going to be the first species to build its successor species and We can debate about Whether we want to do that or not But that's what it means and then for your question when will it happen This is where there is a really genuine Controversy among experts. I think it's easier to see the Not lose sight of the forest for all the trees by just zooming out a little bit so alan turing the godfather of ai He said in 1951 already that if you build a Basically a new species it's smarter than us you know by default. It's going to take control Just walk down to the nearest zoo and ask yourself Is it the humans in the cages or? Some dumber species and it's the default outcome as you've all said that the smarter species controls Because intelligence gives power now Alan turing also said in 1950. Don't worry. It's far away Far away, but i'm going to give you a test so you know when it's close. It's called the turing test It's about mastering language and knowledge at the level of a human and Since then ai was mostly Overhyped decade after decade over promising under delivering until about four years ago When it switched and became underhyped Almost every professor and other ai researcher. I know predicted that six years ago that we were Decades away from passing the turing test from getting something as good as chat gpt 4 say And they were all wrong because it happened already and and since then It's continued going faster than most of my technical colleagues thought it went pretty quickly in the past four years from sort of high school level University level phd level to professor level and beyond in some areas and just last year For the first time ai won the gold medal in the international math olympiad Which is sort of the intellectual version of being usain bolt And in the olympics and there's no sign whatsoever of the of the pro slowing down So I think we can say quite confidently that if you buy into the basic premise that the brain is a biological computer Of course, we can build a better one Some people think it'll happen next year two years from now something five years something 10 years But most serious Technical people I know have stopped talking about decades from now I think the amazing thing is if you think about it Where were you on the day that ai passed the turing test? You know for decades people are talking the turing test the turing test Where were you on the date happened nobody remembers because it's just swished yeah Yeah, nobody and people stop talking about the turing test Nobody talks about the turing test anymore. It just happened Yeah, and the thing is that to change the world to change history You don't need super intelligence Very dumb intelligence is still enough to change history. We humans did Yeah, you know you look at say social media, which is controlled by very very primitive ai's And how social media changed society politics psychology over the last 10 years or so So we don't really need I mean super intelligence is a chimera. They keep changing the go the posts I mean even quite primitive ai is sufficient to change history in society I don't know when we reach the point, but i'm sure that in the next decade or so We will have to deal with a new wave of immigration You know immigration one of the biggest political issues right now ai immigration That we will have hundreds of millions of ai immigrants Coming from mainly two countries china and the us And you know it's strange the u.s telling telling countries close your borders to human immigrants But open them wide to our ai immigrants And i'm not against immigration We will have you know ai doctors in the healthcare system and ai teachers in the education system But they will bring problems And the big question is how does society human society adapt To a giant wave of immigration from a different species Can you talk first of all of how you see it changing so how is it changing our economy? When we have super intelligence? How is it changing the fabric of society? People understand but it's actually very difficult to see what does it mean? What does it mean? I'll give just maybe two two examples Finance Once ai's can act as financial agents And start investing money by themselves making money by themselves What happens with if ai's come up with new financial investment strategies? Which are like move 37 of Of the famous alpha go game completely new financial strategies And next stage new financial devices The financial history of humanity is humans inventing new financial devices Money Checks Checks Stocks Bonds ETFs If you remember the 2007-8 financial crisis It started with the invention of new financial devices the cdo's That people thought for a few years were wonderful until they brought the market down What happens if ai financial agents invent new financial devices? Which are mathematically so complex that no human understands the financial system anymore And therefore cannot regulate it anymore, but we don't want to regulate it because It makes trillions and then there is a crash And not a single human on the planet Understands what is happening because the financial system has developed to a stage that only ai's understand what is happening there A different example What happens when you raise kids from day zero? When they interact with ai's more than they interact with other humans That if you ask the child or if you watch the child To see what are the main interactions of the child and how does the child's psychology develops and things like attachment and friendship The main Interaction is with ai What are the implications for human psychology and in society? We have no idea We will know in 20 years This is the biggest Psychological and social experiment in history And we are conducting it and nobody has any idea What the consequences will be you know just to go back to the theme of immigration A lot of the people who oppose immigration if they hear that their son or daughter Is dating an immigrant boyfriend they get nervous What will happen when their son or daughter starts dating an ai boyfriend? More nervous Max i mean and this is to the point I mean you you believe that actually you know the only way to make this a success is to try and align super intelligence with the human goals Well, no In davos you also see i mean what is the human goal? Yeah, I don't actually believe that let me just clarify a little bit so For your this great question you just asked what happens in the world when The jobs and so on when you build super intelligence, you know It's important to remember we do not have super intelligence now So it's a huge mistake to start thinking about how ai is having some small effects on the job market now when you can do reskilling So by definition ai can do all the jobs much better and cheaper than our super intelligence can so by definition We are economically obsolete When super intelligence comes Open ai used to have on their website that their goal was to replace all valuable human work So forget about jobs we cannot get paid for anything after that Maybe society can find a way of still giving some money to people if humans stay in control But right now the the famous control problem which people have worked on for decades many of the smartest minds How do you control a smarter species is unsolved? Many believe it's impossible just like it's impossible for chimpanzees you know to control us So most likely if we build super intelligence, it's the end of the era where humans are in charge of earth Elon musk was saying that on a stage just a month ago, you know It's gonna be machines in charge not us But this is not inevitable It's a huge mistake I think many people make That's what's going to happen as if we humans run now or just some sort of passive bystanders, you know eating popcorn Waiting for ai to take over the world We're building this stuff and many of the most influential people steering this development are here in davos, right? So you can build it differently and what about this? Yes, we totally can We totally can yeah, so for example raise your hand here in the audience if you're excited about ai that cures cancer and helps us It's a lot of hands. Take them down. Who is excited about ai that simply makes us economically obsolete and replaces us? Okay, one guy, but nobody else wants it, right? So the vast majority of people Do not want humans to remain in charge So I think it's quite likely we will not actually race to build super intelligence because almost nobody wants it Not just ordinary people But you think the chinese government and the us government want to have something built that's just going to overthrow them Of course not But so if you can control it right if you can align it with what you want Then you think that you know, that's a possibility Those are two totally different things actually I'm so glad you asked control that means you know, you have the power over it. You can shut it down if you want alignment As opposed to without control means that we lose control over it ai is the boss of earth But for some reason it decides to be nice to us This is what most of the companies are pushing for right now And I think if it was wide more widely understood by politicians that they're this actually implies the overthrow of the u.s government, you know They wouldn't be so cool with it. Yeah, you've I mean is this you know, do you have to control the concentration of power? of this of this I think it's not a coincidence that we see the rise of ai and the return of imperialism at the same time And I think certainly in the us the new imperial vision of the world is based on the assumption that we are winning the ai race ai will give us control of everything the economy military Culture so we don't need allies We don't need anybody We can just take control of the world ourselves And it's all premised on the assumption that we are building We are winning the ai race And it will give us everything Yeah Except This is a bit like a greek tragedy in that what a lot of the politicians haven't understood yet Which is pretty obvious Many of the scientists is that we have no way of controlling right now something that's smart so what will happen first Is you know some company maybe gets more powerful than the u.s government and sort of starts more or less becoming the government And then they lose control over the machines and then it's a very sad ending for all the humans And there are so for the actual there are actually two separate races going on here which must not conflate one is a race to dominance Whereas superpowers Are trying to win get the dominance by building more powerful tools economic tools military tools that they can still control Then there's a second race to see who can be the first to build super intelligence which there was just going to take Overthrow them right so that if someone really wants control what they should build is The tools and have very strict regulations to make sure nobody messes up and builds the new species that replaces us Can democracy survive this? Hopefully yes I mean democracy is ideally suited to survive this because we are going to make mistakes with ai With the way we develop it with the way we deploy it and we need a self-correcting mechanism We need a mechanism that says okay, we made a mistake Let's go back and try something else in history the best mechanism We know of this type is democracy the whole idea of democracy is you elect somebody you try a set of policies And after four years or five years you say hey, we made a mistake. Let's try something else In many ways the ai becomes much more dangerous in a dictatorial setting Because you know in a democracy say for ai to take control or to manipulate the system It's very difficult to manipulate a democratic system in a dictatorship in an autocratic regime You just need to learn how to manipulate a single person Who is usually very paranoid and very narcissistic which is why it's very easy to manipulate them at least for a super intelligence Can I add some optimism here because you're looking a little bit concerned? No, not at all. I mean we're having a great time cocktails are coming I completely agree that we don't need to build super intelligence. We don't need to go down that road And hopefully the the politicians, you know, especially powerful politicians the last thing they want Is to build something that will take power away exactly and hopefully when they realize that this is serious Uh, they will not go down that path But is it too late and actually I wasn't worried. I was thinking about you know, how is it too late? When is it too late to design something that is not omnipotent? If you give it all the power then you become obsolete. I think it goes more the other way around Once society gives the right incentives to those who build the tech they'll figure out a way of doing these things So you can have your cancer cure and all the great tools, but not the out of control skynet so the optimism comes from Is why I think neither the US nor the nor China is going to ultimately Let their own companies build the out of control super intelligence skynet for china You've all just explained why clearly xi jinping and the ccp don't want to lose control And they have all the means they need to have to be able to stop chinese companies from building super intelligence that can be uncontrolled right in america similarly the natsack establishment in america that will start see it as a this is a natsack threat very bipartisan but even before that we're seeing I think we're seeing an amazingly crazy bipartisan coalition emerging now in the recent in recent months in america I call it the bernie to bannon coalition the b2b coalition you hear these two people saying exactly the same stuff about ai there's they say things like you know it's so crazy it's illegal for creepy 60 year old man to be manipulating And pretending to be a girlfriend of a young teenager and persuade them to commit suicide It's illegal for a drug company to sell medicines that haven't been tested in a clinical trial to these kids why on earth should it be legal for an ai company to sell an ai girlfriend chatbot which has now caused many teenage suicide They're saying basically we need to treat ai companies the same way we treat pharma companies and restaurants and everyone else first you meet the safety standards and then you can sell them i actually think we're going to start seeing these incentives where ai companies have to meet the safety standards no one will have a clue how to make super intelligence pass any kind of safety standards right so that means companies will innovate to build the cancer cures and and make fantastic productivity gains and all the stuff you want And the other stuff will not happen for the foreseeable future and i think that's great i was going to ask who should be in charge of i don't know if it's an ethics committee or something to to see you need to do it before right but we this is a solved problem we we know how to do clinical trials and we we you have some the company is in charge of convincing a bunch of government appointed experts that this medicine here is not going to cause massive birth defects like thalidomide once did even in a restaurant the restaurant is in charge of cleaning up the kitchen and making sure it's not full of rats and persuading the health inspector that this is okay we we this is a solved problem we don't need to reinvent the wheel of how to put safety standards on an industry because we've done it on every american industry except ai at this point you've how do you see that humans changing with ai anyway i know there's you know there's a debate on whether humans want to be or the superior species because it's intelligence or whether it's a sense of belonging also and and purpose that that keeps society together well ai will challenge our deepest identity that not not you know i'm not talking about super intelligence just a i'm talking about again this wave of ai immigrants that we will encounter more and more everywhere and uh they will challenge us in many of the things we thought define our humanity that you know when a robot or a car runs faster than us we are okay with it because we never defined ourselves by our ability to run faster than everybody else we always knew that cheetahs can run faster than us so if cars and robots can do that that's fine but we defined ourselves by things like the ability to think i think therefore i am by our ability to create we are the most creative species on the planet what happens to human identity when there is something on the planet which is maybe not this scary super intelligence but is still able to think better than us is still much more creative than us in many fields we already saw it in narrow fields like in chess or in goal that ai thinks better is more creative this will happen in more and more fields what happens when it comes to religion that you know i have uh uh friends i'm i'm a meditator i'm part of a meditating community when they have an issue with their meditation they no longer go to a meditation master they go to an llm they go to an ai to get advice and this is likely to happen in christianity in islam in hinduism what happens to religion when ais replace the and you know especially in religions which are based on texts on scriptures no jewish rabbi is able to remember all the jewish texts ever written a.i can easily do that so if you have a question about judaism and you go to the ai and not to the rabbi what does it mean for human religion and for religious identity what happens if a is creating your religion you know it shouldn't sound so far-fetched because almost every religion in history claimed that it was created by a non-human intelligence until now this was all fiction but now it can be true you can actually have a religion created by a non-human intelligence what does it mean for human identity i mean a lot of the big tech companies will say that we'll have more time from human to to spend quality time emotional time with people maybe that's one way of looking at it but then again if if you if you grew up interacting and much of your again your psychological makeup is through interactions with ais how will it impact the way we interact with other humans you know with other humans part of the issue is that sometimes they have feelings that annoy us we are angry at them they are angry at us um ai assuming that it has no feelings of its own at least you know it it can feed our narcissism it can be this thing that is always focused on you like you come back home from work and your husband or your wife don't really pay attention to you and they are grumpy because of something that happened in in work to them ai will never do that it will always focus on you horrible dogs yeah and getting used to having a relationship with something like that and then trying to build a relationship with a human being that can become much more difficult than in any previous time in history so when you speak both of you when you speak to heads of states or chief executives of big companies that say look i'm worried about the picture that you're painting here what do i do about it how should i look at it what do you tell them i tell them if they're in government this start treating ai companies like you treat any other government that's not a problem so that's why i think that's why i think that's why i think that's important to govern companies in your country put out put safety standards on them and then they'll innovate to meet them and when i talk to people in the companies who are lobbying against all regulations i ask them you have all these voluntary commitments you promised that your company is going to hold you these standards why don't you go lobby your politicians to make your own promises be binding law on all your competitors also i encourage you to ask them here as well those who are in that was why they aren't doing that yet but it's important to remember there it's not too late for us to steer towards a really inspiring future with technology why shouldn't we cure cancer why shouldn't we solve all these other challenges that human intelligence has been stumped by we can do it but that is not the path we're on right now right now we're on this race to replace and i'm not just talking about ultimately trying to replace all jobs we are starting to see those of us who are parents how there's a race to replace human relationships by having people instead put little rectangles between the humans and and even um the attention economy is shifting in more towards even an attachment economy where some people some children have been so attached and manipulated by ais that they kill themselves you know that is the wrong direction we need it of course we need to really change direction and um the solution again is i don't want to sound like a broken record but if we we know how to do this we've we've we've we've decided to regulate every other industry with safety standards that's why we can trust our medicines now we can trust our cars we can trust our food in the restaurants to not give us salmonella we just have to do this with ai as well it's tough because there's a lot of lobbying money going against it but there was justice there was massive lobbying against seat belts as well you know we can do this you know what would you tell them i have an international agreement banning uh legal personhood to ai the i think the most dangerous move at the present moment is ais gaining legal personhood or functional personhood ais are not persons they don't have bodies they don't have minds but in the legal and political system we have legal personhood for instance to corporations corporations can own bank accounts they can sue you in court they can donate to politicians they are considered legal persons in india gods certain gods are considered legal persons now until today this was legal fiction because in the end when google decides to buy a corporation when google decides to donate money to presidential campaign it's a human being making the decision we say it's google but if you look you aren't actually a human being there an executive a shareholder a trustee who decided same with the indian gods it's not really shiva who is suing you in court it's the human trustees ais can actually manage a bank account they can actually manage a corporation if you allow legal personhoods to ais you can have corporations without humans that might become the most successful corporations in the world lobbying politicians suing you in court and there is no human behind i'm not it doesn't mean stopping any kind of research you can continue all the research you want but until we are sure about this thing no legal personhood to ais which also mean that for instance ais cannot operate by themselves on social media this is also legal personhood yeah i just want to say this is so wise i mean granting robot rights and then making super intelligence would be the dumbest thing we've ever done in human history and probably the last okay okay um you vote i mean you know people here there's there's a lot of political shocks there's geoeconomics people are are that we're inundated by by news good news bad news and you're one of the greatest minds of our century and it really actually caught my attention that you go on a silent retreat so you not many people think about their brains and how they think they just do it they have to show up every day in the office early so how do you think about and how do you actually really take time to think and reset and you know this is our most important tool at least you know whether i'm a public intellectual or a politician or a manager of a company my mind is my most important tool and i need a healthy and balanced mind to deal with the world especially the world of 2026 it's crazy to invest in everything else and not in my mind and the thing about investing in the mind nobody can do that for you i can send my suit to the dry cleaner so somebody cleans my suit for money i cannot send my mind to be cleaned by somebody else it's it is the one thing i need to do uh for myself also you know in in the field of ai we constantly talk about ai versus human intelligence ai versus human mind what do we know about the human mind if you don't understand the human mind you cannot understand ai you know i hear people say oh ai is just glorified autocomplete it just complete it just predicts the next word in a sentence that's nothing and then i sit for meditation and observe what's happening inside my mind and i'm a verbal person i think in words and i see words popping in my mind and forming sentences and one of the practices of meditation is trying to observe the next word that pops up in your mind where did it come from why this word and not another word you know just this sentence i i i'm not saying i don't know how it will end when i begin to say it like what did i say how it will end and not how it will conclude how it will terminate how it will develop where did the word end come from when i started the sentence i did not know that it will end with the word end something in my mind kind of predicted okay the next word will be end and if i don't understand how this is happening in my mind how can i have the kind of hebris to say what ai can and cannot do and what will be the future relationship between ais and humans if you don't understand the human mind and that's why it feels like we have free will because we can't predict what we're going to decide until we've actually finished the thought process and made the decision yeah gentlemen that was so interesting thank you so much for for a wonderful conversation please give everyone a big round of applause you've all right