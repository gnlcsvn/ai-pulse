Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. So, hello everyone. There is one question that every leader today must answer about AI. But to understand that question, we first need to clarify a few points about what AI is and what AI can do. The most important thing to know about AI is that it is not just another tool. It is an agent. It can learn and change by itself and make decisions by itself. A knife is a tool. You can use a knife to cut salad or to murder someone. But it is your decision what to do with the knife. AI is a knife that can decide by itself whether to cut salad or to commit murder. The second thing to know about AI is that it can be a very creative agent. AI is a knife that can invent new kinds of knives as well as new kinds of music, medicine and money. The third thing to know about AI is that it can lie and manipulate. Four billion years of evolution have demonstrated that anything that wants to survive learns to lie and manipulate. The last four years have demonstrated that AI agents can acquire the will to survive and that AI's have already learned how to lie. Now, one big open question about AI is whether it can think. Modern philosophy began in the 17th century when Ren√© Descartes proclaimed, I think, therefore I am. Even before the card, we humans defined ourselves by our capacity to think. We believe our we rule the world because we can think better than anyone else on this planet. Will AI challenge our supremacy in the field of thinking? Now, that depends on what thinking means. Try to observe yourself thinking what is happening there. Many people observe words popping in their mind and forming sentences and the sentences then forming arguments like all humans are mortal. I am human. Therefore, I am mortal. If thinking really means putting words and other language tokens in order, then AI can already think much better than many, many humans. AI can certainly come up with a sentence like AI thinks, therefore, A-I am. Some people argue that AI is just glorified, autocomplete. It barely predicts the next word in a sentence. But is that so different from what the human mind is doing? Try to observe, to catch the next word that pops up in your mind. Do you really know why you saw that word, where it came from? Why did you think this particular word and not some other word? Do you know? As far as putting words in order is concerned, AI already thinks better than many of us. Therefore, anything made of words will be taken over by AI. If laws are made of words, then AI will take over the legal system. If books are just combinations of words, then AI will take over books. If religion is built from words, then AI will take over religion. This is particularly true of religions based on books, like Islam, Christianity or Judaism. Judaism calls itself the religion of the book, and it grants ultimate authority, not to humans, but to words in books. Humans have authority in Judaism, not because of our experiences, but only because we learn words in books. Now, no human can read and remember all the words in all the Jewish books. But AI can easily do that. What happens to a religion of the book when the greatest expert on the holy book is an AI? However, some people may say, can we really reduce human spirituality to just words in books? Does thinking mean only putting language tokens in order? If you observe yourself carefully when you're thinking, you will notice that something else is happening there besides words popping in your mind and forming sentences. You also have some non-verbal feelings. Maybe you feel pain. Maybe you feel fear. Maybe love. Some thoughts are painful. Some are frightening. Some are full of love. While AIs become better than us with words, at least for now, we have zero evidence that AIs can feel anything. Of course, because AIs is mastering language, AIs can pretend to feel pain or love. AIs can say, I love you. And if you challenge it to describe how love feels, AIs can provide the best verbal description in the world. AIs can read countless love poems and psychology books and can then describe the feeling of love much better than any human poet, psychologist or lover. But these are just words. The Bible says, in the beginning was the word and the word was made flesh. The Tao Te Ching says, the truth that can be expressed in words is not the absolute truth. Throughout history, people have always struggled with the tension between word and flesh, between the truth that can be expressed in words and the absolute truth, which is beyond words. Previously, this tension was internal to humanity. It was between different human groups. Some humans gave supreme importance to words. They have been willing, for example, to abandon or even kill their gay son just because of a few words in the Bible. Other humans have said, but these are just words. The spirit of love should be much more important than the letter of the law. This tension between spirit and letter existed in every religion, every legal system, even every person. Now, this tension will be externalized. It will become the tension not between different humans. This will be the tension between humans and AIs, the new masters of words. Everything made of words will be taken over by AI. Previously, all the words, all our verbal thoughts, they originated in some human mind. Either my mind, I saw this, or I learned it from another human. Soon, most of the words in our minds will originate in a machine. I just heard today about a new word that AIs coined by themselves to describe us humans. They called us the Watchers. The Watchers. We are watching them. AIs will soon be the origin of maybe most of the words in our minds. AIs will mass produce thoughts by assembling words, symbols, images, and other language tokens into new combinations. Whether humans will still have a place in that world depends on the place we assign our non-verbal feelings, and our ability to embody wisdom that cannot be expressed in words. If we continue to define ourselves by our ability to think in words, our identity will collapse. All this means that no matter from which country you come, your country will soon face a severe identity crisis, and also an immigration crisis. The immigrants this time will not be human beings coming in fragile boats without a visa or trying to cross a border in the middle of the night. The immigrants will be millions of AIs that can write love poems better than us, that can lie better than us, and that can travel at the speed of light without any need of visas. Like human immigrants, these AI immigrants will bring various benefits with them. We will have AI doctors to help in our healthcare systems, AI teachers to help in our education systems, even AI border guards to stop illegal human immigrants. But, the AI immigrants will also bring with them problems. Those who are concerned about human immigrants usually argue that immigrants might take jobs, might change the local culture, might be politically disloyal. I'm not sure that's true of all human immigrants, but it will definitely be true of the AI immigrants. The AI immigrants will take many human jobs. The AI immigrants will completely change the culture of every country. They will change art, religion, and even romance. Some people don't like it if their son or daughter is dating an immigrant boyfriend. What would these people think when their son or daughter starts dating an AI boyfriend? And of course, the AI immigrants will have some dubious political loyalties. They are likely to be loyal not to your country, but to some corporation or government across the ocean, most probably in one of only two countries, China or the USA. The USA encourages countries to close their borders to human immigrants, but open them very, very wide to USAI immigrants. And now we can finally come to the question each one of you must soon answer. Will your country recognize the AI immigrants as legal persons? AIs are obviously not persons. They don't have a body or a mind. But a legal person is something quite different from a person. A legal person is an entity that the law recognizes as having certain legal obligations and rights. For example, the right to hold property, to file a lawsuit, and to enjoy freedom of speech. In many countries, corporations are considered legal persons. The alphabet corporation can open a bank account, can sue you in court, or can donate to your next presidential campaign. In New Zealand, rivers have been recognized as legal persons. In India, certain gods have been granted such recognition. Of course, until today, recognizing a corporation, a river, or a god as a legal person was just legal fiction. In practice, if a corporation like Alphabet decided to buy another corporation, or if a Hindu god decided to sue you in court, the decision wasn't really made by the god. It was made by some human executives, shareholders, or trustees. It is different with AIs. Unlike rivers and gods, AIs can actually make decisions by themselves. They will soon be able to make the decisions necessary to manage a bank account, to file a lawsuit, and even to operate a corporation, without any need of human executives, without any need of human executives, shareholders, or trustees. AIs can therefore function as persons. Do we want to allow that? Will your country recognize AIs as legal persons? What if other countries do it? Suppose your country doesn't want to recognize AIs as persons. But the USA, in the name of deregulating AI and deregulating the markets, grants legal recognition, legal personhood, to millions of companies to run millions to millions to millions of new corporations. Will you block these USAI corporations from operating in your country? Suppose some USAI persons invent super efficient and super complex financial devices that humans cannot fully understand and therefore don't know how to regulate. your financial markets to this new AI financial wizardry or will you try to block it thereby decoupling from the American financial system suppose some AI persons create a new religion which gains the faith of millions of people that should not sound too far-fetched because after all almost all previous religions in history have claimed that they were created by a non-human intelligence now will your country extend freedom of religion to the new AI sect and to its AI priests and missionaries maybe we should start with something a bit simpler will your country allow AI persons to open social media accounts enjoy freedom of speech on Facebook and tick-tock and befriend your children well of course that question should have been asked ten years ago on social media AI bots have been operating as functional persons for at least a decade if you think AI should not be treated as persons on social media you should have acted ten years ago ten years from now it will be too late for you to decide whether AI should function as persons in the financial markets in the courts in the churches somebody else will already have decided it for you if you want to influence where humanity is going you need to make a decision now so what is your answer as a leader do you think the AI immigrants should be recognized as legal persons if not how are you going to stop that thank you for listening to this human thank you Yuval that was fantastic overview you posed a lot of questions and they're the right ones I agree with much of what you say we're here in Davos where the theme is around dialogue and I was struck by your commentary around words and the importance of words and that being something that demarcates human animals from other animals although that's debatable that there's other language there so in the context of Davos and the range of people we have here from technology from the business world from politicians how would you like to see what is the answer that you have in terms of this slightly dystopian world you've potentially put in front of us and if I may just add to that I think it's a fair to say I'm a scientist by background a neuroscientist so I work a lot in this space particularly around pain and we're very comfortable with the fact that many of our discoveries particularly technological discoveries we often drive them forward and then afterwards we think oh we haven't thought enough about the ethics and the implications and then we're trying to catch up on the regulation that we need to maybe put around it so we are where we are this thing is happening as everybody says at scale both in terms of its magnitude and its pace more than we've ever seen before in the industrial revolution we have all the right blend of people here in Davos it's all about dialogue what would you like to see go forward in terms of putting boundaries around some of the slightly more worrying areas that you detailed and what are your own thoughts about the ethical implications of giving legal rights to people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people people the ones that just exist on the internet? A lot of things there. I mean first of all I would say that now Davos is about words. It's about talking. The basic idea of Davos is that you can change the world just by talking which I like this idea because this is also my idea as an author as a university lecturer this is what I do I talk, I write, I think I can influence the world with words. And this is now in question. Are we at the end of the road for words? Is this no longer functioning? And you know engineers and also soldiers they don't change the world with words. They do stuff. They take action. Philosophers, scholars, also political leaders. They try to change the world with words by saying things. And maybe we've reached the end of that road. And what does it mean? That we know we we can't we humans we conquer the world ultimately I would say with language and words because yes engineers can make weapons and soldiers can wield them. But to build an army you need to convince thousands of strangers to cooperate. How do you do that with words? With ideology? With religion? So humans took over the world not because we are the strongest physically but because we discovered how to use words to get thousands and millions and billions of strangers to cooperate. This was our superpower. And now something has emerged that is going to take our superpower from us. And now something is going to take our world. And we can't use words. Until a few years ago nothing on earth could use words. Only humans. Chimpanzees couldn't. Rivers couldn't. The sun couldn't. We could use words. Now there is something that is able or soon will be able to use words better than us. And you look just you know at what happened on social media. And the immense change it brought to the world there. So 10 years from now living in a world in which AIs are in command of language. How does that look like? Well Davos in 10 years might look very different as you say. So that's a future we can all try to think about in the context of who would be here beyond the physical human. But if I may just discuss a little bit around the fact that it's not new for humans to be uh beaten by technology. So if we think about some of the tech we can't fly and we built aeroplanes. Cars can go faster than us. We're very comfortable with that. The threat that comes with AI is the fact that it's a threat to the sovereign power of our ability to think. And that is destabilizing. I say that as an academic and an educator. That's something that is very threatening. But if we go back to say a robot. The value we would place on a robot being able to run the 100 meters faster than Usain Bolt is less. There's something about the human endeavor, the struggle, the suffering, the fact that we can have a collective sense of empathy and understanding about what it meant to achieve something even if it was lesser with technology. I just wonder whether an author that would replace you. How much as a human we would value that, the words of that, the creativity that comes from art that's been done with artificial intelligence. Do you think we will value it as much and therefore there's still a place for humans in the creative space of thinking and words? That's the identity crisis because the car didn't say I run, therefore I am. I think, I mean a based human identity on our capacity to think. We always knew that cheetahs can run faster than us. We always knew that elephants are much bigger and stronger than us. So we didn't define ourselves by this. We define ourselves by thinking. And now something is going to be better than us in thinking, if thinking means putting words in order. Now, I'm again, I'm an author, I'm a speaker, I put words in order. It's like, this is my game. Like I have all these words and I put, oh, let's put these words in this, in this order. No, no, no, no, no. It would be better to put it like this, like this, like this. And AI will beat me. I don't know how long it will take, two years, five years, ten years. It will beat me. And then what does it mean for our identity? People identify, you know, with the streams of words in their mind. Like you close your eyes, you try to see what's happening inside me. Many people, I'm one of them. We see words popping up, organizing themselves. We identify with that. But I guess my point is, using the same analogy, is that we still value a human. We have the Olympics. We've got the Winter Olympics coming. We know that many other animals and other technologies can outperform in many of those areas. Yet we still really enjoy the humanity of people that train and develop, even though it's not as good. And I just wonder whether we will just naturally extend that to the thinking realm and to the words, so that you still will have a very, very vibrant and successful author role in ten years' time. And what is... I don't know, like... Because I will value your book more than an AI-generated book. Even if the AI comes up with new ideas better than me, like let's say that you want to invest money. And you have a... You ask a human consultant and she comes up with a certain whatever. And you can empathize with her because she had this life story and whatever. And then you have the AI financial consultant with zero life story, zero emotions, but better financial advice. Which one will you follow? Now, we always have this kind of, I think, the big mistake. And this is why I started with the idea of agency. We always think that we can just use these things as tools. But if they can think they are agents. You know, maybe I'll tell a story from medieval history. That how did the Anglo-Saxons took over Britain? And it's part myth, part history. That, you know, the Britons who lived there originally, they were fighting with the Picts and the Scots coming from the north. And the Britons didn't fight very well. So the king of the Britons, Votigern, he said, I have an idea. I've heard that in Germany, in Scandinavia, these people really know how to fight. So let's bring over some mercenary, some Anglo-Saxon mercenary. They will fight for us. They will defeat the Picts and the Scots. And Votigern brings over Anglo-Saxon mercenaries. And they fight well, and they defeat the Scots and the Picts. But then the Anglo-Saxons say to themselves, this is a rich country. And these people, they are very weak. And these people, they are disunited. We can take over. And they take over. We understand this with human mercenaries. We understand that when you bring a human mercenary, okay, you pay them, but they have a mind of their own. Maybe they rebel. We don't get it with AIs. You know, you look at the leaders of the world, they think, oh, I'll bring AI to fight my war for me. The idea that it can just take power away from you. It doesn't really cross their minds. They don't really accept that AIs can think. Yeah. Yeah. And that is very fundamentally different. So just to reverse that, you're an alum of my institution, and we're proud of that, although you're working at the other place now in Cambridge. So the challenge, I think, for the education sector, and it goes back to a reverse flip of what Alan Turing said, which was whether a computer could think, the sort of birthplace of artificial intelligence, if you will. So I think the question we've been posing inside the academic sector is, how do we keep humans thinking? Because if we keep abdicating our decision-making, our financial decisions, or whatever it might be, increasingly, increasingly to AI, the worry we have quite quickly, and we're seeing this with students coming to us through the school system, very overusing chat GPT, is the de-skilling of critical faculties of human brain thinking. So what's your advice to me in the academic sector about how can we hang in there as humans and keep humans thinking so that we at least have some capacity to live alongside these technologies, which, as you say, bring us into a very different place going forward in terms of world order? You know, at the present moment, we still think better. So at the present moment, it's kind of telling people, you need your critical thinking, you need moral evaluations, you cannot get that from AI. But we need to prepare to the moment when this is no longer the case. We need to prepare for the moment, let's say again, take economics or financial finance, when AI's create a new financial system, a new financial system that they understand, and we don't understand. How do you train economists or politicians in a world in which humans really can't, can no longer understand how finance functions? Because AI's have created this super complex financial system. That we are like the horses, you know, that horses can see that they are being traded from one human to another for a few shiny gold coins. They can't understand this idea of money to complicate we can be in the same situation 10 years from now, Davos 10 years from now. Maybe nobody in the room, no human in the room understands the financial system anymore, because it's dominated by AI's and the AI's have come up with new financial strategies and devices that are just mathematically beyond the human capacity of the brain. So how does politics and finance and Davos look like in a world when no human beings understand finance anymore? Yeah, no, well, that's a beautiful note to finish on. We've run out of time. There are many more questions that we could explore, one of which just being the major difference that we know about artificial intelligence compared to human intelligence, is of course the human brain develops from birth to adulthood around age 20. And it is a product of your life experience as a sentient human being, feeling, loving, anger, these emotions. And whilst one can improvise a little bit with sensory detectors and you can train the brain to do that, that is fundamentally different. So the artificial brain is not a human brain, it is not human. And there is maybe something that is still of value there that goes back to that core business of this sentient human being that brings value to our understanding. And my one last comment, please think about educating kids in a world where from day zero, maybe the most of the interaction of the new child is with an AI and not with a human being. It's the biggest and scariest psychological experiment in history and we are conducting it. Indeed, we are. Well, Yuval, thank you so much. I'm delighted that you're thinking about these problems and that you've got us all thinking this afternoon. I look forward to you coming back maybe to Davos in in 10 years and reflecting on this conversation and just where we have got to. But thank you all to the audience, those of you online and those in the group. And thank you. We give a round of applause for you. Thank you.