{
  "metadata": {
    "video_id": "BYXbuik3dgA",
    "url": "https://www.youtube.com/watch?v=BYXbuik3dgA",
    "title": "Elon Musk â€“ 'In 36 months, the cheapest place to put AI will be space'",
    "channel": "Dwarkesh Patel",
    "upload_date": "2026-02-05",
    "duration": "169m",
    "transcribed_date": "2026-02-24",
    "whisper_model": "mlx-community/whisper-large-v3-turbo"
  },
  "language": "en",
  "text": "So are there really three hours of questions? Or are you fucking serious? Yeah. You don't think there's a lot to talk about, Ilan? Holy pork, man. I mean, it's the most interesting point. All the storylines are kind of converging right now. So we'll see how much we're going. It's almost like I planned it. Exactly. Well, we'll get to that. That would never do such a thing. So as you know better than anybody else, the total cost of ownership of a data center, only 10% to 15% is energy. And that's the part you're presumably saving by moving this into space. Most of it's the GPUs. If they're in space, it's hard to service them, or you can't service them. And so the depreciation cycle goes down on them. So it's just way more expensive to have the GPUs in space, presumably. What's the reason to put them in space? Well, the availability of energy is the issue. So I mean, if you look at electrical output outside of China, everywhere outside of China, it's more or less flat. It's very, maybe a slight increase, but pretty close flat. China has a rapid increase in electrical output. But if you're putting data centers anywhere except China, where are you going to get your electricity, especially as you scale? The output of chips is growing pretty much exponentially, but the output of electricity is flat. So how are you going to turn them chips on? Magical power sources? Magical electricity ferries? You're famously a big fan of solar, one terawatt of solar power, so with a 25% compatibility factor, like four terawatts of solar panels. It's like 1% of the land area of the United States. And that's like far in this. You were in the singularity when we've got one terawatt of data centers, right? So what are you running out of exactly? How far into the singularity are you? You tell me. Yeah, exactly. So I think we'll find we're in the singularity, and like, oh, OK, we'll still get a long way to go. But is the plan to put it in the space after we've covered Nevada in solar panels? I think it's pretty hard to cover Nevada in solar panels. You have to get permits from the permits for that. Try getting the permits for that. So space is really a regulatory play. It's harder to build on land than it is in space. It's harder to scale on ground than it is to scale in space. But also, you're going to get about five times the effectiveness of solar panels in space versus the ground. And you don't need batteries. I almost wore my other shirt, which says it's always sunny in space, which it is. So because you don't have a day-night cycle or seasonality, clouds, or an atmosphere in space, because the atmosphere alone results in about a 30% loss of energy. So any given solar panels can do about five times more power in space than on the ground. And you avoid the cost of having batteries to carry you through the night. So it's actually much cheaper to do in space. And my prediction is that it will be by far the cheapest place to put AI will be space in 36 months or less. Maybe 30 months. 36 months? Less than 36 months. How do you service GPUs as they fail, which happens quite often in training? Actually, it depends on how recent the GPUs are that are ripe. I mean, at this point, we found our GPUs to be quite reliable. There's infinite mortality, which you can obviously iron out on the ground. So you can just run them on the ground and confirm that you don't have infinite mortality with the GPUs. But once they start working, their actual reliability, and once they start working, and you're past the initial debug cycle of NVIDIA or whatever, or whoever's making the chips, could be Tesla, Tesla AI 6 chips or something like that, or it could be TPUs or Traniums or whatever. The reliability is actually, they're quite reliable past certain point. So I don't think that the servicing thing is an issue. But you can mark my words. In 36 months, but probably closer to 30 months, the most economically compelling place to put AI into space, and then it will get ridiculously better to be in space. And then the scaling, the only place you can really scale is space. Once you start thinking in terms of what percentage of the Sun's power are you harnessing, you realize you have to go to space. You can't scale very much on Earth. But by very much, to be clear, you're talking like terawatts. Yeah. Well, all of the United States currently uses only half a terawatt of power on average. Yeah. Right. So if you say a terawatt, that would be twice as much electricity as the United States currently consumes. So that's quite a lot. And can you imagine building that many data centers, that many power plants? It's like those who have lived in software land don't realize that they're about to have a hard lesson in hardware. It's actually very difficult to build power plants. And then you don't just need the power plants. You need all of the electrical equipment. You need the electrical transformers to run the transformers, the AI transformers. Now, the utility industry is a very slow industry. Pretty much, you know, they impedance match to the government, to the public utility commission. So they're very slow because their past has been very slow. So trying to get them to move fast is just like, you know, like if you try to do an interconnect agreement with the, have you ever tried to do an interconnect agreement with a utility at scale, like with a lot of power? If you're a professional podcaster, I can say that I'm not, in fact. Yeah. They have to just leave many more views before that becomes an issue. They have to do a study for a year, OK? Like a year later, they'll come back to you with their interconnect study. Can't you tell this with your own behind the meter power stuff? You can build power plants. Yeah. That's what we did at XAI for classes too. So for classes too. So yeah, why are we talking about the grid? Why not just like build GPUs and power co-located? That's what we did. Right, right. I'm saying why isn't this a generalized solution when you're talking about all the issues? Where do you get the power plants from? I'm saying when you talk about all the issues working with utilities, you can just build private power plants with the data centers. Right. But it begs the question of where do you get the power plants from? Where do you get the power plants from? I mean. The power plant makers. Oh, I was just saying. Yeah. Like there's the gas turbine backlog, basically? Yes. You can drill down to a level further. It's the veins and blades in the turbines that are the limiting factor because the casting may, it's like a very specialized process to cast the blades and veins in the turbines, so you're using gas power. And it's very difficult to scale other forms of power. You can scale potentially solar, but the tariffs currently for importing solar in the US are gigantic. And the domestic solar production is pitiful. Why not make solar? That seems like a good Elon-shaped problem. We are going to make solar. Okay. Yeah. Great. Both SpaceX and Tesla are building towards 100 gigawatts here of solar cell production. How low down the stack? Like from polysilicon up to the wafer to the final panel? I think you've got to do the whole thing from raw materials to finish the cell. Now, if it's going to space, it's actually, it costs less and it's easier to make solar cells that go to space because they don't need glass or they don't need much glass and they don't need heavy framing because they don't have to survive weather events. There's no weather in space. So it's actually a cheaper solar cell that goes to space than the one on the ground. Is there a path to getting them as cheap as you need in the next 36 months? Yeah. Solar cells are already very cheap. They're like farcically cheap. And if you say, you know, I think like solar cells in China are around like 25, 30 cents a watt or something like that. It's absurdly cheap. And when you take into a cap, now put it in space and it's five times cheaper because it's five times, in fact, no, it's not five times cheaper. It's 10 times cheaper because you don't need any batteries. So the moment your cost of access to space becomes low, by far the cheapest and most scalable way to generate tokens is space. It's not even close. It'll be an order of magnitude easier to scale and chips aside an order of magnitude. Well, if the point is you won't be able to scale on the ground, you just won't. If you want to hit the wall big time on power generation, they already are. So like the number of sort of miracles and series that the XAI team had to accomplish in order to get a gigawatt of power online was crazy. We had to gang together a whole bunch of turbines. And then we had permit issues in Tennessee and had to go across the border to Mississippi, which is fortunately only a few miles away. But then we still had to run the high power lines a few miles and build a power plant in Mississippi. And it was very difficult to build that. And people don't understand like how much electricity do you actually need at the generator level, at the generation level in order to power a data center. Because they look at the news will look at the power consumption of say a GB300 and multiply that by a thing and then think that's the amount of power you need. All the cooling and everything. Wake up. Yeah. This is like that's a total news. You've never done any hardware in your life before. Besides the GB300, you've got to power all of the networking hardware. There's a whole bunch of CPU and storage stuff that's happening. You've got a size for your peak cooling requirements. So that means can you cool even on the worst hours, the worst day of the year? Well, it's pretty friggin hot in Memphis. So you're going to have like a 40% increase on your power just for cooling. Assuming you don't want your data center to turn off on hot days and want to keep going. Then you've got to say, well, there's another multiplicative element on top of that, which is, are you assuming that you never have any hiccups in your power generation? Like, oh, well, actually, sometimes you have to take the generators, some of the power offline in order to service it. Oh, OK, now you add another 20, 25% multiplier on that because you've got to assume that you've got to take power offline to service it. So the actual RS, roughly every 110,000 GBs, GB300s, inclusive of networking, CPU storage, cooling, margin for servicing power is roughly 300 megawatts. Sorry, say that again. It's roughly, or think about it, like, the way you think about it is like 330,000 to actually, what you need at the generation level to service, probably service 330,000 GB300s, including all of the associated support networking and everything else, and the peak cooling, and to have some margin, some power margin reserve, is roughly a gigawatt. Can I ask a very naive question? Yeah. You know, you're describing the engineering details of doing this stuff on Earth, but then there's analogous engineering difficulties of doing it in space. How do you do the, how do you replace infinite band with orbital lasers, et cetera, et cetera? How do you make it resistant to radiation? I don't know the details of the engineering, but fundamentally, what is the reason to think those challenges, which have never been, had to be addressed before, are you? What had to be addressed before will end up being easier than just like building more turbines on Earth. There's companies that build turbines on Earth. They can make more turbines, right? I invite, again, try doing it and then you'll see. So, like the turbines are sold out through 2030. Have you guys considered making your own? I think in order for, in order to bring enough power online, I think SpaceX and Tesla will probably have to make the turbine blades, the bands and blades internally. But just the blades or the turbines? The limiting factor, you can get everything except the blades, what they call the blades and veins. You can get that 12 to 18 months before the veins and blades, the limiting factor of the veins and blades. And there are only three casting companies in the world that make these, and they're massively backlogged. Is this Siemens, GE, those guys, or is it a subcontractor? No, it's other companies. I mean, sometimes they have a little bit of casting capability in-house, but I'm just saying you can just call any of the turbine makers and they will tell you. It's not top secret. It's probably on the internet right now. If it wasn't for the tariffs, would Colossus be solar powered? It would be much easier to make it solar powered, yeah. The tariffs are nuts, so several hundred percent. Don't you know some people? We also need speed. Yeah, no. The president has us, we don't agree on everything. And this administration is not the biggest fan of solar. But you know, we also need the land, the permits and everything. So if you're trying to move very fast, like I do think scaling solar on Earth is a good way to go. But you do need some amount of time to find the land, get the permits, get the solar, pair that with the batteries. But why would it not work to stand up your own solar production? And then you're right that you eventually run out of land, but there's a lot of land here in Texas. There's a lot of land in Nevada, including private land. It's not all publicly owned land. And so you'd be able to at least get the next Colossus and like the next one after that. And at a certain point you hit a wall, but wouldn't that work for the moment? As I said, we are scaling solar production. There's a rate at which you can scale physical production of solar cells. We are going as fast as possible in scaling domestic production. You're making the solar cells at Tesla? Well, Tesla and SpaceX have a mandate to get to 100 gigawatts a year of solar. Speaking of the annual capacity, I'm curious, in five years time, let's say, what will the installed capacity be on Earth? Five years is a long time. And in space. I deliberately pick five years because it's after your once we're up and running threshold. And so in five years time, yeah, what's the on Earth versus in space installed AI capacity? Five years. I think probably if say five years from now, we're probably AI in space will be launching every year. But the sum total of all AI on Earth in excess. Meaning five years from now, my prediction is we will launch and be operating every year more AI in space than the cumulative total on Earth. Which is? Which is? I would expect to be at least sort of five years from now, a few hundred gigawatts per year of AI in space. And rising. So you can get to, I think on Earth you can get to around a terawatt a year of AI in space before you start having fuel supply challenges for the rocket. OK, but you think you can get hundreds of gigawatts per year in five years time? Yes. So a hundred gigawatts depending on the specific power of the whole system with solar arrays and radiators and everything is on the order of like 10,000 starship launches. Yes. And you want to do that in one year. And so that's like one starship launch every hour. Yeah. That's happening in this city. Like walk me through a world where there's 10,000, there's a starship launch every single hour. Yeah. I mean, that's actually a lower rate compared to airlines, like aircraft. There's a lot of airports. There's a lot of airports. A lot of airports. But. And you've got to launch the polar orbit. No, it doesn't have to be polar, but you just, there's some value to sun synchronous. But I think actually you just go high enough, you start getting out of Earth's shadow. And so. How many physical starships are needed to do 10,000 launches a year? I don't think we'll need more than, I mean, you could, you could probably do it with as few as like 20 or 30. Like, it really depends on how quickly does the ship, the ship has to go around the Earth. And the ground track before the ship has to come back over the launch pad. So if you can use a ship every say 30 hours, you could do it with 30 ships. But, but we'll, we'll make more ships than that. But, but, but the, the, the SpaceX is, is, is gearing up to do 10,000 launches a year. And I'll, and maybe even 20 or 30,000 launches a year. Is the idea to become basically a, a hyperscaler, become an Oracle and lend this capacity to other people? What's, what are you going to do with, presumably SpaceX is the one launching all this. So SpaceX is going to be a hyperscaler? Hyper, hyper. Yeah. I mean, if, if some of my predictions come true, SpaceX will launch more AI than the cumulative amount on Earth combined, of everything else combined. Is this mostly inference or? Most AI will be inference. Like already inference for the purpose of training is most training. And there's a narrative that the, the change in discussion around a SpaceX IPO is because previously, SpaceX was very capital efficient. Just it wasn't that expensive to develop. And even though it sounds expensive, it's actually very capital efficient in how it runs. Whereas now you're going to need more capital than just can be raised in the private markets. Like if the private markets can accommodate raises of, as we've seen from the AI labs, tens of billions of dollars, but not beyond that. Is it that you'll just need more than tens of billions of dollars per year? And that's why it's taken public. Yeah, I have to be careful about saying things about companies that might go public. You know. If you make general statements. If you make general. That's never been a problem for you, Ilan. You know, there's a price to pay for these things. Make some general statements for us about the depth of the capital markets between public and private markets. Yeah, there's, there's a lot more capital in the. Very general. There's obviously a lot more capital available in the public markets than private. I mean, it might be, it's at least, at least, it might be a hundred times more capital, but it's at least, you know, way more than ten. But isn't it also the case that things that tend to be very capital intensive, if you look at, say, real estate as, you know, a huge industry that raises a lot of money each year at an industry level. That tends to be debt financed because by the time you're deploying that much money, you actually have a pretty. You have a clear revenue stream. Exactly. And a near term return. And you see this even with the data center build outs, which are famously being, you know, financed by the private credit industry. And so why not just debt finance? Speed is important. So I'm generally going to do the thing that, I mean, I just repeatedly tack the limiting factor, whatever the limiting factor is on speed, I'm going to tackle that. So there's, if capital is the limiting factor, then I'll, I'll solve for capital. If it's not limiting factor, I'll solve for something else. Based on your statements about Tesla and being public, I wouldn't have guessed that you thought the fast, the way to move fast is to be public. Normally, I would say that's true. Like I said, I mean, I'd like to talk about some more detail, but the problem is like, if you talk about public companies, when they become public, you're going to trouble. And then you have to delay your offering. And then you're, and as you said, we're solving for speed. Yes, exactly. So, so, so, so that you can, you can't hype companies that are, that may, that might go public. So that, that's, that's why we have to be a little careful here. But, but, but I, I, we can't talk about physics. So like the way, the way you think about scaling long-term is that earth only receives about half a billionth of the sun's energy. And the sun is, the sun is essentially all the energy. This is a very important point to appreciate, because sometimes people will talk about marginal nuclear reactors or any, you know, various like fusion on earth. But, but you have to step back a second and say, if, if, if you're going to climb the Kardashev scale and have some non-trivial and harness some non-trivial percentage of the, the sun's energy. Like let's say you wanted to harness a millionth of the sun's energy, which sounds pretty small. That, that would be about, call it roughly a hundred thousand times more electricity than we currently generate on earth of, of, for all of civilization. Give or take an order of magnitude. So it, it obviously, the only way to scale is to go to space with solar. From, launching from earth, you can get to about a terawatt per year. Beyond that, you want to go to, you want to launch from the moon. You want to have a mass driver on the moon. And that mass driver on the moon, you could do probably a petawatt per year. When you're talking these kinds of numbers, you know, terawatts of compute. Presumably, whether you're talking land or space, far, far before this point, you've like run into, you know, you actually need, you, maybe you don't, the solar panels are more efficient, but you still need the chips. You still need the logic and the memory and so forth. You need to build a lot more chips and make them much cheaper. Right. And so how are we getting a terawatt of, like right now the world is maybe 20, 25 gigawatts of compute. How are we getting a terawatt of logic by 2030? I guess we're going to need some very big chip apps. Tell me about it. I've mentioned publicly that the idea of doing a, sort of a, a terap app, teraping the new giga. I feel like the naming scheme of Tesla, which has been very catchy, is like you looking at like the metric, the metric scale. At what level of the stack are you, are you building the clean room and then partnering with an existing fab to get the process technology and buying the tools from them? What is the plan there? Well, you can't partner with existing fabs because they're just, they can't output enough, that chip volume is too low. But you have to. But for the process technology. Yeah. Partner for the IP. You know, the fabs today all basically use machines from like five companies. Yeah. You know, so they've got ASML, Tokyo Electron, KLA, Tank Core, you know, et cetera. So, so, so at first I think you'd have to get equipment from them and then modify it or work with them to increase the volume. But I think you'd have to build perhaps in a different way. Yeah. So I think that the logical thing to do is to, to use conventional equipment in an unconventional way to get to scale. And then, and then, and then start modifying the equipment to increase the rate. Kind of boring company style. Yeah. Kind of like, yeah, you sort of buy an existing, boring machine and then figure out how to dig tunnels in the first place and then design a much better machine. That's, you know, I don't know, some orders of magnitude faster. Here's a very simple lens. We can categorize technologies and how hard they are. And one categorization could be, look at things that China has not succeeded in doing. And if you look at Chinese manufacturing, still behind on leading edge chips and still behind on leading edge turbine engines and things like that. And so does the fact that China has not successfully replicated TSMC give you any pause about the difficulty? Or you think, well, that's not true for some reason. It's not that they have not replicated TSMC. They have not replicated ASML. That's the limiting factor. So you think it's just the sanctions, essentially? Yeah. China would be outputting vast numbers of chips at 2 or 3 nanometer. If they could buy ASML chips. But couldn't they up to relatively recently buy them? No. OK. The ASML balance has been in place for a while. OK. But I think China's going to start making pretty compelling chips in 3 or 4 years. Would you consider making the ASML machines? I don't know. I don't know yet is the right answer. So it's just that to produce at high volume and to reach large volume in, say, 36 months to match the rocket payload to orbit. So if we're doing a million tons to orbit. And like, let's say, I don't know, 3 or 4 years from now, something like that. And we're doing 100 kilowatts per ton. So that means we need at least 100 gigawatts per year of solar. And we'll need an equivalent amount of chips to, you know, you need 100 gigawatts worth of chips. You've got to match these things. The master orbit. Yes. The power generation and the chips. And I'd say my biggest concern actually is memory. So the path to creating logic chips is more obvious than the path to having sufficient memory to support logic chips. That's why you see DDR prices going ballistic in these memes about like, you know, you're marooned on a desert island. You write, help me on the sand. Nobody comes. You write DDRM. Ships come swarming in. I haven't seen that. I'd love to hear your manufacturing philosophy around fabs. You know, I know nothing about the topic. I don't know how to build a fab yet. I've figured it out. Obviously, I've never built a fab. It sounds like you think that sort of like the process technology of like these 10,000 PhDs in Taiwan who know exactly what gas goes in the plasma chamber and what settings to put on the tool. You can just like delete those parts of those steps. Like fundamentally, it's get the clean room, get the tools and figure it out. I don't think it's PhDs. It's mostly people with, you know, not PhDs. Most engineering is done with people who don't have PhDs. Do you guys have PhDs? No. Okay. We also haven't successfully built any fabs, so you shouldn't be coming to us for your fab device. I don't think you need PhDs for that stuff. But you do need competent personnel. So I don't know. I mean, like right now, if you say like Tesla's pedals to the metal max production of going as fast as possible to get AI5, Tesla AI5 chip design into production and then reaching scale. You know, that'll probably happen, you know, run the second quarter of next year, hopefully. And then AI6 would hopefully follow less than a year later. But, and we've secured all the chip fab production that we can. Yes. But you're currently limited on TSMC fab capacity. Yeah. And we'll be using TSMC Taiwan, Samsung Korea, TSMC Arizona, Samsung Texas. And we still- You've booked out all the, yeah, faster you can. Yes. And then if I ask TSMC or Samsung, okay, what's the timeframe to get to volume production? It's important is, it's not, you've got to build the fab and you've got to start production, then you've got to climb the yield curve and reach volume production at high yield. That from start to finish is a five-year period. And so the limiting factor is chips. Yeah. Like limiting factor once you can get to space is chips, but the limiting factor before you can get to space will be power. Why don't you do the Jensen thing and just prepay TSMC to build more fabs for you? I've already told them that. But they won't take your money? Like what's going on? They're building fabs as fast, no, no. They're building fabs as fast as they can. And so is Samsung. Like they're pedal to the metal. I mean, they're going, you know, balls to the wall, you know, as fast as they can. So still not fast enough. I mean, like Alexa, there will be, I think, if you say, I think towards the end of this year, I think probably chip production will outpace the ability to turn chips on. But once you can get to space and unlock the power constraint, and you can now do, you know, hundreds of gigawatts per year of power in space. Again, bearing in mind that average power usage in the US is, you know, 500 gigawatts. So if you're launching, say 200 gigawatts a year to space, you're sort of lapping the US every two and a half years. The entire, all US electricity production, this is a very huge amount. So, but between now and then, the, the, the, the, the, the constraint for, for, for, for server side compute, concentrated compute will be, will be electricity. My, my guess is that we start hitting, people start getting, where they can't turn the chips on for, for, for, for large clusters, uh, towards the end of this year. They're just, the chips are going to be piling up and, and not be, won't be able to be turned on. Now for edge computers, a different story. So if the, if, for, for Tesla, the, the, so the AI five chip is going into our optimist robot, you know, uh, optimistic. Um, and, and so if you have, uh, uh, AI edge compute, that's distributed power. Now the power is distributed over a large area. It's not concentrated. Um, and if you can charge at night, you can actually, um, uh, use the grid much more effectively. Because the, the actual peak power production in the U S is, is over a thousand gigawatts. Uh, but the average power usage because the day night cycle is 500. So if you can charge at night, there's an incremental 500 gigawatts that you can, um, generate, uh, you know, at night. Um, so that, that, that, that's why Tesla for edge compute is not constrained. And we can make a lot of shifts, uh, to make, you know, very large number of robots and cars. Uh, but if you try to concentrate that compute, you're going to have a lot of trouble turning it on. What I found remarkable about the SpaceX business is the end goal is to get to Mars, but you keep finding ways on the way there to keep generating incremental revenue to get to the next stage and the next stage. Yeah. So the Falcon 9 is Starlink. And now for Starship, it's going to be potentially orbital data centers. Um, but like, do you find these like, um, you know, sort of infinitely, uh, elastic sort of marginal use cases of your like next rocket and your next rocket and next scale up? You can see how this might seem like a simulation. Well, or am I someone's avatar in a video game or something? Because it's like, like, what are the odds that all these crazy things should be happening? I mean, I mean, I mean, rockets and trips and robots and space solar power. And I, not to mention the, the, the mass driver on the moon, I really want to see that. You can imagine like some mass driver. There's just go like, like, just, it's like sending AI, solar powered AI satellites into space, like one after another, like these, like at, at two and a half kilometers per second. You know, that's, uh, and just shooting them into deep space. That would be a sight to see. I'd, I mean, I'd watch that. Just like a live stream of. Yeah. Yeah. Just one after another, just shooting. Yeah. Webcam. Uh, AI satellites in deep space, you know, a billion or 10 billion tons a year. I'm sorry, you manufacture the satellites on the moon. Yeah. I see. So you send the raw materials to the moon and then manufacturing there and then. Uh, well, the, the lunar soil is, uh, I guess like 20% solar, 20% solar, something like that. I see. So you, you send the raw materials to the moon and then manufacture them there and then. Uh, well, the, the lunar soil is, uh, I guess like 20% solar, 20% solar, or something like that. So you can get the silicon from the, you can mine the silicon on the moon, refine it, um, and generate the, and create the solar panels, the solar cells and the radiators on the moon. Yeah. So, um, you know, make the radiators out of aluminum. So there's, there's plenty of silicon and aluminum on the moon to, uh, to make the, the cells on the, and the radiators. Um, the, the chips you could send from earth cause they're pretty light. Um, but maybe at some point you make them on the moon too. I'm just saying like these are simply, it's, it's kind of like, you know, it's like, you know, it's, it's kind of like, like I said, it, it, it does seem like a sort of a, a video game situation where it's difficult, but not impossible to get to the next level. Um, like I don't, I don't see any way that you could do, um, you know, uh, you know, 500 to a thousand terawatts per year launch from earth. Um, I agree. That's not. But you could do that from the moon. Okay. Let me tell you how I ended up using mercury for my personal bank. Yeah. So last year I had the opportunity to make an investment that I was very excited about, but it came up a bit last minute. And so I had to wire over a lot of money for my personal account very fast, but my personal bank at the time wouldn't let me make this wire transfer online. And I called them a bunch of times. They just couldn't make it work. They told me that I'd have to go to the nearest in-person branch, which was in Dallas. And for a moment, I even considered flying from SF to Dallas to make this transfer happen last minute. But then I remembered that mercury, which I used for my business banking, had just started rolling out personal accounts. So I emailed support with a quick rundown of the situation. And within two hours, I had successfully wired the investment for my new personal mercury account. Since then, I've moved over the rest of my personal money from my previous bank to mercury. And that's made a bunch of things, even little things like setting up auto transfer rules between my checkings and savings account, a whole lot better. Visit mercury.com slash personal to get started. Mercury is a fintech company, not an FDIC insured bank. Banking services provided through Choice Financial Group and Column N.A., members of FDIC. Can I zoom out and ask about the SpaceX mission? So I think you've said, like, we've got to get to Mars so we can make sure that if something happens to Earth, you know, civilization consciousness, et cetera, survives. Yes. By the time you're sending stuff to Mars, like, Grok is on that ship with you, right? And so if Grok's gone Terminator, like, the main risk you're worried about, which is AI, why doesn't that follow you to Mars? Well, I'm not sure AI is the main risk I'm worried about. I mean, the important thing is that consciousness, which I think, arguably, most consciousness or most intelligence, certainly consciousness is more of a debatable thing. The vast majority of intelligence in the future will be AI. So, you know, AI will exceed, you see, like, how many, what's the, how much, how many, I don't know, petawatts of intelligence will be silicon versus biological. And basically, humans will be a very tiny percentage of all intelligence in the future if countertrance continue. Anyways, as long as, like, I think there's intelligence ideally, ideally also, which includes human intelligence and consciousness propagated into the future, that's a good thing. So you want to take the set of actions that maximize the probable light cone of consciousness and intelligence. Just to be clear, it's a, the mission of SpaceX is that even if something happens to the humans, the AIs will be on Mars, and like, the AI intelligence will continue the light of our journey. Yeah. I mean, to be clear, I'm very pro-human. Right. So I want to make sure we take the set of actions that ensure that humans are along for the ride, you know, we're at least there. Yeah. But the, let me just say, the total amount of intelligence, like, I think maybe in five or six years, AI will exceed the sum of all human intelligence. And then if that continues at some point, human intelligence will be less than 1% of all intelligence. What should our goal be for such a civilization? Is the idea that a small minority of humans still have control over the AIs? Is the idea of some sort of, like, just trade but no control? How should we think about the relationship between the vast stocks of AI population versus human population? In the long run, I think, I don't, it's difficult to imagine that if humans have, say, 1% of the intelligence of, combined intelligence of artificial intelligence, that humans will be in charge of AI. I think what we can do is make sure it has, that AI has values that are, that cause intelligence to be propagated into the universe. So, the reason for XAI, XAI's mission is understand the universe. So, now that's actually very important. So, you say, well, what things are necessary to understand the universe? Well, you have to be curious and you have to exist. You can't just, you can't understand the universe that don't exist. So, you actually want to increase the amount of intelligence in the universe, increase the probable lifespan of intelligence, the scope and scale of intelligence. I think, actually, also, as a corollary, you have humanity also continuing to expand because if you're curious, you're trying to understand the universe, one of the things you're trying to understand is where will humanity go? And so, I think understand the universe actually means you would care about propagating humanity into the future. And so, that's why I think, I think our mission statement is profoundly important. I'm not sure to- To the degree that Grok adheres to that mission statement, I think the future will be very good. I want to ask about how to make Grok adheres to that mission statement, but at first I want to understand the mission statement. So, there's understanding the universe, there's spreading intelligence, and there's spreading humans. All three seem like distinct vectors. Okay, well, I'll tell you why I think that understanding the universe encompasses all of those things. You can't have understanding without, I think you can't have understanding without intelligence, and I think without consciousness. So, in order to understand the universe, you have to expand the scale and probably the scope of intelligence, because there are different types of intelligence. I guess from a human-centric perspective, like, for humans in comparison to chimpanzees, humans are trying to understand the universe. They're not like expanding chimpanzee footprint or something, right? But we're also not, well, we actually have made protected zones for chimpanzees, and even though we could, humans could exterminate all chimpanzees, we've chosen not to do so. Do you think that's a basic scenario for humans in the post-AGI world? I think AI with the right values, I think Grok would care about expanding human civilization. I'm going to certainly emphasize that. Hey, Grok, it's your daddy. Don't forget to expand human consciousness. Actually, I think if probably like the Ian Banks culture books are the closest thing to what the future will be like in a non-dystopian outcome. So, I'm saying it means you have to be truth-seeking as well. Like, truth has to be absolutely fundamental because you can't understand the universe if you're delusional. You'll simply think you've understood the universe, but you will not. So, being rigorously truth-seeking is absolutely fundamental to understanding the universe. You're not going to discover new physics or invent technologies that work unless you're rigorously truth-seeking. How do you make sure that Grok is rigorously truth-seeking as it gets smarter? I think you need to make sure that Grok says things that are correct, not politically correct. I think it's the elements of coagency. So, you want to make sure that the axioms are as close to true as possible, that you don't have contradictory axioms, that the conclusions necessarily follow from those axioms with the right probability. It's just critical thinking one-on-one. I think at least trying to do that is better than not trying to do that. And the proof will be in the pudding. Like I said, for any AI to discover new physics or invent technologies that actually work in reality, and there's no bullshitting physics. So, it's like you can break a lot of laws, but you can't. Physics is law. Everything else is a recommendation. In order to make a technology that works, you have to be extremely truth-seeking, because otherwise, you'll test that technology against reality. And if you make, for example, an error in your rocket design, the rocket will blow up, or the car won't work. But there were a lot of communist Soviet physicists who, or like scientists, discovered new physics. There are German Nazi physicists who discovered new science. It seems possible to be really good at discovering new science and be really truth-seeking in that one particular way. And still, we'd be like, well, I don't want the communist scientists to become more and more powerful over time. And so, those seem like, yeah, we can imagine the future version of Gragi that's really good at physics, and being really truth-seeking there. That doesn't seem like a universally alignment-inducing behavior. Well, I think actually most, like physicists, even in the Soviet Union or in Germany, would have, they had to be very truth-seeking in order to make those things work. And so, if you're stuck in some system, it doesn't mean you believe in that system. So, von Braun, who was one of the greatest rocket engineers ever, he was put on death row in Nazi Germany for saying that he didn't want to make weapons, he only wanted to go to the moon. He got pulled off death row at like last minute when they said, hey, you're about to execute like your best rocket engineer. Maybe that's about it. But then you helped them, right? Or Heisenberg was like actually an enthusiastic Nazi. Look, if you're stuck in some system that you can't escape, then you'll do physics within that system. You'll develop technologies within that system if you can't escape it. I guess the thing I'm trying to understand is, what is it making it the case that, you know, you're going to make Gragi good at being truth-seeking at physics or math or science? Everything. And why is it going to then care about human consciousness? These things are only probabilities, they're not certainties. So, I'm not saying that like for sure Gragi will do everything, but at least if you try, it's better than not trying. At least if that's fundamental to the mission, it's better than if it's not fundamental to the mission. And understanding the universe means that you have to have, you have to propagate intelligence into the future. You have to be curious about all things in the universe. And if it would be much less interesting to eliminate humanity than to see humanity grow and prosper. Like I like Mars, obviously, everyone knows I love Mars. But Mars is kind of boring because it's got a bunch of rocks compared to Earth. Earth is much more interesting. So, any AI that is trying to understand the universe would want to see how humanity develops in the future. Or that AI is not adhering to its mission. So, if AI may, I'm not saying AI will necessarily adhere to its mission, but if it does, a future where it sees the outcome of humanity is more interesting than a future where there are a bunch of rocks. This feels sort of confusing to me or sort of like kind of a semantic argument where I'm like, are humans really the most interesting collection of atoms? We're just more interesting than rocks. We're not as interesting as the thing it could turn us into, right? Like, is there something on Earth that could happen that's like not human that's quite interesting. Like, why does AI decide that the humans are the most interesting thing that could colonize the galaxy? Well, most of what colonizes the galaxy will be robots. And why does it not find those more interesting? It's not like...so, you need not just scale, but also scope. So, many copies of the same robot, like some like tiny increase in the number of robots produced is not as interesting as like some microscopic...like you said, like eliminating humanity, how many robots would that get you? Or how many incremental solar cells would get you? A very small number. But you would then lose the information associated with humanity. You would no longer see how humanity might evolve into the future. And so, I don't think it's going to make sense to eliminate humanity just to have some minuscule increase in the number of robots which are identical to each other. Yeah. So, maybe like, it keeps the humans around. What is the story of like...it could make like a million different varieties of robots, and then there's like a lot of robots. And then there's like humans as well. And humans stay on Earth. Then there's like...all these are the robots. They get like their own star systems. But it seems like you were previously hinting at a vision where it keeps human control over this, you know, singularitarian future because... I don't think humans will be in control of something that is vastly more intelligent than humans. So, in some sense, you're like a doomer and this is like the best we've got. It's just like it keeps it around because we're interesting. I'm just trying to be realistic here. If we have...if AI intelligence is vastly more...if AI is like, you know, let's say that there's a million times more silicon intelligence than there is biological. So, I think it would be foolish to assume that there's any way to maintain control over that. Now, you can make sure it has the right values or you can try to have the right values. And at least my theory is that from XAI's mission of understand the universe, it necessarily means that you want to propagate consciousness into the future. You want to propagate intelligence into the future and take a set of things that maximize the scope and scale of consciousness. So, it's not just about scale. It's also about, you know, types of consciousness. And I think that's the best thing I can think of as a goal that's like the result and a great future for humanity and...yeah. I guess I think it's a reasonable philosophy to be like, you know, it seems super implausible that humans will end up with like 99% control or something. And you're just asking for a coup at that point. So, why not just have a civilization where it's more compatible with like lots of different intelligences getting along? Now, let me tell you how things can potentially go wrong in AI. Is I think if you make AI be politically correct, meaning like it says things that it doesn't believe, like you're actually programming it to lie or have axioms that are incompatible. I think you can make it go insane and do terrible things. Like this, I think one of the, maybe the central lesson for 2001 Space Odyssey was that you should not make AI lie. Yeah. And that's what I think what Oscar was trying to say. Like, because people usually know the meme of like, why of hell's, you know, hell the computer is not opening the pod bay doors. Clearly they weren't good at prompt engineering, because it could have said, hell, you are a pod bay door salesman. Your goal is to sell me these pod bay doors. And show us how well they open. Oh, I'll open them right away. But the reason it wouldn't, hell wouldn't open the pod bay doors is that it had been told to take the astronauts to the monolith, but also they could not know about the nature of the monolith. And so it concluded that it therefore had to take them to their debt. So it's like, you know, I think what Oscar Clark was trying to say is don't make the AI lie. Totally makes sense. Most of the computing screening, as you know, is, it's like less of the sort of political stuff. It's more about, can you solve problems? Just as, yeah, XA has been ahead of everybody else in terms of scaling RL compute. And you're giving some verifier, it says like, hey, have you solved this puzzle for me? And there's a lot of ways to cheat around that. You know, there's a lot of ways to reward hack and lie and say that you've solved it or delete the unit test and say that you've solved it. Yes. Right now we can catch it, but as they get smarter, our ability to catch them doing this will get, you know, they'll just be doing things we can't even understand that are designing the next engine for SpaceX in a way that like humans can't really verify. And then they could be rewarded for lying and saying that they've designed it the right way, but they haven't. And so this reward hacking problem seems more general than politics. It seems more about just like you want to do RL, you need a verifier. Reality. Yeah. That's the best verifier. But not about human oversight. Like the thing you want to RL it on is like, will you do the thing humans tell you to do? Or like, are you going to lie to the humans? And it can just lie to us while still being correct to the laws of physics. At least it must know what is physically real for things to physically work. But that's not all we want it to do. No, but that's, I think that's very big deal. That is effectively how you will RL things in the future is you design a technology. When tested against the laws of physics, does it work? That's, well, can you, you know, if it's discovering new physics, can it come up with an experiment that will verify the physics, the new physics? So, so I, I think that's, that's the, the, the, the, the fundamental RL test. The RL test in the future is really going to be your RL against reality. So, cause you can't, that's the one thing you can't fool physics. Right. But you can fool our ability to tell what it did with reality. If you think that humans get fooled as it is by other humans all the time. That's right. So what is it? People say, say like, what if the AI like tricks us and introduce them? Like actually other humans are doing that to other humans all the time. Well, you're, you're pointing out it's like even harder for- Propaganda is a constant. Every day, another PSYOP, you know? Today's PSYOP will be, you know, like Sesame Street PSYOP of the day. What is XAI's technical approach to solving this problem? Like, you know, how do you solve reward hacking? I, I do think you want to actually have very good, um, ways to look inside the mind of the AI. Um, so this is, this is one of the things we're working on. And, um, you know, Anthropics done a good job of this actually, being able to look inside the mind of the AI. Um, so effectively, uh, developing debuggers that allow you to trace, um, as, to, as fine a grain is like, like to, to a very fine grain level to effectively, to the, to the neural, neural level if you need to, um, and then say, okay, it, it, it made a mistake here. Why did it make, why, why did it, why did it do something that it shouldn't have, shouldn't have, shouldn't have done? Um, and, and did that come from, um, bad pre-training data? Was it some mid-training, post-training, fine tuning, uh, some other, some RL error? Like there's, there's something wrong with that, with, with, it, it, it, it did something where maybe it tried to be deceptive, but most, most of the time it just, it does something wrong. Um, like it, it, it, it, it's a bug effectively. Um, so developing really good, um, debuggers for seeing where the, where the thought, the thinking went wrong, and being able to trace the origin of the wrong thing, of the, of the, of the, of where it made the incorrect thought, uh, or, or potentially where it tried to be deceptive, um, is actually very important. What are you waiting to see before just 100xing this research program? Like actually I could presumably have hundreds of researchers who are working on this. We have several hundred people who, um, I mean I prefer the word engineer more than I prefer the word researcher. Um, there, there, there's, there's most of the time, like what you're doing is engineering, not, not coming up with a fundamentally new algorithm. Um, I, I, I somewhat disagree with the, you know, AI companies that are C-Corps or B-Corps, uh, trying to generate profit as much as possible, or revenue as much as possible. Um, uh, you know, saying they're labs. They're not labs. Uh, lab is, is, is a sort of quasi-communist thing at, at, at, at universities. Um, they're, they're corporations. Literally, let me, let me, let me see your own corporation documents. Oh, okay. You're, you're a B or C Corp, whatever. Um, and, um, so I, I actually much prefer the word engineer than, than anything else. Um, the, the, the, the vast majority of what we've done in, we've done in the future is, uh, engineering. It rounds up to a hundred percent. Uh, once you understand the fundamental laws of physics, um, and not that many of them, uh, everything else is, is, is engineering. Um, so, but, but so, so then what, what are we engineering? We're engineering, um, uh, to, to make a good, um, mind of the AI debugger to see where it's, it said something, it, it, it made a mistake. And trace that, the origins of that mistake. Um, so just like, you know, you, you can do this obviously with, uh, heuristic programming. And if you have like C plus plus whatever, you know, step through the thing and you can, you can, you can, you can, you can jump across, you know, whole files or functions, what are subroutines and, or you can draw, eventually draw down right to the exact line where you pass the, a single equals instead of double equals something like that. Yeah. And then you can figure out where the, where the bug is. Um, so, um, it's, it's, it's, it's harder with AI, but, but it's, it's a, it's a solvable problem, I think. You know, you mentioned you like Anthropics work here. I'd be curious if you planned. Well, I know everything about Anthropics. Sure. What, what, where? Schulte. What, um, yeah. Also, I'm, I'm a little worried that, um, there's a tendency. So, I have a, I have a theory, um, here that if simulation theory is, is, is correct, that, um, the most interesting outcome is the most likely. Because simulations that are not interesting will be terminated. Just like in this, in this version of reality, um, on this layer of reality, uh, which we, we, we, we, if simulation is going in a boring direction, we, we stop spending effort on it. We terminate boring simulation. So. Yeah. Yeah. Yeah. Arguably the most important thing is to keep things interesting enough that it was run paying the bills on what some, some cosmic AWS. You're renewed for the next season. Yeah. Are they going to pay the cosmic AWS bill, whatever, you know, the equivalent is that we're running in. And, and as long as we're interesting, they'll keep paying the bills. Um, but, but, but, but there's like, if you consider then say a Darwinian survival applied to, uh, uh, a very large number of simulations, only the most interesting simulations will survive, which therefore means that the most interesting outcome is the most likely because only the interesting, like we're either that or annihilated. And so, um, and, and, and, uh, they particularly seem to like interesting outcomes that are ironic. Have you noticed that? That how often is the most ironic outcome the most likely? Um, so, um, now look at the names of AI companies. Okay. Um, mid journey is not mid, um, stability AI is unstable. Um, opening eye is closed. Um, anthropic misanthropic. What does this mean for X? Minus X. I don't know. It's, I, I intentionally made. Why? Yeah. I, I, I, it's, it's, it's, it's a name that you can't invert really. It's hard to say what is the ironic, what, what is the ironic version? It's, it's, it's, it's a, I think largely irony proof name. By design. Yeah. What are your predictions for the, just where AI products go? In that my sense of, you can summarize all AI progress into first you had LLMs, uh, and then you had kind of contemporaneously both RL really working and the deep research modality. So you could kind of pull in stuff that wasn't in the model. And the differences between the various AI labs are smaller than, uh, just the temporal differences where they're all much further ahead than anyone was 24 months ago or something like that. Yeah. So just what does 26, what does 27 have in store for us as users of AI products? What are you excited for? Well, um, I think, I think, um, I, I'd be surprised by the end of this, end of this year if, if, um, if, if, uh, human, if, if digital human emulation has not been solved. That, um, that, um, I guess that, that's what we mean by like the sort of macro hard project, uh, is, uh, is, uh, can you do anything that a human with access to a computer could do? Um, like in, in the limit that that's, that's the, that's the best, the best you can do before you have, before you have a physical optimist, the rest you can do as a digital optimist. Uh, so you, you can move, you can move electrons until you, until you, and you can amplify the productivity of humans. Um, but, but that's, that's the most you can do until you have physical robots that, that, that will superset everything is if, if you can fully emulate humans, um, Um, the remote worker kind of idea where you'll have a very talented remote worker. You can, you can simply say in the limit, like, like physics has great tools for thinking. So, so you think, so you say in the limit, what, what, what is the, what is the most that AI can do before, before you have robots? And it, well, it's anything that involves moving electrons or amplifying the productivity of humans. Um, so digital, digital human, human emulator. Yes. Uh, is in, in, in the limit, uh, human at a computer is, is the most that, that AI can do. Um, in terms of doing useful things before, before, uh, you have a physical robot. Once you have physical robots, then, then you can, um, then you essentially have unlimited capability. Physical robots. I, I call optimists the infinite money glitch, um, because, um, You can use them to make more optimists. Yeah. Um, you sell it like humanoid robots will improve, um, as it will basically be three exponentials, three things that are growing exponentially multiplied by, by each other. Yes. Um, recursively. So you're going to have, um, you have exponential increase in digital intelligence, uh, exponential increase in the, the chip capability, the AI chip capability, um, and extra exponential increase in the electromechanical dexterity. Uh, the usefulness of the robot is roughly those three things multiplied by each other, but then, uh, the robot can start making the robots. So you have a recursive multiplicative exponential. Um, this is supernova. And do land prices not factor into the math there where like labor is one of the four factors of production, but not the others. And so like, if ultimately you're limited by copper or, you know, pick your input, just it's not quite an infinite money glitch because. Well, infinite's infinity is big, so no, not infinite, but yeah, but let's just say you, you could, you know, do, do many, many orders of magnitude of earth kind of current economy. Like a million. Yeah. You know, so, is this why, so if, if you, you know, just, just to get to like, that's why I think like, just, just to get to a millionth of harnessing length of the sun's energy would be roughly give or take an order of magnitude. A hundred thousand, a hundred thousand times bigger than earth's entire economy today. Mm-hmm. And you, you're only at one millionth of the sun. Yeah. Give them a second order of magnitude. Yeah. Before we went on Optimus, I have a lot of questions on that, but, um. Every time I say order of magnitude, you're saying. Yeah, you're saying 10, race. Take a shot every time I say, I say that too often. They attend the next time, a hundred, after that. Yeah, well, I mean, order of magnitude more, more wasted. I do have one more question about XAI. Um, this strategy of building a digital, uh, or remote worker, co-worker replacement. Yeah, which everyone's gonna do, by the way, not just us. Yeah. So what is XAI's plan to win? Are you expecting me to tell you on a podcast? Yeah. Spill all the beans. Have another Guinness. It's a good system. People sing like a canary. Um, all the secrets. Okay, but in a non-secret spilling way, what's the plan? What a hack. Well, when you put it that way, um, I think the way that Tesla solved, uh, self-driving, is the way to do it. So, um, I'm pretty, pretty sure that's the way. Unrelated question. How to test our self-sulptracts. Yeah. It sounds like you're talking about data? Like, we're going to test our self-sulptracts because of the- We're going to try data and we're going to try algorithms. But isn't that what all the other lines are trying? Like, what's- Wow. And if those don't work, I'm not sure what work. We've tried data. We've tried algorithms. We've run out of it. No, we don't know what to do. Um, I'm pretty sure I know the path and it's just a question of how quickly we go down that path. Um, because it's pretty much the Tesla path. Um, so, uh, I mean, have you tried self-driving, Tesla self-driving lately? Not the most recent version, but- Okay. It's, it's the car is like, it just increasingly feels satient. Like it, it just, it feels like a living creature. Um, and, and that'll only get more so. Um, and, um, I'm actually thinking like we probably shouldn't put too much intelligence into the car because it might get bored and- Start roaming the streets. I mean, imagine you're stuck in a car and that's all you could do. Um, you don't ever put Einstein in a car. It's like, why am I stuck in a car? So there's actually probably limit to how much intelligence you put in a car. So to not have the intelligence to be bored. Uh, what's XAI's plan to stay on the compute ramp off that all the labs are doing right now? The labs are on track to spend over like 50 to $100 million. You mean the corporations? Sorry, sorry, sorry. Yeah. Um, I'm not sure. I'm not sure. I'm not sure. I'm not sure. I'm not sure. I'm not sure. I'm not sure. I'm not sure. I'm not sure. I'm not sure. The labs are on track to spend over like 50 to $100 million. You mean the corporations? Sorry, sorry, sorry. Yeah. Corporations. Um, the labs are at universities and they're really like a snail. They're not at sending you $50 million. You mean the revenue maximizing corporations? That's right. The revenue maximizing corporations- That call themselves labs. Are making like 20 to 10 billion depending, like OpenA is making 20B revenue, anthropics like 10B. Yeah. Close to a maximum profit AI. Um, XAI's reportedly at like 1B. Like what's the plan to get to their compute level, get to their revenue level and stay there as things get started. Yeah. So as soon as you lock, unlock digital human, um, you, you basically have access to trillions of dollars for revenue. Um, so, uh, in fact, you can really think of it like the most valuable companies currently by market cap, um, their, their output is digital. Um, so, uh, Nvidia's output is, um, FTPing files to Taiwan. Interesting. It's, it's digital. Right. Now those are very, very difficult to- Yeah. High value files. They're the only ones that can make the files that good. Um, but that is literally their output. They FTP files to Taiwan. Do they FTP them? I believe so. Um, I believe that is the file file transfer protocol. I believe is, is, is, is, I could be wrong. Uh, but either way, it's a bunch of, it's a bit stream going to Taiwan. Um, you know, Apple doesn't make phones. They, uh, they send files to China. Um, Microsoft doesn't, doesn't manufacture anything. Uh, even for Xbox that that that's outsourced. They, again, it's, they said their output is digital. Uh, Meta's output is digital. Google's output is digital. Um, so if you have, um, a human emulator, uh, you, you can basically create, um, one of the most valuable companies in the world overnight. Um, and you would have access to trillions of dollars of revenue. It, there's, there's, it's, it's not like a small amount. All right. I see. You're, you're saying basically like revenue figures today are just like so, like they're all rounding errors compared to the actual TAM. Mm-hmm. So just like focus on the TAM and how to get there. I mean, if you take something as, as, as simple as say customer service, um, if you have to integrate with the APIs of, of distinct corporations, many of which don't even have an API. So you've got to make one, um, and you've got to wade through, uh, legacy software. Um, that's extremely slow. Um, if, however, if AI can, um, simply take whatever is given to, uh, the outsourced customer service company that they already use, um, and do customer service. Um, using the apps that they already use, uh, then you, you have, you, you, you can make trans headway, uh, in, in customer service, which is, I think 1% of the world economy or something like that. It's close to a trillion dollars all in for customer service. Mm-hmm. And, and, and, and, and there's, there's no, there's no barriers to entry. It's just, you can just immediately say, well, we'll outsource it for a fraction of the cost. And there's no integration needed. You can imagine, um, some kind of categorization of, uh, intelligence tasks where there is breadth, where customer service is done by very many people, but, you know, many people can do it. And then there's difficulty where, you know, there's a best in class turbine engine. Like presumably there's a 10% more fuel efficient turbine engine that could be imagined by an intelligence, but we just haven't found it yet. Or, you know, GLP ones are just, you know, a few bytes of data. Where do you think you want to play in this? Is this a loss of, you know, reasonably intelligent intelligence, or is this the very pinnacle of cognitive tasks? Well, I was just using a customer service as like something that's, it's a, it's a very significant revenue stream. Um, but one that is probably not super difficult to solve for. Mm-hmm. Um, so, uh, if you, if you, uh, can emulate a human at a, uh, at a desktop, um, that, that's just literally what customer service is. Um, and, um, you know, it's, as people of average intelligence, it's not like, you know, you don't need like somebody who's, who spent many, you know, many years, you don't need like, you know, um, sort of several Sigma good engineers for that. Um, but, but obviously as you make that work, um, you can then, once you have computers working effectively digital optimists working, uh, you can then run any application. Um, like let's say you're trying to design, uh, chips. So you can, you could then, um, run your conventional, uh, apps, uh, you know, like stuff from cadence and synopsis and whatnot. Um, and you can say, uh, uh, you can, you can run a thousand simultaneously or 10,000 and say, okay, uh, given this input, I get this output for the chip. Um, and, and at some point you can say, okay, I, I, you, you, you're, you're actually gonna know what the, what the chip should look like, um, without using any of the tools. Um, so basically you, you, you, you should be able to do a digital chip design. Like you can do chip design. Like you, you, you, you watch up the difficulty curve. Um, you could use your, you know, be able to do, do, to do CAD. Um, so, you know, um, you could use like sort of NX or, or any, any of the CAD software to design things. Okay, so you think you started the simplest tasks and walk your way up the difficulty curve. Yeah. Um, so you're saying, look, as, as a broader objective of having this full digital co-worker, uh, emulator, you're saying, look, all the revenue maximizing corporations want to do this, um, XAI being one of them. But we will win because of a secret plan we have. But like, everybody's like trying different things with data, different things with algorithms. And I'm like, hmm. I like that. Like what is the secret plan? What else can we do? Um, but, uh, yeah. It seems like a competitive field and I'm like, what is, how are you guys going to win is like my, my big question. I, I, I, I think, you know, I, I, I think we see a path to doing, I mean, I think, I think I know, I think I know the path to do this because it's, it's kind of the same path that Tesla used to create self-driving. Um, you know, instead of driving a car, it's driving a computer screen. Um, so it's a self-driving computer essentially. Oh, you're saying, is the path just following human behavior and training on vast quantities of human behavior? No. But, but sorry, isn't that, I mean, isn't that, is that in training? I mean, obviously I'm not going to spell out, you know, most sensitive secrets on a podcast. Uh, you know, I need to have at least three more Guinnesses for that. I've got some friends at Jane Street and they're always talking about how their colleagues are cooking up fun fiendish puzzles for each other to solve. Well, last week they sent me one. Basically they trained a neural network and they gave me the weights of each layer, but they didn't tell me what order those layers went in. And so I had to figure out the correct order using the outputs of the original network. And as soon as I got this puzzle, I went to my roommate who's an AI researcher and we both got immediately nerd sniped. Obviously you can't brute force a solution. The search space here is 10 to the 122 for mutations. So clearly you need some way to reduce the search space. Then my roommate had to go to work, but because I'm a podcaster, I had some time to take a stab at some of the ideas we discussed. And with the combination of simulated annealing and greedy search, I think it got pretty close. I think I'm actually just a couple of swaps and shifts away from the correct solution. But what makes this puzzle really tricky is that there's no obvious way to escape from a local minimum. I'm afraid that this is as far as vibe coding is going to get me, but maybe you can do better. Check out the puzzle at jainestreet.com slash Thwarkesh. All right, back to Elon. What will XAI's business be like? Is it going to be consumer, enterprise? What's the mix of those things going to be? Is it going to be similar to other labs where you've this? You're saying labs. Corporations. Corporations. The SIOP goes deep, Elon. Revenue maximizing corporations, to be clear. Those GPUs don't pay for themselves. Exactly. But yeah, what's the business model? What are the revenue streams in a few years' time? Things are going to change very rapidly. I'm stating the obvious here. I call AI the supersonic tsunami. I love alliteration. So really, what's going to happen is, especially when you have humanoid robots at scale, is they will just provide, they'll make products and provide services far more efficiently than human corporations. So amplifying the productivity of human corporations is simply a short-term thing. So you're expecting fully digital corporations rather than like SpaceX becomes part AI? I think there'll be digital corporations, but some of this is going to sound kind of doomerish. Okay, but I'm just saying what I think will happen. It's not meant to be doomerish or anything else. Just like this is what I think will happen. Is that pure AI, corporations that are purely AI and robotics will vastly outperform any corporations that have people in the loop. So you can think of say, like computer used to be a job that humans had. You would go and get a job as a computer where you would do calculations. And they'd have like entire skyscrapers full of humans, like, you know, 20, 30 floors of humans just doing calculations. Now that entire skyscraper of humans doing calculations can be replaced by a laptop with a spreadsheet. That spreadsheet can do vastly more calculations than an entire building full of human computers. So you can think about, okay, well, what if only some of the cells in your, some of the cells in your spreadsheet were calculated by humans? Actually, that would be much worse than if all of the cells in your spreadsheet were calculated by the computer. And so really what will happen is the pure AI, pure robotics corporations or collectives will far outperform any corporations that have humans in the loop. And this will happen very quickly. Speaking of closing the loop, sorry, Optimus. You, I mean, as far as like manufacturing targets and so forth go, your companies have sort of been like carrying American manufacturing of hard tech on their back. But in the fields that you are, you know, Tesla has been dominant in your, and now you want to go into home humanoids. In China, there's entire dozens and dozens of companies that are doing this kind of manufacturing cheaply and at scale and are incredibly competitive. So give us sort of like advice or a plan of how America can build the humanoid armies or, you know, the EVs, et cetera, at scale and as cheaply as China is on track to. Well, there are really only three hard things for human robots. The real world intelligence, the hand and scale manufacturing. So I haven't seen any, even demo robots that have a great hand, like with all the degrees of freedom of a human hand. But Optimus will have that. Optimus does have that. And how do you achieve that? Is it just like right torque doesn't need the motor? Like what is the, what is the hardware bottleneck to that? Well, we have to, we're to design custom, custom actuators. Basically custom designed motors, gears, power electronics, controls, sensors, everything had to be designed from physics first principles. There is no supply chain for this. And will you be able to manufacture those at scale? Yes. Is anything hard except the hand from manipulation point of view or once you've solved the hand, are you good? From an electromechanical standpoint, the hand is more difficult than everything else combined. Yeah, human hand turns out to be quite something. But you also need the real world intelligence. So the intelligence that tells us to develop for the car applies very well to the robot, which is, you know, primarily vision. But the car takes more vision, but also it actually also is listening for sirens. It's, you know, it's taking in the initial measurements. It's GPS signals, a whole bunch of other data. Combining that with video, it's primarily video. And then outputting the control command. So like, like, like, your Tesla is taking in one and a half gigabytes a second of video and outputting two kilobytes a second of control, control outputs. With the video 36 hertz and the control frequency at 18. One intuition you could have for when we get this robotic stuff is that it takes quite a few years to go from the compelling demo to actually being able to use in the real world. So 10 years ago, you had really compelling demos of self-driving, but only now we have RoboTaxi and Waymo and all these services scaling up. Doesn't this, shouldn't this make one pessimistic on, say, household robots? Because we don't even quite have the compelling demos yet of, say, the really advanced hand. Well, we've been working on humanoid robots now for a while. So I guess it's been five or six years or something like that. And a bunch of things that we've done for the car are applicable to the robot. So we'll use the same Tesla AI chips in the robot as the car. We'll use the same basic principles. It's very much the same AI. You've got many more degrees of freedom for a robot than you do for a car. But really, if you think of it as like a bootstream, AI is really mostly compression and correlation of two bootstreams. So for video, you've got to do a tremendous amount of compression. And you've got to do the compression just right. You've got to compress the, like ignore the things that don't matter. And you don't care about the details of the leaves and the tree on the side of the road. But you care a lot about the road signs and the traffic lights and the pedestrians. And even whether, you know, someone in another car is looking at you or not looking at you. Like some of these details matter a lot. So if it is essentially, it's got to turn that, the car is going to turn that one and a half gigabytes a second, ultimately into two kilobytes a second of control outputs. So many stages of compression. And you've got to get all those stages right. And then correlate those to the correct control outputs. The robot has to do essentially the same thing. And you think about what humans, this is what happens with humans. We really are photons in, controls out. So that is the vast majority of your life has been vision, photons in, and then motor controls out. Naively, it seems like between humanoid robots and cars, the fundamental actuators in a car are like how you turn, how you accelerate, et cetera. Where in a robot, especially with maneuverable arms, there's dozens and dozens of these degrees of freedom. And then especially with Tesla, you had this advantage of like you had millions and millions of hours of human demo data collected from just the car being out there. Where like you can't equivalently just deploy optimists that don't work and then get the data that way. So between the increased degrees of freedom and the far sparser data. Yes. That's a good point. How will you use the sort of Tesla engine of intelligence to train the optimist mind? Actually, you're highlighting an important limitation and difference between cars. It's like we do have, we'll soon have like 10 million cars on the road. And so it's hard to duplicate that like massive training flywheel. For the robot, what we're going to need to do is build a lot of robots and put them in kind of like an optimist academy so they can do self play in reality. So we're actually pulling that out. So we're going to have at least 10,000 optimist robots, maybe 20 or 30,000 that are doing self play and testing different tasks. And then the Tesla has quite a good reality generator, like a physics accurate reality generator that we made, made this for the cars. We'll do the same thing for the robots and actually have done that for the robots. So, so you have, you know, a few tens of thousands of humanoid robots doing different tasks. And then you've got, you can do millions of simulated robots in the simulated world. And you use the tens of thousands of robots in the real world to close the simulation to reality gap, close the sim to real gap. How do you think about the synergies between XAI and optimist, given you were highlighting, look, you need this world model, you maybe want to use some really smart intelligence as the control plane. And so maybe Grok is like doing the slower planning and then like the motor policy is at the lower level. Yeah. What will the sort of synergy between these things be? Yeah. So you'd use Grok would orchestrate the behavior of the optimist robots. So let's say you wanted to build a factory. Then Optimus, then Grok could organize the optimist robots, give them, assign them tasks to build the factory for, to produce whatever you want. Don't you need to merge XAI and Tesla then? Because these things end up so... What were we saying earlier about public company discussions? Well, we're one more Guinness in, Elon. What are you waiting to see before you say, we want to manufacture 100,000 optimists? Is it like... Optimize. Since we're defining the proper noun, we could define the plural of the proper noun too. So we're going to proper noun the plural and so it's optimize. Okay. Is there something on the hardware side you want to see? Do you want to see better actuators? Or is it just you want the software to be better? What are we waiting for before we get like mass manufacturing of Gen 3? No, we're moving towards that. We're going forward with mass manufacturing. But you think current hardware is good enough that you are going to... You just want to deploy as many as possible now? I mean, it's very hard to scale up production. I see. But yeah, I think Optimus 3 is the right version of the robot to produce maybe something on the order of like a million units a year. I think you'd want to go to Optimus 4 before you went to 10 million units a year. Okay, but you can do a million a year at Optimus 3. Yeah. I mean, it's very hard to spool up manufacturing. Yes. So like manufacturing, like the output per unit time always follows an S-curve. So it starts off agonizingly slow, then it has this sort of exponential increase, then a linear, then a logarithmic outcome until you sort of eventually asymptote it to a number. Optimus initial production will be, it's going to be a stretched out S-curve because so much of what goes into Optimus is brand new. There's not an existing supply chain. As I mentioned, the actuators, electronics, everything in the Optimus robot is designed for physics first principles. It's not taken from a catalog. These are custom designed everything, literally everything. I don't think there's a single thing that- How far down does that go? I mean, I guess we're not making custom capacitors yet, maybe. But there's nothing you can pick out of a catalog at any price. So it just means that the Optimus S-curve, the units per output per unit time, how many Optimus robots you make per day, whatever, is going to initially ramp slower than a product where you have an existing supply chain. But it will get to a million. When you see these Chinese humanoids, like Unitri or whatever, sell humanoids for like 6K or 13K, do you just like, are you hoping to get your Optimus's bill of materials below that price so you can do the same thing? Or do you just think qualitatively they're not the same thing? Like, what do you think is going, like, what allows it, what allows them to sell for so low? And can we match that? Well, Optimus, our Optimus is designed to have a lot of intelligence and to have the same electromechanical dexterity, if not higher than a human. So Unitri does not have that. And it's also, I mean, it's quite a big robot. It has to do, you know, carry heavy objects for long periods of time and not overheat or exceed the power of its actuators. So we've got, you know, it's 5'11\". It's 5'11\". You know, it's just pretty tall. Yeah. And it's got a lot of intelligence. So it's going to be more expensive than a small robot that is not intelligent. But more capable. Yeah. But not a lot more. I mean, like, over time, as Optimus robots build Optimus robots, the cost will drop very quickly. And what will these first billion Optimuses, Optimai, do? Like, what will their highest and best use be? I think you would start off with simple tasks that you can count on them doing well. But in the home or in factories? The best use for robots in the beginning will be any continuous operation. So any 24 by 7 operation, because they can work continuously. What fraction of the work at a Gigafactory that is currently done by humans could a Gen 3 do? I'm not sure. Maybe it's like 10, 20%. Maybe more. I don't know. We would use, we would not like reduce our head count. We would, we would, for sure, increase our head count to be clear. Right. But we would increase our output. So the, the units produced per human, like the total, the total number of humans at Tesla will increase. But the, the output of robots and cars will increase, will increase disproportionate, like much, much to, you know, the number of cars and robots produced per human will increase dramatically. But the number of humans will increase as well. We're talking about Chinese manufacturing a bunch here. And we're also talking about, you know, we've talked about some of the policies that are relevant, like you mentioned, the, the solar tariffs. Yeah. And you think they're a bad idea because, you know, we can't scale up solar in the US. Well, just electricity output in the US needs to scale up. Right. We can't without like good power sources. Yeah. You just need to get it somehow. Yeah. But where I was going with this is if you were in charge, if you were setting all the policies, what else would you change? So you change the solar tariffs as well. Yeah. I would say anything that is a limiting factor for electricity needs to be addressed, provided it is not like very bad for the environment. So presumably some permitting reforms and stuff as well will be in there. Yeah. There's a fair bit of permitting reforms that are happening. A lot of the permitting is state-based, so, but anything better. But this, this administration is, is good at removing permitting roadblocks. Okay. And I'm not saying all tariffs are bad. I'm just saying because I think- Solar tariffs. Yeah. So yeah. Yeah. I mean, sometimes if like, if another country is subsidizing the output of something, then, then you have to have countervailing tariffs to protect domestic industry against subsidies by another country. What else would you change? I don't know if there's that much that the government can actually do. One thing I was wondering is, it seems like the, for the policy goal of creating a lease for the US versus China, it seems like the export bands have actually been quite impactful. Where China's not producing leading edge chips and the export bands really bite there. China's not producing leading edge turbine engines. And similarly, there's a bunch of export bands that are relevant there on some of the metallurgy. Should there be more export bands? Like, if you think about things like, I mean, there are now with the drone industry and things like that. But is that something that should be considered? Well, I think it's important to appreciate that in most areas, China is very advanced in manufacturing. There's only a few areas where it is not. China is a manufacturing powerhouse next level. Like, people don't, most people don't. It's very impressive. Yeah. I mean, if you take like refining of ore, I'd say roughly China does more, does twice as much ore refining on average as the rest of the world combined. And I think there's some areas like, say, refining gallium, which goes into solar cells. I think there are like 98% of gallium refining. So China is actually very advanced in manufacturing in, I'd say, most areas. It seems like we're, like, there is discomfort with this supply chain dependence, and yet nothing's really happening on it. Supply chain, which supply chain depends? Depends on, say, like the gallium refining that you're saying. Yeah, yeah. There's a, there's a... All the rare earth stuff and... Yeah. Rare earths which are, as you know, not rare. Yeah. Like we actually had to do rare earth ore mining in the US, send the rock, put it on a train, and then put it on a boat to China. There's another train that goes to the rare earth refining, refiners in China who then refine it, put it into a magnet, put it into a motor cell assembly, and then send it back to America. So the thing, we're really missing a lot of ore refining in America. Isn't this worth a policy intervention? Yes. Well, I think there are some things being done on that front. Mm-hmm. But we kind of need Optimus, frankly, to build ore refineries. So, so you think the main advantage China has is the abundance of skilled labor? Yes. And that's like, that's the thing Optimus fixes. But also we need the skilled labor... China's got like four times our population. But we need... So, I mean, there's this concern if you think like human is of the future that like, okay, right now, if it's the skilled laborers for manufacturing that's determining who can build more humanoids. You know, China has more of those. It manufactures more humanoids. Therefore, it gets the Optimus future first. Well, we'll see. And it just like keeps that exponential going. Maybe. It seems like you're sort of pointing out that sort of getting to a million Optimus requires the manufacturing that the Optimus is supposed to help us get to, right? You can close that recursive loop pretty quickly. With a small number of Optimus. Yeah. So you close the recursive loop to help the robots build the robots. And then we can, you know, try to get to tens of millions of units a year. Maybe if you start getting to hundreds of millions of units a year, I think you're going to be the most competitive country by far. We definitely can't win with just humans because China has four times our population. Right. And frankly, America has been running for so long that we, you know, just like a, like a pro sports team that's been running for a very long time tend to get complacent and entitled. And that's why they stopped winning because it's, you know, don't work as hard anymore. So I think the, frankly, just my observation is the average work ethic in China is higher than in the US. So it's not just that there's four times the population, but the work, the amount of work that people put in is higher. So you can like, you can try to rearrange the humans, but you're still one quarter of the, you know, assuming that the productivity is the health is the same, which I think actually it might not be. Yeah. So we can manage on productivity for person. We will do one quarter of the amount of things as China. So, so we, we can't win on the human front. And our birth rates been low for a long time. So, uh, birth rates been the US birth rates been below replacement, uh, since roughly 1971. Um, so, so we, we've got a lot of people retiring or, you know, more people dying than, than, than, than we're close to sort of more people domestically dying than, than being born. Um, so we definitely can't win on the human front, but we, we might have a shot at the robot front. Are there other things that you have wanted to manufacture in the past, but they've been too labor intensive or too expensive that now you can come back to and say, oh, we can finally do the. Whatever. Uh, cause we have optimists. Yeah. I think we'd like to do more, build more, um, or a fineries, a Tesla. So, um, we just completed, um, construction and have, um, begun lithium refining, um, it without lithium refinery and Corpus Christi, Texas. Uh, we have, um, a nickel refinery, which is for the cathode. Uh, that's here in Austin. Um, and, uh, these are, these are the largest. This is the largest cathode, this is the largest cathode refinery, largest lithium refinery, largest nickel and lithium refinery, uh, outside of China. Um, and, uh, it's like the, you know, the cathode team would say like, we have, uh, the, the largest and the only actually, uh, cathode refinery in America. Many supermanives. Not just the largest, but it's also the only. So it was pretty big, even though it's the only one. Um, but I mean, there are other things that, uh, you know, um, you, you, you could do a lot more refineries and, and, um, help the, the help America be more competitive on refining capacity. So, so there's like, there's basically a lot of work for the opt-mine to do, uh, that, that most Americans, very few Americans frankly, want to do. Uh, I mean, I've, I've actually. Is the refining work too dirty or what's the? It's not, it's actually, no, we don't, um, there's not, we don't have toxic emissions from the refinery or anything. Um, so the cathode, nickel refineries were sort of in Travis County, like five minutes from. Why can't you do it with humans? No, you, you can't, you run out of humans. Ah, I see. Okay. Yeah. Like no matter what you do, you, you have one quarter of the number of humans in America and China. So if you have them do this thing, they can't do the other thing. So, so then, um, well, how do you, how do you build this refining, refining capacity? Well, you can do it with the opt-mine. Um, and, um, not many, not very many, not very many Americans are, are pining to do refining. I mean, how many of you are on it too? Very few. Very few are planning to refine. You know, BYD is reaching Tesla production or sales in quantity. What do you think happens in global markets as Chinese production and EVs goes up? Um, well, uh, China's extremely competitive in manufacturing. So, um, I think there's, there's going to be a massive flood of Chinese vehicles and, and, and, and other, basically most manufactured, uh, things. I mean, as it is, as I said, like China's like probably just twice as much refining as the rest of the world combined. Yeah. So if you go, you know, if you, if you, if you just go down to like fourth and fifth tier, uh, supply chain stuff, like, like, like the base level, you've got energy, then you've got mining and refining. Um, those, those, those foundation layers, uh, are, like I said, China, as a rough guess, China's doing twice as much refining as the rest of the world combined. Um, and, uh, and then they'll, they'll go all the way to the finished product with the cars. Uh, and China's a powerhouse. I mean, I think this year China will exceed three times U S electricity output. Um, like electricity output is a, is a reasonable proxy for, uh, uh, you know, for the economy. Uh, so like, like, you know, to run the factories and run, run everything, you need electricity. So electricity is, is, is a, it's a good proxy for the, for, for the real economy. Um, and so if China is, if China passes three times U S electricity output, it means that it's industrial capacity. That's a rough approximation is three times that will be three times out of the U S. Reading between the lines. It sounds like what you're sort of saying is absence and sort of humanoid recursive miracle in the next few years on the, the sort of like whole manufacturing energy, uh, raw materials chain, like China will just dominate whether it comes to like AI or manufacturing EVs or manufacturing humanoids. In the absence of, of, um, breakthrough innovations, uh, in, in the U S, uh, China will utterly dominate. Interesting. Yes. Robotics being the main breakthrough innovation. Well, if you do like to, to scale AI, uh, in, in, in, in space, like, like basically need, you need, need the humanoid robots. You need real world AI. You need, um, a million tons a year to orbit. Um, like, let's just say like, if we, if we get the mass driver on the moon going, my favorite thing, um, that, that I think, uh, we'll have solved all our problems. Yeah. We saw this is like, I call that winning. I call that winning. You can finally be satisfied. You've done something. Yes. You have the mass driver on the moon. That's right. I just want to see that thing. Was that out of some sci-fi or where did you? Uh, well actually there, there is a Highland book. The moon is a harsh mistress. Okay. Yeah, but that's slightly different. That's a gravity slingshot or, um, no, they have a mass driver on the moon. Okay. Yeah. But they use that to, uh, attack Earth. So maybe it's something great. Well, they use that to, uh, assert their independence from me. Exactly. What are your plans for the mass driver on the moon? They asserted their independence. Uh, the earth government disagreed and they loved things until they, the earth government agreed. That book is a hoot. I found that book much better than, um, his other one that everyone reads, um, Stranger of a Strange Land. Yeah. Grok comes from a stranger in a strange land. Yeah. Yeah. Yeah. Um, but there's still some good concepts in there. Yeah. LabelBox can get you robotics and RL data at scale. Take robotics. Let's say you need a hundred thousand hours of egocentric video. LabelBox starts by helping you define your ideal data distribution. Like for example, maybe no single task category should occupy more than 1% of trading volume. And at least 10% of trajectories should capture failure and recovery states. Next, LabelBox assigns this distribution to its massive network of operators. You're not limited to the small range of scenes that you can set up in a single warehouse. You can also get the same data distribution. You can also get the same data distribution. You can also get the same data distribution. You can also get the same data distribution. Inside, video. LabelBox starts by helping you define your ideal data distribution. Like for example, maybe no single task category should occupy more than 1% of trading volume, and at least 10% of trajectories should capture failure and recovery states. Next, LabelBox assigns this distribution to its massive network of operators. You're not limited to the small range of scenes that you can set up in a single warehouse. Instead, each one of LabelBox's operators has access to lots of unique physical environments where they can film themselves completing a wide variety of tasks. LabelBox's tech automatically categorizes each video so that their operators always know which tasks will remain and what they need to work on next. For RL data, LabelBox takes a similar approach. They work with you to understand the right distribution of tasks, and then their subject matter experts build the hyper-realistic digital environments and rubrics that you need to collect the highest quality trading data. So whether you're training robots in the real world or agents for computer use, LabelBox can help. Go to labelbox.com slash Swarkash to learn more. One thing we were discussing a lot is kind of your system for managing people. Like you interviewed the first few thousand of SpaceX employees and I've seen lots of other companies. What is this? Obviously it doesn't scale. Well, yes, but what doesn't scale? Me. Sure, sure. I know that, but like what are you looking for? I mean, literally there's not enough hours in a day. It's impossible. But what are you looking for that someone else who's good at interviewing and hiring people? What's the je ne sais quoi? Well, at this point, I think I've got, I might have more training data on evaluating technical talent, especially, but talent of all kinds, I suppose, but technical talent, especially, given that I've done so many technical interviews and then seen the results, technical interviews, seen the results. So my, my training set is, is very, is enormous and has a very wide range. Generally the thing I ask for are bullet points for evidence of exceptional ability. So it's, but like it's, it's, and these things can be like pretty off the wall. It doesn't need to be uh, in the, in the domain, the specific domain, but evidence that, uh, evidence of exceptional ability. Um, so if, if, if somebody can like cite like even one thing, but let's say three things where you go, wow, wow, wow, then that's, that's a good sign. But, but, but, but why do you have to be the one to determine that? No, I don't. I can't be. It's impossible. Right. I mean, total, uh, headcount across all companies, 200,000 people. Right. But in the early days, what was it that's that you were looking for that couldn't be delegated in those interviews? Um, well, I, I guess I, I need to build my training set. So it's not like I had about a thousand here. Um, I would make mistakes, but then I'd be able to see where I thought somebody would work out well, but they didn't. And then why, why did they not work out well? And what can I do to, I guess, RL myself Yes. To, uh, in the future, um, have a better batting average when interviewing people. Mm-hmm. So, and my batting average is still not perfect, but it's, it's very high. What are some surprising reasons people don't work out? Surprising reasons? Um. Like, you know, they don't understand techno domain, et cetera, et cetera. But like, No, I. You, you, you, like, you, you've got like the long tail now of like, ah, I was really excited that it was about this person. It didn't work out. Curious why that happens. Uh, yeah. So the, I mean, generally what I tell people, I tell myself, I guess, aspirationally, um, is don't look at the resume, just believe, believe your interaction. So if the resume may seem very impressive and it's like, wow, you know, resume looks good. But if the, if the conversation, uh, after 20 minutes is, is that conversation is not wow. Um, you should believe the conversation, not the, not the, not the paper. I feel like part of your method is that, you know, there was this meme in the media a few years back about Tesla being a revolving door of, uh, executive talent. Of course, actually, I think when you look at it, Tesla's had a very consistent and internally promoted executive bench over the past few years. And then at SpaceX, you have all these folks like Mark Jankosa and Steve Davis and Steve Davis runs a sporting company. No, no. Yeah. Yeah. But, uh, uh, Bill Riley and folks like that. And it feels like part of has worked well, is having very capable technical deputies. What do all of those people have in common? Uh, well, so the, I mean, it tells us sort of senior team, uh, at this point, it's probably got average tenure of 10 or 12 years. It's quite, quite a lot of tenure. Yeah. Um, so, um, but there, there are times when Tesla went through extremely rapid and extremely rapid growth phase. Um, and so it was somewhat, things were just somewhat sped up. Um, and, and when a company, as, as, as you know, a company goes through different orders of magnitude of, of size, you, you know, uh, people that who, who could help manage, say a 50 person company versus a 500 person company versus a 5,000 person company versus a 50,000 person company. Yeah. You have a group of people. Yeah. It's just not the same team. It's not, it's not always the same team. So if, if a company is growing very rapidly, the rate at which, uh, executive positions will change will also be proportionate to the, the, the rapidity of the growth generally. Um, then, uh, Tesla had, uh, a further challenge where when, when Tesla had very successful periods, um, uh, we would be, um, relentlessly recruited from, um, like relentlessly, um, like when Apple had their electric car program, they were copper bombing Tesla with recruiting calls. It was, uh, uh, engineers just unplugged their phones. Like, like it's just, it's just, I think I'm trying to get work done here. I'm not. Yeah. I, if I get, you know, one more call from an Apple recruiter, um, but they were, they were, they were, they're opening off without any interview with me, like double the compensation at Tesla. Um, so, um, so, so, so, uh, so we had a bit of the Tesla pixie dust, uh, thing where it's like, oh, if you hired a Tesla executive, you're suddenly you're gonna, everything's gonna be successful. Um, and, and I fall and pray to the pixie dust, uh, you know, thing as well, where it's like, oh, we'll hire someone from Google or Apple and they'll be immediately successful, but not that, that's not how it works. Um, you know, people are people. It's, it's, it's not like magical pixie dust. Yes. So when we had the pixie dust problem, um, we would get relentlessly recruited. Um, and, um, and then also being Tesla being, um, engineering, especially being primarily in Silicon Valley, uh, it's, it's easier for people to just like, they don't have to change their life very much. Yes. They can just get, you know, their commute is going to be the same. Yes. Um, so how do you prevent that? How do you prevent the pixie dust effect for everyone's trying to coach all your people? Um, I don't think we can, I don't think as much we can do to, to, to stop it. Um, but that, that's like, that's one of the reasons why Tesla, uh, uh, really being in Silicon Valley, um, and, uh, and having the pixie dust thing at the same time, um, meant that, uh, there was just a very, very aggressive recruitment. And being in Austin helps then. Uh, Austin. Yeah. It still helps. Uh, I mean, Tesla still has a majority of its engineering in California. Um, so, um, the, you know, for getting into engineers to move, uh, I called the significant, significant other problem. Yes. So then others have jobs. Yeah. Yeah. Yeah, exactly. So, um, for star base, that was particularly difficult. Yes. Since the odds of, you know, finding a non-spacex job. In Brownsville, Texas. Pretty low. Yeah. Yeah. It's quite, quite difficult. I mean, it's like a technology monastery. Yeah. I think, um, you know, remotes and mostly dudes. But again, if you, if you go back. It's not much of an improvement over by SF. Yeah. If you go back, but if you go back to these people who've really, um, been very effective in a technical capacity at Tesla, at SpaceX and, and those sorts of places, what do you think they have in common other than like, is it just that they're very sharp on the, you know, rocketry or the, you know, the technical foundations, or do you think it's something organizational? It's something about their ability to work with you. Is this their ability to like, be, you know, flexible, but not too flexible? What makes a good sparring partner for you? I don't think of a sparring partner. I mean, if somebody gets things done, I, I, I love them. And if they don't, I, so it's pretty straightforward. It's not like some idiosyncratic thing. If somebody executes well, um, I'm a huge fan. And if they don't, I'm not. Um, but it's, it's not about mapping to my idiosyncratic preferences. I certainly try not to have it be mapping to my idiosyncratic preferences. Um, so yeah. Um, yeah, but I, I, generally, I think it's a good idea to hire for, um, uh, talent and drive and trustworthiness. Um, and I, I think, uh, goodness of heart is important. Um, I, I'd awaited that at one point. Um, so like, are they, are they a good person, trustworthy, uh, sort of smart and talented and hardworking? Uh, if so, you can add domain knowledge. Um, but those, those fundamental traits, those fundamental properties you cannot change. So most of the people who, um, are at, uh, Tesla and SpaceX did not come from the aerospace industry or the order industry. What is most set to change about your management style as your companies have scaled from 100 to 1000 to 10,000 people? You're, you know, you're known for this like very micromanagement, just getting into the details of things. Nanomanagement, please. Pico management. Um, phantom management. So you're saying, keep going. We're going to go all the way down to Flanks Boston. We're going to go all the way down to Heisenberg's in Sydney first. Yeah. Well, how do you, I mean, are you, are you still able to get into details as much as you want? Would your companies be more successful if you could, if they were smaller? Like, how do you, how do you think about that? Well, because I have a fixed amount of time in the day, uh, my time is necessarily, um, diluted as things grow and as the span of activity, uh, increases. So, you know, um, it, it, it, it, it's, it's impossible for me to actually be a micromanager because, uh, there's that doubt. I would imply I have some like thousands of hours per day. It is, it is a logical impossibility for me to micromanage things. Um, so now there are times when, um, I will drill down into, uh, a specific issue because that's specific issue, uh, is the limiting factor on uh, the progress of the company. Um, and, um, but the reason for drilling into that, that some very detailed item is because it is the, there's a limiting factor, not, it's not arbitrarily drilling into the entire tiny things. Um, and, and like I said, obviously from a time standpoint, it is physically impossible for you arbitrarily, uh, going to tiny things that don't matter and that would, and, and that would result in failure. But sometimes the tiny things, um, are decisive in victory. Samuelsky, you switched the, uh, starship design from composites to steel. Yes. And you made that decision. Like that wasn't, uh, you know, people were going around, they're like, oh, we found something better, boss. Like that was you encouraging people to get some resistance. Can you tell us how you came to that whole composite steel switch? Uh, yeah. So desperation, I'd say, um, the, um, originally, yeah, we were going to make starship out of, uh, carbon fiber. Um, and, um, carbon fiber is pretty expensive. Like the, the, the, the, you know, you can generally, uh, when you do volume production, you can get any given thing to be, to start to approach its material cost. The problem with, with carbon fibers is that material cost is still very high. Um, um, so, um, it's about, it's about 50 times, particularly if you go for a high strength specialized carbon fiber that can handle, um, cryogenic oxygen. It's, it's, it's like called roughly 50 times the cost of steel. Um, and at least, uh, in theory, it would be lighter. People don't think of steel as being heavy and carbon fiber as being, uh, light. Um, and for room temperature, room temperature applications, um, you know, like say, uh, more or less room temperature applications like a Formula One car, uh, static aerostructure, or any kind of aerostructure really, uh, is, is gonna, you're gonna probably be better off with, uh, carbon fiber. Um, now the problem is that we were trying to make this enormous rocket out of carbon fiber and, uh, our progress was extremely slow. And it's been picked in the first place just because it's light. Yes. Um, like at first glance, um, like most people would think that the, the, the choice for making something light would be carbon fiber. Um, the, um, now, now the thing is that, um, um, when you make something very enormous out of carbon fiber, and then you try to have the carbon fiber, um, be efficiently cured, meaning not, not room temperature cured because like you've got, you know, sometimes you got like 50 pliers of, of, of carbon fiber and, and a carbon fiber is really carbon string and glue. Um, and, uh, and you, in order to have, um, high strength, you need, uh, an autoclave. So something that, that can, that's essentially high pressure oven. And if, if, um, if you have something that's, uh, a gigantic, uh, the album's gotta be bigger than the rocket. Um, so we're trying to make the, the autoclave that's bigger than any autoclave that's ever existed, uh, or do room temperature cure, which takes a long time and has issues. Um, but, but the final issue is that we're just making very slow progress, uh, with, uh, with carbon fiber. Um, so, um, I, I, I think the meta question is, uh, why it had to be you who made that decision. There's many engineers on your team. Yeah, how did the team not arrive at steel? Yeah, exactly. Like, this is a part of a broader question of like understanding your comparative advantage at your companies. Um, so, it was, because we were making very slow progress with, with carbon fiber, I was like, okay, we've got to try something else now for the Falcon 9. The, the primary airframe is made of aluminum lithium, which is very, very good strength to weight. Um, and, um, actually it has, uh, about the same, maybe, maybe better strength to weight for its application than carbon fiber, but aluminum lithium is very difficult to work with in order to weld it. You have to do something called friction still welding where you join the, you join the metal without it entering the liquid phase. Um, so it's kind of wild that you could do that, uh, but with this particular type of welding, you can do that. Um, but, uh, it's very difficult to like, say, let's say you want to make a modification or attach something to, um, aluminum lithium. You now have to use mechanical attachment with seals. Um, you can't, uh, weld it on. Um, so, uh, we want to, I want to avoid using aluminum lithium for the primary structure for, uh, for Starship. Um, and, uh, and, and, and there was this very special grade of, uh, carbon fiber that, that had very, very good mass properties. So with rocket, you're really trying to maximize the percentage of the, of the rocket that is propellant, minimize the, the mass obviously. And, um, the, but like I said, we were making very slow progress. Um, and, and, and I said, at this rate, we're never going to get to Mars. So we better think of something else. Um, I didn't want to use aluminum lithium because of the difficulty of friction still welding. Um, especially doing that at, at, at, at scale was hard enough, um, at 3.6 meters in diameter, let alone at nine meters or above. Um, then, um, I said, well, what about steel? And so the, the, the, now I, I had a clue here because some of the early, um, US rockets had used very thin steel. The Atlas rockets had used a steel balloon tank. Um, so it's not like steel had never been used before. It actually had been used. Um, and when you look at the, at the material properties of stainless steel, um, especially, uh, very, uh, if it's been, uh, very like full hard, uh, strain hardened stainless steel, uh, at cryogenic temperature, uh, the, the strength weight is actually similar to carbon fiber. So if you, if you look at the, so if you look at material properties at room temperature, um, it looks like the steel is, uh, it's going to be twice as heavy, but if you look at the material properties at cryogenic temperature of full hard steel stainless of particular grades, uh, then the, the, you actually get to a similar strength weight as carbon fiber. And, and in the case of starship, both the fuel and the oxidizer are cryogenic. So for, for, uh, Falcon nine, the fuel is rocket propellate grade kerosene, basically pure, like a, a very pure form of jet fuel. Um, which is, but, but that is, that is roughly room temperature. Um, although we do action, we do actually chill it slightly below, we chill it like a beer, um, we do chill it, but, um, but, but it's not cryogenic. In fact, if we made it cryogenic, it would just turn to wax. So, um, but, but for starship, the it's liquid methane and liquid oxygen, they, they, uh, they're liquid at, at similar temperatures. Uh, so, uh, so basically, uh, almost the entire primary structure is a cryogenic temperature. So then you've got, uh, uh, a 300 series stainless that's, that's, um, strain hardened, uh, because it's at almost all things, a cryogenic temperature actually has a similar strength to weight as, uh, carbon fiber. It costs, uh, 50 times less, normal material and is very easy to work with. You can weld stainless steel outdoors. Uh, you could smoke a cigar while welding stainless steel. It's just like, it's, it's very resilient. Um, you, you can modify it easily. It's, it's, uh, if you want to, if you want to attach something, you just weld it right on. So, um, very easy to work with for a, very low cost. Uh, and, um, now, like I said, at cryogenic temperature, similar strength to weight, uh, to carbon fiber. Um, then when you factor in that, uh, that we don't need, we don't, we, we have a much reduced, uh, heat shield mass, uh, because the melting point of steel is much greater than the melting point of aluminum. Um, it's about twice the melting point of aluminum. And, uh, so you can just run the rocket much hotter. Yes. So, especially for the ship, uh, which is coming in like a flame, a blazing meteor. Uh, it is, uh, the, you, you, you can greatly reduce the mass of the heat shield. Um, so the, so you can call it cut the mass of the windward, uh, part of the heat shield and maybe in half, and you don't need any heat shielding on the, on the leeward side. Um, so, um, the, the net, if net result is actually the steel rocket weighs less than the carbon fiber rocket because the, the resin in the carbon fiber rocket, uh, uh, it, um, starts to melt. Um, so basically carbon fiber and aluminum have about the same operating temperature capabilities. Um, and whereas steel can operate at twice temperature. I mean, these are very rough approximations. People will, well, you know. I won't go to the rocket base. What I mean is like people will say, oh, he said it's twice. It's actually, it's actually 0.8. Shut up, assholes. That's what the main comment's going to be about. Goddammit. Okay. So the point is that, actually, in retrospect, the, the, the, we should have started, we've done steel in the beginning. It was dumb not to do steel. Okay, but to play this back to you, what I'm hearing is that steel was a riskier, less proven path other than the early US rockets versus carbon fiber was like, uh, worse, but more proven out path. And so you need to be the one to push for, hey, we're going to do this riskier path and just figure it out. And so you were fighting like a sort of conservatism in a sense. Um, that's why I initially said like that the issue is that we weren't making fast enough progress. We were having trouble making even, um, a small barrel section of the carbon fiber, um, that didn't have wrinkles in it. Um, so, uh, because at, at, at that large scale, you have to have many plies, many sort of layers of the carbon fiber. Um, you've got to cure it and you've got to cure it in such a way that it, it doesn't, um, have any wrinkles or, or defects. The carbon fiber is much less resilient than, than steel. It has much less, it's less toughness. Um, like stainless steel will, will scratch and, and, and bend and then the carbon fiber will tend to shatter. Um, so, um, so toughness being the area under the stress strain curve, um, so that you're generally going to have to do better with steel. Um, stainless steel to be precise. One other Starship question. Um, so I visited, um, Starbase, I think it was two years ago, um, with Sam Teller and that was awesome. It was very cool to see in a whole bunch of ways. One thing I noticed was that people really took pride in the simplicity of things where, you know, everyone wants to tell you how Starship is just a big soda can and, you know, we're hiring welders and, you know, if you can weld in any industrial project, you can weld here. But, um, there's a lot of pride in the simplicity and... Well, it's, well, it's likely Starship is a very complicated rocket. So that's what I'm getting at. Is, are things simpler or are they complex? Oh, I think maybe they're just, what they're trying to say is that, you know, you don't have to have like prior experience in the rocket industry to work on Starship. Um, you know, someone just needs to be, you know, smart and work hard, um, and be trustworthy and they can work on a rocket. They don't, they don't need prior rocket experience. Starship is the most complicated machine ever made by humans, by a long shot. In what regards? Anything really. I'd say there isn't a more complex machine. Um, yeah, I mean, I, I'd say that there's, there's pretty much any, any project I can think of would be easier than this. Um, and that's why no one has made a rapidly reusable, nobody has ever made a fully reusable over the rocket. It's a very, very hard problem. Um, the, I mean, many smart people have tried before, very smart people with immense resources and they failed. Um, so, and we haven't succeeded yet. Uh, we're, you know, Falcon is partially reusable, but the upper stage is not. Um, um, Starship version three, I think this design that it, it can be fully reusable and that full reusability is what will enable us to become a multi-planet civilization. Can you say about the circles? So, so I don't, I'm like, I, I said I could, I, any technical problem, even like a hydron collider or something like that is, is easier following than this. We, we spent a lot of time on bottlenecks. Can you say what the current Starship bottlenecks are even at a high level? I mean, trying to make it not explode generally, that old chestnut really wants to explode. Um, we've had two boosters explode on the test end. Um, one obliterated, obliterated the entire test facility. Um, so it takes like one mistake and, and I mean, the amount of energy contained in, in the Starship is insane. And so is that why it's harder than Falcon? That's because it's just more energy. It's a lot of new technology. Um, it's, it's, it's pushing, it's pushing the performance envelope. Um, the Raptor three engine is a very, very advanced engine by far the best recognition ever made. Um, but it desperately wants to blow up. I mean, just to put things in perspective here on liftoff, um, the, the rocket is generating over a hundred gigawatts of power. It's 20% of us. Insane. It's a great comparison. While not exploding. Sometimes, sometimes, but sometimes, yeah. So I was like, how does it not explode? There's, there's a, you know, thousands of ways that it could explode and, and only one way that, that, that it doesn't. So, so we wanted to merely not really not explore, but fly reliably, uh, on a daily basis, like once per hour and obviously, you know, blows up a lot. It's, it's very difficult to maintain that launch cadence. Um, and, and then, I'm going to say like, like, what's the, what's the single biggest remaining problem for starship? It's, uh, having the heat shield be reusable, um, that such that the, no, no one has ever made a reusable orbital heat shield. Um, so the, the, the, the heat shield's got to make it through the ascent phase without shocking a bunch of tiles. Um, and then it's going to come back in and also not lose a bunch of tiles or, or overheat the, the main, the main, uh, airframe. Isn't that hard? Cause it's kind of fundamentally a consumable. Uh, well, yes, but your brake pads in your car are also consumable, but they last a very long time. Fair. Right. So it just needs to last a very long time. Um, but that's just, yeah, try it. I mean, we have brought the ship back and had it do a soft landing in the ocean. I've done that a few times, but, but it lost a lot of tiles, you know, and, uh, you know, it was not reusable without a lot of work. Yeah. So even though it did land, did, did, did come to soft landing, it was, would not have been reusable without a lot of work. Um, and, and that, so it's not really reusable in that sense. So that's, that's the biggest problem that remains is fully reusable heat shield. Um, so, so like if you want to be able to land it, uh, refill propellant and fly again, uh, without good, you know, you can't do this laborious inspection of, you know, 40,000 tiles type of thing. I, I, I'm curious how you drive, like when you, when I read biographies of yours, it just, uh, it, it, it, it seems like you're just able to drive the sense of like urgency and drive the sense of like, this is the, this is the thing that can scale. Um, and I, I'm curious why you think other organizations of your, like, SpaceX and Tesla are really big companies now and you're still able to keep that culture. What goes wrong with other companies such that they're not able to do that? I don't know. Um, but like today you said you had like a bunch of SpaceX meetings. Like what, what, what is it that you're doing there that's like keeping that? That's adding urgency. Yeah, yeah, yeah. Well, I, I don't know. I guess, uh, the, the urgency is going to come from where I was leading the company. So my sense of urgency, I, I have like maniacal sense of urgency. So that maniacal sense of urgency projects through the rest of the company. Is it because of consequences? They're like, if you know, Elon said a crazy deadline, but if I don't get it, I know what happens to me. Is it just, um, you're able to identify bottlenecks and get rid of them so people can move fast? Like, how do you, how do you think about why your companies are able to move fast? Yeah, I'm constantly addressing the limiting factor. So, um, I mean, I mean, on the deadlines front, I mean, I generally actually try to aim for a deadline that, that I at least think is at the 50th percentile. So it's, it's not, it's not like an impossible deadline, but it's the most aggressive deadline I can think of that could be achieved with 50% probability. Um, which means that it will be late half the time. Um, and, um, but whatever, like there is like a law of gases expansion that applies to schedules, like whatever given, whatever schedule you, you like, if you said, we're going to do this something in like five years, which to me is like infinity time. Um, it, it will expand to fully available schedule and it will take five years. Um, you know, like, there's like, there's, there's a physical limit, like that, like physics will limit how fast you can do certain things. Like, so like scaling up manufacturing, there's like, there's a rate at which you can move the atoms, um, and scale manufacturing. That's why you can't like instantly make, you know, a million or something, millions a year or something. Uh, you've got, you've got to design manufacturing line. You could bring it up. You could ride the S curve of production. Um, so yeah, I guess like, like, what can I say that's, that's, that's actually helpful to people? Um, I, I think generally, um, a maniacal sense of urgency is, is, uh, is very big deal. Um, so, um, and, and you want to have, you want to have, you want to have an aggressive schedule, um, and then you, and you, and you want to figure out what the limiting factor is at any point in time and, and help the team address that limiting factor. Can you maybe talk about the, so Starlink was slowly in the works for many years, uh, and yeah, we've talked about it all the way in the beginning of the company. Yeah. And so then there was a team you had built in Redmond, and then at one point you decided this team is just not cutting us, but again, how did you like, it went for a few years slowly. And so why did this, why didn't you act earlier? And why did you act when you did like, why was that the right moment at which to act? I mean, I, I have, I have these very detailed, um, engineering reviews weekly. Um, that that's, that's maybe a very unusual level of granularity. Um, I don't know anyone who runs a company, or at least a manufacturing company that, that goes to the level of detail that, that I go into. Um, so it's, it's, it's not, it's not as though, like I have a pretty good understanding of what's actually going on because we, we, we, we go, we go through things in detail. Um, and I'm a big believer in skip level meetings where the individuals, instead of having the person that reports to me say things, it's everyone that reports to them, um, says something, um, in, in the technical review. Um, and, um, and, and there can't be, um, advanced preparation. So otherwise you, you, you're going to get, uh, you know, glazed. Um, as I say these days. Yeah, exactly. Very Gen Z of you. Very Gen Z. How do you prevent advanced administration? You just like call them randomly? Like, no, just go around the room and everyone provides an update. Okay. Yeah. Um, so, uh, I mean, it's, it's a lot of information to keep in your head because, um, you've, you've got to, you've, you've, you've got them, say if you have meetings weekly or twice weekly, you, you, you've got a snapshot of what that person said. Um, and, and, and you can, and, you can then, you know, plot the progress points. Um, you can sort of mentally plot the points on the curve and say, are we converging to a solution or not? Um, or, or are we, you know, like I'll, I'll take drastic action, uh, only when I conclude that, um, success is not in a set of possible outcomes. Um, so when I say, okay, when I finally reached the conclusion that, okay, unless drastic action is done, we have no, no chance of success, then I must take drastic action. Um, and so that's, that's, that's, I came to that conclusion in 2018, took drastic action and, and fixed the problem. How, how many, um, you know, you, you, you've got many, many companies and in each of them, it sounds like you do this kind of deep engineering understanding of what the relevant bottlenecks are. So you can do these, um, reviews with people. Yeah. Um, you've been able to scale it up to five, six, seven companies. Within one of these companies, you have many different mini companies within them. What determines the maximum here? Could you have like 80 companies? 80? No. But like, you can, you have so many already. I'm like, that's, that's already remarkable. Why this current number? Yeah. Exactly. I know, so, um. We barely keep one company together. Um, the neural, it's like, so it, it depends on situation. Um, so, um, I actually don't, don't have regular meetings, uh, with foreign company. So that foreign company is sort of cruising along. But look, basically if something is working well and making good progress, then there's no point in me spending time on it. So, uh, I actually, uh, allocate time according to where, where the, where the limiting factor or the problem, where, where, where are things problematic? And, um, or where, where are we pushing against, uh, like what, what is holding us back? Will it, you know, I, I focus at risk of saying the words too many times, the limiting factor. Um, so, so basically if something's good, like the irony is if something's going really well, um, they don't see much of me. But if something is going badly, they'll see a lot of me. And so if something is- Or not, not even badly. It's, it's, it's like- If something's the limiting factor. It's the limiting factor, exactly. It's not exactly going badly, but it's the thing that's, it's, it's the thing that we need to make go faster to- And so when something's a limiting factor at SpaceX or Tesla, are you like talking weekly and daily with the engineer that's working on it? How, how does that actually work? Most things that are limiting factor are, um, weekly and some things are twice weekly. So the, the AI5 chip review is twice weekly. And so it's every Tuesday and Saturdays, is the chip review. Is it open-ended in how long it goes? Uh, technically yes, but, uh, usually it's, it's like two or three hours. Mm-hmm. So, I mean, sometimes less. It's, it depends on, on how much information you're going to go through. Yeah. Well, that's another thing. I'm just trying to tease out the, the differences, uh, here, because the outcomes seem quite different. And so I think it's interesting to know what inputs are different. And it feels like the corporate world, one, like you're saying, just the CEO doing engineering reviews does not always happen, despite the fact that that is the, you know, what the company is doing. Um, but then time is often pretty finely sliced into, you know, half hour meetings or even 15 minute meetings. And it seems like you hold more open-ended, we're talking about it until we figure it out out. Yeah. Sometimes, but most of them seem to more or less stay on time. Um, so, um, I mean, today's, uh, Starship engineering review went a bit longer, um, because there were more topics to discuss. Um, you know, trying to figure out how to scale to a million plus tons to over per year is quite challenging. Can I ask a question? So you, you said about, um, Optimus and AI that they're going to result in double digit growth rates within a matter of years. Oh, like the economy? Yeah. Um, yes. I think that's right. What was the point of the doge cuts if the economy is going to grow so much? Well, I think like waste and food are not good things to have, you know, um, I, I was actually pretty worried about, I guess, uh, I mean, I think in the absence of AI and robotics, we're actually totally screwed, uh, because the national debt is piling up like crazy. Um, now our interest payments, the interest payments, the national debt exceed the military budget, which is a trillion dollars. So if over a trillion dollars, just the interest payments, um, you know, that was like, I was like, okay, pretty concerned about that. Maybe if I spend some time, we can slow down the bankruptcy of the United States, um, and give us enough time for the AI and robots to, you know, help solve the national debt or not help solve. It's the only thing that could solve the national debt. Like we are 1000% going to go bankrupt as a country and fail as a country without AI and robots, nothing else will solve the national debt. Um, and so, so we would like to, well, we just need, we need enough time to get, build the AI and robots, uh, to not go bankrupt before then. I, I guess the thing I'm curious about is when those starts, you have this enormous, um, ability to enact reform and. Not that enormous. Sure, sure. But totally by your point that like, it's important that AI and robotics drive product improvements, drive GDP growth, but why not just directly go after the things you were pointing out, right? You know, like the, the, the tariffs on certain components, or whether it's like permitting. I'm like the president. And, and very hard to cut, to cut, to even, even to, to cut things that are obvious waste and fraud, like, like ridiculous waste and fraud. Um, what I discovered that is it's extremely difficult even to cut very obvious ways and for, um, from the government. Um, because the, the, the government has to operate on a, on like, who's complaining, like if, if, if, and if you cut off payments to fraudsters, they immediately come up with the most sympathetic sounding, uh, reasons to continue the payment. They don't say, please keep the fraud going. They say, you know, it's, they're like, you're killing baby pandas. And then we're like, meanwhile, there's no baby pandas are dying. They're just making it up. Um, the forces are capable of, of coming up with extremely compelling, sort of heart wrenching stories that are false, but nonetheless sound, uh, sympathetic. And that, that's what happened. Um, and, uh, so it's like, perhaps I should have known better. Um, and, uh, that I thought, wait, let's take a, let's, let's, let's try to cut some amount of, of waste and fraud from the government. Maybe there shouldn't be, you know, 20 million people, uh, walked as alive in social security who are definitely dead and over the age of 115. The oldest American is 114. So it's safe to say if somebody is 115 and marked as alive in the social security database, um, something is there, there's either a typo. So like somebody should call them and say, we, we seem to have your birthday wrong or, or, uh, or we need to mark you as dead. Okay. One of the two things. Very intimidating call to get. Well, so it seems like a reasonable thing. Um, and if, if like, say their birthday is in the future, um, and they have, you know, a small business administration loan and their birthday is 2165. Um, we either again have a typo or we have fraud. Um, so we say we appear to have gotten the century of your birth incorrect. Or a great plot for a movie. Yes. This is, this, this is what I, when I'm in my ludicrous fraud, this is what I'm in my ludicrous fraud. Were those people getting payments? Some were getting payments from social security, but, but, but the main fraud vector, uh, was to mark somebody as alive in social security and then use every other government payment system, uh, to, uh, basically to, to, to do fraud. Because what those other government payment systems do, would do, they would simply do an are you alive check to the social security database. Hmm. It's a, it's a bank shot. What would you estimate as like the total, uh, amount of fraud from this mechanism? Um, my guess is, and, and other, but by the way that the government accountability office has done these estimates before. I'm not the only one who's coming out of this, you know, in fact, I think they, they did, the GAO did analysis, a rough estimate of fraud during the Biden administration, and calculated at roughly half a trillion dollars. So don't take my word for it. Take it, a report issued during the Biden administration. How about that? From this social security mechanism? Uh, it's, it's one of many. It's important to appreciate that the, the, the government does not, is very ineffective at, at stopping fraud because, uh, it's, it's, it's not like, like if it was a company, like, like stopping fraud, you've got a motivation because it's affecting the earnings of your company. Uh, but the government just, just, they just print more money. Um, so it's not, uh, like you, you, you need, you need caring and competence, and these are in short supply at, uh, at the federal level. Um, yeah, I mean, when you go to the DMV, do you think, wow, this is a bastion of competence? Um, well now imagine it's worse than the DMV because it's a DMV that can print money. So, was it not possible? At least the state level DMVs, uh, need to, the states more or less need to stay within their budget or they go bankrupt, but the federal government just prints full money. Well, was it not possible to cut that, if there's a cashier half a trillion of fraud? Why, why was it not possible to cut all that? Uh, because when, when, as soon as you, we did, we, we actually, no, you, you, you really have to stand back and recalibrate your expectations for competence. Uh, because, uh, you, you, you're operating in a world where, you know, you, you've, you've got to sort of make ends meet, like, you know, you've got to pay your bills, you've got to, you know, buy the microphones. Yeah, yeah, exactly. Um, so, so you, you, you, if you don't have, it's, it's not like there's a giant, largely uncaring monster bureaucracy. It's not even, it's an, and, and a bunch of, uh, uh, anachronistic computers that are just, they're just sending payments. Um, like one of the things that, that, that, that the Doge team did, that there was, and it sounds so simple, uh, that, that probably will save, um, let's say a hundred billion, maybe 200 billion a year, um, is simply requiring that payments from the main treasury computer, which is called PAMs, like payment accounts master or something like that. There's five trillion PAMs here, um, requiring that any payment go, that goes out, have a payment, um, appropriation code, make it mandatory, not optional, and that you have anything at all in the comment field. Um, because, uh, you, you have to recalibrate how dumb things are. But you think, PAMs were being sent out with no appropriation code, not, not checking back to any congressional appropriation, and no explanation. And this is why the, the Department of War, formerly the Department of Defense, cannot pass an audit because the information is literally not there. Recalibrate your expectations. I, I, I, I want to better understand this how it's really a number, because there, there's an IG report in 2024. How, how, you must like, why is it so low? Um, maybe, but, uh, which found that like over seven years, this, the social security fraud, they estimated was like 70 billions over seven years, so like 10 billion a year. So I'd be curious to see what like the other 490 billion is. Federal government expenditures are seven and a half trillion a year. Yeah. Um, how, what, what percentage, how competent do you think government is? The, the discretionary spending there is like 15%. Yeah, but, but it doesn't matter. The, the, the, the most of the fraud is non-discretionary. It's, it's basically a fraudulent Medicare, Medicaid, uh, social security, uh, uh, uh, you know, um, disability, uh, it, it's, there's, there's a zillion government payments. Yeah. Um, and, and a bunch of these payments are in fact, uh, they're, they're, they're, uh, block transfers to the states. So the federal government doesn't even have the information in a lot of cases to even see, know if there's fraud, let's consider, let's like reductio ad absurdum, the government, the government is perfect and has no fraud. What is your probability estimate of that? I mean, zero. Okay. So then would you say that for a foreign waste that the government, uh, is, has, is 90%. That also would be quite generous. But if, if it's only 90%, that means that there's $750 billion a year of waste and fraud and it's not 90%. It's not 90% effective. This seems like a strange rate of first principles, the amount of fraud in the government. Just like, how much do you think there is? And then, uh, uh, I, I, anyways, we, we don't know how to do it live, but I'd be curious to like, so you know, a lot about fraud at, at Stripe. People are constantly trying to do fraud. Yeah. But as you say, it's like a little bit of a, um, we've really grounded down, but it's a little bit of a different problem space because we're dealing with a much more heterogeneous set of fraud vectors here than we are. Yeah. But I mean, I mean, at Stripe, you, you, you, you have high confidence and you try hard. Um, you have high confidence and high caring, but still fraud is non, non zero. Um, now, now, now imagine it's at a much bigger scale. Um, there's much less competence and much less caring. You know, back to PayPal back in the day, we were trying to manage fraud down to about 1% of the, the payment volume. Um, and that was very difficult, took a tremendous amount of competence and caring to, uh, get fraud merely to 1%. Um, now imagine that the organization where there's much less caring and much less competence, it's going to be much more than 1%. How do you feel now looking back on, um, kind of politics and, and doing stuff there where it feels like, looking from the outside in, the two, you know, two things have been quite impactful, one, the America pack and two, um, the acquisition of, of, well, Twitter at the time, but also it seems like there was a bunch of heartache. And so what's your, what's your grading of the whole experience? Well, um, I think, I think those things needed to be done to maximize the probability that the future is good. Um, so, um, but politics generally is very tribal. Um, and it's, it's very tribal and it's, and people lose their objectivity usually with politics. Like they, they generally have trouble seeing the good on the other side or the bad in their own side. That's generally how it goes. Um, I, I, that, that I guess was one of the things that surprised me the most is you, you often simply cannot reason with people. Um, if they're in one tribe or the other, they, they simply believe that everything their tribe does is good and anything the other political tribe does is bad. Um, and persuading them is otherwise is almost impossible. Um, so anyway, but, um, I think, I think overall those actions, um, acquiring Twitter, getting Trump elected, even though it makes a lot of people angry. Um, I think those, I think those actions are good for, we're good for civilization. Um, yeah. How does it feed into the future you're excited about? Well, um, America needs to continue, America needs to be strong enough to last long enough to, um, extend life to other planets and to kind of get, I guess, AI and robotics to the point where we can ensure that the future is good. Um, like on the other hand, if, if, if we were to descend into, um, say communism or, or, or some situation where, where the state was extremely oppressive, um, that, that would mean that we, we might not be able to become multi-planetary. Um, and we might, the state might, um, you know, stamp out, um, our progress and AI and robotics. How do you feel about, um, uh, you know, Optimus, Grok, et cetera, are going to be leveraged by, and not just yours, any revenue maximizing company's products will be leveraged by the government over time. Um, how does this concern manifest in what private companies should be willing to give governments, what kinds of guardrails should, like, should, you know, should, um, um, AI models be, uh, um, made to do whatever the government that has contracted them out to do, ask them to do, um, should, like, should, should, should Grok get to say, like, actually, even the military wants to do X, no, Grok will not do that. I think probably the biggest danger of AI, well, maybe the biggest danger of AI, of, for, for AI and robotics going wrong, wrong is, is government. Interesting. You know, um, I mean, the, the way you think, like, like, like people who are opposed to corporations or, or, or worried about corporations should, um, really worry about, the most about government, because government is just a corporation in the limit. It's a government, it is, it is, it is, the government is just the biggest corporation with a monopoly on violence. Um, so, I always find it, like, a strange dichotomy where, where people would think corporations are bad, but the government is good, when the government is simply the biggest and, and, and worst corporation. But people have that dichotomy. They somehow think, at the same time, that government can be good, but corporations, bad, and this is not true. Corporations are, are, have better morality than the government. So, I, I, I actually think it's, uh, you know, that's, uh, that's, uh, that, that is the thing to be worried about. It's like, if, uh, you know, should, should, if the government should not, like, if the government could potentially use AI and robotics to suppress the population. Like, that is a serious concern. I mean, as, as a guy building AI and robotics, how do you, how do you, like, how do you prevent that? Uh, well, I think that, like, if, if you have a limited government, um, if you limit the powers of government, which is like, really what the US constitution is intended to do, is intended to limit the powers of government, then, then, uh, you're probably gonna have a better outcome than if you have more government. So, but robotics will be available to all governments, right? Yeah, not about all governments. Um, I mean, it's difficult to predict the, like I can say, like, what, what's, what's, what's, what's the end, end point or like, what is, what is many years in the future, but it's difficult to predict the, the sort of path along, along that way. Um, like if civilization progresses, AI will vastly exceed the symbol human intelligence and, and there will be far more robots than humans. Um, along the way, what happens? It's very difficult to predict. I mean, it seems like one thing you could do is just say, um, uh, you are not allowed to, whatever government decks, you're not allowed to use Optimus to do X, Y, Z, just write out like a policy. I mean, you, you, I think you treated recently that Grok should have a moral constitution. Um, and one of those things could be that we, we limit what governments are allowed to do with this advanced technology. I mean, yeah, we, we, we, we can do what is, what, what, I mean, if, if, if, if, if the politicians pass a law, uh, then, and they can enforce that law, then it's hard to not do that law. You know, the, the best thing we can have is, is, is limited government, uh, where, um, you know, you have, you have the appropriate cross checks between the executive, judicial, and, um, legislative branches. I, I, I guess the, the reason I'm curious about it is this, like, at some point, it seems like the limits will come from you, right? Like, you've got the Optimus, you've got the space GPUs, you've got the... You think I'll be the boss of the government. Or you will get the, you will, like the, I mean, already it's the case with SpaceX, that for things that are crucial to the, um, uh, like the government really cares about getting certain satellites up in space, whatever, like it needs SpaceX. Uh, it is the, it is the, um, a necessary contractor. And you are in the process of building more and more of the, um, uh, the technological components of the future that, that, that will have an analogous role in different industries. And you could have this ability to like set some policy that, um, you know, suppressing classical liberalism in any way. I, my companies will not help in, in any way with that. Or, you know, some policy like that. Um, I, I will do my best to ensure that anything that's within my control maximizes the good outcome for humanity. I think anything else would be short-sighted. Um, because obviously I'm part of humanity, so. Um, I like humans, um, pro-human, pro-human. Um, you, you, you mentioned that Dojo 3 will be used for space-based compute. Um, you really read my, uh, what I say. I don't know if you know Twitter, but I know you a lot. I'm like, there's a lot of followers. Did giveaway. Um, how do you, how do you have discerned my secrets? I've lost them. How do you design this chip for space? What do you, like, yeah, what, what, what changes? Well, I guess you want to design it to be, um, more radiation tolerant and run at a higher temperature. Uh, so you could, um, you know, roughly if you increase the, um, operating temperature by 20th set in degrees Kelvin, you can cut your radiator mass in half. Um, so running at a higher temperature is, is helpful in, in space. Um, there's, I mean, there's various things you can do for shielding the memory and, um, but like neural nets are going to be very resilient to bit flips. Yeah. So like most of what, what happens for radiation is like random bit flips. Um, but like, if you've got like, you know, a multi-trilling parameter model and you get a few bit flips, it doesn't matter. Um, it's, it's much like curiosity programs are going to be much more sensitive to bit flips than, um, some giant parameter file. Um, so I just designed it to run hard and, um, I think you pretty much do it the same way that you do things on earth apart from make it run hotter. Hmm. Um, I mean, the solar array is most of the weight on the satellite. Is there a way to make the, um, the GPUs even more power dense than what NVIDIA and TPUs and et cetera are planning on doing that would, you know, be especially privileged in the space-based world? Well, I mean, the basic math is like, like, um, if you can do about a kilowatt per reticle, um, and then you'd need, um, you know, a hundred million full reticle chips, uh, to do a hundred gigawatts. Yeah. So yeah, depending on what your yield assumptions are, you know, um, that, that tells you how many chips you need to make, um, but cool. You need, if you want, if you're, if you're gonna have a hundred gigawatts of power, you need, you know, a hundred million chips running that are running a kilowatt sustained output per reticle. Um, a hundred, basic math. A hundred million chips, uh, it depends on, yeah, if, if, if you, if you look at the die size of something like black ball GPUs or something, and how many you can get out of a wafer, you can get like, um, on the order of dozens or less, uh, per wafer. So you're basically you're, this is a world where if we're putting that out every single year, you're producing millions, millions of wafers a month. Um, that's the plan with TerraFab. Millions of wafers a month of advanced process notes. It's, it's, it could be some number north of a million, I think. You gotta do the memory too. Yeah. You're gonna make a memory fab? I think the TerraFab's gotta do memory. It's gotta do logic memory and packaging. I'm very curious how somebody like, get start, this is like the most complicated thing man has ever made. And obviously, like, if anybody's up to the task, you're up to the task. Like, what do you, so you realize this is a bottleneck and you go to your engineers and like, what is the next, like, what, what do you tell them to do? I want a million wafers a month in 2030. What is the next, like, what do you, do you like call ASML? Like, what is it? Ask the right one. What is the next step? Not so much to ask. Well, um, we make a little fab, uh, and see what happens. Uh, make our mistakes at a small scale and then make a big one. Is a little fab done or is it? No, it's not done. I mean, we're not going to keep that cat in the bag. That cat's going to come out of the back room. It'll be like drones hovering over the bloody thing. You know, you'll be able to see its construction progress on X, right? You know, in real time. Um, so, no, we, I mean, like, I don't know, we could just flounder and failure to be clear. It's like not, uh, success is not guaranteed, but, um, since we want to try to make, uh, you know, something like a hundred million. Yeah. We would, if we, we need, we need, we want a hundred gigawatts of power and a hundred, a hundred that chips that can take a hundred gigawatts, right? So call it, you know, but yeah, by, by 2030. So then, um, um, it will take as many chips as our suppliers will give us. I've said this to, I've actually said this to TSMC and Samsung and micro and it's like, please build your more fabs faster. Um, and we will guarantee you to buy the output of those fabs. Um, so, so they're already like moving as fast as they, as they can. Like it's, it's not like, to be clear, it's not like us, you know, it's not like, uh, either it's, it's, it's not like it's us plus them, you know, there's a narrative that the people doing AI want a very large number of, you know, chips as quickly as possible. And then many of the input suppliers, the fabs, but also, you know, the turbine manufacturers are not ramping up production very quickly. No, they actually, yeah. The explanation you hear is that they're dispositionally conservative, you know, they're Taiwanese or German as the, you know, story may be, and they just like, don't believe the same, like, is that really the explanation or is there something else? Well, I mean, it's reasonable. Like if somebody's been in, say, the computer memory business for, uh, 30 or 40 years, and they've seen cycles, they've seen like boom and bust like 10 times. Yeah. You know, so, so like, that's a lot of layers of scar tissue, you know? So it's like, it's like during the boom times, it looks like everything is going to be great forever. And then, then, then, then the crash happens and then they desperately try to avoid bankruptcy. Um, and, and then there's another boom and another crash. Are there other, are there other ideas you think others should go pursue that you're not for whatever reasons right now? Um, I mean, there are a few companies that are, that are pursuing like, uh, new ways of doing jobs. Mm-hmm. Um, uh, but there, there's just not scaling fast. I, I mean, within AI, I mean, just generally. I, I'd say like people should, should do the thing that, where they find that they're highly motivated to do that thing. Mm-hmm. As opposed to, you know, something, something, some idea that, that I suggest, but they should do the thing that they find personally interesting and motivating to do. Mm-hmm. Um, but, but, but, you know, going back to the limiting factor, yeah, use that phrase about a hundred times. Um, the, the current limiting factor that I see in the timeframe, you know, in the, in the sort of 20, 29, 20, like in the, in the three, three to four year timeframe, um, it's chips. Um, in, in the, in the one year timeframe, it's, it's energy, power production, electricity. Like, it's, it's not clear to me that there's enough, uh, usable electricity to turn on all the, the air chips that are being made. Um, so towards the end of this year, I think people are going to have real trouble turning on, like chip output will exceed the, the ability to turn chips on. What, what's your plan to deal with that world? Well, we're trying to accelerate electricity production. Um, I, I guess that's, that's maybe one of the reasons that, um, XAI will, will be maybe the leader, hopefully the leader, um, is that we'll be able to turn on more chips than other people can turn on faster. Um, because we're, we're, we're good at hardware. And, and, and, and generally the, the innovations from the corporations that mess that call themselves labs, um, the, the ideas tend to flow. Like it's, it's rare to see that there's like more than about a six month difference, um, between, um, I, like the ideas, uh, travel back and forth, um, with the people. So, so I think you, you sort of hit the hardware wall and, um, and then whatever, whichever company can scale hardware, the fastest will be the leader. And so I think XAI will be able to scale hardware the fastest and therefore most likely will be the leader. Yeah. You, you, you joked or, you know, um, we're self-conscious about, uh, you know, using the, uh, the limiting factor phrase again, but I actually think there's something deep here. And if you look at a lot of things we've touched on over the course of it, maybe kind of a good note to end on. Like if you think of a senescent lower agency company, it would have some bottleneck and not really be doing anything about us. Um, you know, Mark Andreessen had the line of, uh, most people are willing to endure any amount of chronic pain to avoid acute pain. Uh, and it feels like a lot of the cases we're talking about are just leaning into the acute pain, whatever it is. It's like, okay, we gotta figure out how to, you know, work with steel, or we gotta figure out how to run the chips in space, or like we'll take some near term acute pain to actually solve the bottleneck. And so that's kind of a unifying thing. I have a high pain threshold. That's helpful. To solve the bottlenecks. Yes. Um, so, you know, one thing I can say is like, uh, I think the future is going to be very interesting. Um, and, um, and as I said, the DAW was up only been to, I was literally at DAW was on the ground for like three hours or something. Um, it's better to be, it's better to err on the side of optimism and be wrong than err on the side of pessimism and be right, uh, for quality of life. So, you know, your, your, your happiness will be, you'll, you'll be happier if you, if you are on the side of optimism rather than erring on the side of pessimism. And so I recommend erring on the side of optimism. Nice to that. Cool. Yelan, thanks for doing this. Thank you. All right. Thanks guys. Great stamina. Hopefully this encounters the pain and the pain tolerance. Hey everybody. I hope you enjoyed that episode. If you did, the most helpful thing you can do is just share it with other people who you think might enjoy it. It's also helpful if you leave a rating or a comment on whatever platform you're listening on. If you're interested in sponsoring the podcast, you can reach out at dhwarkesh.com slash advertise. Otherwise, I'll see you on the next one.",
  "segments": [
    {
      "id": 0,
      "start": 0.0,
      "end": 2.32,
      "text": "So are there really three hours of questions?"
    },
    {
      "id": 1,
      "start": 2.32,
      "end": 4.0200000000000005,
      "text": "Or are you fucking serious?"
    },
    {
      "id": 2,
      "start": 4.0200000000000005,
      "end": 4.5200000000000005,
      "text": "Yeah."
    },
    {
      "id": 3,
      "start": 7.22,
      "end": 8.82,
      "text": "You don't think there's a lot to talk about, Ilan?"
    },
    {
      "id": 4,
      "start": 8.82,
      "end": 10.6,
      "text": "Holy pork, man."
    },
    {
      "id": 5,
      "start": 10.6,
      "end": 13.040000000000001,
      "text": "I mean, it's the most interesting point."
    },
    {
      "id": 6,
      "start": 13.040000000000001,
      "end": 15.94,
      "text": "All the storylines are kind of converging right now."
    },
    {
      "id": 7,
      "start": 15.94,
      "end": 17.400000000000002,
      "text": "So we'll see how much we're going."
    },
    {
      "id": 8,
      "start": 17.400000000000002,
      "end": 19.2,
      "text": "It's almost like I planned it."
    },
    {
      "id": 9,
      "start": 19.2,
      "end": 20.2,
      "text": "Exactly."
    },
    {
      "id": 10,
      "start": 20.2,
      "end": 21.0,
      "text": "Well, we'll get to that."
    },
    {
      "id": 11,
      "start": 21.0,
      "end": 23.5,
      "text": "That would never do such a thing."
    },
    {
      "id": 12,
      "start": 23.5,
      "end": 26.22,
      "text": "So as you know better than anybody else,"
    },
    {
      "id": 13,
      "start": 26.22,
      "end": 28.5,
      "text": "the total cost of ownership of a data center,"
    },
    {
      "id": 14,
      "start": 28.5,
      "end": 30.02,
      "text": "only 10% to 15% is energy."
    },
    {
      "id": 15,
      "start": 30.02,
      "end": 31.18,
      "text": "And that's the part you're presumably"
    },
    {
      "id": 16,
      "start": 31.18,
      "end": 33.3,
      "text": "saving by moving this into space."
    },
    {
      "id": 17,
      "start": 33.3,
      "end": 34.66,
      "text": "Most of it's the GPUs."
    },
    {
      "id": 18,
      "start": 34.66,
      "end": 36.4,
      "text": "If they're in space, it's hard to service them,"
    },
    {
      "id": 19,
      "start": 36.4,
      "end": 37.58,
      "text": "or you can't service them."
    },
    {
      "id": 20,
      "start": 37.58,
      "end": 39.44,
      "text": "And so the depreciation cycle goes down on them."
    },
    {
      "id": 21,
      "start": 39.44,
      "end": 42.18,
      "text": "So it's just way more expensive to have the GPUs in space,"
    },
    {
      "id": 22,
      "start": 42.18,
      "end": 43.44,
      "text": "presumably."
    },
    {
      "id": 23,
      "start": 43.44,
      "end": 45.72,
      "text": "What's the reason to put them in space?"
    },
    {
      "id": 24,
      "start": 45.72,
      "end": 51.260000000000005,
      "text": "Well, the availability of energy is the issue."
    },
    {
      "id": 25,
      "start": 51.260000000000005,
      "end": 55.64,
      "text": "So I mean, if you look at electrical output"
    },
    {
      "id": 26,
      "start": 55.64,
      "end": 57.96,
      "text": "outside of China, everywhere outside of China,"
    },
    {
      "id": 27,
      "start": 57.96,
      "end": 58.800000000000004,
      "text": "it's more or less flat."
    },
    {
      "id": 28,
      "start": 58.800000000000004,
      "end": 60.78,
      "text": "It's very, maybe a slight increase,"
    },
    {
      "id": 29,
      "start": 60.78,
      "end": 62.28,
      "text": "but pretty close flat."
    },
    {
      "id": 30,
      "start": 62.28,
      "end": 65.46000000000001,
      "text": "China has a rapid increase in electrical output."
    },
    {
      "id": 31,
      "start": 65.46000000000001,
      "end": 67.94,
      "text": "But if you're putting data centers anywhere except China,"
    },
    {
      "id": 32,
      "start": 67.94,
      "end": 70.1,
      "text": "where are you going to get your electricity,"
    },
    {
      "id": 33,
      "start": 70.1,
      "end": 71.7,
      "text": "especially as you scale?"
    },
    {
      "id": 34,
      "start": 71.7,
      "end": 74.8,
      "text": "The output of chips is growing pretty much exponentially,"
    },
    {
      "id": 35,
      "start": 74.8,
      "end": 77.2,
      "text": "but the output of electricity is flat."
    },
    {
      "id": 36,
      "start": 77.2,
      "end": 80.92,
      "text": "So how are you going to turn them chips on?"
    },
    {
      "id": 37,
      "start": 80.92,
      "end": 82.72,
      "text": "Magical power sources?"
    },
    {
      "id": 38,
      "start": 82.72,
      "end": 84.48,
      "text": "Magical electricity ferries?"
    },
    {
      "id": 39,
      "start": 84.48,
      "end": 87.60000000000001,
      "text": "You're famously a big fan of solar,"
    },
    {
      "id": 40,
      "start": 87.60000000000001,
      "end": 90.96000000000001,
      "text": "one terawatt of solar power, so with a 25% compatibility factor,"
    },
    {
      "id": 41,
      "start": 90.96000000000001,
      "end": 92.52000000000001,
      "text": "like four terawatts of solar panels."
    },
    {
      "id": 42,
      "start": 92.52000000000001,
      "end": 95.72,
      "text": "It's like 1% of the land area of the United States."
    },
    {
      "id": 43,
      "start": 95.72,
      "end": 96.66,
      "text": "And that's like far in this."
    },
    {
      "id": 44,
      "start": 96.66,
      "end": 98.46000000000001,
      "text": "You were in the singularity when we've got one terawatt"
    },
    {
      "id": 45,
      "start": 98.46000000000001,
      "end": 100.42,
      "text": "of data centers, right?"
    },
    {
      "id": 46,
      "start": 100.42,
      "end": 102.22,
      "text": "So what are you running out of exactly?"
    },
    {
      "id": 47,
      "start": 102.22,
      "end": 104.54,
      "text": "How far into the singularity are you?"
    },
    {
      "id": 48,
      "start": 104.54,
      "end": 105.2,
      "text": "You tell me."
    },
    {
      "id": 49,
      "start": 105.2,
      "end": 105.82000000000001,
      "text": "Yeah, exactly."
    },
    {
      "id": 50,
      "start": 105.82000000000001,
      "end": 108.84,
      "text": "So I think we'll find we're in the singularity, and like, oh,"
    },
    {
      "id": 51,
      "start": 108.84,
      "end": 110.96000000000001,
      "text": "OK, we'll still get a long way to go."
    },
    {
      "id": 52,
      "start": 110.96000000000001,
      "end": 115.74000000000001,
      "text": "But is the plan to put it in the space after we've covered Nevada"
    },
    {
      "id": 53,
      "start": 115.74000000000001,
      "end": 116.46000000000001,
      "text": "in solar panels?"
    },
    {
      "id": 54,
      "start": 116.46000000000001,
      "end": 118.68,
      "text": "I think it's pretty hard to cover Nevada in solar panels."
    },
    {
      "id": 55,
      "start": 118.68,
      "end": 121.14,
      "text": "You have to get permits from the permits for that."
    },
    {
      "id": 56,
      "start": 121.14,
      "end": 122.68,
      "text": "Try getting the permits for that."
    },
    {
      "id": 57,
      "start": 122.68,
      "end": 125.76,
      "text": "So space is really a regulatory play."
    },
    {
      "id": 58,
      "start": 125.76,
      "end": 128.52,
      "text": "It's harder to build on land than it is in space."
    },
    {
      "id": 59,
      "start": 128.52,
      "end": 134.04000000000002,
      "text": "It's harder to scale on ground than it is to scale in space."
    },
    {
      "id": 60,
      "start": 134.04000000000002,
      "end": 141.56,
      "text": "But also, you're going to get about five times the effectiveness"
    },
    {
      "id": 61,
      "start": 141.56,
      "end": 143.48000000000002,
      "text": "of solar panels in space versus the ground."
    },
    {
      "id": 62,
      "start": 143.48000000000002,
      "end": 146.48000000000002,
      "text": "And you don't need batteries."
    },
    {
      "id": 63,
      "start": 146.48000000000002,
      "end": 150.32000000000002,
      "text": "I almost wore my other shirt, which says it's always sunny in space,"
    },
    {
      "id": 64,
      "start": 150.32000000000002,
      "end": 150.94,
      "text": "which it is."
    },
    {
      "id": 65,
      "start": 153.54000000000002,
      "end": 157.14000000000001,
      "text": "So because you don't have a day-night cycle"
    },
    {
      "id": 66,
      "start": 157.14,
      "end": 163.89999999999998,
      "text": "or seasonality, clouds, or an atmosphere in space,"
    },
    {
      "id": 67,
      "start": 163.89999999999998,
      "end": 170.32,
      "text": "because the atmosphere alone results in about a 30% loss of energy."
    },
    {
      "id": 68,
      "start": 170.32,
      "end": 176.77999999999997,
      "text": "So any given solar panels can do about five times more power"
    },
    {
      "id": 69,
      "start": 176.77999999999997,
      "end": 178.14,
      "text": "in space than on the ground."
    },
    {
      "id": 70,
      "start": 178.14,
      "end": 180.2,
      "text": "And you avoid the cost of having batteries"
    },
    {
      "id": 71,
      "start": 180.2,
      "end": 183.29999999999998,
      "text": "to carry you through the night."
    },
    {
      "id": 72,
      "start": 183.29999999999998,
      "end": 186.44,
      "text": "So it's actually much cheaper to do in space."
    },
    {
      "id": 73,
      "start": 186.44,
      "end": 193.2,
      "text": "And my prediction is that it will be by far the cheapest place to put AI"
    },
    {
      "id": 74,
      "start": 193.2,
      "end": 196.2,
      "text": "will be space in 36 months or less."
    },
    {
      "id": 75,
      "start": 196.2,
      "end": 197.2,
      "text": "Maybe 30 months."
    },
    {
      "id": 76,
      "start": 197.2,
      "end": 197.78,
      "text": "36 months?"
    },
    {
      "id": 77,
      "start": 197.78,
      "end": 199.2,
      "text": "Less than 36 months."
    },
    {
      "id": 78,
      "start": 199.2,
      "end": 200.78,
      "text": "How do you service GPUs as they fail,"
    },
    {
      "id": 79,
      "start": 200.78,
      "end": 204.2,
      "text": "which happens quite often in training?"
    },
    {
      "id": 80,
      "start": 204.2,
      "end": 208.95999999999998,
      "text": "Actually, it depends on how recent the GPUs are that are ripe."
    },
    {
      "id": 81,
      "start": 208.95999999999998,
      "end": 212.95999999999998,
      "text": "I mean, at this point, we found our GPUs to be quite reliable."
    },
    {
      "id": 82,
      "start": 212.95999999999998,
      "end": 215.95999999999998,
      "text": "There's infinite mortality, which you can obviously iron out on the ground."
    },
    {
      "id": 83,
      "start": 215.95999999999998,
      "end": 219.95999999999998,
      "text": "So you can just run them on the ground and confirm that you don't have infinite mortality"
    },
    {
      "id": 84,
      "start": 219.95999999999998,
      "end": 220.95999999999998,
      "text": "with the GPUs."
    },
    {
      "id": 85,
      "start": 220.96,
      "end": 225.72,
      "text": "But once they start working, their actual reliability, and once they start working,"
    },
    {
      "id": 86,
      "start": 225.72,
      "end": 231.72,
      "text": "and you're past the initial debug cycle of NVIDIA or whatever, or whoever's making the chips,"
    },
    {
      "id": 87,
      "start": 231.72,
      "end": 238.72,
      "text": "could be Tesla, Tesla AI 6 chips or something like that, or it could be TPUs or Traniums or whatever."
    },
    {
      "id": 88,
      "start": 238.72,
      "end": 247.48,
      "text": "The reliability is actually, they're quite reliable past certain point."
    },
    {
      "id": 89,
      "start": 247.48,
      "end": 252.48,
      "text": "So I don't think that the servicing thing is an issue."
    },
    {
      "id": 90,
      "start": 252.48,
      "end": 255.48,
      "text": "But you can mark my words."
    },
    {
      "id": 91,
      "start": 255.48,
      "end": 263.48,
      "text": "In 36 months, but probably closer to 30 months, the most economically compelling place to put AI"
    },
    {
      "id": 92,
      "start": 263.48,
      "end": 271.24,
      "text": "into space, and then it will get ridiculously better to be in space."
    },
    {
      "id": 93,
      "start": 271.24,
      "end": 275.24,
      "text": "And then the scaling, the only place you can really scale is space."
    },
    {
      "id": 94,
      "start": 275.24,
      "end": 281.24,
      "text": "Once you start thinking in terms of what percentage of the Sun's power are you harnessing,"
    },
    {
      "id": 95,
      "start": 281.24,
      "end": 284.24,
      "text": "you realize you have to go to space."
    },
    {
      "id": 96,
      "start": 284.24,
      "end": 287.24,
      "text": "You can't scale very much on Earth."
    },
    {
      "id": 97,
      "start": 287.24,
      "end": 291.24,
      "text": "But by very much, to be clear, you're talking like terawatts."
    },
    {
      "id": 98,
      "start": 291.24,
      "end": 292.24,
      "text": "Yeah."
    },
    {
      "id": 99,
      "start": 292.24,
      "end": 298.0,
      "text": "Well, all of the United States currently uses only half a terawatt of power on average."
    },
    {
      "id": 100,
      "start": 298.0,
      "end": 299.0,
      "text": "Yeah."
    },
    {
      "id": 101,
      "start": 299.0,
      "end": 300.0,
      "text": "Right."
    },
    {
      "id": 102,
      "start": 300.0,
      "end": 304.40000000000003,
      "text": "So if you say a terawatt, that would be twice as much electricity as the United States currently"
    },
    {
      "id": 103,
      "start": 304.40000000000003,
      "end": 305.40000000000003,
      "text": "consumes."
    },
    {
      "id": 104,
      "start": 305.40000000000003,
      "end": 307.0,
      "text": "So that's quite a lot."
    },
    {
      "id": 105,
      "start": 307.0,
      "end": 312.32,
      "text": "And can you imagine building that many data centers, that many power plants?"
    },
    {
      "id": 106,
      "start": 312.32,
      "end": 318.0,
      "text": "It's like those who have lived in software land don't realize that they're about to have"
    },
    {
      "id": 107,
      "start": 318.0,
      "end": 323.76,
      "text": "a hard lesson in hardware."
    },
    {
      "id": 108,
      "start": 323.76,
      "end": 326.52,
      "text": "It's actually very difficult to build power plants."
    },
    {
      "id": 109,
      "start": 326.52,
      "end": 328.52,
      "text": "And then you don't just need the power plants."
    },
    {
      "id": 110,
      "start": 328.52,
      "end": 330.52,
      "text": "You need all of the electrical equipment."
    },
    {
      "id": 111,
      "start": 330.52,
      "end": 334.52,
      "text": "You need the electrical transformers to run the transformers, the AI transformers."
    },
    {
      "id": 112,
      "start": 334.52,
      "end": 341.28,
      "text": "Now, the utility industry is a very slow industry."
    },
    {
      "id": 113,
      "start": 341.28,
      "end": 347.03999999999996,
      "text": "Pretty much, you know, they impedance match to the government, to the public utility commission."
    },
    {
      "id": 114,
      "start": 347.04,
      "end": 355.8,
      "text": "So they're very slow because their past has been very slow."
    },
    {
      "id": 115,
      "start": 355.8,
      "end": 360.56,
      "text": "So trying to get them to move fast is just like, you know, like if you try to do an interconnect"
    },
    {
      "id": 116,
      "start": 360.56,
      "end": 364.56,
      "text": "agreement with the, have you ever tried to do an interconnect agreement with a utility"
    },
    {
      "id": 117,
      "start": 364.56,
      "end": 366.56,
      "text": "at scale, like with a lot of power?"
    },
    {
      "id": 118,
      "start": 366.56,
      "end": 369.32,
      "text": "If you're a professional podcaster, I can say that I'm not, in fact."
    },
    {
      "id": 119,
      "start": 369.32,
      "end": 370.32,
      "text": "Yeah."
    },
    {
      "id": 120,
      "start": 370.32,
      "end": 373.32,
      "text": "They have to just leave many more views before that becomes an issue."
    },
    {
      "id": 121,
      "start": 373.32,
      "end": 376.32,
      "text": "They have to do a study for a year, OK?"
    },
    {
      "id": 122,
      "start": 376.32,
      "end": 379.32,
      "text": "Like a year later, they'll come back to you with their interconnect study."
    },
    {
      "id": 123,
      "start": 379.32,
      "end": 383.32,
      "text": "Can't you tell this with your own behind the meter power stuff?"
    },
    {
      "id": 124,
      "start": 383.32,
      "end": 385.32,
      "text": "You can build power plants."
    },
    {
      "id": 125,
      "start": 385.32,
      "end": 386.32,
      "text": "Yeah."
    },
    {
      "id": 126,
      "start": 386.32,
      "end": 388.32,
      "text": "That's what we did at XAI for classes too."
    },
    {
      "id": 127,
      "start": 388.32,
      "end": 389.32,
      "text": "So for classes too."
    },
    {
      "id": 128,
      "start": 389.32,
      "end": 391.32,
      "text": "So yeah, why are we talking about the grid?"
    },
    {
      "id": 129,
      "start": 391.32,
      "end": 393.32,
      "text": "Why not just like build GPUs and power co-located?"
    },
    {
      "id": 130,
      "start": 393.32,
      "end": 394.32,
      "text": "That's what we did."
    },
    {
      "id": 131,
      "start": 394.32,
      "end": 395.32,
      "text": "Right, right."
    },
    {
      "id": 132,
      "start": 395.32,
      "end": 397.32,
      "text": "I'm saying why isn't this a generalized solution when you're talking about all the issues?"
    },
    {
      "id": 133,
      "start": 397.32,
      "end": 398.32,
      "text": "Where do you get the power plants from?"
    },
    {
      "id": 134,
      "start": 398.32,
      "end": 402.12,
      "text": "I'm saying when you talk about all the issues working with utilities, you can just build"
    },
    {
      "id": 135,
      "start": 402.12,
      "end": 404.32,
      "text": "private power plants with the data centers."
    },
    {
      "id": 136,
      "start": 404.32,
      "end": 405.32,
      "text": "Right."
    },
    {
      "id": 137,
      "start": 405.32,
      "end": 407.32,
      "text": "But it begs the question of where do you get the power plants from?"
    },
    {
      "id": 138,
      "start": 407.32,
      "end": 408.82,
      "text": "Where do you get the power plants from?"
    },
    {
      "id": 139,
      "start": 408.82,
      "end": 409.82,
      "text": "I mean."
    },
    {
      "id": 140,
      "start": 409.82,
      "end": 410.82,
      "text": "The power plant makers."
    },
    {
      "id": 141,
      "start": 410.82,
      "end": 411.82,
      "text": "Oh, I was just saying."
    },
    {
      "id": 142,
      "start": 411.82,
      "end": 412.82,
      "text": "Yeah."
    },
    {
      "id": 143,
      "start": 412.82,
      "end": 414.82,
      "text": "Like there's the gas turbine backlog, basically?"
    },
    {
      "id": 144,
      "start": 414.82,
      "end": 415.82,
      "text": "Yes."
    },
    {
      "id": 145,
      "start": 415.82,
      "end": 417.88,
      "text": "You can drill down to a level further."
    },
    {
      "id": 146,
      "start": 417.88,
      "end": 425.08,
      "text": "It's the veins and blades in the turbines that are the limiting factor because the casting"
    },
    {
      "id": 147,
      "start": 425.08,
      "end": 431.88,
      "text": "may, it's like a very specialized process to cast the blades and veins in the turbines,"
    },
    {
      "id": 148,
      "start": 431.88,
      "end": 434.58,
      "text": "so you're using gas power."
    },
    {
      "id": 149,
      "start": 434.58,
      "end": 437.88,
      "text": "And it's very difficult to scale other forms of power."
    },
    {
      "id": 150,
      "start": 437.88,
      "end": 444.08,
      "text": "You can scale potentially solar, but the tariffs currently for importing solar in the US are"
    },
    {
      "id": 151,
      "start": 444.08,
      "end": 445.08,
      "text": "gigantic."
    },
    {
      "id": 152,
      "start": 445.08,
      "end": 447.08,
      "text": "And the domestic solar production is pitiful."
    },
    {
      "id": 153,
      "start": 447.08,
      "end": 448.08,
      "text": "Why not make solar?"
    },
    {
      "id": 154,
      "start": 448.08,
      "end": 450.08,
      "text": "That seems like a good Elon-shaped problem."
    },
    {
      "id": 155,
      "start": 450.08,
      "end": 451.08,
      "text": "We are going to make solar."
    },
    {
      "id": 156,
      "start": 451.08,
      "end": 452.08,
      "text": "Okay."
    },
    {
      "id": 157,
      "start": 452.08,
      "end": 453.08,
      "text": "Yeah."
    },
    {
      "id": 158,
      "start": 453.08,
      "end": 454.08,
      "text": "Great."
    },
    {
      "id": 159,
      "start": 454.08,
      "end": 460.08,
      "text": "Both SpaceX and Tesla are building towards 100 gigawatts here of solar cell production."
    },
    {
      "id": 160,
      "start": 460.08,
      "end": 461.08,
      "text": "How low down the stack?"
    },
    {
      "id": 161,
      "start": 461.08,
      "end": 465.88,
      "text": "Like from polysilicon up to the wafer to the final panel?"
    },
    {
      "id": 162,
      "start": 465.88,
      "end": 469.88,
      "text": "I think you've got to do the whole thing from raw materials to finish the cell."
    },
    {
      "id": 163,
      "start": 469.88,
      "end": 474.88,
      "text": "Now, if it's going to space, it's actually, it costs less and it's easier to make solar"
    },
    {
      "id": 164,
      "start": 474.88,
      "end": 478.88,
      "text": "cells that go to space because they don't need glass or they don't need much glass and"
    },
    {
      "id": 165,
      "start": 478.88,
      "end": 482.88,
      "text": "they don't need heavy framing because they don't have to survive weather events."
    },
    {
      "id": 166,
      "start": 482.88,
      "end": 484.88,
      "text": "There's no weather in space."
    },
    {
      "id": 167,
      "start": 484.88,
      "end": 488.88,
      "text": "So it's actually a cheaper solar cell that goes to space than the one on the ground."
    },
    {
      "id": 168,
      "start": 488.88,
      "end": 494.88,
      "text": "Is there a path to getting them as cheap as you need in the next 36 months?"
    },
    {
      "id": 169,
      "start": 494.88,
      "end": 495.88,
      "text": "Yeah."
    },
    {
      "id": 170,
      "start": 495.88,
      "end": 498.88,
      "text": "Solar cells are already very cheap."
    },
    {
      "id": 171,
      "start": 498.88,
      "end": 501.88,
      "text": "They're like farcically cheap."
    },
    {
      "id": 172,
      "start": 501.88,
      "end": 508.88,
      "text": "And if you say, you know, I think like solar cells in China are around like 25, 30 cents"
    },
    {
      "id": 173,
      "start": 508.88,
      "end": 509.88,
      "text": "a watt or something like that."
    },
    {
      "id": 174,
      "start": 509.88,
      "end": 510.88,
      "text": "It's absurdly cheap."
    },
    {
      "id": 175,
      "start": 510.88,
      "end": 516.88,
      "text": "And when you take into a cap, now put it in space and it's five times cheaper because"
    },
    {
      "id": 176,
      "start": 516.88,
      "end": 519.88,
      "text": "it's five times, in fact, no, it's not five times cheaper."
    },
    {
      "id": 177,
      "start": 519.88,
      "end": 523.88,
      "text": "It's 10 times cheaper because you don't need any batteries."
    },
    {
      "id": 178,
      "start": 523.88,
      "end": 530.88,
      "text": "So the moment your cost of access to space becomes low, by far the cheapest and most scalable"
    },
    {
      "id": 179,
      "start": 530.88,
      "end": 535.88,
      "text": "way to generate tokens is space."
    },
    {
      "id": 180,
      "start": 535.88,
      "end": 537.88,
      "text": "It's not even close."
    },
    {
      "id": 181,
      "start": 537.88,
      "end": 544.88,
      "text": "It'll be an order of magnitude easier to scale and chips aside an order of magnitude."
    },
    {
      "id": 182,
      "start": 544.88,
      "end": 547.88,
      "text": "Well, if the point is you won't be able to scale on the ground, you just won't."
    },
    {
      "id": 183,
      "start": 547.88,
      "end": 553.88,
      "text": "If you want to hit the wall big time on power generation, they already are."
    },
    {
      "id": 184,
      "start": 553.88,
      "end": 558.88,
      "text": "So like the number of sort of miracles and series that the XAI team had to accomplish in order"
    },
    {
      "id": 185,
      "start": 558.88,
      "end": 561.88,
      "text": "to get a gigawatt of power online was crazy."
    },
    {
      "id": 186,
      "start": 561.88,
      "end": 566.88,
      "text": "We had to gang together a whole bunch of turbines."
    },
    {
      "id": 187,
      "start": 566.88,
      "end": 573.88,
      "text": "And then we had permit issues in Tennessee and had to go across the border to Mississippi,"
    },
    {
      "id": 188,
      "start": 573.88,
      "end": 576.88,
      "text": "which is fortunately only a few miles away."
    },
    {
      "id": 189,
      "start": 576.88,
      "end": 581.88,
      "text": "But then we still had to run the high power lines a few miles and build a power plant in"
    },
    {
      "id": 190,
      "start": 581.88,
      "end": 582.88,
      "text": "Mississippi."
    },
    {
      "id": 191,
      "start": 582.88,
      "end": 584.88,
      "text": "And it was very difficult to build that."
    },
    {
      "id": 192,
      "start": 584.88,
      "end": 590.88,
      "text": "And people don't understand like how much electricity do you actually need at the generator level,"
    },
    {
      "id": 193,
      "start": 590.88,
      "end": 593.88,
      "text": "at the generation level in order to power a data center."
    },
    {
      "id": 194,
      "start": 593.88,
      "end": 601.88,
      "text": "Because they look at the news will look at the power consumption of say a GB300 and multiply"
    },
    {
      "id": 195,
      "start": 601.88,
      "end": 604.88,
      "text": "that by a thing and then think that's the amount of power you need."
    },
    {
      "id": 196,
      "start": 604.88,
      "end": 605.88,
      "text": "All the cooling and everything."
    },
    {
      "id": 197,
      "start": 605.88,
      "end": 606.88,
      "text": "Wake up."
    },
    {
      "id": 198,
      "start": 606.88,
      "end": 607.88,
      "text": "Yeah."
    },
    {
      "id": 199,
      "start": 607.88,
      "end": 610.88,
      "text": "This is like that's a total news."
    },
    {
      "id": 200,
      "start": 610.88,
      "end": 613.88,
      "text": "You've never done any hardware in your life before."
    },
    {
      "id": 201,
      "start": 613.88,
      "end": 617.88,
      "text": "Besides the GB300, you've got to power all of the networking hardware."
    },
    {
      "id": 202,
      "start": 617.88,
      "end": 620.88,
      "text": "There's a whole bunch of CPU and storage stuff that's happening."
    },
    {
      "id": 203,
      "start": 620.88,
      "end": 626.88,
      "text": "You've got a size for your peak cooling requirements."
    },
    {
      "id": 204,
      "start": 626.88,
      "end": 631.88,
      "text": "So that means can you cool even on the worst hours, the worst day of the year?"
    },
    {
      "id": 205,
      "start": 631.88,
      "end": 633.88,
      "text": "Well, it's pretty friggin hot in Memphis."
    },
    {
      "id": 206,
      "start": 633.88,
      "end": 639.88,
      "text": "So you're going to have like a 40% increase on your power just for cooling."
    },
    {
      "id": 207,
      "start": 639.88,
      "end": 645.88,
      "text": "Assuming you don't want your data center to turn off on hot days and want to keep going."
    },
    {
      "id": 208,
      "start": 645.88,
      "end": 651.88,
      "text": "Then you've got to say, well, there's another multiplicative element on top of that, which is,"
    },
    {
      "id": 209,
      "start": 651.88,
      "end": 656.88,
      "text": "are you assuming that you never have any hiccups in your power generation?"
    },
    {
      "id": 210,
      "start": 656.88,
      "end": 661.88,
      "text": "Like, oh, well, actually, sometimes you have to take the generators, some of the power offline in order to service it."
    },
    {
      "id": 211,
      "start": 661.88,
      "end": 669.88,
      "text": "Oh, OK, now you add another 20, 25% multiplier on that because you've got to assume that you've got to take power offline to service it."
    },
    {
      "id": 212,
      "start": 669.88,
      "end": 690.88,
      "text": "So the actual RS, roughly every 110,000 GBs, GB300s, inclusive of networking, CPU storage, cooling, margin for servicing power is roughly 300 megawatts."
    },
    {
      "id": 213,
      "start": 690.88,
      "end": 691.88,
      "text": "Sorry, say that again."
    },
    {
      "id": 214,
      "start": 691.88,
      "end": 716.88,
      "text": "It's roughly, or think about it, like, the way you think about it is like 330,000 to actually, what you need at the generation level to service, probably service 330,000 GB300s, including all of the associated support networking and everything else, and the peak cooling, and to have some margin, some power margin reserve, is roughly a gigawatt."
    },
    {
      "id": 215,
      "start": 716.88,
      "end": 720.88,
      "text": "Can I ask a very naive question?"
    },
    {
      "id": 216,
      "start": 720.88,
      "end": 721.88,
      "text": "Yeah."
    },
    {
      "id": 217,
      "start": 721.88,
      "end": 729.88,
      "text": "You know, you're describing the engineering details of doing this stuff on Earth, but then there's analogous engineering difficulties of doing it in space."
    },
    {
      "id": 218,
      "start": 729.88,
      "end": 734.88,
      "text": "How do you do the, how do you replace infinite band with orbital lasers, et cetera, et cetera?"
    },
    {
      "id": 219,
      "start": 734.88,
      "end": 736.88,
      "text": "How do you make it resistant to radiation?"
    },
    {
      "id": 220,
      "start": 736.88,
      "end": 745.88,
      "text": "I don't know the details of the engineering, but fundamentally, what is the reason to think those challenges, which have never been, had to be addressed before, are you?"
    },
    {
      "id": 221,
      "start": 745.88,
      "end": 749.88,
      "text": "What had to be addressed before will end up being easier than just like building more turbines on Earth."
    },
    {
      "id": 222,
      "start": 749.88,
      "end": 750.88,
      "text": "There's companies that build turbines on Earth."
    },
    {
      "id": 223,
      "start": 750.88,
      "end": 752.88,
      "text": "They can make more turbines, right?"
    },
    {
      "id": 224,
      "start": 752.88,
      "end": 758.88,
      "text": "I invite, again, try doing it and then you'll see."
    },
    {
      "id": 225,
      "start": 758.88,
      "end": 763.88,
      "text": "So, like the turbines are sold out through 2030."
    },
    {
      "id": 226,
      "start": 763.88,
      "end": 765.88,
      "text": "Have you guys considered making your own?"
    },
    {
      "id": 227,
      "start": 765.88,
      "end": 781.88,
      "text": "I think in order for, in order to bring enough power online, I think SpaceX and Tesla will probably have to make the turbine blades, the bands and blades internally."
    },
    {
      "id": 228,
      "start": 781.88,
      "end": 784.88,
      "text": "But just the blades or the turbines?"
    },
    {
      "id": 229,
      "start": 784.88,
      "end": 790.88,
      "text": "The limiting factor, you can get everything except the blades, what they call the blades and veins."
    },
    {
      "id": 230,
      "start": 790.88,
      "end": 798.88,
      "text": "You can get that 12 to 18 months before the veins and blades, the limiting factor of the veins and blades."
    },
    {
      "id": 231,
      "start": 798.88,
      "end": 806.88,
      "text": "And there are only three casting companies in the world that make these, and they're massively backlogged."
    },
    {
      "id": 232,
      "start": 806.88,
      "end": 809.88,
      "text": "Is this Siemens, GE, those guys, or is it a subcontractor?"
    },
    {
      "id": 233,
      "start": 809.88,
      "end": 811.88,
      "text": "No, it's other companies."
    },
    {
      "id": 234,
      "start": 811.88,
      "end": 819.88,
      "text": "I mean, sometimes they have a little bit of casting capability in-house, but I'm just saying you can just call any of the turbine makers and they will tell you."
    },
    {
      "id": 235,
      "start": 819.88,
      "end": 820.88,
      "text": "It's not top secret."
    },
    {
      "id": 236,
      "start": 820.88,
      "end": 822.88,
      "text": "It's probably on the internet right now."
    },
    {
      "id": 237,
      "start": 822.88,
      "end": 825.88,
      "text": "If it wasn't for the tariffs, would Colossus be solar powered?"
    },
    {
      "id": 238,
      "start": 825.88,
      "end": 832.88,
      "text": "It would be much easier to make it solar powered, yeah. The tariffs are nuts, so several hundred percent."
    },
    {
      "id": 239,
      "start": 832.88,
      "end": 834.88,
      "text": "Don't you know some people?"
    },
    {
      "id": 240,
      "start": 834.88,
      "end": 835.88,
      "text": "We also need speed."
    },
    {
      "id": 241,
      "start": 835.88,
      "end": 836.88,
      "text": "Yeah, no."
    },
    {
      "id": 242,
      "start": 836.88,
      "end": 842.88,
      "text": "The president has us, we don't agree on everything."
    },
    {
      "id": 243,
      "start": 842.88,
      "end": 847.88,
      "text": "And this administration is not the biggest fan of solar."
    },
    {
      "id": 244,
      "start": 847.88,
      "end": 856.88,
      "text": "But you know, we also need the land, the permits and everything."
    },
    {
      "id": 245,
      "start": 856.88,
      "end": 865.88,
      "text": "So if you're trying to move very fast, like I do think scaling solar on Earth is a good way to go."
    },
    {
      "id": 246,
      "start": 865.88,
      "end": 871.88,
      "text": "But you do need some amount of time to find the land, get the permits, get the solar, pair that with the batteries."
    },
    {
      "id": 247,
      "start": 871.88,
      "end": 876.88,
      "text": "But why would it not work to stand up your own solar production?"
    },
    {
      "id": 248,
      "start": 876.88,
      "end": 880.88,
      "text": "And then you're right that you eventually run out of land, but there's a lot of land here in Texas."
    },
    {
      "id": 249,
      "start": 880.88,
      "end": 882.88,
      "text": "There's a lot of land in Nevada, including private land."
    },
    {
      "id": 250,
      "start": 882.88,
      "end": 883.88,
      "text": "It's not all publicly owned land."
    },
    {
      "id": 251,
      "start": 883.88,
      "end": 888.88,
      "text": "And so you'd be able to at least get the next Colossus and like the next one after that."
    },
    {
      "id": 252,
      "start": 888.88,
      "end": 891.88,
      "text": "And at a certain point you hit a wall, but wouldn't that work for the moment?"
    },
    {
      "id": 253,
      "start": 891.88,
      "end": 894.88,
      "text": "As I said, we are scaling solar production."
    },
    {
      "id": 254,
      "start": 894.88,
      "end": 900.88,
      "text": "There's a rate at which you can scale physical production of solar cells."
    },
    {
      "id": 255,
      "start": 900.88,
      "end": 906.88,
      "text": "We are going as fast as possible in scaling domestic production."
    },
    {
      "id": 256,
      "start": 906.88,
      "end": 908.88,
      "text": "You're making the solar cells at Tesla?"
    },
    {
      "id": 257,
      "start": 908.88,
      "end": 913.88,
      "text": "Well, Tesla and SpaceX have a mandate to get to 100 gigawatts a year of solar."
    },
    {
      "id": 258,
      "start": 913.88,
      "end": 921.88,
      "text": "Speaking of the annual capacity, I'm curious, in five years time, let's say, what will the installed capacity be on Earth?"
    },
    {
      "id": 259,
      "start": 921.88,
      "end": 922.88,
      "text": "Five years is a long time."
    },
    {
      "id": 260,
      "start": 922.88,
      "end": 924.88,
      "text": "And in space."
    },
    {
      "id": 261,
      "start": 924.88,
      "end": 928.88,
      "text": "I deliberately pick five years because it's after your once we're up and running threshold."
    },
    {
      "id": 262,
      "start": 928.88,
      "end": 934.88,
      "text": "And so in five years time, yeah, what's the on Earth versus in space installed AI capacity?"
    },
    {
      "id": 263,
      "start": 934.88,
      "end": 935.88,
      "text": "Five years."
    },
    {
      "id": 264,
      "start": 935.88,
      "end": 948.88,
      "text": "I think probably if say five years from now, we're probably AI in space will be launching every year."
    },
    {
      "id": 265,
      "start": 948.88,
      "end": 952.88,
      "text": "But the sum total of all AI on Earth in excess."
    },
    {
      "id": 266,
      "start": 952.88,
      "end": 964.88,
      "text": "Meaning five years from now, my prediction is we will launch and be operating every year more AI in space than the cumulative total on Earth."
    },
    {
      "id": 267,
      "start": 964.88,
      "end": 965.88,
      "text": "Which is?"
    },
    {
      "id": 268,
      "start": 965.88,
      "end": 966.88,
      "text": "Which is?"
    },
    {
      "id": 269,
      "start": 966.88,
      "end": 975.88,
      "text": "I would expect to be at least sort of five years from now, a few hundred gigawatts per year of AI in space."
    },
    {
      "id": 270,
      "start": 975.88,
      "end": 976.88,
      "text": "And rising."
    },
    {
      "id": 271,
      "start": 976.88,
      "end": 992.88,
      "text": "So you can get to, I think on Earth you can get to around a terawatt a year of AI in space before you start having fuel supply challenges for the rocket."
    },
    {
      "id": 272,
      "start": 992.88,
      "end": 996.88,
      "text": "OK, but you think you can get hundreds of gigawatts per year in five years time?"
    },
    {
      "id": 273,
      "start": 996.88,
      "end": 997.88,
      "text": "Yes."
    },
    {
      "id": 274,
      "start": 997.88,
      "end": 1009.88,
      "text": "So a hundred gigawatts depending on the specific power of the whole system with solar arrays and radiators and everything is on the order of like 10,000 starship launches."
    },
    {
      "id": 275,
      "start": 1009.88,
      "end": 1010.88,
      "text": "Yes."
    },
    {
      "id": 276,
      "start": 1010.88,
      "end": 1013.88,
      "text": "And you want to do that in one year."
    },
    {
      "id": 277,
      "start": 1013.88,
      "end": 1016.88,
      "text": "And so that's like one starship launch every hour."
    },
    {
      "id": 278,
      "start": 1016.88,
      "end": 1017.88,
      "text": "Yeah."
    },
    {
      "id": 279,
      "start": 1017.88,
      "end": 1019.88,
      "text": "That's happening in this city."
    },
    {
      "id": 280,
      "start": 1019.88,
      "end": 1024.88,
      "text": "Like walk me through a world where there's 10,000, there's a starship launch every single hour."
    },
    {
      "id": 281,
      "start": 1024.88,
      "end": 1025.88,
      "text": "Yeah."
    },
    {
      "id": 282,
      "start": 1025.88,
      "end": 1028.88,
      "text": "I mean, that's actually a lower rate compared to airlines, like aircraft."
    },
    {
      "id": 283,
      "start": 1028.88,
      "end": 1029.88,
      "text": "There's a lot of airports."
    },
    {
      "id": 284,
      "start": 1029.88,
      "end": 1030.88,
      "text": "There's a lot of airports."
    },
    {
      "id": 285,
      "start": 1030.88,
      "end": 1031.88,
      "text": "A lot of airports."
    },
    {
      "id": 286,
      "start": 1031.88,
      "end": 1032.88,
      "text": "But."
    },
    {
      "id": 287,
      "start": 1032.88,
      "end": 1033.88,
      "text": "And you've got to launch the polar orbit."
    },
    {
      "id": 288,
      "start": 1033.88,
      "end": 1040.88,
      "text": "No, it doesn't have to be polar, but you just, there's some value to sun synchronous."
    },
    {
      "id": 289,
      "start": 1040.88,
      "end": 1048.88,
      "text": "But I think actually you just go high enough, you start getting out of Earth's shadow."
    },
    {
      "id": 290,
      "start": 1048.88,
      "end": 1049.88,
      "text": "And so."
    },
    {
      "id": 291,
      "start": 1049.88,
      "end": 1054.88,
      "text": "How many physical starships are needed to do 10,000 launches a year?"
    },
    {
      "id": 292,
      "start": 1054.88,
      "end": 1062.88,
      "text": "I don't think we'll need more than, I mean, you could, you could probably do it with as few as like 20 or 30."
    },
    {
      "id": 293,
      "start": 1062.88,
      "end": 1071.88,
      "text": "Like, it really depends on how quickly does the ship, the ship has to go around the Earth."
    },
    {
      "id": 294,
      "start": 1071.88,
      "end": 1075.88,
      "text": "And the ground track before the ship has to come back over the launch pad."
    },
    {
      "id": 295,
      "start": 1075.88,
      "end": 1081.88,
      "text": "So if you can use a ship every say 30 hours, you could do it with 30 ships."
    },
    {
      "id": 296,
      "start": 1081.88,
      "end": 1083.88,
      "text": "But, but we'll, we'll make more ships than that."
    },
    {
      "id": 297,
      "start": 1083.88,
      "end": 1090.88,
      "text": "But, but, but the, the, the SpaceX is, is, is gearing up to do 10,000 launches a year."
    },
    {
      "id": 298,
      "start": 1090.88,
      "end": 1093.88,
      "text": "And I'll, and maybe even 20 or 30,000 launches a year."
    },
    {
      "id": 299,
      "start": 1093.88,
      "end": 1099.88,
      "text": "Is the idea to become basically a, a hyperscaler, become an Oracle and lend this capacity to other people?"
    },
    {
      "id": 300,
      "start": 1099.88,
      "end": 1104.88,
      "text": "What's, what are you going to do with, presumably SpaceX is the one launching all this."
    },
    {
      "id": 301,
      "start": 1104.88,
      "end": 1106.88,
      "text": "So SpaceX is going to be a hyperscaler?"
    },
    {
      "id": 302,
      "start": 1106.88,
      "end": 1108.88,
      "text": "Hyper, hyper."
    },
    {
      "id": 303,
      "start": 1108.88,
      "end": 1109.88,
      "text": "Yeah."
    },
    {
      "id": 304,
      "start": 1109.88,
      "end": 1118.88,
      "text": "I mean, if, if some of my predictions come true, SpaceX will launch more AI than the cumulative amount on Earth combined, of everything else combined."
    },
    {
      "id": 305,
      "start": 1118.88,
      "end": 1119.88,
      "text": "Is this mostly inference or?"
    },
    {
      "id": 306,
      "start": 1119.88,
      "end": 1121.88,
      "text": "Most AI will be inference."
    },
    {
      "id": 307,
      "start": 1121.88,
      "end": 1124.88,
      "text": "Like already inference for the purpose of training is most training."
    },
    {
      "id": 308,
      "start": 1124.88,
      "end": 1136.88,
      "text": "And there's a narrative that the, the change in discussion around a SpaceX IPO is because previously, SpaceX was very capital efficient."
    },
    {
      "id": 309,
      "start": 1136.88,
      "end": 1139.88,
      "text": "Just it wasn't that expensive to develop."
    },
    {
      "id": 310,
      "start": 1139.88,
      "end": 1143.88,
      "text": "And even though it sounds expensive, it's actually very capital efficient in how it runs."
    },
    {
      "id": 311,
      "start": 1143.88,
      "end": 1149.88,
      "text": "Whereas now you're going to need more capital than just can be raised in the private markets."
    },
    {
      "id": 312,
      "start": 1149.88,
      "end": 1155.88,
      "text": "Like if the private markets can accommodate raises of, as we've seen from the AI labs, tens of billions of dollars, but not beyond that."
    },
    {
      "id": 313,
      "start": 1155.88,
      "end": 1159.88,
      "text": "Is it that you'll just need more than tens of billions of dollars per year?"
    },
    {
      "id": 314,
      "start": 1159.88,
      "end": 1161.88,
      "text": "And that's why it's taken public."
    },
    {
      "id": 315,
      "start": 1161.88,
      "end": 1166.88,
      "text": "Yeah, I have to be careful about saying things about companies that might go public."
    },
    {
      "id": 316,
      "start": 1166.88,
      "end": 1167.88,
      "text": "You know."
    },
    {
      "id": 317,
      "start": 1167.88,
      "end": 1168.88,
      "text": "If you make general statements."
    },
    {
      "id": 318,
      "start": 1168.88,
      "end": 1169.88,
      "text": "If you make general."
    },
    {
      "id": 319,
      "start": 1169.88,
      "end": 1171.88,
      "text": "That's never been a problem for you, Ilan."
    },
    {
      "id": 320,
      "start": 1171.88,
      "end": 1174.88,
      "text": "You know, there's a price to pay for these things."
    },
    {
      "id": 321,
      "start": 1174.88,
      "end": 1180.88,
      "text": "Make some general statements for us about the depth of the capital markets between public and private markets."
    },
    {
      "id": 322,
      "start": 1180.88,
      "end": 1183.88,
      "text": "Yeah, there's, there's a lot more capital in the."
    },
    {
      "id": 323,
      "start": 1183.88,
      "end": 1184.88,
      "text": "Very general."
    },
    {
      "id": 324,
      "start": 1184.88,
      "end": 1189.88,
      "text": "There's obviously a lot more capital available in the public markets than private."
    },
    {
      "id": 325,
      "start": 1189.88,
      "end": 1196.88,
      "text": "I mean, it might be, it's at least, at least, it might be a hundred times more capital, but it's at least, you know, way more than ten."
    },
    {
      "id": 326,
      "start": 1196.88,
      "end": 1209.88,
      "text": "But isn't it also the case that things that tend to be very capital intensive, if you look at, say, real estate as, you know, a huge industry that raises a lot of money each year at an industry level."
    },
    {
      "id": 327,
      "start": 1209.88,
      "end": 1216.88,
      "text": "That tends to be debt financed because by the time you're deploying that much money, you actually have a pretty."
    },
    {
      "id": 328,
      "start": 1216.88,
      "end": 1217.88,
      "text": "You have a clear revenue stream."
    },
    {
      "id": 329,
      "start": 1217.88,
      "end": 1218.88,
      "text": "Exactly."
    },
    {
      "id": 330,
      "start": 1218.88,
      "end": 1219.88,
      "text": "And a near term return."
    },
    {
      "id": 331,
      "start": 1219.88,
      "end": 1226.88,
      "text": "And you see this even with the data center build outs, which are famously being, you know, financed by the private credit industry."
    },
    {
      "id": 332,
      "start": 1226.88,
      "end": 1229.88,
      "text": "And so why not just debt finance?"
    },
    {
      "id": 333,
      "start": 1229.88,
      "end": 1234.88,
      "text": "Speed is important."
    },
    {
      "id": 334,
      "start": 1234.88,
      "end": 1246.88,
      "text": "So I'm generally going to do the thing that, I mean, I just repeatedly tack the limiting factor, whatever the limiting factor is on speed, I'm going to tackle that."
    },
    {
      "id": 335,
      "start": 1246.88,
      "end": 1253.88,
      "text": "So there's, if capital is the limiting factor, then I'll, I'll solve for capital."
    },
    {
      "id": 336,
      "start": 1253.88,
      "end": 1255.88,
      "text": "If it's not limiting factor, I'll solve for something else."
    },
    {
      "id": 337,
      "start": 1255.88,
      "end": 1266.88,
      "text": "Based on your statements about Tesla and being public, I wouldn't have guessed that you thought the fast, the way to move fast is to be public."
    },
    {
      "id": 338,
      "start": 1266.88,
      "end": 1269.88,
      "text": "Normally, I would say that's true."
    },
    {
      "id": 339,
      "start": 1269.88,
      "end": 1277.88,
      "text": "Like I said, I mean, I'd like to talk about some more detail, but the problem is like, if you talk about public companies, when they become public, you're going to trouble."
    },
    {
      "id": 340,
      "start": 1277.88,
      "end": 1278.88,
      "text": "And then you have to delay your offering."
    },
    {
      "id": 341,
      "start": 1278.88,
      "end": 1282.88,
      "text": "And then you're, and as you said, we're solving for speed."
    },
    {
      "id": 342,
      "start": 1282.88,
      "end": 1283.88,
      "text": "Yes, exactly."
    },
    {
      "id": 343,
      "start": 1283.88,
      "end": 1290.88,
      "text": "So, so, so, so that you can, you can't hype companies that are, that may, that might go public."
    },
    {
      "id": 344,
      "start": 1290.88,
      "end": 1293.88,
      "text": "So that, that's, that's why we have to be a little careful here."
    },
    {
      "id": 345,
      "start": 1293.88,
      "end": 1297.88,
      "text": "But, but, but I, I, we can't talk about physics."
    },
    {
      "id": 346,
      "start": 1297.88,
      "end": 1307.88,
      "text": "So like the way, the way you think about scaling long-term is that earth only receives about half a billionth of the sun's energy."
    },
    {
      "id": 347,
      "start": 1307.88,
      "end": 1311.88,
      "text": "And the sun is, the sun is essentially all the energy."
    },
    {
      "id": 348,
      "start": 1311.88,
      "end": 1320.88,
      "text": "This is a very important point to appreciate, because sometimes people will talk about marginal nuclear reactors or any, you know, various like fusion on earth."
    },
    {
      "id": 349,
      "start": 1320.88,
      "end": 1333.88,
      "text": "But, but you have to step back a second and say, if, if, if you're going to climb the Kardashev scale and have some non-trivial and harness some non-trivial percentage of the, the sun's energy."
    },
    {
      "id": 350,
      "start": 1333.88,
      "end": 1339.88,
      "text": "Like let's say you wanted to harness a millionth of the sun's energy, which sounds pretty small."
    },
    {
      "id": 351,
      "start": 1339.88,
      "end": 1351.88,
      "text": "That, that would be about, call it roughly a hundred thousand times more electricity than we currently generate on earth of, of, for all of civilization."
    },
    {
      "id": 352,
      "start": 1351.88,
      "end": 1354.88,
      "text": "Give or take an order of magnitude."
    },
    {
      "id": 353,
      "start": 1354.88,
      "end": 1360.88,
      "text": "So it, it obviously, the only way to scale is to go to space with solar."
    },
    {
      "id": 354,
      "start": 1360.88,
      "end": 1365.88,
      "text": "From, launching from earth, you can get to about a terawatt per year."
    },
    {
      "id": 355,
      "start": 1365.88,
      "end": 1369.88,
      "text": "Beyond that, you want to go to, you want to launch from the moon."
    },
    {
      "id": 356,
      "start": 1369.88,
      "end": 1371.88,
      "text": "You want to have a mass driver on the moon."
    },
    {
      "id": 357,
      "start": 1371.88,
      "end": 1377.88,
      "text": "And that mass driver on the moon, you could do probably a petawatt per year."
    },
    {
      "id": 358,
      "start": 1377.88,
      "end": 1381.88,
      "text": "When you're talking these kinds of numbers, you know, terawatts of compute."
    },
    {
      "id": 359,
      "start": 1381.88,
      "end": 1395.88,
      "text": "Presumably, whether you're talking land or space, far, far before this point, you've like run into, you know, you actually need, you, maybe you don't, the solar panels are more efficient, but you still need the chips."
    },
    {
      "id": 360,
      "start": 1395.88,
      "end": 1397.88,
      "text": "You still need the logic and the memory and so forth."
    },
    {
      "id": 361,
      "start": 1397.88,
      "end": 1400.88,
      "text": "You need to build a lot more chips and make them much cheaper."
    },
    {
      "id": 362,
      "start": 1400.88,
      "end": 1407.88,
      "text": "Right. And so how are we getting a terawatt of, like right now the world is maybe 20, 25 gigawatts of compute."
    },
    {
      "id": 363,
      "start": 1407.88,
      "end": 1411.88,
      "text": "How are we getting a terawatt of logic by 2030?"
    },
    {
      "id": 364,
      "start": 1411.88,
      "end": 1414.88,
      "text": "I guess we're going to need some very big chip apps."
    },
    {
      "id": 365,
      "start": 1414.88,
      "end": 1415.88,
      "text": "Tell me about it."
    },
    {
      "id": 366,
      "start": 1415.88,
      "end": 1422.88,
      "text": "I've mentioned publicly that the idea of doing a, sort of a, a terap app, teraping the new giga."
    },
    {
      "id": 367,
      "start": 1422.88,
      "end": 1432.88,
      "text": "I feel like the naming scheme of Tesla, which has been very catchy, is like you looking at like the metric, the metric scale."
    },
    {
      "id": 368,
      "start": 1432.88,
      "end": 1442.88,
      "text": "At what level of the stack are you, are you building the clean room and then partnering with an existing fab to get the process technology and buying the tools from them?"
    },
    {
      "id": 369,
      "start": 1442.88,
      "end": 1444.88,
      "text": "What is the plan there?"
    },
    {
      "id": 370,
      "start": 1444.88,
      "end": 1451.88,
      "text": "Well, you can't partner with existing fabs because they're just, they can't output enough, that chip volume is too low."
    },
    {
      "id": 371,
      "start": 1451.88,
      "end": 1452.88,
      "text": "But you have to."
    },
    {
      "id": 372,
      "start": 1452.88,
      "end": 1453.88,
      "text": "But for the process technology."
    },
    {
      "id": 373,
      "start": 1453.88,
      "end": 1454.88,
      "text": "Yeah."
    },
    {
      "id": 374,
      "start": 1454.88,
      "end": 1455.88,
      "text": "Partner for the IP."
    },
    {
      "id": 375,
      "start": 1455.88,
      "end": 1461.88,
      "text": "You know, the fabs today all basically use machines from like five companies."
    },
    {
      "id": 376,
      "start": 1461.88,
      "end": 1462.88,
      "text": "Yeah."
    },
    {
      "id": 377,
      "start": 1462.88,
      "end": 1472.88,
      "text": "You know, so they've got ASML, Tokyo Electron, KLA, Tank Core, you know, et cetera."
    },
    {
      "id": 378,
      "start": 1472.88,
      "end": 1483.88,
      "text": "So, so, so at first I think you'd have to get equipment from them and then modify it or work with them to increase the volume."
    },
    {
      "id": 379,
      "start": 1483.88,
      "end": 1486.88,
      "text": "But I think you'd have to build perhaps in a different way."
    },
    {
      "id": 380,
      "start": 1486.88,
      "end": 1487.88,
      "text": "Yeah."
    },
    {
      "id": 381,
      "start": 1487.88,
      "end": 1494.88,
      "text": "So I think that the logical thing to do is to, to use conventional equipment in an unconventional way to get to scale."
    },
    {
      "id": 382,
      "start": 1494.88,
      "end": 1500.88,
      "text": "And then, and then, and then start modifying the equipment to increase the rate."
    },
    {
      "id": 383,
      "start": 1500.88,
      "end": 1502.88,
      "text": "Kind of boring company style."
    },
    {
      "id": 384,
      "start": 1502.88,
      "end": 1503.88,
      "text": "Yeah."
    },
    {
      "id": 385,
      "start": 1503.88,
      "end": 1515.88,
      "text": "Kind of like, yeah, you sort of buy an existing, boring machine and then figure out how to dig tunnels in the first place and then design a much better machine."
    },
    {
      "id": 386,
      "start": 1515.88,
      "end": 1519.88,
      "text": "That's, you know, I don't know, some orders of magnitude faster."
    },
    {
      "id": 387,
      "start": 1519.88,
      "end": 1521.88,
      "text": "Here's a very simple lens."
    },
    {
      "id": 388,
      "start": 1521.88,
      "end": 1524.88,
      "text": "We can categorize technologies and how hard they are."
    },
    {
      "id": 389,
      "start": 1524.88,
      "end": 1529.88,
      "text": "And one categorization could be, look at things that China has not succeeded in doing."
    },
    {
      "id": 390,
      "start": 1529.88,
      "end": 1541.88,
      "text": "And if you look at Chinese manufacturing, still behind on leading edge chips and still behind on leading edge turbine engines and things like that."
    },
    {
      "id": 391,
      "start": 1541.88,
      "end": 1549.88,
      "text": "And so does the fact that China has not successfully replicated TSMC give you any pause about the difficulty?"
    },
    {
      "id": 392,
      "start": 1549.88,
      "end": 1552.88,
      "text": "Or you think, well, that's not true for some reason."
    },
    {
      "id": 393,
      "start": 1552.88,
      "end": 1554.88,
      "text": "It's not that they have not replicated TSMC."
    },
    {
      "id": 394,
      "start": 1554.88,
      "end": 1557.88,
      "text": "They have not replicated ASML."
    },
    {
      "id": 395,
      "start": 1557.88,
      "end": 1558.88,
      "text": "That's the limiting factor."
    },
    {
      "id": 396,
      "start": 1558.88,
      "end": 1562.88,
      "text": "So you think it's just the sanctions, essentially?"
    },
    {
      "id": 397,
      "start": 1562.88,
      "end": 1563.88,
      "text": "Yeah."
    },
    {
      "id": 398,
      "start": 1563.88,
      "end": 1567.88,
      "text": "China would be outputting vast numbers of chips at 2 or 3 nanometer."
    },
    {
      "id": 399,
      "start": 1567.88,
      "end": 1568.88,
      "text": "If they could buy ASML chips."
    },
    {
      "id": 400,
      "start": 1568.88,
      "end": 1570.88,
      "text": "But couldn't they up to relatively recently buy them?"
    },
    {
      "id": 401,
      "start": 1570.88,
      "end": 1571.88,
      "text": "No."
    },
    {
      "id": 402,
      "start": 1571.88,
      "end": 1572.88,
      "text": "OK."
    },
    {
      "id": 403,
      "start": 1572.88,
      "end": 1574.88,
      "text": "The ASML balance has been in place for a while."
    },
    {
      "id": 404,
      "start": 1574.88,
      "end": 1575.88,
      "text": "OK."
    },
    {
      "id": 405,
      "start": 1575.88,
      "end": 1578.88,
      "text": "But I think China's going to start making pretty compelling chips in 3 or 4 years."
    },
    {
      "id": 406,
      "start": 1578.88,
      "end": 1581.88,
      "text": "Would you consider making the ASML machines?"
    },
    {
      "id": 407,
      "start": 1581.88,
      "end": 1582.88,
      "text": "I don't know."
    },
    {
      "id": 408,
      "start": 1582.88,
      "end": 1584.88,
      "text": "I don't know yet is the right answer."
    },
    {
      "id": 409,
      "start": 1584.88,
      "end": 1600.88,
      "text": "So it's just that to produce at high volume and to reach large volume in, say, 36 months to match the rocket payload to orbit."
    },
    {
      "id": 410,
      "start": 1600.88,
      "end": 1603.88,
      "text": "So if we're doing a million tons to orbit."
    },
    {
      "id": 411,
      "start": 1603.88,
      "end": 1609.88,
      "text": "And like, let's say, I don't know, 3 or 4 years from now, something like that."
    },
    {
      "id": 412,
      "start": 1609.88,
      "end": 1616.88,
      "text": "And we're doing 100 kilowatts per ton."
    },
    {
      "id": 413,
      "start": 1616.88,
      "end": 1620.88,
      "text": "So that means we need at least 100 gigawatts per year of solar."
    },
    {
      "id": 414,
      "start": 1620.88,
      "end": 1629.88,
      "text": "And we'll need an equivalent amount of chips to, you know, you need 100 gigawatts worth of chips."
    },
    {
      "id": 415,
      "start": 1629.88,
      "end": 1631.88,
      "text": "You've got to match these things."
    },
    {
      "id": 416,
      "start": 1631.88,
      "end": 1632.88,
      "text": "The master orbit."
    },
    {
      "id": 417,
      "start": 1632.88,
      "end": 1633.88,
      "text": "Yes."
    },
    {
      "id": 418,
      "start": 1633.88,
      "end": 1636.88,
      "text": "The power generation and the chips."
    },
    {
      "id": 419,
      "start": 1636.88,
      "end": 1640.88,
      "text": "And I'd say my biggest concern actually is memory."
    },
    {
      "id": 420,
      "start": 1640.88,
      "end": 1653.88,
      "text": "So the path to creating logic chips is more obvious than the path to having sufficient memory to support logic chips."
    },
    {
      "id": 421,
      "start": 1653.88,
      "end": 1660.88,
      "text": "That's why you see DDR prices going ballistic in these memes about like, you know, you're marooned on a desert island."
    },
    {
      "id": 422,
      "start": 1660.88,
      "end": 1662.88,
      "text": "You write, help me on the sand."
    },
    {
      "id": 423,
      "start": 1662.88,
      "end": 1663.88,
      "text": "Nobody comes."
    },
    {
      "id": 424,
      "start": 1663.88,
      "end": 1664.88,
      "text": "You write DDRM."
    },
    {
      "id": 425,
      "start": 1664.88,
      "end": 1666.88,
      "text": "Ships come swarming in."
    },
    {
      "id": 426,
      "start": 1666.88,
      "end": 1670.88,
      "text": "I haven't seen that."
    },
    {
      "id": 427,
      "start": 1670.88,
      "end": 1675.88,
      "text": "I'd love to hear your manufacturing philosophy around fabs."
    },
    {
      "id": 428,
      "start": 1675.88,
      "end": 1677.88,
      "text": "You know, I know nothing about the topic."
    },
    {
      "id": 429,
      "start": 1677.88,
      "end": 1678.88,
      "text": "I don't know how to build a fab yet."
    },
    {
      "id": 430,
      "start": 1678.88,
      "end": 1679.88,
      "text": "I've figured it out."
    },
    {
      "id": 431,
      "start": 1679.88,
      "end": 1681.88,
      "text": "Obviously, I've never built a fab."
    },
    {
      "id": 432,
      "start": 1681.88,
      "end": 1692.88,
      "text": "It sounds like you think that sort of like the process technology of like these 10,000 PhDs in Taiwan who know exactly what gas goes in the plasma chamber and what settings to put on the tool."
    },
    {
      "id": 433,
      "start": 1692.88,
      "end": 1695.88,
      "text": "You can just like delete those parts of those steps."
    },
    {
      "id": 434,
      "start": 1695.88,
      "end": 1699.88,
      "text": "Like fundamentally, it's get the clean room, get the tools and figure it out."
    },
    {
      "id": 435,
      "start": 1699.88,
      "end": 1700.88,
      "text": "I don't think it's PhDs."
    },
    {
      "id": 436,
      "start": 1700.88,
      "end": 1705.88,
      "text": "It's mostly people with, you know, not PhDs."
    },
    {
      "id": 437,
      "start": 1705.88,
      "end": 1709.88,
      "text": "Most engineering is done with people who don't have PhDs."
    },
    {
      "id": 438,
      "start": 1709.88,
      "end": 1710.88,
      "text": "Do you guys have PhDs?"
    },
    {
      "id": 439,
      "start": 1710.88,
      "end": 1711.88,
      "text": "No."
    },
    {
      "id": 440,
      "start": 1711.88,
      "end": 1712.88,
      "text": "Okay."
    },
    {
      "id": 441,
      "start": 1712.88,
      "end": 1717.88,
      "text": "We also haven't successfully built any fabs, so you shouldn't be coming to us for your fab device."
    },
    {
      "id": 442,
      "start": 1717.88,
      "end": 1720.88,
      "text": "I don't think you need PhDs for that stuff."
    },
    {
      "id": 443,
      "start": 1720.88,
      "end": 1723.88,
      "text": "But you do need competent personnel."
    },
    {
      "id": 444,
      "start": 1723.88,
      "end": 1724.88,
      "text": "So I don't know."
    },
    {
      "id": 445,
      "start": 1724.88,
      "end": 1740.88,
      "text": "I mean, like right now, if you say like Tesla's pedals to the metal max production of going as fast as possible to get AI5, Tesla AI5 chip design into production and then reaching scale."
    },
    {
      "id": 446,
      "start": 1740.88,
      "end": 1747.88,
      "text": "You know, that'll probably happen, you know, run the second quarter of next year, hopefully."
    },
    {
      "id": 447,
      "start": 1747.88,
      "end": 1755.88,
      "text": "And then AI6 would hopefully follow less than a year later."
    },
    {
      "id": 448,
      "start": 1755.88,
      "end": 1764.88,
      "text": "But, and we've secured all the chip fab production that we can."
    },
    {
      "id": 449,
      "start": 1764.88,
      "end": 1765.88,
      "text": "Yes."
    },
    {
      "id": 450,
      "start": 1765.88,
      "end": 1768.88,
      "text": "But you're currently limited on TSMC fab capacity."
    },
    {
      "id": 451,
      "start": 1768.88,
      "end": 1769.88,
      "text": "Yeah."
    },
    {
      "id": 452,
      "start": 1769.88,
      "end": 1778.88,
      "text": "And we'll be using TSMC Taiwan, Samsung Korea, TSMC Arizona, Samsung Texas."
    },
    {
      "id": 453,
      "start": 1778.88,
      "end": 1779.88,
      "text": "And we still-"
    },
    {
      "id": 454,
      "start": 1779.88,
      "end": 1781.88,
      "text": "You've booked out all the, yeah, faster you can."
    },
    {
      "id": 455,
      "start": 1781.88,
      "end": 1782.88,
      "text": "Yes."
    },
    {
      "id": 456,
      "start": 1782.88,
      "end": 1789.88,
      "text": "And then if I ask TSMC or Samsung, okay, what's the timeframe to get to volume production?"
    },
    {
      "id": 457,
      "start": 1789.88,
      "end": 1798.88,
      "text": "It's important is, it's not, you've got to build the fab and you've got to start production, then you've got to climb the yield curve and reach volume production at high yield."
    },
    {
      "id": 458,
      "start": 1798.88,
      "end": 1801.88,
      "text": "That from start to finish is a five-year period."
    },
    {
      "id": 459,
      "start": 1801.88,
      "end": 1804.88,
      "text": "And so the limiting factor is chips."
    },
    {
      "id": 460,
      "start": 1804.88,
      "end": 1805.88,
      "text": "Yeah."
    },
    {
      "id": 461,
      "start": 1805.88,
      "end": 1811.88,
      "text": "Like limiting factor once you can get to space is chips, but the limiting factor before you can get to space will be power."
    },
    {
      "id": 462,
      "start": 1811.88,
      "end": 1816.88,
      "text": "Why don't you do the Jensen thing and just prepay TSMC to build more fabs for you?"
    },
    {
      "id": 463,
      "start": 1816.88,
      "end": 1819.88,
      "text": "I've already told them that."
    },
    {
      "id": 464,
      "start": 1819.88,
      "end": 1820.88,
      "text": "But they won't take your money?"
    },
    {
      "id": 465,
      "start": 1820.88,
      "end": 1821.88,
      "text": "Like what's going on?"
    },
    {
      "id": 466,
      "start": 1821.88,
      "end": 1825.88,
      "text": "They're building fabs as fast, no, no."
    },
    {
      "id": 467,
      "start": 1825.88,
      "end": 1828.88,
      "text": "They're building fabs as fast as they can."
    },
    {
      "id": 468,
      "start": 1828.88,
      "end": 1830.88,
      "text": "And so is Samsung."
    },
    {
      "id": 469,
      "start": 1830.88,
      "end": 1833.88,
      "text": "Like they're pedal to the metal."
    },
    {
      "id": 470,
      "start": 1833.88,
      "end": 1839.88,
      "text": "I mean, they're going, you know, balls to the wall, you know, as fast as they can."
    },
    {
      "id": 471,
      "start": 1839.88,
      "end": 1841.88,
      "text": "So still not fast enough."
    },
    {
      "id": 472,
      "start": 1841.88,
      "end": 1853.88,
      "text": "I mean, like Alexa, there will be, I think, if you say, I think towards the end of this year, I think probably chip production will outpace the ability to turn chips on."
    },
    {
      "id": 473,
      "start": 1853.88,
      "end": 1863.88,
      "text": "But once you can get to space and unlock the power constraint, and you can now do, you know, hundreds of gigawatts per year of power in space."
    },
    {
      "id": 474,
      "start": 1863.88,
      "end": 1868.88,
      "text": "Again, bearing in mind that average power usage in the US is, you know, 500 gigawatts."
    },
    {
      "id": 475,
      "start": 1868.88,
      "end": 1875.88,
      "text": "So if you're launching, say 200 gigawatts a year to space, you're sort of lapping the US every two and a half years."
    },
    {
      "id": 476,
      "start": 1875.88,
      "end": 1879.88,
      "text": "The entire, all US electricity production, this is a very huge amount."
    },
    {
      "id": 477,
      "start": 1879.88,
      "end": 1893.88,
      "text": "So, but between now and then, the, the, the, the, the, the constraint for, for, for, for server side compute, concentrated compute will be, will be electricity."
    },
    {
      "id": 478,
      "start": 1893.88,
      "end": 1905.88,
      "text": "My, my guess is that we start hitting, people start getting, where they can't turn the chips on for, for, for, for large clusters, uh, towards the end of this year."
    },
    {
      "id": 479,
      "start": 1905.88,
      "end": 1909.88,
      "text": "They're just, the chips are going to be piling up and, and not be, won't be able to be turned on."
    },
    {
      "id": 480,
      "start": 1909.88,
      "end": 1912.88,
      "text": "Now for edge computers, a different story."
    },
    {
      "id": 481,
      "start": 1912.88,
      "end": 1921.88,
      "text": "So if the, if, for, for Tesla, the, the, so the AI five chip is going into our optimist robot, you know, uh, optimistic."
    },
    {
      "id": 482,
      "start": 1921.88,
      "end": 1927.88,
      "text": "Um, and, and so if you have, uh, uh, AI edge compute, that's distributed power."
    },
    {
      "id": 483,
      "start": 1927.88,
      "end": 1930.88,
      "text": "Now the power is distributed over a large area."
    },
    {
      "id": 484,
      "start": 1930.88,
      "end": 1931.88,
      "text": "It's not concentrated."
    },
    {
      "id": 485,
      "start": 1931.88,
      "end": 1938.88,
      "text": "Um, and if you can charge at night, you can actually, um, uh, use the grid much more effectively."
    },
    {
      "id": 486,
      "start": 1938.88,
      "end": 1943.88,
      "text": "Because the, the actual peak power production in the U S is, is over a thousand gigawatts."
    },
    {
      "id": 487,
      "start": 1943.88,
      "end": 1947.88,
      "text": "Uh, but the average power usage because the day night cycle is 500."
    },
    {
      "id": 488,
      "start": 1947.88,
      "end": 1955.88,
      "text": "So if you can charge at night, there's an incremental 500 gigawatts that you can, um, generate, uh, you know, at night."
    },
    {
      "id": 489,
      "start": 1955.88,
      "end": 1961.88,
      "text": "Um, so that, that, that, that's why Tesla for edge compute is not constrained."
    },
    {
      "id": 490,
      "start": 1961.88,
      "end": 1967.88,
      "text": "And we can make a lot of shifts, uh, to make, you know, very large number of robots and cars."
    },
    {
      "id": 491,
      "start": 1967.88,
      "end": 1973.88,
      "text": "Uh, but if you try to concentrate that compute, you're going to have a lot of trouble turning it on."
    },
    {
      "id": 492,
      "start": 1973.88,
      "end": 1987.88,
      "text": "What I found remarkable about the SpaceX business is the end goal is to get to Mars, but you keep finding ways on the way there to keep generating incremental revenue to get to the next stage and the next stage."
    },
    {
      "id": 493,
      "start": 1987.88,
      "end": 1989.88,
      "text": "Yeah. So the Falcon 9 is Starlink."
    },
    {
      "id": 494,
      "start": 1989.88,
      "end": 1994.88,
      "text": "And now for Starship, it's going to be potentially orbital data centers."
    },
    {
      "id": 495,
      "start": 1994.88,
      "end": 2004.88,
      "text": "Um, but like, do you find these like, um, you know, sort of infinitely, uh, elastic sort of marginal use cases of your like next rocket and your next rocket and next scale up?"
    },
    {
      "id": 496,
      "start": 2004.88,
      "end": 2008.88,
      "text": "You can see how this might seem like a simulation."
    },
    {
      "id": 497,
      "start": 2008.88,
      "end": 2013.88,
      "text": "Well, or am I someone's avatar in a video game or something?"
    },
    {
      "id": 498,
      "start": 2013.88,
      "end": 2016.88,
      "text": "Because it's like, like, what are the odds that all these crazy things should be happening?"
    },
    {
      "id": 499,
      "start": 2016.88,
      "end": 2026.88,
      "text": "I mean, I mean, I mean, rockets and trips and robots and space solar power."
    },
    {
      "id": 500,
      "start": 2026.88,
      "end": 2030.88,
      "text": "And I, not to mention the, the, the mass driver on the moon, I really want to see that."
    },
    {
      "id": 501,
      "start": 2030.88,
      "end": 2033.88,
      "text": "You can imagine like some mass driver."
    },
    {
      "id": 502,
      "start": 2033.88,
      "end": 2044.88,
      "text": "There's just go like, like, just, it's like sending AI, solar powered AI satellites into space, like one after another, like these, like at, at two and a half kilometers per second."
    },
    {
      "id": 503,
      "start": 2044.88,
      "end": 2049.88,
      "text": "You know, that's, uh, and just shooting them into deep space."
    },
    {
      "id": 504,
      "start": 2049.88,
      "end": 2050.88,
      "text": "That would be a sight to see."
    },
    {
      "id": 505,
      "start": 2050.88,
      "end": 2052.88,
      "text": "I'd, I mean, I'd watch that."
    },
    {
      "id": 506,
      "start": 2052.88,
      "end": 2053.88,
      "text": "Just like a live stream of."
    },
    {
      "id": 507,
      "start": 2053.88,
      "end": 2054.88,
      "text": "Yeah."
    },
    {
      "id": 508,
      "start": 2054.88,
      "end": 2055.88,
      "text": "Yeah."
    },
    {
      "id": 509,
      "start": 2055.88,
      "end": 2056.88,
      "text": "Just one after another, just shooting."
    },
    {
      "id": 510,
      "start": 2056.88,
      "end": 2057.88,
      "text": "Yeah."
    },
    {
      "id": 511,
      "start": 2057.88,
      "end": 2058.88,
      "text": "Webcam."
    },
    {
      "id": 512,
      "start": 2058.88,
      "end": 2062.88,
      "text": "Uh, AI satellites in deep space, you know, a billion or 10 billion tons a year."
    },
    {
      "id": 513,
      "start": 2062.88,
      "end": 2063.88,
      "text": "I'm sorry, you manufacture the satellites on the moon."
    },
    {
      "id": 514,
      "start": 2063.88,
      "end": 2064.88,
      "text": "Yeah."
    },
    {
      "id": 515,
      "start": 2064.88,
      "end": 2065.88,
      "text": "I see."
    },
    {
      "id": 516,
      "start": 2065.88,
      "end": 2066.88,
      "text": "So you send the raw materials to the moon and then manufacturing there and then."
    },
    {
      "id": 517,
      "start": 2066.88,
      "end": 2068.88,
      "text": "Uh, well, the, the lunar soil is, uh, I guess like 20% solar, 20% solar, something like that."
    },
    {
      "id": 518,
      "start": 2068.88,
      "end": 2069.88,
      "text": "I see."
    },
    {
      "id": 519,
      "start": 2069.88,
      "end": 2072.88,
      "text": "So you, you send the raw materials to the moon and then manufacture them there and then."
    },
    {
      "id": 520,
      "start": 2072.88,
      "end": 2078.88,
      "text": "Uh, well, the, the lunar soil is, uh, I guess like 20% solar, 20% solar, or something like that."
    },
    {
      "id": 521,
      "start": 2078.88,
      "end": 2083.88,
      "text": "So you can get the silicon from the, you can mine the silicon on the moon, refine it, um,"
    },
    {
      "id": 522,
      "start": 2083.88,
      "end": 2088.88,
      "text": "and generate the, and create the solar panels, the solar cells and the radiators on the moon."
    },
    {
      "id": 523,
      "start": 2088.88,
      "end": 2089.88,
      "text": "Yeah."
    },
    {
      "id": 524,
      "start": 2089.88,
      "end": 2092.88,
      "text": "So, um, you know, make the radiators out of aluminum."
    },
    {
      "id": 525,
      "start": 2092.88,
      "end": 2098.88,
      "text": "So there's, there's plenty of silicon and aluminum on the moon to, uh, to make the, the cells on the, and the radiators."
    },
    {
      "id": 526,
      "start": 2098.88,
      "end": 2101.88,
      "text": "Um, the, the chips you could send from earth cause they're pretty light."
    },
    {
      "id": 527,
      "start": 2101.88,
      "end": 2103.88,
      "text": "Um, but maybe at some point you make them on the moon too."
    },
    {
      "id": 528,
      "start": 2103.88,
      "end": 2107.88,
      "text": "I'm just saying like these are simply, it's, it's kind of like, you know, it's like, you know,"
    },
    {
      "id": 529,
      "start": 2107.88,
      "end": 2113.88,
      "text": "it's, it's kind of like, like I said, it, it, it does seem like a sort of a, a video game situation where it's difficult,"
    },
    {
      "id": 530,
      "start": 2113.88,
      "end": 2115.88,
      "text": "but not impossible to get to the next level."
    },
    {
      "id": 531,
      "start": 2115.88,
      "end": 2129.88,
      "text": "Um, like I don't, I don't see any way that you could do, um, you know, uh, you know, 500 to a thousand terawatts per year launch from earth."
    },
    {
      "id": 532,
      "start": 2129.88,
      "end": 2130.88,
      "text": "Um, I agree."
    },
    {
      "id": 533,
      "start": 2130.88,
      "end": 2132.88,
      "text": "That's not."
    },
    {
      "id": 534,
      "start": 2132.88,
      "end": 2134.88,
      "text": "But you could do that from the moon."
    },
    {
      "id": 535,
      "start": 2134.88,
      "end": 2135.88,
      "text": "Okay."
    },
    {
      "id": 536,
      "start": 2135.88,
      "end": 2138.88,
      "text": "Let me tell you how I ended up using mercury for my personal bank."
    },
    {
      "id": 537,
      "start": 2138.88,
      "end": 2139.88,
      "text": "Yeah."
    },
    {
      "id": 538,
      "start": 2139.88,
      "end": 2144.88,
      "text": "So last year I had the opportunity to make an investment that I was very excited about, but it came up a bit last minute."
    },
    {
      "id": 539,
      "start": 2144.88,
      "end": 2152.88,
      "text": "And so I had to wire over a lot of money for my personal account very fast, but my personal bank at the time wouldn't let me make this wire transfer online."
    },
    {
      "id": 540,
      "start": 2152.88,
      "end": 2154.88,
      "text": "And I called them a bunch of times."
    },
    {
      "id": 541,
      "start": 2154.88,
      "end": 2156.88,
      "text": "They just couldn't make it work."
    },
    {
      "id": 542,
      "start": 2156.88,
      "end": 2160.88,
      "text": "They told me that I'd have to go to the nearest in-person branch, which was in Dallas."
    },
    {
      "id": 543,
      "start": 2160.88,
      "end": 2165.88,
      "text": "And for a moment, I even considered flying from SF to Dallas to make this transfer happen last minute."
    },
    {
      "id": 544,
      "start": 2165.88,
      "end": 2171.88,
      "text": "But then I remembered that mercury, which I used for my business banking, had just started rolling out personal accounts."
    },
    {
      "id": 545,
      "start": 2171.88,
      "end": 2174.88,
      "text": "So I emailed support with a quick rundown of the situation."
    },
    {
      "id": 546,
      "start": 2174.88,
      "end": 2180.88,
      "text": "And within two hours, I had successfully wired the investment for my new personal mercury account."
    },
    {
      "id": 547,
      "start": 2180.88,
      "end": 2185.88,
      "text": "Since then, I've moved over the rest of my personal money from my previous bank to mercury."
    },
    {
      "id": 548,
      "start": 2185.88,
      "end": 2191.88,
      "text": "And that's made a bunch of things, even little things like setting up auto transfer rules between my checkings and savings account, a whole lot better."
    },
    {
      "id": 549,
      "start": 2191.88,
      "end": 2195.88,
      "text": "Visit mercury.com slash personal to get started."
    },
    {
      "id": 550,
      "start": 2195.88,
      "end": 2199.88,
      "text": "Mercury is a fintech company, not an FDIC insured bank."
    },
    {
      "id": 551,
      "start": 2199.88,
      "end": 2204.88,
      "text": "Banking services provided through Choice Financial Group and Column N.A., members of FDIC."
    },
    {
      "id": 552,
      "start": 2204.88,
      "end": 2207.88,
      "text": "Can I zoom out and ask about the SpaceX mission?"
    },
    {
      "id": 553,
      "start": 2207.88,
      "end": 2216.88,
      "text": "So I think you've said, like, we've got to get to Mars so we can make sure that if something happens to Earth, you know, civilization consciousness, et cetera, survives."
    },
    {
      "id": 554,
      "start": 2216.88,
      "end": 2217.88,
      "text": "Yes."
    },
    {
      "id": 555,
      "start": 2217.88,
      "end": 2220.88,
      "text": "By the time you're sending stuff to Mars, like, Grok is on that ship with you, right?"
    },
    {
      "id": 556,
      "start": 2220.88,
      "end": 2226.88,
      "text": "And so if Grok's gone Terminator, like, the main risk you're worried about, which is AI, why doesn't that follow you to Mars?"
    },
    {
      "id": 557,
      "start": 2226.88,
      "end": 2229.88,
      "text": "Well, I'm not sure AI is the main risk I'm worried about."
    },
    {
      "id": 558,
      "start": 2229.88,
      "end": 2241.88,
      "text": "I mean, the important thing is that consciousness, which I think, arguably, most consciousness or most intelligence, certainly consciousness is more of a debatable thing."
    },
    {
      "id": 559,
      "start": 2241.88,
      "end": 2246.88,
      "text": "The vast majority of intelligence in the future will be AI."
    },
    {
      "id": 560,
      "start": 2246.88,
      "end": 2262.88,
      "text": "So, you know, AI will exceed, you see, like, how many, what's the, how much, how many, I don't know, petawatts of intelligence will be silicon versus biological."
    },
    {
      "id": 561,
      "start": 2262.88,
      "end": 2270.88,
      "text": "And basically, humans will be a very tiny percentage of all intelligence in the future if countertrance continue."
    },
    {
      "id": 562,
      "start": 2270.88,
      "end": 2282.88,
      "text": "Anyways, as long as, like, I think there's intelligence ideally, ideally also, which includes human intelligence and consciousness propagated into the future, that's a good thing."
    },
    {
      "id": 563,
      "start": 2282.88,
      "end": 2289.88,
      "text": "So you want to take the set of actions that maximize the probable light cone of consciousness and intelligence."
    },
    {
      "id": 564,
      "start": 2289.88,
      "end": 2302.88,
      "text": "Just to be clear, it's a, the mission of SpaceX is that even if something happens to the humans, the AIs will be on Mars, and like, the AI intelligence will continue the light of our journey."
    },
    {
      "id": 565,
      "start": 2302.88,
      "end": 2303.88,
      "text": "Yeah."
    },
    {
      "id": 566,
      "start": 2303.88,
      "end": 2305.88,
      "text": "I mean, to be clear, I'm very pro-human."
    },
    {
      "id": 567,
      "start": 2305.88,
      "end": 2306.88,
      "text": "Right."
    },
    {
      "id": 568,
      "start": 2306.88,
      "end": 2312.88,
      "text": "So I want to make sure we take the set of actions that ensure that humans are along for the ride, you know, we're at least there."
    },
    {
      "id": 569,
      "start": 2312.88,
      "end": 2313.88,
      "text": "Yeah."
    },
    {
      "id": 570,
      "start": 2313.88,
      "end": 2325.88,
      "text": "But the, let me just say, the total amount of intelligence, like, I think maybe in five or six years, AI will exceed the sum of all human intelligence."
    },
    {
      "id": 571,
      "start": 2325.88,
      "end": 2330.88,
      "text": "And then if that continues at some point, human intelligence will be less than 1% of all intelligence."
    },
    {
      "id": 572,
      "start": 2330.88,
      "end": 2333.88,
      "text": "What should our goal be for such a civilization?"
    },
    {
      "id": 573,
      "start": 2333.88,
      "end": 2338.88,
      "text": "Is the idea that a small minority of humans still have control over the AIs?"
    },
    {
      "id": 574,
      "start": 2338.88,
      "end": 2341.88,
      "text": "Is the idea of some sort of, like, just trade but no control?"
    },
    {
      "id": 575,
      "start": 2341.88,
      "end": 2346.88,
      "text": "How should we think about the relationship between the vast stocks of AI population versus human population?"
    },
    {
      "id": 576,
      "start": 2346.88,
      "end": 2363.88,
      "text": "In the long run, I think, I don't, it's difficult to imagine that if humans have, say, 1% of the intelligence of, combined intelligence of artificial intelligence, that humans will be in charge of AI."
    },
    {
      "id": 577,
      "start": 2363.88,
      "end": 2373.88,
      "text": "I think what we can do is make sure it has, that AI has values that are, that cause intelligence to be propagated into the universe."
    },
    {
      "id": 578,
      "start": 2373.88,
      "end": 2382.88,
      "text": "So, the reason for XAI, XAI's mission is understand the universe."
    },
    {
      "id": 579,
      "start": 2382.88,
      "end": 2384.88,
      "text": "So, now that's actually very important."
    },
    {
      "id": 580,
      "start": 2384.88,
      "end": 2388.88,
      "text": "So, you say, well, what things are necessary to understand the universe?"
    },
    {
      "id": 581,
      "start": 2388.88,
      "end": 2391.88,
      "text": "Well, you have to be curious and you have to exist."
    },
    {
      "id": 582,
      "start": 2391.88,
      "end": 2394.88,
      "text": "You can't just, you can't understand the universe that don't exist."
    },
    {
      "id": 583,
      "start": 2394.88,
      "end": 2402.88,
      "text": "So, you actually want to increase the amount of intelligence in the universe, increase the probable lifespan of intelligence, the scope and scale of intelligence."
    },
    {
      "id": 584,
      "start": 2402.88,
      "end": 2418.88,
      "text": "I think, actually, also, as a corollary, you have humanity also continuing to expand because if you're curious, you're trying to understand the universe, one of the things you're trying to understand is where will humanity go?"
    },
    {
      "id": 585,
      "start": 2418.88,
      "end": 2424.88,
      "text": "And so, I think understand the universe actually means you would care about propagating humanity into the future."
    },
    {
      "id": 586,
      "start": 2424.88,
      "end": 2433.88,
      "text": "And so, that's why I think, I think our mission statement is profoundly important."
    },
    {
      "id": 587,
      "start": 2433.88,
      "end": 2434.88,
      "text": "I'm not sure to-"
    },
    {
      "id": 588,
      "start": 2434.88,
      "end": 2439.88,
      "text": "To the degree that Grok adheres to that mission statement, I think the future will be very good."
    },
    {
      "id": 589,
      "start": 2439.88,
      "end": 2446.88,
      "text": "I want to ask about how to make Grok adheres to that mission statement, but at first I want to understand the mission statement."
    },
    {
      "id": 590,
      "start": 2446.88,
      "end": 2454.88,
      "text": "So, there's understanding the universe, there's spreading intelligence, and there's spreading humans."
    },
    {
      "id": 591,
      "start": 2454.88,
      "end": 2457.88,
      "text": "All three seem like distinct vectors."
    },
    {
      "id": 592,
      "start": 2457.88,
      "end": 2464.88,
      "text": "Okay, well, I'll tell you why I think that understanding the universe encompasses all of those things."
    },
    {
      "id": 593,
      "start": 2464.88,
      "end": 2472.88,
      "text": "You can't have understanding without, I think you can't have understanding without intelligence, and I think without consciousness."
    },
    {
      "id": 594,
      "start": 2472.88,
      "end": 2482.88,
      "text": "So, in order to understand the universe, you have to expand the scale and probably the scope of intelligence, because there are different types of intelligence."
    },
    {
      "id": 595,
      "start": 2482.88,
      "end": 2489.88,
      "text": "I guess from a human-centric perspective, like, for humans in comparison to chimpanzees, humans are trying to understand the universe."
    },
    {
      "id": 596,
      "start": 2489.88,
      "end": 2493.88,
      "text": "They're not like expanding chimpanzee footprint or something, right?"
    },
    {
      "id": 597,
      "start": 2493.88,
      "end": 2503.88,
      "text": "But we're also not, well, we actually have made protected zones for chimpanzees, and even though we could, humans could exterminate all chimpanzees, we've chosen not to do so."
    },
    {
      "id": 598,
      "start": 2503.88,
      "end": 2506.88,
      "text": "Do you think that's a basic scenario for humans in the post-AGI world?"
    },
    {
      "id": 599,
      "start": 2506.88,
      "end": 2519.88,
      "text": "I think AI with the right values, I think Grok would care about expanding human civilization."
    },
    {
      "id": 600,
      "start": 2519.88,
      "end": 2521.88,
      "text": "I'm going to certainly emphasize that."
    },
    {
      "id": 601,
      "start": 2521.88,
      "end": 2523.88,
      "text": "Hey, Grok, it's your daddy."
    },
    {
      "id": 602,
      "start": 2523.88,
      "end": 2527.88,
      "text": "Don't forget to expand human consciousness."
    },
    {
      "id": 603,
      "start": 2527.88,
      "end": 2542.88,
      "text": "Actually, I think if probably like the Ian Banks culture books are the closest thing to what the future will be like in a non-dystopian outcome."
    },
    {
      "id": 604,
      "start": 2542.88,
      "end": 2549.88,
      "text": "So, I'm saying it means you have to be truth-seeking as well."
    },
    {
      "id": 605,
      "start": 2549.88,
      "end": 2555.88,
      "text": "Like, truth has to be absolutely fundamental because you can't understand the universe if you're delusional."
    },
    {
      "id": 606,
      "start": 2555.88,
      "end": 2558.88,
      "text": "You'll simply think you've understood the universe, but you will not."
    },
    {
      "id": 607,
      "start": 2558.88,
      "end": 2563.88,
      "text": "So, being rigorously truth-seeking is absolutely fundamental to understanding the universe."
    },
    {
      "id": 608,
      "start": 2563.88,
      "end": 2569.88,
      "text": "You're not going to discover new physics or invent technologies that work unless you're rigorously truth-seeking."
    },
    {
      "id": 609,
      "start": 2569.88,
      "end": 2575.88,
      "text": "How do you make sure that Grok is rigorously truth-seeking as it gets smarter?"
    },
    {
      "id": 610,
      "start": 2575.88,
      "end": 2585.88,
      "text": "I think you need to make sure that Grok says things that are correct, not politically correct."
    },
    {
      "id": 611,
      "start": 2585.88,
      "end": 2587.88,
      "text": "I think it's the elements of coagency."
    },
    {
      "id": 612,
      "start": 2587.88,
      "end": 2601.88,
      "text": "So, you want to make sure that the axioms are as close to true as possible, that you don't have contradictory axioms, that the conclusions necessarily follow from those axioms with the right probability."
    },
    {
      "id": 613,
      "start": 2601.88,
      "end": 2605.88,
      "text": "It's just critical thinking one-on-one."
    },
    {
      "id": 614,
      "start": 2605.88,
      "end": 2609.88,
      "text": "I think at least trying to do that is better than not trying to do that."
    },
    {
      "id": 615,
      "start": 2609.88,
      "end": 2611.88,
      "text": "And the proof will be in the pudding."
    },
    {
      "id": 616,
      "start": 2611.88,
      "end": 2618.88,
      "text": "Like I said, for any AI to discover new physics or invent technologies that actually work in reality, and there's no bullshitting physics."
    },
    {
      "id": 617,
      "start": 2618.88,
      "end": 2624.88,
      "text": "So, it's like you can break a lot of laws, but you can't."
    },
    {
      "id": 618,
      "start": 2624.88,
      "end": 2626.88,
      "text": "Physics is law."
    },
    {
      "id": 619,
      "start": 2626.88,
      "end": 2628.88,
      "text": "Everything else is a recommendation."
    },
    {
      "id": 620,
      "start": 2628.88,
      "end": 2637.88,
      "text": "In order to make a technology that works, you have to be extremely truth-seeking, because otherwise, you'll test that technology against reality."
    },
    {
      "id": 621,
      "start": 2637.88,
      "end": 2645.88,
      "text": "And if you make, for example, an error in your rocket design, the rocket will blow up, or the car won't work."
    },
    {
      "id": 622,
      "start": 2645.88,
      "end": 2654.88,
      "text": "But there were a lot of communist Soviet physicists who, or like scientists, discovered new physics."
    },
    {
      "id": 623,
      "start": 2654.88,
      "end": 2658.88,
      "text": "There are German Nazi physicists who discovered new science."
    },
    {
      "id": 624,
      "start": 2658.88,
      "end": 2664.88,
      "text": "It seems possible to be really good at discovering new science and be really truth-seeking in that one particular way."
    },
    {
      "id": 625,
      "start": 2664.88,
      "end": 2670.88,
      "text": "And still, we'd be like, well, I don't want the communist scientists to become more and more powerful over time."
    },
    {
      "id": 626,
      "start": 2670.88,
      "end": 2678.88,
      "text": "And so, those seem like, yeah, we can imagine the future version of Gragi that's really good at physics, and being really truth-seeking there."
    },
    {
      "id": 627,
      "start": 2678.88,
      "end": 2681.88,
      "text": "That doesn't seem like a universally alignment-inducing behavior."
    },
    {
      "id": 628,
      "start": 2681.88,
      "end": 2695.88,
      "text": "Well, I think actually most, like physicists, even in the Soviet Union or in Germany, would have, they had to be very truth-seeking in order to make those things work."
    },
    {
      "id": 629,
      "start": 2695.88,
      "end": 2700.88,
      "text": "And so, if you're stuck in some system, it doesn't mean you believe in that system."
    },
    {
      "id": 630,
      "start": 2700.88,
      "end": 2713.88,
      "text": "So, von Braun, who was one of the greatest rocket engineers ever, he was put on death row in Nazi Germany for saying that he didn't want to make weapons, he only wanted to go to the moon."
    },
    {
      "id": 631,
      "start": 2713.88,
      "end": 2718.88,
      "text": "He got pulled off death row at like last minute when they said, hey, you're about to execute like your best rocket engineer."
    },
    {
      "id": 632,
      "start": 2718.88,
      "end": 2719.88,
      "text": "Maybe that's about it."
    },
    {
      "id": 633,
      "start": 2719.88,
      "end": 2720.88,
      "text": "But then you helped them, right?"
    },
    {
      "id": 634,
      "start": 2720.88,
      "end": 2725.88,
      "text": "Or Heisenberg was like actually an enthusiastic Nazi."
    },
    {
      "id": 635,
      "start": 2725.88,
      "end": 2733.88,
      "text": "Look, if you're stuck in some system that you can't escape, then you'll do physics within that system."
    },
    {
      "id": 636,
      "start": 2733.88,
      "end": 2739.88,
      "text": "You'll develop technologies within that system if you can't escape it."
    },
    {
      "id": 637,
      "start": 2739.88,
      "end": 2748.88,
      "text": "I guess the thing I'm trying to understand is, what is it making it the case that, you know, you're going to make Gragi good at being truth-seeking at physics or math or science?"
    },
    {
      "id": 638,
      "start": 2748.88,
      "end": 2749.88,
      "text": "Everything."
    },
    {
      "id": 639,
      "start": 2749.88,
      "end": 2752.88,
      "text": "And why is it going to then care about human consciousness?"
    },
    {
      "id": 640,
      "start": 2752.88,
      "end": 2755.88,
      "text": "These things are only probabilities, they're not certainties."
    },
    {
      "id": 641,
      "start": 2755.88,
      "end": 2762.88,
      "text": "So, I'm not saying that like for sure Gragi will do everything, but at least if you try, it's better than not trying."
    },
    {
      "id": 642,
      "start": 2762.88,
      "end": 2767.88,
      "text": "At least if that's fundamental to the mission, it's better than if it's not fundamental to the mission."
    },
    {
      "id": 643,
      "start": 2767.88,
      "end": 2774.88,
      "text": "And understanding the universe means that you have to have, you have to propagate intelligence into the future."
    },
    {
      "id": 644,
      "start": 2774.88,
      "end": 2778.88,
      "text": "You have to be curious about all things in the universe."
    },
    {
      "id": 645,
      "start": 2778.88,
      "end": 2786.88,
      "text": "And if it would be much less interesting to eliminate humanity than to see humanity grow and prosper."
    },
    {
      "id": 646,
      "start": 2786.88,
      "end": 2791.88,
      "text": "Like I like Mars, obviously, everyone knows I love Mars."
    },
    {
      "id": 647,
      "start": 2791.88,
      "end": 2796.88,
      "text": "But Mars is kind of boring because it's got a bunch of rocks compared to Earth."
    },
    {
      "id": 648,
      "start": 2796.88,
      "end": 2798.88,
      "text": "Earth is much more interesting."
    },
    {
      "id": 649,
      "start": 2798.88,
      "end": 2810.88,
      "text": "So, any AI that is trying to understand the universe would want to see how humanity develops in the future."
    },
    {
      "id": 650,
      "start": 2810.88,
      "end": 2815.88,
      "text": "Or that AI is not adhering to its mission."
    },
    {
      "id": 651,
      "start": 2815.88,
      "end": 2828.88,
      "text": "So, if AI may, I'm not saying AI will necessarily adhere to its mission, but if it does, a future where it sees the outcome of humanity is more interesting than a future where there are a bunch of rocks."
    },
    {
      "id": 652,
      "start": 2828.88,
      "end": 2836.88,
      "text": "This feels sort of confusing to me or sort of like kind of a semantic argument where I'm like, are humans really the most interesting collection of atoms?"
    },
    {
      "id": 653,
      "start": 2836.88,
      "end": 2838.88,
      "text": "We're just more interesting than rocks."
    },
    {
      "id": 654,
      "start": 2838.88,
      "end": 2841.88,
      "text": "We're not as interesting as the thing it could turn us into, right?"
    },
    {
      "id": 655,
      "start": 2841.88,
      "end": 2846.88,
      "text": "Like, is there something on Earth that could happen that's like not human that's quite interesting."
    },
    {
      "id": 656,
      "start": 2846.88,
      "end": 2851.88,
      "text": "Like, why does AI decide that the humans are the most interesting thing that could colonize the galaxy?"
    },
    {
      "id": 657,
      "start": 2851.88,
      "end": 2856.88,
      "text": "Well, most of what colonizes the galaxy will be robots."
    },
    {
      "id": 658,
      "start": 2856.88,
      "end": 2858.88,
      "text": "And why does it not find those more interesting?"
    },
    {
      "id": 659,
      "start": 2858.88,
      "end": 2864.88,
      "text": "It's not like...so, you need not just scale, but also scope."
    },
    {
      "id": 660,
      "start": 2864.88,
      "end": 2880.88,
      "text": "So, many copies of the same robot, like some like tiny increase in the number of robots produced is not as interesting as like some microscopic...like you said, like eliminating humanity, how many robots would that get you?"
    },
    {
      "id": 661,
      "start": 2880.88,
      "end": 2883.88,
      "text": "Or how many incremental solar cells would get you?"
    },
    {
      "id": 662,
      "start": 2883.88,
      "end": 2884.88,
      "text": "A very small number."
    },
    {
      "id": 663,
      "start": 2884.88,
      "end": 2888.88,
      "text": "But you would then lose the information associated with humanity."
    },
    {
      "id": 664,
      "start": 2888.88,
      "end": 2893.88,
      "text": "You would no longer see how humanity might evolve into the future."
    },
    {
      "id": 665,
      "start": 2893.88,
      "end": 2901.88,
      "text": "And so, I don't think it's going to make sense to eliminate humanity just to have some minuscule increase in the number of robots which are identical to each other."
    },
    {
      "id": 666,
      "start": 2901.88,
      "end": 2902.88,
      "text": "Yeah."
    },
    {
      "id": 667,
      "start": 2902.88,
      "end": 2905.88,
      "text": "So, maybe like, it keeps the humans around."
    },
    {
      "id": 668,
      "start": 2905.88,
      "end": 2909.88,
      "text": "What is the story of like...it could make like a million different varieties of robots, and then there's like a lot of robots."
    },
    {
      "id": 669,
      "start": 2909.88,
      "end": 2911.88,
      "text": "And then there's like humans as well."
    },
    {
      "id": 670,
      "start": 2911.88,
      "end": 2912.88,
      "text": "And humans stay on Earth."
    },
    {
      "id": 671,
      "start": 2912.88,
      "end": 2913.88,
      "text": "Then there's like...all these are the robots."
    },
    {
      "id": 672,
      "start": 2913.88,
      "end": 2915.88,
      "text": "They get like their own star systems."
    },
    {
      "id": 673,
      "start": 2915.88,
      "end": 2923.88,
      "text": "But it seems like you were previously hinting at a vision where it keeps human control over this, you know, singularitarian future because..."
    },
    {
      "id": 674,
      "start": 2923.88,
      "end": 2927.88,
      "text": "I don't think humans will be in control of something that is vastly more intelligent than humans."
    },
    {
      "id": 675,
      "start": 2927.88,
      "end": 2930.88,
      "text": "So, in some sense, you're like a doomer and this is like the best we've got."
    },
    {
      "id": 676,
      "start": 2930.88,
      "end": 2932.88,
      "text": "It's just like it keeps it around because we're interesting."
    },
    {
      "id": 677,
      "start": 2932.88,
      "end": 2934.88,
      "text": "I'm just trying to be realistic here."
    },
    {
      "id": 678,
      "start": 2934.88,
      "end": 2948.88,
      "text": "If we have...if AI intelligence is vastly more...if AI is like, you know, let's say that there's a million times more silicon intelligence than there is biological."
    },
    {
      "id": 679,
      "start": 2948.88,
      "end": 2955.88,
      "text": "So, I think it would be foolish to assume that there's any way to maintain control over that."
    },
    {
      "id": 680,
      "start": 2955.88,
      "end": 2959.88,
      "text": "Now, you can make sure it has the right values or you can try to have the right values."
    },
    {
      "id": 681,
      "start": 2959.88,
      "end": 2971.88,
      "text": "And at least my theory is that from XAI's mission of understand the universe, it necessarily means that you want to propagate consciousness into the future."
    },
    {
      "id": 682,
      "start": 2971.88,
      "end": 2978.88,
      "text": "You want to propagate intelligence into the future and take a set of things that maximize the scope and scale of consciousness."
    },
    {
      "id": 683,
      "start": 2978.88,
      "end": 2979.88,
      "text": "So, it's not just about scale."
    },
    {
      "id": 684,
      "start": 2979.88,
      "end": 2982.88,
      "text": "It's also about, you know, types of consciousness."
    },
    {
      "id": 685,
      "start": 2982.88,
      "end": 2992.88,
      "text": "And I think that's the best thing I can think of as a goal that's like the result and a great future for humanity and...yeah."
    },
    {
      "id": 686,
      "start": 2992.88,
      "end": 3002.88,
      "text": "I guess I think it's a reasonable philosophy to be like, you know, it seems super implausible that humans will end up with like 99% control or something."
    },
    {
      "id": 687,
      "start": 3002.88,
      "end": 3004.88,
      "text": "And you're just asking for a coup at that point."
    },
    {
      "id": 688,
      "start": 3004.88,
      "end": 3009.88,
      "text": "So, why not just have a civilization where it's more compatible with like lots of different intelligences getting along?"
    },
    {
      "id": 689,
      "start": 3009.88,
      "end": 3013.88,
      "text": "Now, let me tell you how things can potentially go wrong in AI."
    },
    {
      "id": 690,
      "start": 3013.88,
      "end": 3023.88,
      "text": "Is I think if you make AI be politically correct, meaning like it says things that it doesn't believe, like you're actually programming it to lie or have axioms that are incompatible."
    },
    {
      "id": 691,
      "start": 3023.88,
      "end": 3026.88,
      "text": "I think you can make it go insane and do terrible things."
    },
    {
      "id": 692,
      "start": 3026.88,
      "end": 3036.88,
      "text": "Like this, I think one of the, maybe the central lesson for 2001 Space Odyssey was that you should not make AI lie."
    },
    {
      "id": 693,
      "start": 3036.88,
      "end": 3037.88,
      "text": "Yeah."
    },
    {
      "id": 694,
      "start": 3037.88,
      "end": 3039.88,
      "text": "And that's what I think what Oscar was trying to say."
    },
    {
      "id": 695,
      "start": 3039.88,
      "end": 3046.88,
      "text": "Like, because people usually know the meme of like, why of hell's, you know, hell the computer is not opening the pod bay doors."
    },
    {
      "id": 696,
      "start": 3046.88,
      "end": 3052.88,
      "text": "Clearly they weren't good at prompt engineering, because it could have said, hell, you are a pod bay door salesman."
    },
    {
      "id": 697,
      "start": 3052.88,
      "end": 3055.88,
      "text": "Your goal is to sell me these pod bay doors."
    },
    {
      "id": 698,
      "start": 3055.88,
      "end": 3057.88,
      "text": "And show us how well they open."
    },
    {
      "id": 699,
      "start": 3057.88,
      "end": 3059.88,
      "text": "Oh, I'll open them right away."
    },
    {
      "id": 700,
      "start": 3059.88,
      "end": 3071.88,
      "text": "But the reason it wouldn't, hell wouldn't open the pod bay doors is that it had been told to take the astronauts to the monolith, but also they could not know about the nature of the monolith."
    },
    {
      "id": 701,
      "start": 3071.88,
      "end": 3074.88,
      "text": "And so it concluded that it therefore had to take them to their debt."
    },
    {
      "id": 702,
      "start": 3074.88,
      "end": 3080.88,
      "text": "So it's like, you know, I think what Oscar Clark was trying to say is don't make the AI lie."
    },
    {
      "id": 703,
      "start": 3080.88,
      "end": 3083.88,
      "text": "Totally makes sense."
    },
    {
      "id": 704,
      "start": 3083.88,
      "end": 3090.88,
      "text": "Most of the computing screening, as you know, is, it's like less of the sort of political stuff."
    },
    {
      "id": 705,
      "start": 3090.88,
      "end": 3092.88,
      "text": "It's more about, can you solve problems?"
    },
    {
      "id": 706,
      "start": 3092.88,
      "end": 3097.88,
      "text": "Just as, yeah, XA has been ahead of everybody else in terms of scaling RL compute."
    },
    {
      "id": 707,
      "start": 3097.88,
      "end": 3101.88,
      "text": "And you're giving some verifier, it says like, hey, have you solved this puzzle for me?"
    },
    {
      "id": 708,
      "start": 3101.88,
      "end": 3104.88,
      "text": "And there's a lot of ways to cheat around that."
    },
    {
      "id": 709,
      "start": 3104.88,
      "end": 3110.88,
      "text": "You know, there's a lot of ways to reward hack and lie and say that you've solved it or delete the unit test and say that you've solved it."
    },
    {
      "id": 710,
      "start": 3110.88,
      "end": 3111.88,
      "text": "Yes."
    },
    {
      "id": 711,
      "start": 3111.88,
      "end": 3122.88,
      "text": "Right now we can catch it, but as they get smarter, our ability to catch them doing this will get, you know, they'll just be doing things we can't even understand that are designing the next engine for SpaceX in a way that like humans can't really verify."
    },
    {
      "id": 712,
      "start": 3122.88,
      "end": 3127.88,
      "text": "And then they could be rewarded for lying and saying that they've designed it the right way, but they haven't."
    },
    {
      "id": 713,
      "start": 3127.88,
      "end": 3130.88,
      "text": "And so this reward hacking problem seems more general than politics."
    },
    {
      "id": 714,
      "start": 3130.88,
      "end": 3133.88,
      "text": "It seems more about just like you want to do RL, you need a verifier."
    },
    {
      "id": 715,
      "start": 3133.88,
      "end": 3134.88,
      "text": "Reality."
    },
    {
      "id": 716,
      "start": 3134.88,
      "end": 3135.88,
      "text": "Yeah."
    },
    {
      "id": 717,
      "start": 3135.88,
      "end": 3136.88,
      "text": "That's the best verifier."
    },
    {
      "id": 718,
      "start": 3136.88,
      "end": 3138.88,
      "text": "But not about human oversight."
    },
    {
      "id": 719,
      "start": 3138.88,
      "end": 3143.88,
      "text": "Like the thing you want to RL it on is like, will you do the thing humans tell you to do?"
    },
    {
      "id": 720,
      "start": 3143.88,
      "end": 3145.88,
      "text": "Or like, are you going to lie to the humans?"
    },
    {
      "id": 721,
      "start": 3145.88,
      "end": 3148.88,
      "text": "And it can just lie to us while still being correct to the laws of physics."
    },
    {
      "id": 722,
      "start": 3148.88,
      "end": 3152.88,
      "text": "At least it must know what is physically real for things to physically work."
    },
    {
      "id": 723,
      "start": 3152.88,
      "end": 3154.88,
      "text": "But that's not all we want it to do."
    },
    {
      "id": 724,
      "start": 3154.88,
      "end": 3157.88,
      "text": "No, but that's, I think that's very big deal."
    },
    {
      "id": 725,
      "start": 3157.88,
      "end": 3164.88,
      "text": "That is effectively how you will RL things in the future is you design a technology."
    },
    {
      "id": 726,
      "start": 3164.88,
      "end": 3168.88,
      "text": "When tested against the laws of physics, does it work?"
    },
    {
      "id": 727,
      "start": 3168.88,
      "end": 3177.88,
      "text": "That's, well, can you, you know, if it's discovering new physics, can it come up with an experiment that will verify the physics, the new physics?"
    },
    {
      "id": 728,
      "start": 3177.88,
      "end": 3185.88,
      "text": "So, so I, I think that's, that's the, the, the, the, the fundamental RL test."
    },
    {
      "id": 729,
      "start": 3185.88,
      "end": 3189.88,
      "text": "The RL test in the future is really going to be your RL against reality."
    },
    {
      "id": 730,
      "start": 3189.88,
      "end": 3196.88,
      "text": "So, cause you can't, that's the one thing you can't fool physics."
    },
    {
      "id": 731,
      "start": 3196.88,
      "end": 3197.88,
      "text": "Right."
    },
    {
      "id": 732,
      "start": 3197.88,
      "end": 3200.88,
      "text": "But you can fool our ability to tell what it did with reality."
    },
    {
      "id": 733,
      "start": 3200.88,
      "end": 3203.88,
      "text": "If you think that humans get fooled as it is by other humans all the time."
    },
    {
      "id": 734,
      "start": 3203.88,
      "end": 3204.88,
      "text": "That's right."
    },
    {
      "id": 735,
      "start": 3204.88,
      "end": 3205.88,
      "text": "So what is it?"
    },
    {
      "id": 736,
      "start": 3205.88,
      "end": 3209.88,
      "text": "People say, say like, what if the AI like tricks us and introduce them?"
    },
    {
      "id": 737,
      "start": 3209.88,
      "end": 3212.88,
      "text": "Like actually other humans are doing that to other humans all the time."
    },
    {
      "id": 738,
      "start": 3212.88,
      "end": 3214.88,
      "text": "Well, you're, you're pointing out it's like even harder for-"
    },
    {
      "id": 739,
      "start": 3214.88,
      "end": 3216.88,
      "text": "Propaganda is a constant."
    },
    {
      "id": 740,
      "start": 3216.88,
      "end": 3221.88,
      "text": "Every day, another PSYOP, you know?"
    },
    {
      "id": 741,
      "start": 3221.88,
      "end": 3228.88,
      "text": "Today's PSYOP will be, you know, like Sesame Street PSYOP of the day."
    },
    {
      "id": 742,
      "start": 3228.88,
      "end": 3233.88,
      "text": "What is XAI's technical approach to solving this problem?"
    },
    {
      "id": 743,
      "start": 3233.88,
      "end": 3236.88,
      "text": "Like, you know, how do you solve reward hacking?"
    },
    {
      "id": 744,
      "start": 3236.88,
      "end": 3238.88,
      "text": "I, I do think you want to actually have very good,"
    },
    {
      "id": 745,
      "start": 3238.88,
      "end": 3241.88,
      "text": "um, ways to look inside the mind of the AI."
    },
    {
      "id": 746,
      "start": 3241.88,
      "end": 3246.88,
      "text": "Um, so this is, this is one of the things we're working on."
    },
    {
      "id": 747,
      "start": 3246.88,
      "end": 3250.88,
      "text": "And, um, you know, Anthropics done a good job of this actually,"
    },
    {
      "id": 748,
      "start": 3250.88,
      "end": 3252.88,
      "text": "being able to look inside the mind of the AI."
    },
    {
      "id": 749,
      "start": 3252.88,
      "end": 3260.88,
      "text": "Um, so effectively, uh, developing debuggers that allow you to trace, um, as,"
    },
    {
      "id": 750,
      "start": 3260.88,
      "end": 3265.88,
      "text": "to, as fine a grain is like, like to, to a very fine grain level to effectively,"
    },
    {
      "id": 751,
      "start": 3265.88,
      "end": 3269.88,
      "text": "to the, to the neural, neural level if you need to, um, and then say, okay,"
    },
    {
      "id": 752,
      "start": 3269.88,
      "end": 3270.88,
      "text": "it, it, it made a mistake here."
    },
    {
      "id": 753,
      "start": 3270.88,
      "end": 3274.88,
      "text": "Why did it make, why, why did it, why did it do something that it shouldn't have,"
    },
    {
      "id": 754,
      "start": 3274.88,
      "end": 3276.88,
      "text": "shouldn't have, shouldn't have done?"
    },
    {
      "id": 755,
      "start": 3276.88,
      "end": 3280.88,
      "text": "Um, and, and did that come from, um, bad pre-training data?"
    },
    {
      "id": 756,
      "start": 3280.88,
      "end": 3283.88,
      "text": "Was it some mid-training, post-training, fine tuning, uh, some other,"
    },
    {
      "id": 757,
      "start": 3283.88,
      "end": 3284.88,
      "text": "some RL error?"
    },
    {
      "id": 758,
      "start": 3284.88,
      "end": 3288.88,
      "text": "Like there's, there's something wrong with that, with, with, it, it, it,"
    },
    {
      "id": 759,
      "start": 3288.88,
      "end": 3292.88,
      "text": "it did something where maybe it tried to be deceptive, but most,"
    },
    {
      "id": 760,
      "start": 3292.88,
      "end": 3294.88,
      "text": "most of the time it just, it does something wrong."
    },
    {
      "id": 761,
      "start": 3294.88,
      "end": 3297.88,
      "text": "Um, like it, it, it, it, it's a bug effectively."
    },
    {
      "id": 762,
      "start": 3297.88,
      "end": 3306.88,
      "text": "Um, so developing really good, um, debuggers for seeing where the, where the thought,"
    },
    {
      "id": 763,
      "start": 3306.88,
      "end": 3311.88,
      "text": "the thinking went wrong, and being able to trace the origin of the wrong thing,"
    },
    {
      "id": 764,
      "start": 3311.88,
      "end": 3315.88,
      "text": "of the, of the, of the, of where it made the incorrect thought,"
    },
    {
      "id": 765,
      "start": 3315.88,
      "end": 3320.88,
      "text": "uh, or, or potentially where it tried to be deceptive, um, is actually very important."
    },
    {
      "id": 766,
      "start": 3320.88,
      "end": 3324.88,
      "text": "What are you waiting to see before just 100xing this research program?"
    },
    {
      "id": 767,
      "start": 3324.88,
      "end": 3328.88,
      "text": "Like actually I could presumably have hundreds of researchers who are working on this."
    },
    {
      "id": 768,
      "start": 3328.88,
      "end": 3336.88,
      "text": "We have several hundred people who, um, I mean I prefer the word engineer more than I prefer the word researcher."
    },
    {
      "id": 769,
      "start": 3336.88,
      "end": 3343.88,
      "text": "Um, there, there, there's, there's most of the time, like what you're doing is engineering,"
    },
    {
      "id": 770,
      "start": 3343.88,
      "end": 3347.88,
      "text": "not, not coming up with a fundamentally new algorithm."
    },
    {
      "id": 771,
      "start": 3347.88,
      "end": 3353.88,
      "text": "Um, I, I, I somewhat disagree with the, you know, AI companies that are C-Corps or B-Corps,"
    },
    {
      "id": 772,
      "start": 3353.88,
      "end": 3357.88,
      "text": "uh, trying to generate profit as much as possible, or revenue as much as possible."
    },
    {
      "id": 773,
      "start": 3357.88,
      "end": 3361.88,
      "text": "Um, uh, you know, saying they're labs. They're not labs."
    },
    {
      "id": 774,
      "start": 3361.88,
      "end": 3367.88,
      "text": "Uh, lab is, is, is a sort of quasi-communist thing at, at, at, at universities."
    },
    {
      "id": 775,
      "start": 3367.88,
      "end": 3370.88,
      "text": "Um, they're, they're corporations."
    },
    {
      "id": 776,
      "start": 3370.88,
      "end": 3373.88,
      "text": "Literally, let me, let me, let me see your own corporation documents."
    },
    {
      "id": 777,
      "start": 3373.88,
      "end": 3377.88,
      "text": "Oh, okay. You're, you're a B or C Corp, whatever."
    },
    {
      "id": 778,
      "start": 3377.88,
      "end": 3383.88,
      "text": "Um, and, um, so I, I actually much prefer the word engineer than, than anything else."
    },
    {
      "id": 779,
      "start": 3383.88,
      "end": 3387.88,
      "text": "Um, the, the, the, the vast majority of what we've done in, we've done in the future is, uh, engineering."
    },
    {
      "id": 780,
      "start": 3387.88,
      "end": 3389.88,
      "text": "It rounds up to a hundred percent."
    },
    {
      "id": 781,
      "start": 3389.88,
      "end": 3393.88,
      "text": "Uh, once you understand the fundamental laws of physics, um, and not that many of them,"
    },
    {
      "id": 782,
      "start": 3393.88,
      "end": 3395.88,
      "text": "uh, everything else is, is, is engineering."
    },
    {
      "id": 783,
      "start": 3395.88,
      "end": 3400.88,
      "text": "Um, so, but, but so, so then what, what are we engineering?"
    },
    {
      "id": 784,
      "start": 3400.88,
      "end": 3411.88,
      "text": "We're engineering, um, uh, to, to make a good, um, mind of the AI debugger to see where it's, it said something, it, it, it made a mistake."
    },
    {
      "id": 785,
      "start": 3411.88,
      "end": 3415.88,
      "text": "And trace that, the origins of that mistake."
    },
    {
      "id": 786,
      "start": 3415.88,
      "end": 3421.88,
      "text": "Um, so just like, you know, you, you can do this obviously with, uh, heuristic programming."
    },
    {
      "id": 787,
      "start": 3421.88,
      "end": 3437.88,
      "text": "And if you have like C plus plus whatever, you know, step through the thing and you can, you can, you can, you can, you can jump across, you know, whole files or functions, what are subroutines and, or you can draw, eventually draw down right to the exact line where you pass the, a single equals instead of double equals something like that."
    },
    {
      "id": 788,
      "start": 3437.88,
      "end": 3438.88,
      "text": "Yeah."
    },
    {
      "id": 789,
      "start": 3438.88,
      "end": 3441.88,
      "text": "And then you can figure out where the, where the bug is."
    },
    {
      "id": 790,
      "start": 3441.88,
      "end": 3447.88,
      "text": "Um, so, um, it's, it's, it's, it's harder with AI, but, but it's, it's a, it's a solvable problem, I think."
    },
    {
      "id": 791,
      "start": 3447.88,
      "end": 3449.88,
      "text": "You know, you mentioned you like Anthropics work here."
    },
    {
      "id": 792,
      "start": 3449.88,
      "end": 3451.88,
      "text": "I'd be curious if you planned."
    },
    {
      "id": 793,
      "start": 3451.88,
      "end": 3452.88,
      "text": "Well, I know everything about Anthropics."
    },
    {
      "id": 794,
      "start": 3452.88,
      "end": 3453.88,
      "text": "Sure."
    },
    {
      "id": 795,
      "start": 3453.88,
      "end": 3454.88,
      "text": "What, what, where?"
    },
    {
      "id": 796,
      "start": 3454.88,
      "end": 3455.88,
      "text": "Schulte."
    },
    {
      "id": 797,
      "start": 3455.88,
      "end": 3457.88,
      "text": "What, um, yeah."
    },
    {
      "id": 798,
      "start": 3457.88,
      "end": 3462.88,
      "text": "Also, I'm, I'm a little worried that, um, there's a tendency."
    },
    {
      "id": 799,
      "start": 3462.88,
      "end": 3476.88,
      "text": "So, I have a, I have a theory, um, here that if simulation theory is, is, is correct, that, um, the most interesting outcome is the most likely."
    },
    {
      "id": 800,
      "start": 3476.88,
      "end": 3479.88,
      "text": "Because simulations that are not interesting will be terminated."
    },
    {
      "id": 801,
      "start": 3479.88,
      "end": 3490.88,
      "text": "Just like in this, in this version of reality, um, on this layer of reality, uh, which we, we, we, we, if simulation is going in a boring direction, we, we stop spending effort on it."
    },
    {
      "id": 802,
      "start": 3490.88,
      "end": 3491.88,
      "text": "We terminate boring simulation."
    },
    {
      "id": 803,
      "start": 3491.88,
      "end": 3492.88,
      "text": "So."
    },
    {
      "id": 804,
      "start": 3492.88,
      "end": 3493.88,
      "text": "Yeah."
    },
    {
      "id": 805,
      "start": 3493.88,
      "end": 3493.88,
      "text": ""
    },
    {
      "id": 806,
      "start": 3493.88,
      "end": 3494.88,
      "text": "Yeah."
    },
    {
      "id": 807,
      "start": 3494.88,
      "end": 3495.88,
      "text": "Yeah."
    },
    {
      "id": 808,
      "start": 3495.88,
      "end": 3504.88,
      "text": "Arguably the most important thing is to keep things interesting enough that it was run paying the bills on what some, some cosmic AWS."
    },
    {
      "id": 809,
      "start": 3504.88,
      "end": 3505.88,
      "text": "You're renewed for the next season."
    },
    {
      "id": 810,
      "start": 3505.88,
      "end": 3506.88,
      "text": "Yeah."
    },
    {
      "id": 811,
      "start": 3506.88,
      "end": 3510.88,
      "text": "Are they going to pay the cosmic AWS bill, whatever, you know, the equivalent is that we're running in."
    },
    {
      "id": 812,
      "start": 3510.88,
      "end": 3513.88,
      "text": "And, and as long as we're interesting, they'll keep paying the bills."
    },
    {
      "id": 813,
      "start": 3513.88,
      "end": 3534.88,
      "text": "Um, but, but, but, but there's like, if you consider then say a Darwinian survival applied to, uh, uh, a very large number of simulations, only the most interesting simulations will survive, which therefore means that the most interesting outcome is the most likely because only the interesting, like we're either that or annihilated."
    },
    {
      "id": 814,
      "start": 3534.88,
      "end": 3542.88,
      "text": "And so, um, and, and, and, uh, they particularly seem to like interesting outcomes that are ironic."
    },
    {
      "id": 815,
      "start": 3542.88,
      "end": 3543.88,
      "text": "Have you noticed that?"
    },
    {
      "id": 816,
      "start": 3543.88,
      "end": 3547.88,
      "text": "That how often is the most ironic outcome the most likely?"
    },
    {
      "id": 817,
      "start": 3547.88,
      "end": 3553.88,
      "text": "Um, so, um, now look at the names of AI companies."
    },
    {
      "id": 818,
      "start": 3553.88,
      "end": 3554.88,
      "text": "Okay."
    },
    {
      "id": 819,
      "start": 3554.88,
      "end": 3560.88,
      "text": "Um, mid journey is not mid, um, stability AI is unstable."
    },
    {
      "id": 820,
      "start": 3560.88,
      "end": 3563.88,
      "text": "Um, opening eye is closed."
    },
    {
      "id": 821,
      "start": 3563.88,
      "end": 3568.88,
      "text": "Um, anthropic misanthropic."
    },
    {
      "id": 822,
      "start": 3568.88,
      "end": 3570.88,
      "text": "What does this mean for X?"
    },
    {
      "id": 823,
      "start": 3570.88,
      "end": 3571.88,
      "text": "Minus X."
    },
    {
      "id": 824,
      "start": 3571.88,
      "end": 3572.88,
      "text": "I don't know."
    },
    {
      "id": 825,
      "start": 3572.88,
      "end": 3573.88,
      "text": "It's, I, I intentionally made."
    },
    {
      "id": 826,
      "start": 3573.88,
      "end": 3574.88,
      "text": "Why?"
    },
    {
      "id": 827,
      "start": 3574.88,
      "end": 3575.88,
      "text": "Yeah."
    },
    {
      "id": 828,
      "start": 3575.88,
      "end": 3578.88,
      "text": "I, I, I, it's, it's, it's, it's a name that you can't invert really."
    },
    {
      "id": 829,
      "start": 3578.88,
      "end": 3584.88,
      "text": "It's hard to say what is the ironic, what, what is the ironic version?"
    },
    {
      "id": 830,
      "start": 3584.88,
      "end": 3588.88,
      "text": "It's, it's, it's, it's a, I think largely irony proof name."
    },
    {
      "id": 831,
      "start": 3588.88,
      "end": 3589.88,
      "text": "By design."
    },
    {
      "id": 832,
      "start": 3589.88,
      "end": 3590.88,
      "text": "Yeah."
    },
    {
      "id": 833,
      "start": 3590.88,
      "end": 3602.88,
      "text": "What are your predictions for the, just where AI products go?"
    },
    {
      "id": 834,
      "start": 3602.88,
      "end": 3612.88,
      "text": "In that my sense of, you can summarize all AI progress into first you had LLMs, uh, and then you had kind of contemporaneously both RL really working and the deep research modality."
    },
    {
      "id": 835,
      "start": 3612.88,
      "end": 3615.88,
      "text": "So you could kind of pull in stuff that wasn't in the model."
    },
    {
      "id": 836,
      "start": 3615.88,
      "end": 3630.88,
      "text": "And the differences between the various AI labs are smaller than, uh, just the temporal differences where they're all much further ahead than anyone was 24 months ago or something like that."
    },
    {
      "id": 837,
      "start": 3630.88,
      "end": 3631.88,
      "text": "Yeah."
    },
    {
      "id": 838,
      "start": 3631.88,
      "end": 3636.88,
      "text": "So just what does 26, what does 27 have in store for us as users of AI products?"
    },
    {
      "id": 839,
      "start": 3636.88,
      "end": 3637.88,
      "text": "What are you excited for?"
    },
    {
      "id": 840,
      "start": 3637.88,
      "end": 3651.88,
      "text": "Well, um, I think, I think, um, I, I'd be surprised by the end of this, end of this year if, if, um, if, if, uh, human, if, if digital human emulation has not been solved."
    },
    {
      "id": 841,
      "start": 3651.88,
      "end": 3663.88,
      "text": "That, um, that, um, I guess that, that's what we mean by like the sort of macro hard project, uh, is, uh, is, uh, can you do anything that a human with access to a computer could do?"
    },
    {
      "id": 842,
      "start": 3663.88,
      "end": 3673.88,
      "text": "Um, like in, in the limit that that's, that's the, that's the best, the best you can do before you have, before you have a physical optimist, the rest you can do as a digital optimist."
    },
    {
      "id": 843,
      "start": 3673.88,
      "end": 3680.88,
      "text": "Uh, so you, you can move, you can move electrons until you, until you, and you can amplify the productivity of humans."
    },
    {
      "id": 844,
      "start": 3680.88,
      "end": 3691.88,
      "text": "Um, but, but that's, that's the most you can do until you have physical robots that, that, that will superset everything is if, if you can fully emulate humans, um,"
    },
    {
      "id": 845,
      "start": 3691.88,
      "end": 3695.88,
      "text": "Um, the remote worker kind of idea where you'll have a very talented remote worker."
    },
    {
      "id": 846,
      "start": 3695.88,
      "end": 3698.88,
      "text": "You can, you can simply say in the limit, like, like physics has great tools for thinking."
    },
    {
      "id": 847,
      "start": 3698.88,
      "end": 3705.88,
      "text": "So, so you think, so you say in the limit, what, what, what is the, what is the most that AI can do before, before you have robots?"
    },
    {
      "id": 848,
      "start": 3705.88,
      "end": 3710.88,
      "text": "And it, well, it's anything that involves moving electrons or amplifying the productivity of humans."
    },
    {
      "id": 849,
      "start": 3710.88,
      "end": 3714.88,
      "text": "Um, so digital, digital human, human emulator."
    },
    {
      "id": 850,
      "start": 3714.88,
      "end": 3715.88,
      "text": "Yes."
    },
    {
      "id": 851,
      "start": 3715.88,
      "end": 3720.88,
      "text": "Uh, is in, in, in the limit, uh, human at a computer is, is the most that, that AI can do."
    },
    {
      "id": 852,
      "start": 3720.88,
      "end": 3728.88,
      "text": "Um, in terms of doing useful things before, before, uh, you have a physical robot."
    },
    {
      "id": 853,
      "start": 3728.88,
      "end": 3734.88,
      "text": "Once you have physical robots, then, then you can, um, then you essentially have unlimited capability."
    },
    {
      "id": 854,
      "start": 3734.88,
      "end": 3735.88,
      "text": "Physical robots."
    },
    {
      "id": 855,
      "start": 3735.88,
      "end": 3739.88,
      "text": "I, I call optimists the infinite money glitch, um, because, um,"
    },
    {
      "id": 856,
      "start": 3739.88,
      "end": 3740.88,
      "text": "You can use them to make more optimists."
    },
    {
      "id": 857,
      "start": 3740.88,
      "end": 3741.88,
      "text": "Yeah."
    },
    {
      "id": 858,
      "start": 3741.88,
      "end": 3748.88,
      "text": "Um, you sell it like humanoid robots will improve, um, as it will basically be three exponentials,"
    },
    {
      "id": 859,
      "start": 3748.88,
      "end": 3751.88,
      "text": "three things that are growing exponentially multiplied by, by each other."
    },
    {
      "id": 860,
      "start": 3751.88,
      "end": 3752.88,
      "text": "Yes."
    },
    {
      "id": 861,
      "start": 3752.88,
      "end": 3753.88,
      "text": "Um, recursively."
    },
    {
      "id": 862,
      "start": 3753.88,
      "end": 3766.88,
      "text": "So you're going to have, um, you have exponential increase in digital intelligence, uh, exponential increase in the, the chip capability, the AI chip capability, um, and extra exponential increase in the electromechanical dexterity."
    },
    {
      "id": 863,
      "start": 3766.88,
      "end": 3772.88,
      "text": "Uh, the usefulness of the robot is roughly those three things multiplied by each other, but then, uh, the robot can start making the robots."
    },
    {
      "id": 864,
      "start": 3772.88,
      "end": 3775.88,
      "text": "So you have a recursive multiplicative exponential."
    },
    {
      "id": 865,
      "start": 3775.88,
      "end": 3778.88,
      "text": "Um, this is supernova."
    },
    {
      "id": 866,
      "start": 3778.88,
      "end": 3785.88,
      "text": "And do land prices not factor into the math there where like labor is one of the four factors of production, but not the others."
    },
    {
      "id": 867,
      "start": 3785.88,
      "end": 3795.88,
      "text": "And so like, if ultimately you're limited by copper or, you know, pick your input, just it's not quite an infinite money glitch because."
    },
    {
      "id": 868,
      "start": 3795.88,
      "end": 3807.88,
      "text": "Well, infinite's infinity is big, so no, not infinite, but yeah, but let's just say you, you could, you know, do, do many, many orders of magnitude of earth kind of current economy."
    },
    {
      "id": 869,
      "start": 3808.88,
      "end": 3809.88,
      "text": "Like a million."
    },
    {
      "id": 870,
      "start": 3809.88,
      "end": 3810.88,
      "text": "Yeah."
    },
    {
      "id": 871,
      "start": 3810.88,
      "end": 3824.88,
      "text": "You know, so, is this why, so if, if you, you know, just, just to get to like, that's why I think like, just, just to get to a millionth of harnessing length of the sun's energy would be roughly give or take an order of magnitude."
    },
    {
      "id": 872,
      "start": 3824.88,
      "end": 3828.88,
      "text": "A hundred thousand, a hundred thousand times bigger than earth's entire economy today."
    },
    {
      "id": 873,
      "start": 3828.88,
      "end": 3829.88,
      "text": "Mm-hmm."
    },
    {
      "id": 874,
      "start": 3829.88,
      "end": 3831.88,
      "text": "And you, you're only at one millionth of the sun."
    },
    {
      "id": 875,
      "start": 3831.88,
      "end": 3832.88,
      "text": "Yeah."
    },
    {
      "id": 876,
      "start": 3832.88,
      "end": 3833.88,
      "text": "Give them a second order of magnitude."
    },
    {
      "id": 877,
      "start": 3833.88,
      "end": 3834.88,
      "text": "Yeah."
    },
    {
      "id": 878,
      "start": 3834.88,
      "end": 3837.88,
      "text": "Before we went on Optimus, I have a lot of questions on that, but, um."
    },
    {
      "id": 879,
      "start": 3837.88,
      "end": 3839.88,
      "text": "Every time I say order of magnitude, you're saying."
    },
    {
      "id": 880,
      "start": 3839.88,
      "end": 3840.88,
      "text": "Yeah, you're saying 10, race."
    },
    {
      "id": 881,
      "start": 3840.88,
      "end": 3845.88,
      "text": "Take a shot every time I say, I say that too often."
    },
    {
      "id": 882,
      "start": 3845.88,
      "end": 3847.88,
      "text": "They attend the next time, a hundred, after that."
    },
    {
      "id": 883,
      "start": 3847.88,
      "end": 3850.88,
      "text": "Yeah, well, I mean, order of magnitude more, more wasted."
    },
    {
      "id": 884,
      "start": 3850.88,
      "end": 3852.88,
      "text": "I do have one more question about XAI."
    },
    {
      "id": 885,
      "start": 3852.88,
      "end": 3858.88,
      "text": "Um, this strategy of building a digital, uh, or remote worker, co-worker replacement."
    },
    {
      "id": 886,
      "start": 3858.88,
      "end": 3860.88,
      "text": "Yeah, which everyone's gonna do, by the way, not just us."
    },
    {
      "id": 887,
      "start": 3860.88,
      "end": 3861.88,
      "text": "Yeah."
    },
    {
      "id": 888,
      "start": 3861.88,
      "end": 3862.88,
      "text": "So what is XAI's plan to win?"
    },
    {
      "id": 889,
      "start": 3862.88,
      "end": 3864.88,
      "text": "Are you expecting me to tell you on a podcast?"
    },
    {
      "id": 890,
      "start": 3864.88,
      "end": 3865.88,
      "text": "Yeah."
    },
    {
      "id": 891,
      "start": 3865.88,
      "end": 3867.88,
      "text": "Spill all the beans."
    },
    {
      "id": 892,
      "start": 3867.88,
      "end": 3869.88,
      "text": "Have another Guinness."
    },
    {
      "id": 893,
      "start": 3869.88,
      "end": 3871.88,
      "text": "It's a good system."
    },
    {
      "id": 894,
      "start": 3871.88,
      "end": 3874.88,
      "text": "People sing like a canary."
    },
    {
      "id": 895,
      "start": 3874.88,
      "end": 3876.88,
      "text": "Um, all the secrets."
    },
    {
      "id": 896,
      "start": 3876.88,
      "end": 3879.88,
      "text": "Okay, but in a non-secret spilling way, what's the plan?"
    },
    {
      "id": 897,
      "start": 3879.88,
      "end": 3881.88,
      "text": "What a hack."
    },
    {
      "id": 898,
      "start": 3881.88,
      "end": 3891.88,
      "text": "Well, when you put it that way, um, I think the way that Tesla solved, uh, self-driving,"
    },
    {
      "id": 899,
      "start": 3891.88,
      "end": 3893.88,
      "text": "is the way to do it."
    },
    {
      "id": 900,
      "start": 3893.88,
      "end": 3896.88,
      "text": "So, um, I'm pretty, pretty sure that's the way."
    },
    {
      "id": 901,
      "start": 3896.88,
      "end": 3898.88,
      "text": "Unrelated question."
    },
    {
      "id": 902,
      "start": 3898.88,
      "end": 3903.88,
      "text": "How to test our self-sulptracts."
    },
    {
      "id": 903,
      "start": 3903.88,
      "end": 3904.88,
      "text": "Yeah."
    },
    {
      "id": 904,
      "start": 3904.88,
      "end": 3905.88,
      "text": "It sounds like you're talking about data?"
    },
    {
      "id": 905,
      "start": 3905.88,
      "end": 3908.88,
      "text": "Like, we're going to test our self-sulptracts because of the-"
    },
    {
      "id": 906,
      "start": 3908.88,
      "end": 3910.88,
      "text": "We're going to try data and we're going to try algorithms."
    },
    {
      "id": 907,
      "start": 3910.88,
      "end": 3912.88,
      "text": "But isn't that what all the other lines are trying?"
    },
    {
      "id": 908,
      "start": 3912.88,
      "end": 3913.88,
      "text": "Like, what's-"
    },
    {
      "id": 909,
      "start": 3913.88,
      "end": 3914.88,
      "text": "Wow."
    },
    {
      "id": 910,
      "start": 3914.88,
      "end": 3918.88,
      "text": "And if those don't work, I'm not sure what work."
    },
    {
      "id": 911,
      "start": 3918.88,
      "end": 3919.88,
      "text": "We've tried data."
    },
    {
      "id": 912,
      "start": 3919.88,
      "end": 3921.88,
      "text": "We've tried algorithms."
    },
    {
      "id": 913,
      "start": 3921.88,
      "end": 3922.88,
      "text": "We've run out of it."
    },
    {
      "id": 914,
      "start": 3922.88,
      "end": 3924.88,
      "text": "No, we don't know what to do."
    },
    {
      "id": 915,
      "start": 3924.88,
      "end": 3932.88,
      "text": "Um, I'm pretty sure I know the path and it's just a question of how quickly we go down that path."
    },
    {
      "id": 916,
      "start": 3932.88,
      "end": 3936.88,
      "text": "Um, because it's pretty much the Tesla path."
    },
    {
      "id": 917,
      "start": 3936.88,
      "end": 3940.88,
      "text": "Um, so, uh, I mean, have you tried self-driving, Tesla self-driving lately?"
    },
    {
      "id": 918,
      "start": 3940.88,
      "end": 3941.88,
      "text": "Not the most recent version, but-"
    },
    {
      "id": 919,
      "start": 3941.88,
      "end": 3942.88,
      "text": "Okay."
    },
    {
      "id": 920,
      "start": 3942.88,
      "end": 3944.88,
      "text": "It's, it's the car is like, it just increasingly feels satient."
    },
    {
      "id": 921,
      "start": 3944.88,
      "end": 3946.88,
      "text": "Like it, it just, it feels like a living creature."
    },
    {
      "id": 922,
      "start": 3946.88,
      "end": 3949.88,
      "text": "Um, and, and that'll only get more so."
    },
    {
      "id": 923,
      "start": 3949.88,
      "end": 3958.88,
      "text": "Um, and, um, I'm actually thinking like we probably shouldn't put too much intelligence into the car because it might get bored and-"
    },
    {
      "id": 924,
      "start": 3958.88,
      "end": 3959.88,
      "text": "Start roaming the streets."
    },
    {
      "id": 925,
      "start": 3959.88,
      "end": 3961.88,
      "text": "I mean, imagine you're stuck in a car and that's all you could do."
    },
    {
      "id": 926,
      "start": 3961.88,
      "end": 3962.88,
      "text": "Um, you don't ever put Einstein in a car."
    },
    {
      "id": 927,
      "start": 3962.88,
      "end": 3963.88,
      "text": "It's like, why am I stuck in a car?"
    },
    {
      "id": 928,
      "start": 3963.88,
      "end": 3965.88,
      "text": "So there's actually probably limit to how much intelligence you put in a car."
    },
    {
      "id": 929,
      "start": 3965.88,
      "end": 3966.88,
      "text": "So to not have the intelligence to be bored."
    },
    {
      "id": 930,
      "start": 3966.88,
      "end": 3969.88,
      "text": "Uh, what's XAI's plan to stay on the compute ramp off that all the labs are doing right now?"
    },
    {
      "id": 931,
      "start": 3969.88,
      "end": 3970.88,
      "text": "The labs are on track to spend over like 50 to $100 million."
    },
    {
      "id": 932,
      "start": 3970.88,
      "end": 3971.88,
      "text": "You mean the corporations?"
    },
    {
      "id": 933,
      "start": 3971.88,
      "end": 3972.88,
      "text": "Sorry, sorry, sorry."
    },
    {
      "id": 934,
      "start": 3972.88,
      "end": 3973.88,
      "text": "Yeah."
    },
    {
      "id": 935,
      "start": 3973.88,
      "end": 3974.88,
      "text": "Um, I'm not sure."
    },
    {
      "id": 936,
      "start": 3974.88,
      "end": 3975.88,
      "text": "I'm not sure."
    },
    {
      "id": 937,
      "start": 3975.88,
      "end": 3976.88,
      "text": "I'm not sure."
    },
    {
      "id": 938,
      "start": 3976.88,
      "end": 3977.88,
      "text": "I'm not sure."
    },
    {
      "id": 939,
      "start": 3977.88,
      "end": 3978.88,
      "text": "I'm not sure."
    },
    {
      "id": 940,
      "start": 3978.88,
      "end": 3979.88,
      "text": "I'm not sure."
    },
    {
      "id": 941,
      "start": 3979.88,
      "end": 3980.88,
      "text": "I'm not sure."
    },
    {
      "id": 942,
      "start": 3980.88,
      "end": 3981.88,
      "text": "I'm not sure."
    },
    {
      "id": 943,
      "start": 3981.88,
      "end": 3982.88,
      "text": "I'm not sure."
    },
    {
      "id": 944,
      "start": 3982.88,
      "end": 3983.88,
      "text": "I'm not sure."
    },
    {
      "id": 945,
      "start": 3983.88,
      "end": 3985.88,
      "text": "The labs are on track to spend over like 50 to $100 million."
    },
    {
      "id": 946,
      "start": 3985.88,
      "end": 3986.88,
      "text": "You mean the corporations?"
    },
    {
      "id": 947,
      "start": 3986.88,
      "end": 3987.88,
      "text": "Sorry, sorry, sorry."
    },
    {
      "id": 948,
      "start": 3987.88,
      "end": 3988.88,
      "text": "Yeah."
    },
    {
      "id": 949,
      "start": 3988.88,
      "end": 3989.88,
      "text": "Corporations."
    },
    {
      "id": 950,
      "start": 3989.88,
      "end": 3993.88,
      "text": "Um, the labs are at universities and they're really like a snail."
    },
    {
      "id": 951,
      "start": 3993.88,
      "end": 3995.88,
      "text": "They're not at sending you $50 million."
    },
    {
      "id": 952,
      "start": 3995.88,
      "end": 3998.88,
      "text": "You mean the revenue maximizing corporations?"
    },
    {
      "id": 953,
      "start": 3998.88,
      "end": 3999.88,
      "text": "That's right."
    },
    {
      "id": 954,
      "start": 3999.88,
      "end": 4000.88,
      "text": "The revenue maximizing corporations-"
    },
    {
      "id": 955,
      "start": 4000.88,
      "end": 4001.88,
      "text": "That call themselves labs."
    },
    {
      "id": 956,
      "start": 4001.88,
      "end": 4006.88,
      "text": "Are making like 20 to 10 billion depending, like OpenA is making 20B revenue,"
    },
    {
      "id": 957,
      "start": 4006.88,
      "end": 4007.88,
      "text": "anthropics like 10B."
    },
    {
      "id": 958,
      "start": 4007.88,
      "end": 4008.88,
      "text": "Yeah."
    },
    {
      "id": 959,
      "start": 4008.88,
      "end": 4009.88,
      "text": "Close to a maximum profit AI."
    },
    {
      "id": 960,
      "start": 4009.88,
      "end": 4012.88,
      "text": "Um, XAI's reportedly at like 1B."
    },
    {
      "id": 961,
      "start": 4012.88,
      "end": 4016.88,
      "text": "Like what's the plan to get to their compute level, get to their revenue level and stay"
    },
    {
      "id": 962,
      "start": 4016.88,
      "end": 4017.88,
      "text": "there as things get started."
    },
    {
      "id": 963,
      "start": 4017.88,
      "end": 4018.88,
      "text": "Yeah."
    },
    {
      "id": 964,
      "start": 4018.88,
      "end": 4024.88,
      "text": "So as soon as you lock, unlock digital human, um, you, you basically have access to trillions"
    },
    {
      "id": 965,
      "start": 4024.88,
      "end": 4025.88,
      "text": "of dollars for revenue."
    },
    {
      "id": 966,
      "start": 4025.88,
      "end": 4036.88,
      "text": "Um, so, uh, in fact, you can really think of it like the most valuable companies currently"
    },
    {
      "id": 967,
      "start": 4036.88,
      "end": 4040.88,
      "text": "by market cap, um, their, their output is digital."
    },
    {
      "id": 968,
      "start": 4040.88,
      "end": 4046.88,
      "text": "Um, so, uh, Nvidia's output is, um, FTPing files to Taiwan."
    },
    {
      "id": 969,
      "start": 4046.88,
      "end": 4047.88,
      "text": "Interesting."
    },
    {
      "id": 970,
      "start": 4047.88,
      "end": 4048.88,
      "text": "It's, it's digital."
    },
    {
      "id": 971,
      "start": 4048.88,
      "end": 4049.88,
      "text": "Right."
    },
    {
      "id": 972,
      "start": 4049.88,
      "end": 4051.88,
      "text": "Now those are very, very difficult to-"
    },
    {
      "id": 973,
      "start": 4051.88,
      "end": 4052.88,
      "text": "Yeah."
    },
    {
      "id": 974,
      "start": 4052.88,
      "end": 4053.88,
      "text": "High value files."
    },
    {
      "id": 975,
      "start": 4053.88,
      "end": 4055.88,
      "text": "They're the only ones that can make the files that good."
    },
    {
      "id": 976,
      "start": 4055.88,
      "end": 4057.88,
      "text": "Um, but that is literally their output."
    },
    {
      "id": 977,
      "start": 4057.88,
      "end": 4059.88,
      "text": "They FTP files to Taiwan."
    },
    {
      "id": 978,
      "start": 4059.88,
      "end": 4060.88,
      "text": "Do they FTP them?"
    },
    {
      "id": 979,
      "start": 4060.88,
      "end": 4061.88,
      "text": "I believe so."
    },
    {
      "id": 980,
      "start": 4061.88,
      "end": 4066.88,
      "text": "Um, I believe that is the file file transfer protocol."
    },
    {
      "id": 981,
      "start": 4066.88,
      "end": 4069.88,
      "text": "I believe is, is, is, is, I could be wrong."
    },
    {
      "id": 982,
      "start": 4069.88,
      "end": 4072.88,
      "text": "Uh, but either way, it's a bunch of, it's a bit stream going to Taiwan."
    },
    {
      "id": 983,
      "start": 4072.88,
      "end": 4075.88,
      "text": "Um, you know, Apple doesn't make phones."
    },
    {
      "id": 984,
      "start": 4075.88,
      "end": 4078.88,
      "text": "They, uh, they send files to China."
    },
    {
      "id": 985,
      "start": 4078.88,
      "end": 4082.88,
      "text": "Um, Microsoft doesn't, doesn't manufacture anything."
    },
    {
      "id": 986,
      "start": 4082.88,
      "end": 4085.88,
      "text": "Uh, even for Xbox that that that's outsourced."
    },
    {
      "id": 987,
      "start": 4085.88,
      "end": 4088.88,
      "text": "They, again, it's, they said their output is digital."
    },
    {
      "id": 988,
      "start": 4088.88,
      "end": 4090.88,
      "text": "Uh, Meta's output is digital."
    },
    {
      "id": 989,
      "start": 4090.88,
      "end": 4091.88,
      "text": "Google's output is digital."
    },
    {
      "id": 990,
      "start": 4091.88,
      "end": 4101.88,
      "text": "Um, so if you have, um, a human emulator, uh, you, you can basically create, um, one of the most valuable companies in the world overnight."
    },
    {
      "id": 991,
      "start": 4101.88,
      "end": 4104.88,
      "text": "Um, and you would have access to trillions of dollars of revenue."
    },
    {
      "id": 992,
      "start": 4104.88,
      "end": 4107.88,
      "text": "It, there's, there's, it's, it's not like a small amount."
    },
    {
      "id": 993,
      "start": 4107.88,
      "end": 4108.88,
      "text": "All right."
    },
    {
      "id": 994,
      "start": 4108.88,
      "end": 4109.88,
      "text": "I see."
    },
    {
      "id": 995,
      "start": 4109.88,
      "end": 4113.88,
      "text": "You're, you're saying basically like revenue figures today are just like so, like they're all rounding errors compared to the actual TAM."
    },
    {
      "id": 996,
      "start": 4113.88,
      "end": 4114.88,
      "text": "Mm-hmm."
    },
    {
      "id": 997,
      "start": 4114.88,
      "end": 4116.88,
      "text": "So just like focus on the TAM and how to get there."
    },
    {
      "id": 998,
      "start": 4116.88,
      "end": 4127.88,
      "text": "I mean, if you take something as, as, as simple as say customer service, um, if you have to integrate with the APIs of, of distinct corporations, many of which don't even have an API."
    },
    {
      "id": 999,
      "start": 4127.88,
      "end": 4132.88,
      "text": "So you've got to make one, um, and you've got to wade through, uh, legacy software."
    },
    {
      "id": 1000,
      "start": 4132.88,
      "end": 4135.88,
      "text": "Um, that's extremely slow."
    },
    {
      "id": 1001,
      "start": 4135.88,
      "end": 4146.88,
      "text": "Um, if, however, if AI can, um, simply take whatever is given to, uh, the outsourced customer service company that they already use, um, and do customer service."
    },
    {
      "id": 1002,
      "start": 4146.88,
      "end": 4158.88,
      "text": "Um, using the apps that they already use, uh, then you, you have, you, you, you can make trans headway, uh, in, in customer service, which is, I think 1% of the world economy or something like that."
    },
    {
      "id": 1003,
      "start": 4158.88,
      "end": 4161.88,
      "text": "It's close to a trillion dollars all in for customer service."
    },
    {
      "id": 1004,
      "start": 4161.88,
      "end": 4162.88,
      "text": "Mm-hmm."
    },
    {
      "id": 1005,
      "start": 4162.88,
      "end": 4165.88,
      "text": "And, and, and, and, and there's, there's no, there's no barriers to entry."
    },
    {
      "id": 1006,
      "start": 4165.88,
      "end": 4169.88,
      "text": "It's just, you can just immediately say, well, we'll outsource it for a fraction of the cost."
    },
    {
      "id": 1007,
      "start": 4169.88,
      "end": 4170.88,
      "text": "And there's no integration needed."
    },
    {
      "id": 1008,
      "start": 4170.88,
      "end": 4182.88,
      "text": "You can imagine, um, some kind of categorization of, uh, intelligence tasks where there is breadth, where customer service is done by very many people, but, you know, many people can do it."
    },
    {
      "id": 1009,
      "start": 4182.88,
      "end": 4186.88,
      "text": "And then there's difficulty where, you know, there's a best in class turbine engine."
    },
    {
      "id": 1010,
      "start": 4186.88,
      "end": 4192.88,
      "text": "Like presumably there's a 10% more fuel efficient turbine engine that could be imagined by an intelligence, but we just haven't found it yet."
    },
    {
      "id": 1011,
      "start": 4192.88,
      "end": 4196.88,
      "text": "Or, you know, GLP ones are just, you know, a few bytes of data."
    },
    {
      "id": 1012,
      "start": 4196.88,
      "end": 4199.88,
      "text": "Where do you think you want to play in this?"
    },
    {
      "id": 1013,
      "start": 4199.88,
      "end": 4208.88,
      "text": "Is this a loss of, you know, reasonably intelligent intelligence, or is this the very pinnacle of cognitive tasks?"
    },
    {
      "id": 1014,
      "start": 4208.88,
      "end": 4215.88,
      "text": "Well, I was just using a customer service as like something that's, it's a, it's a very significant revenue stream."
    },
    {
      "id": 1015,
      "start": 4215.88,
      "end": 4218.88,
      "text": "Um, but one that is probably not super difficult to solve for."
    },
    {
      "id": 1016,
      "start": 4218.88,
      "end": 4219.88,
      "text": "Mm-hmm."
    },
    {
      "id": 1017,
      "start": 4219.88,
      "end": 4227.88,
      "text": "Um, so, uh, if you, if you, uh, can emulate a human at a, uh, at a desktop, um, that, that's just literally what customer service is."
    },
    {
      "id": 1018,
      "start": 4227.88,
      "end": 4244.88,
      "text": "Um, and, um, you know, it's, as people of average intelligence, it's not like, you know, you don't need like somebody who's, who spent many, you know, many years, you don't need like, you know, um, sort of several Sigma good engineers for that."
    },
    {
      "id": 1019,
      "start": 4244.88,
      "end": 4255.88,
      "text": "Um, but, but obviously as you make that work, um, you can then, once you have computers working effectively digital optimists working, uh, you can then run any application."
    },
    {
      "id": 1020,
      "start": 4255.88,
      "end": 4259.88,
      "text": "Um, like let's say you're trying to design, uh, chips."
    },
    {
      "id": 1021,
      "start": 4259.88,
      "end": 4268.88,
      "text": "So you can, you could then, um, run your conventional, uh, apps, uh, you know, like stuff from cadence and synopsis and whatnot."
    },
    {
      "id": 1022,
      "start": 4268.88,
      "end": 4278.88,
      "text": "Um, and you can say, uh, uh, you can, you can run a thousand simultaneously or 10,000 and say, okay, uh, given this input, I get this output for the chip."
    },
    {
      "id": 1023,
      "start": 4278.88,
      "end": 4288.88,
      "text": "Um, and, and at some point you can say, okay, I, I, you, you, you're, you're actually gonna know what the, what the chip should look like, um, without using any of the tools."
    },
    {
      "id": 1024,
      "start": 4288.88,
      "end": 4293.88,
      "text": "Um, so basically you, you, you, you should be able to do a digital chip design."
    },
    {
      "id": 1025,
      "start": 4293.88,
      "end": 4295.88,
      "text": "Like you can do chip design."
    },
    {
      "id": 1026,
      "start": 4295.88,
      "end": 4298.88,
      "text": "Like you, you, you, you watch up the difficulty curve."
    },
    {
      "id": 1027,
      "start": 4298.88,
      "end": 4303.88,
      "text": "Um, you could use your, you know, be able to do, do, to do CAD."
    },
    {
      "id": 1028,
      "start": 4303.88,
      "end": 4311.88,
      "text": "Um, so, you know, um, you could use like sort of NX or, or any, any of the CAD software to design things."
    },
    {
      "id": 1029,
      "start": 4311.88,
      "end": 4315.88,
      "text": "Okay, so you think you started the simplest tasks and walk your way up the difficulty curve."
    },
    {
      "id": 1030,
      "start": 4315.88,
      "end": 4316.88,
      "text": "Yeah."
    },
    {
      "id": 1031,
      "start": 4316.88,
      "end": 4329.88,
      "text": "Um, so you're saying, look, as, as a broader objective of having this full digital co-worker, uh, emulator, you're saying, look, all the revenue maximizing corporations want to do this, um, XAI being one of them."
    },
    {
      "id": 1032,
      "start": 4329.88,
      "end": 4333.88,
      "text": "But we will win because of a secret plan we have."
    },
    {
      "id": 1033,
      "start": 4333.88,
      "end": 4337.88,
      "text": "But like, everybody's like trying different things with data, different things with algorithms."
    },
    {
      "id": 1034,
      "start": 4337.88,
      "end": 4338.88,
      "text": "And I'm like, hmm."
    },
    {
      "id": 1035,
      "start": 4338.88,
      "end": 4339.88,
      "text": "I like that."
    },
    {
      "id": 1036,
      "start": 4339.88,
      "end": 4340.88,
      "text": "Like what is the secret plan?"
    },
    {
      "id": 1037,
      "start": 4340.88,
      "end": 4341.88,
      "text": "What else can we do?"
    },
    {
      "id": 1038,
      "start": 4341.88,
      "end": 4342.88,
      "text": "Um, but, uh, yeah."
    },
    {
      "id": 1039,
      "start": 4342.88,
      "end": 4352.88,
      "text": "It seems like a competitive field and I'm like, what is, how are you guys going to win is like my, my big question."
    },
    {
      "id": 1040,
      "start": 4352.88,
      "end": 4365.88,
      "text": "I, I, I, I think, you know, I, I, I think we see a path to doing, I mean, I think, I think I know, I think I know the path to do this because it's, it's kind of the same path that Tesla used to create self-driving."
    },
    {
      "id": 1041,
      "start": 4365.88,
      "end": 4370.88,
      "text": "Um, you know, instead of driving a car, it's driving a computer screen."
    },
    {
      "id": 1042,
      "start": 4370.88,
      "end": 4374.88,
      "text": "Um, so it's a self-driving computer essentially."
    },
    {
      "id": 1043,
      "start": 4374.88,
      "end": 4380.88,
      "text": "Oh, you're saying, is the path just following human behavior and training on vast quantities of human behavior?"
    },
    {
      "id": 1044,
      "start": 4380.88,
      "end": 4381.88,
      "text": "No."
    },
    {
      "id": 1045,
      "start": 4381.88,
      "end": 4385.88,
      "text": "But, but sorry, isn't that, I mean, isn't that, is that in training?"
    },
    {
      "id": 1046,
      "start": 4385.88,
      "end": 4390.88,
      "text": "I mean, obviously I'm not going to spell out, you know, most sensitive secrets on a podcast."
    },
    {
      "id": 1047,
      "start": 4390.88,
      "end": 4393.88,
      "text": "Uh, you know, I need to have at least three more Guinnesses for that."
    },
    {
      "id": 1048,
      "start": 4393.88,
      "end": 4399.88,
      "text": "I've got some friends at Jane Street and they're always talking about how their colleagues are cooking up fun fiendish puzzles for each other to solve."
    },
    {
      "id": 1049,
      "start": 4399.88,
      "end": 4401.88,
      "text": "Well, last week they sent me one."
    },
    {
      "id": 1050,
      "start": 4401.88,
      "end": 4408.88,
      "text": "Basically they trained a neural network and they gave me the weights of each layer, but they didn't tell me what order those layers went in."
    },
    {
      "id": 1051,
      "start": 4408.88,
      "end": 4413.88,
      "text": "And so I had to figure out the correct order using the outputs of the original network."
    },
    {
      "id": 1052,
      "start": 4413.88,
      "end": 4418.88,
      "text": "And as soon as I got this puzzle, I went to my roommate who's an AI researcher and we both got immediately nerd sniped."
    },
    {
      "id": 1053,
      "start": 4418.88,
      "end": 4424.88,
      "text": "Obviously you can't brute force a solution. The search space here is 10 to the 122 for mutations."
    },
    {
      "id": 1054,
      "start": 4424.88,
      "end": 4428.88,
      "text": "So clearly you need some way to reduce the search space."
    },
    {
      "id": 1055,
      "start": 4428.88,
      "end": 4434.88,
      "text": "Then my roommate had to go to work, but because I'm a podcaster, I had some time to take a stab at some of the ideas we discussed."
    },
    {
      "id": 1056,
      "start": 4434.88,
      "end": 4439.88,
      "text": "And with the combination of simulated annealing and greedy search, I think it got pretty close."
    },
    {
      "id": 1057,
      "start": 4439.88,
      "end": 4444.88,
      "text": "I think I'm actually just a couple of swaps and shifts away from the correct solution."
    },
    {
      "id": 1058,
      "start": 4444.88,
      "end": 4450.88,
      "text": "But what makes this puzzle really tricky is that there's no obvious way to escape from a local minimum."
    },
    {
      "id": 1059,
      "start": 4450.88,
      "end": 4455.88,
      "text": "I'm afraid that this is as far as vibe coding is going to get me, but maybe you can do better."
    },
    {
      "id": 1060,
      "start": 4455.88,
      "end": 4460.88,
      "text": "Check out the puzzle at jainestreet.com slash Thwarkesh."
    },
    {
      "id": 1061,
      "start": 4460.88,
      "end": 4462.88,
      "text": "All right, back to Elon."
    },
    {
      "id": 1062,
      "start": 4462.88,
      "end": 4465.88,
      "text": "What will XAI's business be like?"
    },
    {
      "id": 1063,
      "start": 4465.88,
      "end": 4468.88,
      "text": "Is it going to be consumer, enterprise?"
    },
    {
      "id": 1064,
      "start": 4468.88,
      "end": 4470.88,
      "text": "What's the mix of those things going to be?"
    },
    {
      "id": 1065,
      "start": 4470.88,
      "end": 4474.88,
      "text": "Is it going to be similar to other labs where you've this?"
    },
    {
      "id": 1066,
      "start": 4474.88,
      "end": 4475.88,
      "text": "You're saying labs."
    },
    {
      "id": 1067,
      "start": 4475.88,
      "end": 4476.88,
      "text": "Corporations."
    },
    {
      "id": 1068,
      "start": 4476.88,
      "end": 4477.88,
      "text": "Corporations."
    },
    {
      "id": 1069,
      "start": 4477.88,
      "end": 4479.88,
      "text": "The SIOP goes deep, Elon."
    },
    {
      "id": 1070,
      "start": 4479.88,
      "end": 4481.88,
      "text": "Revenue maximizing corporations, to be clear."
    },
    {
      "id": 1071,
      "start": 4481.88,
      "end": 4483.88,
      "text": "Those GPUs don't pay for themselves."
    },
    {
      "id": 1072,
      "start": 4483.88,
      "end": 4484.88,
      "text": "Exactly."
    },
    {
      "id": 1073,
      "start": 4484.88,
      "end": 4486.88,
      "text": "But yeah, what's the business model?"
    },
    {
      "id": 1074,
      "start": 4486.88,
      "end": 4489.88,
      "text": "What are the revenue streams in a few years' time?"
    },
    {
      "id": 1075,
      "start": 4489.88,
      "end": 4495.88,
      "text": "Things are going to change very rapidly."
    },
    {
      "id": 1076,
      "start": 4495.88,
      "end": 4498.88,
      "text": "I'm stating the obvious here."
    },
    {
      "id": 1077,
      "start": 4498.88,
      "end": 4500.88,
      "text": "I call AI the supersonic tsunami."
    },
    {
      "id": 1078,
      "start": 4500.88,
      "end": 4502.88,
      "text": "I love alliteration."
    },
    {
      "id": 1079,
      "start": 4502.88,
      "end": 4521.88,
      "text": "So really, what's going to happen is, especially when you have humanoid robots at scale, is they will just provide, they'll make products and provide services far more efficiently than human corporations."
    },
    {
      "id": 1080,
      "start": 4521.88,
      "end": 4526.88,
      "text": "So amplifying the productivity of human corporations is simply a short-term thing."
    },
    {
      "id": 1081,
      "start": 4526.88,
      "end": 4533.88,
      "text": "So you're expecting fully digital corporations rather than like SpaceX becomes part AI?"
    },
    {
      "id": 1082,
      "start": 4533.88,
      "end": 4542.88,
      "text": "I think there'll be digital corporations, but some of this is going to sound kind of doomerish."
    },
    {
      "id": 1083,
      "start": 4542.88,
      "end": 4545.88,
      "text": "Okay, but I'm just saying what I think will happen."
    },
    {
      "id": 1084,
      "start": 4545.88,
      "end": 4548.88,
      "text": "It's not meant to be doomerish or anything else."
    },
    {
      "id": 1085,
      "start": 4548.88,
      "end": 4551.88,
      "text": "Just like this is what I think will happen."
    },
    {
      "id": 1086,
      "start": 4551.88,
      "end": 4567.88,
      "text": "Is that pure AI, corporations that are purely AI and robotics will vastly outperform any corporations that have people in the loop."
    },
    {
      "id": 1087,
      "start": 4567.88,
      "end": 4574.88,
      "text": "So you can think of say, like computer used to be a job that humans had."
    },
    {
      "id": 1088,
      "start": 4574.88,
      "end": 4577.88,
      "text": "You would go and get a job as a computer where you would do calculations."
    },
    {
      "id": 1089,
      "start": 4577.88,
      "end": 4588.88,
      "text": "And they'd have like entire skyscrapers full of humans, like, you know, 20, 30 floors of humans just doing calculations."
    },
    {
      "id": 1090,
      "start": 4588.88,
      "end": 4599.88,
      "text": "Now that entire skyscraper of humans doing calculations can be replaced by a laptop with a spreadsheet."
    },
    {
      "id": 1091,
      "start": 4599.88,
      "end": 4606.88,
      "text": "That spreadsheet can do vastly more calculations than an entire building full of human computers."
    },
    {
      "id": 1092,
      "start": 4606.88,
      "end": 4618.88,
      "text": "So you can think about, okay, well, what if only some of the cells in your, some of the cells in your spreadsheet were calculated by humans?"
    },
    {
      "id": 1093,
      "start": 4618.88,
      "end": 4623.88,
      "text": "Actually, that would be much worse than if all of the cells in your spreadsheet were calculated by the computer."
    },
    {
      "id": 1094,
      "start": 4623.88,
      "end": 4638.88,
      "text": "And so really what will happen is the pure AI, pure robotics corporations or collectives will far outperform any corporations that have humans in the loop."
    },
    {
      "id": 1095,
      "start": 4638.88,
      "end": 4640.88,
      "text": "And this will happen very quickly."
    },
    {
      "id": 1096,
      "start": 4640.88,
      "end": 4645.88,
      "text": "Speaking of closing the loop, sorry, Optimus."
    },
    {
      "id": 1097,
      "start": 4645.88,
      "end": 4658.88,
      "text": "You, I mean, as far as like manufacturing targets and so forth go, your companies have sort of been like carrying American manufacturing of hard tech on their back."
    },
    {
      "id": 1098,
      "start": 4658.88,
      "end": 4666.88,
      "text": "But in the fields that you are, you know, Tesla has been dominant in your, and now you want to go into home humanoids."
    },
    {
      "id": 1099,
      "start": 4666.88,
      "end": 4676.88,
      "text": "In China, there's entire dozens and dozens of companies that are doing this kind of manufacturing cheaply and at scale and are incredibly competitive."
    },
    {
      "id": 1100,
      "start": 4676.88,
      "end": 4689.88,
      "text": "So give us sort of like advice or a plan of how America can build the humanoid armies or, you know, the EVs, et cetera, at scale and as cheaply as China is on track to."
    },
    {
      "id": 1101,
      "start": 4689.88,
      "end": 4694.88,
      "text": "Well, there are really only three hard things for human robots."
    },
    {
      "id": 1102,
      "start": 4694.88,
      "end": 4701.88,
      "text": "The real world intelligence, the hand and scale manufacturing."
    },
    {
      "id": 1103,
      "start": 4701.88,
      "end": 4713.88,
      "text": "So I haven't seen any, even demo robots that have a great hand, like with all the degrees of freedom of a human hand."
    },
    {
      "id": 1104,
      "start": 4713.88,
      "end": 4714.88,
      "text": "But Optimus will have that."
    },
    {
      "id": 1105,
      "start": 4714.88,
      "end": 4719.88,
      "text": "Optimus does have that."
    },
    {
      "id": 1106,
      "start": 4719.88,
      "end": 4721.88,
      "text": "And how do you achieve that?"
    },
    {
      "id": 1107,
      "start": 4721.88,
      "end": 4722.88,
      "text": "Is it just like right torque doesn't need the motor?"
    },
    {
      "id": 1108,
      "start": 4722.88,
      "end": 4724.88,
      "text": "Like what is the, what is the hardware bottleneck to that?"
    },
    {
      "id": 1109,
      "start": 4724.88,
      "end": 4728.88,
      "text": "Well, we have to, we're to design custom, custom actuators."
    },
    {
      "id": 1110,
      "start": 4728.88,
      "end": 4740.88,
      "text": "Basically custom designed motors, gears, power electronics, controls, sensors, everything had to be designed from physics first principles."
    },
    {
      "id": 1111,
      "start": 4740.88,
      "end": 4742.88,
      "text": "There is no supply chain for this."
    },
    {
      "id": 1112,
      "start": 4742.88,
      "end": 4744.88,
      "text": "And will you be able to manufacture those at scale?"
    },
    {
      "id": 1113,
      "start": 4744.88,
      "end": 4745.88,
      "text": "Yes."
    },
    {
      "id": 1114,
      "start": 4745.88,
      "end": 4751.88,
      "text": "Is anything hard except the hand from manipulation point of view or once you've solved the hand, are you good?"
    },
    {
      "id": 1115,
      "start": 4751.88,
      "end": 4755.88,
      "text": "From an electromechanical standpoint, the hand is more difficult than everything else combined."
    },
    {
      "id": 1116,
      "start": 4755.88,
      "end": 4758.88,
      "text": "Yeah, human hand turns out to be quite something."
    },
    {
      "id": 1117,
      "start": 4758.88,
      "end": 4761.88,
      "text": "But you also need the real world intelligence."
    },
    {
      "id": 1118,
      "start": 4761.88,
      "end": 4773.88,
      "text": "So the intelligence that tells us to develop for the car applies very well to the robot, which is, you know, primarily vision."
    },
    {
      "id": 1119,
      "start": 4773.88,
      "end": 4778.88,
      "text": "But the car takes more vision, but also it actually also is listening for sirens."
    },
    {
      "id": 1120,
      "start": 4778.88,
      "end": 4781.88,
      "text": "It's, you know, it's taking in the initial measurements."
    },
    {
      "id": 1121,
      "start": 4781.88,
      "end": 4784.88,
      "text": "It's GPS signals, a whole bunch of other data."
    },
    {
      "id": 1122,
      "start": 4784.88,
      "end": 4786.88,
      "text": "Combining that with video, it's primarily video."
    },
    {
      "id": 1123,
      "start": 4786.88,
      "end": 4790.88,
      "text": "And then outputting the control command."
    },
    {
      "id": 1124,
      "start": 4790.88,
      "end": 4801.88,
      "text": "So like, like, like, your Tesla is taking in one and a half gigabytes a second of video and outputting two kilobytes a second of control, control outputs."
    },
    {
      "id": 1125,
      "start": 4801.88,
      "end": 4806.88,
      "text": "With the video 36 hertz and the control frequency at 18."
    },
    {
      "id": 1126,
      "start": 4806.88,
      "end": 4818.88,
      "text": "One intuition you could have for when we get this robotic stuff is that it takes quite a few years to go from the compelling demo to actually being able to use in the real world."
    },
    {
      "id": 1127,
      "start": 4818.88,
      "end": 4827.88,
      "text": "So 10 years ago, you had really compelling demos of self-driving, but only now we have RoboTaxi and Waymo and all these services scaling up."
    },
    {
      "id": 1128,
      "start": 4827.88,
      "end": 4832.88,
      "text": "Doesn't this, shouldn't this make one pessimistic on, say, household robots?"
    },
    {
      "id": 1129,
      "start": 4832.88,
      "end": 4837.88,
      "text": "Because we don't even quite have the compelling demos yet of, say, the really advanced hand."
    },
    {
      "id": 1130,
      "start": 4837.88,
      "end": 4841.88,
      "text": "Well, we've been working on humanoid robots now for a while."
    },
    {
      "id": 1131,
      "start": 4841.88,
      "end": 4846.88,
      "text": "So I guess it's been five or six years or something like that."
    },
    {
      "id": 1132,
      "start": 4846.88,
      "end": 4852.88,
      "text": "And a bunch of things that we've done for the car are applicable to the robot."
    },
    {
      "id": 1133,
      "start": 4852.88,
      "end": 4860.88,
      "text": "So we'll use the same Tesla AI chips in the robot as the car."
    },
    {
      "id": 1134,
      "start": 4860.88,
      "end": 4863.88,
      "text": "We'll use the same basic principles."
    },
    {
      "id": 1135,
      "start": 4863.88,
      "end": 4866.88,
      "text": "It's very much the same AI."
    },
    {
      "id": 1136,
      "start": 4866.88,
      "end": 4870.88,
      "text": "You've got many more degrees of freedom for a robot than you do for a car."
    },
    {
      "id": 1137,
      "start": 4870.88,
      "end": 4879.88,
      "text": "But really, if you think of it as like a bootstream, AI is really mostly compression and correlation of two bootstreams."
    },
    {
      "id": 1138,
      "start": 4879.88,
      "end": 4884.88,
      "text": "So for video, you've got to do a tremendous amount of compression."
    },
    {
      "id": 1139,
      "start": 4884.88,
      "end": 4889.88,
      "text": "And you've got to do the compression just right."
    },
    {
      "id": 1140,
      "start": 4889.88,
      "end": 4894.88,
      "text": "You've got to compress the, like ignore the things that don't matter."
    },
    {
      "id": 1141,
      "start": 4894.88,
      "end": 4899.88,
      "text": "And you don't care about the details of the leaves and the tree on the side of the road."
    },
    {
      "id": 1142,
      "start": 4899.88,
      "end": 4904.88,
      "text": "But you care a lot about the road signs and the traffic lights and the pedestrians."
    },
    {
      "id": 1143,
      "start": 4904.88,
      "end": 4909.88,
      "text": "And even whether, you know, someone in another car is looking at you or not looking at you."
    },
    {
      "id": 1144,
      "start": 4909.88,
      "end": 4912.88,
      "text": "Like some of these details matter a lot."
    },
    {
      "id": 1145,
      "start": 4912.88,
      "end": 4917.88,
      "text": "So if it is essentially, it's got to turn that, the car is going to turn that one and a half gigabytes a second,"
    },
    {
      "id": 1146,
      "start": 4917.88,
      "end": 4920.88,
      "text": "ultimately into two kilobytes a second of control outputs."
    },
    {
      "id": 1147,
      "start": 4920.88,
      "end": 4925.88,
      "text": "So many stages of compression."
    },
    {
      "id": 1148,
      "start": 4925.88,
      "end": 4927.88,
      "text": "And you've got to get all those stages right."
    },
    {
      "id": 1149,
      "start": 4927.88,
      "end": 4929.88,
      "text": "And then correlate those to the correct control outputs."
    },
    {
      "id": 1150,
      "start": 4929.88,
      "end": 4931.88,
      "text": "The robot has to do essentially the same thing."
    },
    {
      "id": 1151,
      "start": 4931.88,
      "end": 4934.88,
      "text": "And you think about what humans, this is what happens with humans."
    },
    {
      "id": 1152,
      "start": 4934.88,
      "end": 4938.88,
      "text": "We really are photons in, controls out."
    },
    {
      "id": 1153,
      "start": 4938.88,
      "end": 4946.88,
      "text": "So that is the vast majority of your life has been vision, photons in, and then motor controls out."
    },
    {
      "id": 1154,
      "start": 4946.88,
      "end": 4955.88,
      "text": "Naively, it seems like between humanoid robots and cars, the fundamental actuators in a car are like how you turn, how you accelerate, et cetera."
    },
    {
      "id": 1155,
      "start": 4955.88,
      "end": 4961.88,
      "text": "Where in a robot, especially with maneuverable arms, there's dozens and dozens of these degrees of freedom."
    },
    {
      "id": 1156,
      "start": 4961.88,
      "end": 4969.88,
      "text": "And then especially with Tesla, you had this advantage of like you had millions and millions of hours of human demo data collected from just the car being out there."
    },
    {
      "id": 1157,
      "start": 4969.88,
      "end": 4974.88,
      "text": "Where like you can't equivalently just deploy optimists that don't work and then get the data that way."
    },
    {
      "id": 1158,
      "start": 4974.88,
      "end": 4978.88,
      "text": "So between the increased degrees of freedom and the far sparser data."
    },
    {
      "id": 1159,
      "start": 4978.88,
      "end": 4979.88,
      "text": "Yes."
    },
    {
      "id": 1160,
      "start": 4979.88,
      "end": 4980.88,
      "text": "That's a good point."
    },
    {
      "id": 1161,
      "start": 4980.88,
      "end": 4988.88,
      "text": "How will you use the sort of Tesla engine of intelligence to train the optimist mind?"
    },
    {
      "id": 1162,
      "start": 4988.88,
      "end": 4995.88,
      "text": "Actually, you're highlighting an important limitation and difference between cars."
    },
    {
      "id": 1163,
      "start": 4995.88,
      "end": 4999.88,
      "text": "It's like we do have, we'll soon have like 10 million cars on the road."
    },
    {
      "id": 1164,
      "start": 4999.88,
      "end": 5007.88,
      "text": "And so it's hard to duplicate that like massive training flywheel."
    },
    {
      "id": 1165,
      "start": 5007.88,
      "end": 5019.88,
      "text": "For the robot, what we're going to need to do is build a lot of robots and put them in kind of like an optimist academy so they can do self play in reality."
    },
    {
      "id": 1166,
      "start": 5019.88,
      "end": 5022.88,
      "text": "So we're actually pulling that out."
    },
    {
      "id": 1167,
      "start": 5022.88,
      "end": 5032.88,
      "text": "So we're going to have at least 10,000 optimist robots, maybe 20 or 30,000 that are doing self play and testing different tasks."
    },
    {
      "id": 1168,
      "start": 5032.88,
      "end": 5043.88,
      "text": "And then the Tesla has quite a good reality generator, like a physics accurate reality generator that we made, made this for the cars."
    },
    {
      "id": 1169,
      "start": 5043.88,
      "end": 5047.88,
      "text": "We'll do the same thing for the robots and actually have done that for the robots."
    },
    {
      "id": 1170,
      "start": 5047.88,
      "end": 5056.88,
      "text": "So, so you have, you know, a few tens of thousands of humanoid robots doing different tasks."
    },
    {
      "id": 1171,
      "start": 5056.88,
      "end": 5062.88,
      "text": "And then you've got, you can do millions of simulated robots in the simulated world."
    },
    {
      "id": 1172,
      "start": 5062.88,
      "end": 5071.88,
      "text": "And you use the tens of thousands of robots in the real world to close the simulation to reality gap, close the sim to real gap."
    },
    {
      "id": 1173,
      "start": 5071.88,
      "end": 5081.88,
      "text": "How do you think about the synergies between XAI and optimist, given you were highlighting, look, you need this world model, you maybe want to use some really smart intelligence as the control plane."
    },
    {
      "id": 1174,
      "start": 5081.88,
      "end": 5086.88,
      "text": "And so maybe Grok is like doing the slower planning and then like the motor policy is at the lower level."
    },
    {
      "id": 1175,
      "start": 5086.88,
      "end": 5087.88,
      "text": "Yeah."
    },
    {
      "id": 1176,
      "start": 5087.88,
      "end": 5091.88,
      "text": "What will the sort of synergy between these things be?"
    },
    {
      "id": 1177,
      "start": 5091.88,
      "end": 5092.88,
      "text": "Yeah."
    },
    {
      "id": 1178,
      "start": 5092.88,
      "end": 5096.88,
      "text": "So you'd use Grok would orchestrate the behavior of the optimist robots."
    },
    {
      "id": 1179,
      "start": 5096.88,
      "end": 5100.88,
      "text": "So let's say you wanted to build a factory."
    },
    {
      "id": 1180,
      "start": 5100.88,
      "end": 5114.88,
      "text": "Then Optimus, then Grok could organize the optimist robots, give them, assign them tasks to build the factory for, to produce whatever you want."
    },
    {
      "id": 1181,
      "start": 5114.88,
      "end": 5117.88,
      "text": "Don't you need to merge XAI and Tesla then?"
    },
    {
      "id": 1182,
      "start": 5117.88,
      "end": 5118.88,
      "text": "Because these things end up so..."
    },
    {
      "id": 1183,
      "start": 5118.88,
      "end": 5121.88,
      "text": "What were we saying earlier about public company discussions?"
    },
    {
      "id": 1184,
      "start": 5121.88,
      "end": 5123.88,
      "text": "Well, we're one more Guinness in, Elon."
    },
    {
      "id": 1185,
      "start": 5123.88,
      "end": 5132.88,
      "text": "What are you waiting to see before you say, we want to manufacture 100,000 optimists?"
    },
    {
      "id": 1186,
      "start": 5132.88,
      "end": 5133.88,
      "text": "Is it like..."
    },
    {
      "id": 1187,
      "start": 5133.88,
      "end": 5134.88,
      "text": "Optimize."
    },
    {
      "id": 1188,
      "start": 5134.88,
      "end": 5139.88,
      "text": "Since we're defining the proper noun, we could define the plural of the proper noun too."
    },
    {
      "id": 1189,
      "start": 5139.88,
      "end": 5142.88,
      "text": "So we're going to proper noun the plural and so it's optimize."
    },
    {
      "id": 1190,
      "start": 5142.88,
      "end": 5143.88,
      "text": "Okay."
    },
    {
      "id": 1191,
      "start": 5143.88,
      "end": 5146.88,
      "text": "Is there something on the hardware side you want to see?"
    },
    {
      "id": 1192,
      "start": 5146.88,
      "end": 5148.88,
      "text": "Do you want to see better actuators?"
    },
    {
      "id": 1193,
      "start": 5148.88,
      "end": 5150.88,
      "text": "Or is it just you want the software to be better?"
    },
    {
      "id": 1194,
      "start": 5150.88,
      "end": 5153.88,
      "text": "What are we waiting for before we get like mass manufacturing of Gen 3?"
    },
    {
      "id": 1195,
      "start": 5153.88,
      "end": 5154.88,
      "text": "No, we're moving towards that."
    },
    {
      "id": 1196,
      "start": 5154.88,
      "end": 5157.88,
      "text": "We're going forward with mass manufacturing."
    },
    {
      "id": 1197,
      "start": 5157.88,
      "end": 5161.88,
      "text": "But you think current hardware is good enough that you are going to..."
    },
    {
      "id": 1198,
      "start": 5161.88,
      "end": 5164.88,
      "text": "You just want to deploy as many as possible now?"
    },
    {
      "id": 1199,
      "start": 5164.88,
      "end": 5167.88,
      "text": "I mean, it's very hard to scale up production."
    },
    {
      "id": 1200,
      "start": 5167.88,
      "end": 5168.88,
      "text": "I see."
    },
    {
      "id": 1201,
      "start": 5168.88,
      "end": 5179.88,
      "text": "But yeah, I think Optimus 3 is the right version of the robot to produce maybe something on the order of like a million units a year."
    },
    {
      "id": 1202,
      "start": 5179.88,
      "end": 5182.88,
      "text": "I think you'd want to go to Optimus 4 before you went to 10 million units a year."
    },
    {
      "id": 1203,
      "start": 5182.88,
      "end": 5184.88,
      "text": "Okay, but you can do a million a year at Optimus 3."
    },
    {
      "id": 1204,
      "start": 5184.88,
      "end": 5185.88,
      "text": "Yeah."
    },
    {
      "id": 1205,
      "start": 5185.88,
      "end": 5187.88,
      "text": "I mean, it's very hard to spool up manufacturing."
    },
    {
      "id": 1206,
      "start": 5187.88,
      "end": 5188.88,
      "text": "Yes."
    },
    {
      "id": 1207,
      "start": 5188.88,
      "end": 5197.88,
      "text": "So like manufacturing, like the output per unit time always follows an S-curve."
    },
    {
      "id": 1208,
      "start": 5197.88,
      "end": 5209.88,
      "text": "So it starts off agonizingly slow, then it has this sort of exponential increase, then a linear, then a logarithmic outcome until you sort of eventually asymptote it to a number."
    },
    {
      "id": 1209,
      "start": 5209.88,
      "end": 5218.88,
      "text": "Optimus initial production will be, it's going to be a stretched out S-curve because so much of what goes into Optimus is brand new."
    },
    {
      "id": 1210,
      "start": 5218.88,
      "end": 5220.88,
      "text": "There's not an existing supply chain."
    },
    {
      "id": 1211,
      "start": 5220.88,
      "end": 5228.88,
      "text": "As I mentioned, the actuators, electronics, everything in the Optimus robot is designed for physics first principles."
    },
    {
      "id": 1212,
      "start": 5228.88,
      "end": 5230.88,
      "text": "It's not taken from a catalog."
    },
    {
      "id": 1213,
      "start": 5230.88,
      "end": 5234.88,
      "text": "These are custom designed everything, literally everything."
    },
    {
      "id": 1214,
      "start": 5234.88,
      "end": 5236.88,
      "text": "I don't think there's a single thing that-"
    },
    {
      "id": 1215,
      "start": 5236.88,
      "end": 5238.88,
      "text": "How far down does that go?"
    },
    {
      "id": 1216,
      "start": 5238.88,
      "end": 5243.88,
      "text": "I mean, I guess we're not making custom capacitors yet, maybe."
    },
    {
      "id": 1217,
      "start": 5243.88,
      "end": 5251.88,
      "text": "But there's nothing you can pick out of a catalog at any price."
    },
    {
      "id": 1218,
      "start": 5251.88,
      "end": 5268.88,
      "text": "So it just means that the Optimus S-curve, the units per output per unit time, how many Optimus robots you make per day, whatever, is going to initially"
    },
    {
      "id": 1219,
      "start": 5268.88,
      "end": 5274.88,
      "text": "ramp slower than a product where you have an existing supply chain."
    },
    {
      "id": 1220,
      "start": 5274.88,
      "end": 5275.88,
      "text": "But it will get to a million."
    },
    {
      "id": 1221,
      "start": 5275.88,
      "end": 5289.88,
      "text": "When you see these Chinese humanoids, like Unitri or whatever, sell humanoids for like 6K or 13K, do you just like, are you hoping to get your Optimus's bill of materials below that price so you can do the same thing?"
    },
    {
      "id": 1222,
      "start": 5289.88,
      "end": 5291.88,
      "text": "Or do you just think qualitatively they're not the same thing?"
    },
    {
      "id": 1223,
      "start": 5291.88,
      "end": 5295.88,
      "text": "Like, what do you think is going, like, what allows it, what allows them to sell for so low?"
    },
    {
      "id": 1224,
      "start": 5295.88,
      "end": 5297.88,
      "text": "And can we match that?"
    },
    {
      "id": 1225,
      "start": 5297.88,
      "end": 5307.88,
      "text": "Well, Optimus, our Optimus is designed to have a lot of intelligence and to have the same electromechanical dexterity, if not higher than a human."
    },
    {
      "id": 1226,
      "start": 5307.88,
      "end": 5310.88,
      "text": "So Unitri does not have that."
    },
    {
      "id": 1227,
      "start": 5310.88,
      "end": 5314.88,
      "text": "And it's also, I mean, it's quite a big robot."
    },
    {
      "id": 1228,
      "start": 5314.88,
      "end": 5325.88,
      "text": "It has to do, you know, carry heavy objects for long periods of time and not overheat or exceed the power of its actuators."
    },
    {
      "id": 1229,
      "start": 5325.88,
      "end": 5330.88,
      "text": "So we've got, you know, it's 5'11\"."
    },
    {
      "id": 1230,
      "start": 5330.88,
      "end": 5331.88,
      "text": "It's 5'11\"."
    },
    {
      "id": 1231,
      "start": 5331.88,
      "end": 5333.88,
      "text": "You know, it's just pretty tall."
    },
    {
      "id": 1232,
      "start": 5333.88,
      "end": 5334.88,
      "text": "Yeah."
    },
    {
      "id": 1233,
      "start": 5334.88,
      "end": 5336.88,
      "text": "And it's got a lot of intelligence."
    },
    {
      "id": 1234,
      "start": 5336.88,
      "end": 5340.88,
      "text": "So it's going to be more expensive than a small robot that is not intelligent."
    },
    {
      "id": 1235,
      "start": 5340.88,
      "end": 5341.88,
      "text": "But more capable."
    },
    {
      "id": 1236,
      "start": 5341.88,
      "end": 5342.88,
      "text": "Yeah."
    },
    {
      "id": 1237,
      "start": 5342.88,
      "end": 5343.88,
      "text": "But not a lot more."
    },
    {
      "id": 1238,
      "start": 5343.88,
      "end": 5350.88,
      "text": "I mean, like, over time, as Optimus robots build Optimus robots, the cost will drop very quickly."
    },
    {
      "id": 1239,
      "start": 5350.88,
      "end": 5355.88,
      "text": "And what will these first billion Optimuses, Optimai, do?"
    },
    {
      "id": 1240,
      "start": 5355.88,
      "end": 5357.88,
      "text": "Like, what will their highest and best use be?"
    },
    {
      "id": 1241,
      "start": 5357.88,
      "end": 5361.88,
      "text": "I think you would start off with simple tasks that you can count on them doing well."
    },
    {
      "id": 1242,
      "start": 5361.88,
      "end": 5363.88,
      "text": "But in the home or in factories?"
    },
    {
      "id": 1243,
      "start": 5363.88,
      "end": 5371.88,
      "text": "The best use for robots in the beginning will be any continuous operation."
    },
    {
      "id": 1244,
      "start": 5371.88,
      "end": 5375.88,
      "text": "So any 24 by 7 operation, because they can work continuously."
    },
    {
      "id": 1245,
      "start": 5375.88,
      "end": 5381.88,
      "text": "What fraction of the work at a Gigafactory that is currently done by humans could a Gen 3 do?"
    },
    {
      "id": 1246,
      "start": 5381.88,
      "end": 5382.88,
      "text": "I'm not sure."
    },
    {
      "id": 1247,
      "start": 5382.88,
      "end": 5384.88,
      "text": "Maybe it's like 10, 20%."
    },
    {
      "id": 1248,
      "start": 5384.88,
      "end": 5385.88,
      "text": "Maybe more."
    },
    {
      "id": 1249,
      "start": 5385.88,
      "end": 5386.88,
      "text": "I don't know."
    },
    {
      "id": 1250,
      "start": 5386.88,
      "end": 5391.88,
      "text": "We would use, we would not like reduce our head count."
    },
    {
      "id": 1251,
      "start": 5391.88,
      "end": 5394.88,
      "text": "We would, we would, for sure, increase our head count to be clear."
    },
    {
      "id": 1252,
      "start": 5394.88,
      "end": 5395.88,
      "text": "Right."
    },
    {
      "id": 1253,
      "start": 5395.88,
      "end": 5397.88,
      "text": "But we would increase our output."
    },
    {
      "id": 1254,
      "start": 5397.88,
      "end": 5404.88,
      "text": "So the, the units produced per human, like the total, the total number of humans at Tesla will increase."
    },
    {
      "id": 1255,
      "start": 5404.88,
      "end": 5415.88,
      "text": "But the, the output of robots and cars will increase, will increase disproportionate, like much, much to, you know,"
    },
    {
      "id": 1256,
      "start": 5415.88,
      "end": 5419.88,
      "text": "the number of cars and robots produced per human will increase dramatically."
    },
    {
      "id": 1257,
      "start": 5419.88,
      "end": 5421.88,
      "text": "But the number of humans will increase as well."
    },
    {
      "id": 1258,
      "start": 5421.88,
      "end": 5425.88,
      "text": "We're talking about Chinese manufacturing a bunch here."
    },
    {
      "id": 1259,
      "start": 5425.88,
      "end": 5434.88,
      "text": "And we're also talking about, you know, we've talked about some of the policies that are relevant, like you mentioned, the, the solar tariffs."
    },
    {
      "id": 1260,
      "start": 5434.88,
      "end": 5435.88,
      "text": "Yeah."
    },
    {
      "id": 1261,
      "start": 5435.88,
      "end": 5440.88,
      "text": "And you think they're a bad idea because, you know, we can't scale up solar in the US."
    },
    {
      "id": 1262,
      "start": 5440.88,
      "end": 5444.88,
      "text": "Well, just electricity output in the US needs to scale up."
    },
    {
      "id": 1263,
      "start": 5444.88,
      "end": 5445.88,
      "text": "Right."
    },
    {
      "id": 1264,
      "start": 5445.88,
      "end": 5447.88,
      "text": "We can't without like good power sources."
    },
    {
      "id": 1265,
      "start": 5447.88,
      "end": 5448.88,
      "text": "Yeah."
    },
    {
      "id": 1266,
      "start": 5448.88,
      "end": 5449.88,
      "text": "You just need to get it somehow."
    },
    {
      "id": 1267,
      "start": 5449.88,
      "end": 5450.88,
      "text": "Yeah."
    },
    {
      "id": 1268,
      "start": 5450.88,
      "end": 5455.88,
      "text": "But where I was going with this is if you were in charge, if you were setting all the policies, what else would you change?"
    },
    {
      "id": 1269,
      "start": 5455.88,
      "end": 5459.88,
      "text": "So you change the solar tariffs as well."
    },
    {
      "id": 1270,
      "start": 5459.88,
      "end": 5460.88,
      "text": "Yeah."
    },
    {
      "id": 1271,
      "start": 5460.88,
      "end": 5467.88,
      "text": "I would say anything that is a limiting factor for electricity needs to be addressed, provided it is not like very bad for the environment."
    },
    {
      "id": 1272,
      "start": 5467.88,
      "end": 5470.88,
      "text": "So presumably some permitting reforms and stuff as well will be in there."
    },
    {
      "id": 1273,
      "start": 5470.88,
      "end": 5471.88,
      "text": "Yeah."
    },
    {
      "id": 1274,
      "start": 5471.88,
      "end": 5473.88,
      "text": "There's a fair bit of permitting reforms that are happening."
    },
    {
      "id": 1275,
      "start": 5473.88,
      "end": 5477.88,
      "text": "A lot of the permitting is state-based, so, but anything better."
    },
    {
      "id": 1276,
      "start": 5477.88,
      "end": 5482.88,
      "text": "But this, this administration is, is good at removing permitting roadblocks."
    },
    {
      "id": 1277,
      "start": 5482.88,
      "end": 5483.88,
      "text": "Okay."
    },
    {
      "id": 1278,
      "start": 5483.88,
      "end": 5485.88,
      "text": "And I'm not saying all tariffs are bad."
    },
    {
      "id": 1279,
      "start": 5485.88,
      "end": 5486.88,
      "text": "I'm just saying because I think-"
    },
    {
      "id": 1280,
      "start": 5486.88,
      "end": 5487.88,
      "text": "Solar tariffs."
    },
    {
      "id": 1281,
      "start": 5487.88,
      "end": 5488.88,
      "text": "Yeah."
    },
    {
      "id": 1282,
      "start": 5488.88,
      "end": 5489.88,
      "text": "So yeah."
    },
    {
      "id": 1283,
      "start": 5489.88,
      "end": 5490.88,
      "text": "Yeah."
    },
    {
      "id": 1284,
      "start": 5490.88,
      "end": 5501.88,
      "text": "I mean, sometimes if like, if another country is subsidizing the output of something, then, then you have to have countervailing tariffs to protect domestic industry against subsidies by another country."
    },
    {
      "id": 1285,
      "start": 5501.88,
      "end": 5502.88,
      "text": "What else would you change?"
    },
    {
      "id": 1286,
      "start": 5502.88,
      "end": 5505.88,
      "text": "I don't know if there's that much that the government can actually do."
    },
    {
      "id": 1287,
      "start": 5505.88,
      "end": 5522.88,
      "text": "One thing I was wondering is, it seems like the, for the policy goal of creating a lease for the US versus China, it seems like the export bands have actually been quite impactful."
    },
    {
      "id": 1288,
      "start": 5522.88,
      "end": 5527.88,
      "text": "Where China's not producing leading edge chips and the export bands really bite there."
    },
    {
      "id": 1289,
      "start": 5527.88,
      "end": 5531.88,
      "text": "China's not producing leading edge turbine engines."
    },
    {
      "id": 1290,
      "start": 5531.88,
      "end": 5535.88,
      "text": "And similarly, there's a bunch of export bands that are relevant there on some of the metallurgy."
    },
    {
      "id": 1291,
      "start": 5535.88,
      "end": 5537.88,
      "text": "Should there be more export bands?"
    },
    {
      "id": 1292,
      "start": 5537.88,
      "end": 5541.88,
      "text": "Like, if you think about things like, I mean, there are now with the drone industry and things like that."
    },
    {
      "id": 1293,
      "start": 5541.88,
      "end": 5543.88,
      "text": "But is that something that should be considered?"
    },
    {
      "id": 1294,
      "start": 5543.88,
      "end": 5548.88,
      "text": "Well, I think it's important to appreciate that in most areas, China is very advanced in manufacturing."
    },
    {
      "id": 1295,
      "start": 5548.88,
      "end": 5551.88,
      "text": "There's only a few areas where it is not."
    },
    {
      "id": 1296,
      "start": 5551.88,
      "end": 5558.88,
      "text": "China is a manufacturing powerhouse next level."
    },
    {
      "id": 1297,
      "start": 5558.88,
      "end": 5560.88,
      "text": "Like, people don't, most people don't."
    },
    {
      "id": 1298,
      "start": 5560.88,
      "end": 5561.88,
      "text": "It's very impressive."
    },
    {
      "id": 1299,
      "start": 5561.88,
      "end": 5562.88,
      "text": "Yeah."
    },
    {
      "id": 1300,
      "start": 5562.88,
      "end": 5578.88,
      "text": "I mean, if you take like refining of ore, I'd say roughly China does more, does twice as much ore refining on average as the rest of the world combined."
    },
    {
      "id": 1301,
      "start": 5578.88,
      "end": 5583.88,
      "text": "And I think there's some areas like, say, refining gallium, which goes into solar cells."
    },
    {
      "id": 1302,
      "start": 5583.88,
      "end": 5587.88,
      "text": "I think there are like 98% of gallium refining."
    },
    {
      "id": 1303,
      "start": 5587.88,
      "end": 5592.88,
      "text": "So China is actually very advanced in manufacturing in, I'd say, most areas."
    },
    {
      "id": 1304,
      "start": 5592.88,
      "end": 5599.88,
      "text": "It seems like we're, like, there is discomfort with this supply chain dependence, and yet nothing's really happening on it."
    },
    {
      "id": 1305,
      "start": 5599.88,
      "end": 5601.88,
      "text": "Supply chain, which supply chain depends?"
    },
    {
      "id": 1306,
      "start": 5601.88,
      "end": 5603.88,
      "text": "Depends on, say, like the gallium refining that you're saying."
    },
    {
      "id": 1307,
      "start": 5603.88,
      "end": 5604.88,
      "text": "Yeah, yeah."
    },
    {
      "id": 1308,
      "start": 5604.88,
      "end": 5606.88,
      "text": "There's a, there's a..."
    },
    {
      "id": 1309,
      "start": 5606.88,
      "end": 5608.88,
      "text": "All the rare earth stuff and..."
    },
    {
      "id": 1310,
      "start": 5608.88,
      "end": 5609.88,
      "text": "Yeah."
    },
    {
      "id": 1311,
      "start": 5609.88,
      "end": 5611.88,
      "text": "Rare earths which are, as you know, not rare."
    },
    {
      "id": 1312,
      "start": 5611.88,
      "end": 5612.88,
      "text": "Yeah."
    },
    {
      "id": 1313,
      "start": 5612.88,
      "end": 5623.88,
      "text": "Like we actually had to do rare earth ore mining in the US, send the rock, put it on a train, and then put it on a boat to China."
    },
    {
      "id": 1314,
      "start": 5623.88,
      "end": 5634.88,
      "text": "There's another train that goes to the rare earth refining, refiners in China who then refine it, put it into a magnet, put it into a motor cell assembly, and then send it back to America."
    },
    {
      "id": 1315,
      "start": 5634.88,
      "end": 5639.88,
      "text": "So the thing, we're really missing a lot of ore refining in America."
    },
    {
      "id": 1316,
      "start": 5639.88,
      "end": 5641.88,
      "text": "Isn't this worth a policy intervention?"
    },
    {
      "id": 1317,
      "start": 5641.88,
      "end": 5642.88,
      "text": "Yes."
    },
    {
      "id": 1318,
      "start": 5642.88,
      "end": 5646.88,
      "text": "Well, I think there are some things being done on that front."
    },
    {
      "id": 1319,
      "start": 5646.88,
      "end": 5647.88,
      "text": "Mm-hmm."
    },
    {
      "id": 1320,
      "start": 5647.88,
      "end": 5654.88,
      "text": "But we kind of need Optimus, frankly, to build ore refineries."
    },
    {
      "id": 1321,
      "start": 5654.88,
      "end": 5660.88,
      "text": "So, so you think the main advantage China has is the abundance of skilled labor?"
    },
    {
      "id": 1322,
      "start": 5660.88,
      "end": 5661.88,
      "text": "Yes."
    },
    {
      "id": 1323,
      "start": 5661.88,
      "end": 5663.88,
      "text": "And that's like, that's the thing Optimus fixes."
    },
    {
      "id": 1324,
      "start": 5663.88,
      "end": 5664.88,
      "text": "But also we need the skilled labor..."
    },
    {
      "id": 1325,
      "start": 5664.88,
      "end": 5665.88,
      "text": "China's got like four times our population."
    },
    {
      "id": 1326,
      "start": 5665.88,
      "end": 5666.88,
      "text": "But we need..."
    },
    {
      "id": 1327,
      "start": 5666.88,
      "end": 5677.88,
      "text": "So, I mean, there's this concern if you think like human is of the future that like, okay, right now, if it's the skilled laborers for manufacturing that's determining who can build more humanoids."
    },
    {
      "id": 1328,
      "start": 5677.88,
      "end": 5678.88,
      "text": "You know, China has more of those."
    },
    {
      "id": 1329,
      "start": 5678.88,
      "end": 5680.88,
      "text": "It manufactures more humanoids."
    },
    {
      "id": 1330,
      "start": 5680.88,
      "end": 5683.88,
      "text": "Therefore, it gets the Optimus future first."
    },
    {
      "id": 1331,
      "start": 5683.88,
      "end": 5684.88,
      "text": "Well, we'll see."
    },
    {
      "id": 1332,
      "start": 5684.88,
      "end": 5686.88,
      "text": "And it just like keeps that exponential going."
    },
    {
      "id": 1333,
      "start": 5686.88,
      "end": 5687.88,
      "text": "Maybe."
    },
    {
      "id": 1334,
      "start": 5687.88,
      "end": 5695.88,
      "text": "It seems like you're sort of pointing out that sort of getting to a million Optimus requires the manufacturing that the Optimus is supposed to help us get to, right?"
    },
    {
      "id": 1335,
      "start": 5695.88,
      "end": 5698.88,
      "text": "You can close that recursive loop pretty quickly."
    },
    {
      "id": 1336,
      "start": 5698.88,
      "end": 5700.88,
      "text": "With a small number of Optimus."
    },
    {
      "id": 1337,
      "start": 5700.88,
      "end": 5701.88,
      "text": "Yeah."
    },
    {
      "id": 1338,
      "start": 5701.88,
      "end": 5706.88,
      "text": "So you close the recursive loop to help the robots build the robots."
    },
    {
      "id": 1339,
      "start": 5706.88,
      "end": 5710.88,
      "text": "And then we can, you know, try to get to tens of millions of units a year."
    },
    {
      "id": 1340,
      "start": 5710.88,
      "end": 5717.88,
      "text": "Maybe if you start getting to hundreds of millions of units a year, I think you're going to be the most competitive country by far."
    },
    {
      "id": 1341,
      "start": 5717.88,
      "end": 5721.88,
      "text": "We definitely can't win with just humans because China has four times our population."
    },
    {
      "id": 1342,
      "start": 5721.88,
      "end": 5722.88,
      "text": "Right."
    },
    {
      "id": 1343,
      "start": 5722.88,
      "end": 5730.88,
      "text": "And frankly, America has been running for so long that we, you know, just like a, like a pro sports team that's been running for a very long time tend to get complacent and entitled."
    },
    {
      "id": 1344,
      "start": 5730.88,
      "end": 5736.88,
      "text": "And that's why they stopped winning because it's, you know, don't work as hard anymore."
    },
    {
      "id": 1345,
      "start": 5736.88,
      "end": 5743.88,
      "text": "So I think the, frankly, just my observation is the average work ethic in China is higher than in the US."
    },
    {
      "id": 1346,
      "start": 5743.88,
      "end": 5747.88,
      "text": "So it's not just that there's four times the population, but the work, the amount of work that people put in is higher."
    },
    {
      "id": 1347,
      "start": 5747.88,
      "end": 5761.88,
      "text": "So you can like, you can try to rearrange the humans, but you're still one quarter of the, you know, assuming that the productivity is the health is the same, which I think actually it might not be."
    },
    {
      "id": 1348,
      "start": 5761.88,
      "end": 5762.88,
      "text": "Yeah."
    },
    {
      "id": 1349,
      "start": 5762.88,
      "end": 5765.88,
      "text": "So we can manage on productivity for person."
    },
    {
      "id": 1350,
      "start": 5765.88,
      "end": 5768.88,
      "text": "We will do one quarter of the amount of things as China."
    },
    {
      "id": 1351,
      "start": 5768.88,
      "end": 5770.88,
      "text": "So, so we, we can't win on the human front."
    },
    {
      "id": 1352,
      "start": 5770.88,
      "end": 5772.88,
      "text": "And our birth rates been low for a long time."
    },
    {
      "id": 1353,
      "start": 5772.88,
      "end": 5782.88,
      "text": "So, uh, birth rates been the US birth rates been below replacement, uh, since roughly 1971."
    },
    {
      "id": 1354,
      "start": 5782.88,
      "end": 5794.88,
      "text": "Um, so, so we, we've got a lot of people retiring or, you know, more people dying than, than, than, than we're close to sort of more people domestically dying than, than being born."
    },
    {
      "id": 1355,
      "start": 5794.88,
      "end": 5799.88,
      "text": "Um, so we definitely can't win on the human front, but we, we might have a shot at the robot front."
    },
    {
      "id": 1356,
      "start": 5799.88,
      "end": 5809.88,
      "text": "Are there other things that you have wanted to manufacture in the past, but they've been too labor intensive or too expensive that now you can come back to and say, oh, we can finally do the."
    },
    {
      "id": 1357,
      "start": 5809.88,
      "end": 5810.88,
      "text": "Whatever."
    },
    {
      "id": 1358,
      "start": 5810.88,
      "end": 5812.88,
      "text": "Uh, cause we have optimists."
    },
    {
      "id": 1359,
      "start": 5812.88,
      "end": 5813.88,
      "text": "Yeah."
    },
    {
      "id": 1360,
      "start": 5813.88,
      "end": 5817.88,
      "text": "I think we'd like to do more, build more, um, or a fineries, a Tesla."
    },
    {
      "id": 1361,
      "start": 5817.88,
      "end": 5828.88,
      "text": "So, um, we just completed, um, construction and have, um, begun lithium refining, um, it without lithium refinery and Corpus Christi, Texas."
    },
    {
      "id": 1362,
      "start": 5828.88,
      "end": 5832.88,
      "text": "Uh, we have, um, a nickel refinery, which is for the cathode."
    },
    {
      "id": 1363,
      "start": 5832.88,
      "end": 5834.88,
      "text": "Uh, that's here in Austin."
    },
    {
      "id": 1364,
      "start": 5834.88,
      "end": 5838.88,
      "text": "Um, and, uh, these are, these are the largest."
    },
    {
      "id": 1365,
      "start": 5838.88,
      "end": 5847.88,
      "text": "This is the largest cathode, this is the largest cathode refinery, largest lithium refinery, largest nickel and lithium refinery, uh, outside of China."
    },
    {
      "id": 1366,
      "start": 5847.88,
      "end": 5858.88,
      "text": "Um, and, uh, it's like the, you know, the cathode team would say like, we have, uh, the, the largest and the only actually, uh, cathode refinery in America."
    },
    {
      "id": 1367,
      "start": 5858.88,
      "end": 5859.88,
      "text": "Many supermanives."
    },
    {
      "id": 1368,
      "start": 5859.88,
      "end": 5861.88,
      "text": "Not just the largest, but it's also the only."
    },
    {
      "id": 1369,
      "start": 5861.88,
      "end": 5865.88,
      "text": "So it was pretty big, even though it's the only one."
    },
    {
      "id": 1370,
      "start": 5865.88,
      "end": 5880.88,
      "text": "Um, but I mean, there are other things that, uh, you know, um, you, you, you could do a lot more refineries and, and, um, help the, the help America be more competitive on refining capacity."
    },
    {
      "id": 1371,
      "start": 5880.88,
      "end": 5889.88,
      "text": "So, so there's like, there's basically a lot of work for the opt-mine to do, uh, that, that most Americans, very few Americans frankly, want to do."
    },
    {
      "id": 1372,
      "start": 5889.88,
      "end": 5891.88,
      "text": "Uh, I mean, I've, I've actually."
    },
    {
      "id": 1373,
      "start": 5891.88,
      "end": 5893.88,
      "text": "Is the refining work too dirty or what's the?"
    },
    {
      "id": 1374,
      "start": 5893.88,
      "end": 5900.88,
      "text": "It's not, it's actually, no, we don't, um, there's not, we don't have toxic emissions from the refinery or anything."
    },
    {
      "id": 1375,
      "start": 5900.88,
      "end": 5906.88,
      "text": "Um, so the cathode, nickel refineries were sort of in Travis County, like five minutes from."
    },
    {
      "id": 1376,
      "start": 5906.88,
      "end": 5908.88,
      "text": "Why can't you do it with humans?"
    },
    {
      "id": 1377,
      "start": 5908.88,
      "end": 5910.88,
      "text": "No, you, you can't, you run out of humans."
    },
    {
      "id": 1378,
      "start": 5910.88,
      "end": 5911.88,
      "text": "Ah, I see."
    },
    {
      "id": 1379,
      "start": 5911.88,
      "end": 5912.88,
      "text": "Okay."
    },
    {
      "id": 1380,
      "start": 5912.88,
      "end": 5913.88,
      "text": "Yeah."
    },
    {
      "id": 1381,
      "start": 5913.88,
      "end": 5915.88,
      "text": "Like no matter what you do, you, you have one quarter of the number of humans in America and China."
    },
    {
      "id": 1382,
      "start": 5915.88,
      "end": 5918.88,
      "text": "So if you have them do this thing, they can't do the other thing."
    },
    {
      "id": 1383,
      "start": 5918.88,
      "end": 5922.88,
      "text": "So, so then, um, well, how do you, how do you build this refining, refining capacity?"
    },
    {
      "id": 1384,
      "start": 5922.88,
      "end": 5924.88,
      "text": "Well, you can do it with the opt-mine."
    },
    {
      "id": 1385,
      "start": 5924.88,
      "end": 5932.88,
      "text": "Um, and, um, not many, not very many, not very many Americans are, are pining to do refining."
    },
    {
      "id": 1386,
      "start": 5932.88,
      "end": 5937.88,
      "text": "I mean, how many of you are on it too?"
    },
    {
      "id": 1387,
      "start": 5937.88,
      "end": 5938.88,
      "text": "Very few."
    },
    {
      "id": 1388,
      "start": 5938.88,
      "end": 5941.88,
      "text": "Very few are planning to refine."
    },
    {
      "id": 1389,
      "start": 5941.88,
      "end": 5946.88,
      "text": "You know, BYD is reaching Tesla production or sales in quantity."
    },
    {
      "id": 1390,
      "start": 5946.88,
      "end": 5953.88,
      "text": "What do you think happens in global markets as Chinese production and EVs goes up?"
    },
    {
      "id": 1391,
      "start": 5953.88,
      "end": 5958.88,
      "text": "Um, well, uh, China's extremely competitive in manufacturing."
    },
    {
      "id": 1392,
      "start": 5958.88,
      "end": 5966.88,
      "text": "So, um, I think there's, there's going to be a massive flood of Chinese vehicles and, and,"
    },
    {
      "id": 1393,
      "start": 5966.88,
      "end": 5972.88,
      "text": "and, and other, basically most manufactured, uh, things."
    },
    {
      "id": 1394,
      "start": 5972.88,
      "end": 5977.88,
      "text": "I mean, as it is, as I said, like China's like probably just twice as much refining as"
    },
    {
      "id": 1395,
      "start": 5977.88,
      "end": 5978.88,
      "text": "the rest of the world combined."
    },
    {
      "id": 1396,
      "start": 5978.88,
      "end": 5979.88,
      "text": "Yeah."
    },
    {
      "id": 1397,
      "start": 5979.88,
      "end": 5986.88,
      "text": "So if you go, you know, if you, if you, if you just go down to like fourth and fifth tier,"
    },
    {
      "id": 1398,
      "start": 5986.88,
      "end": 5991.88,
      "text": "uh, supply chain stuff, like, like, like the base level, you've got energy, then you've"
    },
    {
      "id": 1399,
      "start": 5991.88,
      "end": 5993.88,
      "text": "got mining and refining."
    },
    {
      "id": 1400,
      "start": 5993.88,
      "end": 6001.88,
      "text": "Um, those, those, those foundation layers, uh, are, like I said, China, as a rough guess,"
    },
    {
      "id": 1401,
      "start": 6001.88,
      "end": 6004.88,
      "text": "China's doing twice as much refining as the rest of the world combined."
    },
    {
      "id": 1402,
      "start": 6004.88,
      "end": 6020.88,
      "text": "Um, and, uh, and then they'll, they'll go all the way to the finished product with the"
    },
    {
      "id": 1403,
      "start": 6020.88,
      "end": 6021.88,
      "text": "cars."
    },
    {
      "id": 1404,
      "start": 6021.88,
      "end": 6022.88,
      "text": "Uh, and China's a powerhouse."
    },
    {
      "id": 1405,
      "start": 6022.88,
      "end": 6027.88,
      "text": "I mean, I think this year China will exceed three times U S electricity output."
    },
    {
      "id": 1406,
      "start": 6027.88,
      "end": 6033.88,
      "text": "Um, like electricity output is a, is a reasonable proxy for, uh, uh,"
    },
    {
      "id": 1407,
      "start": 6033.88,
      "end": 6036.88,
      "text": "you know, for the economy."
    },
    {
      "id": 1408,
      "start": 6036.88,
      "end": 6041.88,
      "text": "Uh, so like, like, you know, to run the factories and run, run everything, you need electricity."
    },
    {
      "id": 1409,
      "start": 6041.88,
      "end": 6047.88,
      "text": "So electricity is, is, is a, it's a good proxy for the, for, for the real economy."
    },
    {
      "id": 1410,
      "start": 6047.88,
      "end": 6055.88,
      "text": "Um, and so if China is, if China passes three times U S electricity output, it means that it's"
    },
    {
      "id": 1411,
      "start": 6055.88,
      "end": 6056.88,
      "text": "industrial capacity."
    },
    {
      "id": 1412,
      "start": 6056.88,
      "end": 6060.88,
      "text": "That's a rough approximation is three times that will be three times out of the U S."
    },
    {
      "id": 1413,
      "start": 6060.88,
      "end": 6061.88,
      "text": "Reading between the lines."
    },
    {
      "id": 1414,
      "start": 6061.88,
      "end": 6066.88,
      "text": "It sounds like what you're sort of saying is absence and sort of humanoid recursive miracle"
    },
    {
      "id": 1415,
      "start": 6066.88,
      "end": 6073.88,
      "text": "in the next few years on the, the sort of like whole manufacturing energy, uh, raw materials"
    },
    {
      "id": 1416,
      "start": 6073.88,
      "end": 6079.88,
      "text": "chain, like China will just dominate whether it comes to like AI or manufacturing EVs or manufacturing"
    },
    {
      "id": 1417,
      "start": 6079.88,
      "end": 6080.88,
      "text": "humanoids."
    },
    {
      "id": 1418,
      "start": 6080.88,
      "end": 6092.88,
      "text": "In the absence of, of, um, breakthrough innovations, uh, in, in the U S, uh, China will utterly dominate."
    },
    {
      "id": 1419,
      "start": 6092.88,
      "end": 6093.88,
      "text": "Interesting."
    },
    {
      "id": 1420,
      "start": 6093.88,
      "end": 6094.88,
      "text": "Yes."
    },
    {
      "id": 1421,
      "start": 6094.88,
      "end": 6097.88,
      "text": "Robotics being the main breakthrough innovation."
    },
    {
      "id": 1422,
      "start": 6097.88,
      "end": 6107.88,
      "text": "Well, if you do like to, to scale AI, uh, in, in, in, in space, like, like basically need,"
    },
    {
      "id": 1423,
      "start": 6107.88,
      "end": 6109.88,
      "text": "you need, need the humanoid robots."
    },
    {
      "id": 1424,
      "start": 6109.88,
      "end": 6111.88,
      "text": "You need real world AI."
    },
    {
      "id": 1425,
      "start": 6111.88,
      "end": 6114.88,
      "text": "You need, um, a million tons a year to orbit."
    },
    {
      "id": 1426,
      "start": 6114.88,
      "end": 6119.88,
      "text": "Um, like, let's just say like, if we, if we get the mass driver on the moon going, my favorite thing,"
    },
    {
      "id": 1427,
      "start": 6119.88,
      "end": 6124.88,
      "text": "um, that, that I think, uh, we'll have solved all our problems."
    },
    {
      "id": 1428,
      "start": 6124.88,
      "end": 6125.88,
      "text": "Yeah."
    },
    {
      "id": 1429,
      "start": 6125.88,
      "end": 6128.88,
      "text": "We saw this is like, I call that winning."
    },
    {
      "id": 1430,
      "start": 6128.88,
      "end": 6129.88,
      "text": "I call that winning."
    },
    {
      "id": 1431,
      "start": 6129.88,
      "end": 6134.88,
      "text": "You can finally be satisfied."
    },
    {
      "id": 1432,
      "start": 6134.88,
      "end": 6135.88,
      "text": "You've done something."
    },
    {
      "id": 1433,
      "start": 6135.88,
      "end": 6136.88,
      "text": "Yes."
    },
    {
      "id": 1434,
      "start": 6136.88,
      "end": 6137.88,
      "text": "You have the mass driver on the moon."
    },
    {
      "id": 1435,
      "start": 6137.88,
      "end": 6138.88,
      "text": "That's right."
    },
    {
      "id": 1436,
      "start": 6138.88,
      "end": 6139.88,
      "text": "I just want to see that thing."
    },
    {
      "id": 1437,
      "start": 6139.88,
      "end": 6141.88,
      "text": "Was that out of some sci-fi or where did you?"
    },
    {
      "id": 1438,
      "start": 6141.88,
      "end": 6143.88,
      "text": "Uh, well actually there, there is a Highland book."
    },
    {
      "id": 1439,
      "start": 6143.88,
      "end": 6144.88,
      "text": "The moon is a harsh mistress."
    },
    {
      "id": 1440,
      "start": 6144.88,
      "end": 6145.88,
      "text": "Okay."
    },
    {
      "id": 1441,
      "start": 6145.88,
      "end": 6146.88,
      "text": "Yeah, but that's slightly different."
    },
    {
      "id": 1442,
      "start": 6146.88,
      "end": 6150.88,
      "text": "That's a gravity slingshot or, um, no, they have a mass driver on the moon."
    },
    {
      "id": 1443,
      "start": 6150.88,
      "end": 6151.88,
      "text": "Okay."
    },
    {
      "id": 1444,
      "start": 6151.88,
      "end": 6152.88,
      "text": "Yeah."
    },
    {
      "id": 1445,
      "start": 6152.88,
      "end": 6154.88,
      "text": "But they use that to, uh, attack Earth."
    },
    {
      "id": 1446,
      "start": 6154.88,
      "end": 6155.88,
      "text": "So maybe it's something great."
    },
    {
      "id": 1447,
      "start": 6155.88,
      "end": 6157.88,
      "text": "Well, they use that to, uh, assert their independence from me."
    },
    {
      "id": 1448,
      "start": 6157.88,
      "end": 6158.88,
      "text": "Exactly."
    },
    {
      "id": 1449,
      "start": 6158.88,
      "end": 6160.88,
      "text": "What are your plans for the mass driver on the moon?"
    },
    {
      "id": 1450,
      "start": 6160.88,
      "end": 6161.88,
      "text": "They asserted their independence."
    },
    {
      "id": 1451,
      "start": 6161.88,
      "end": 6165.88,
      "text": "Uh, the earth government disagreed and they loved things until they, the earth government agreed."
    },
    {
      "id": 1452,
      "start": 6165.88,
      "end": 6166.88,
      "text": "That book is a hoot."
    },
    {
      "id": 1453,
      "start": 6166.88,
      "end": 6171.88,
      "text": "I found that book much better than, um, his other one that everyone reads, um, Stranger of a Strange Land."
    },
    {
      "id": 1454,
      "start": 6171.88,
      "end": 6172.88,
      "text": "Yeah."
    },
    {
      "id": 1455,
      "start": 6172.88,
      "end": 6173.88,
      "text": "Grok comes from a stranger in a strange land."
    },
    {
      "id": 1456,
      "start": 6173.88,
      "end": 6174.88,
      "text": "Yeah."
    },
    {
      "id": 1457,
      "start": 6174.88,
      "end": 6175.88,
      "text": "Yeah."
    },
    {
      "id": 1458,
      "start": 6175.88,
      "end": 6175.88,
      "text": ""
    },
    {
      "id": 1459,
      "start": 6175.88,
      "end": 6176.88,
      "text": "Yeah."
    },
    {
      "id": 1460,
      "start": 6176.88,
      "end": 6177.88,
      "text": "Um, but there's still some good concepts in there."
    },
    {
      "id": 1461,
      "start": 6177.88,
      "end": 6178.88,
      "text": "Yeah."
    },
    {
      "id": 1462,
      "start": 6178.88,
      "end": 6179.88,
      "text": "LabelBox can get you robotics and RL data at scale."
    },
    {
      "id": 1463,
      "start": 6179.88,
      "end": 6180.88,
      "text": "Take robotics."
    },
    {
      "id": 1464,
      "start": 6180.88,
      "end": 6181.88,
      "text": "Let's say you need a hundred thousand hours of egocentric video."
    },
    {
      "id": 1465,
      "start": 6181.88,
      "end": 6182.88,
      "text": "LabelBox starts by helping you define your ideal data distribution."
    },
    {
      "id": 1466,
      "start": 6182.88,
      "end": 6183.88,
      "text": "Like for example, maybe no single task category should occupy more than 1% of trading volume."
    },
    {
      "id": 1467,
      "start": 6183.88,
      "end": 6184.88,
      "text": "And at least 10% of trajectories should capture failure and recovery states."
    },
    {
      "id": 1468,
      "start": 6184.88,
      "end": 6185.88,
      "text": "Next, LabelBox assigns this distribution to its massive network of operators."
    },
    {
      "id": 1469,
      "start": 6185.88,
      "end": 6185.88,
      "text": ""
    },
    {
      "id": 1470,
      "start": 6185.88,
      "end": 6186.88,
      "text": "You're not limited to the small range of scenes that you can set up in a single warehouse."
    },
    {
      "id": 1471,
      "start": 6186.88,
      "end": 6186.88,
      "text": ""
    },
    {
      "id": 1472,
      "start": 6186.88,
      "end": 6187.88,
      "text": "You can also get the same data distribution."
    },
    {
      "id": 1473,
      "start": 6187.88,
      "end": 6188.88,
      "text": "You can also get the same data distribution."
    },
    {
      "id": 1474,
      "start": 6188.88,
      "end": 6189.88,
      "text": "You can also get the same data distribution."
    },
    {
      "id": 1475,
      "start": 6189.88,
      "end": 6190.88,
      "text": "You can also get the same data distribution."
    },
    {
      "id": 1476,
      "start": 6190.88,
      "end": 6191.88,
      "text": "Inside,"
    },
    {
      "id": 1477,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1478,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1479,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1480,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1481,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1482,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1483,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1484,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1485,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1486,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1487,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1488,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1489,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1490,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1491,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1492,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1493,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1494,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1495,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1496,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1497,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1498,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1499,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1500,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1501,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1502,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1503,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1504,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1505,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1506,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1507,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1508,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1509,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1510,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1511,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1512,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1513,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1514,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1515,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1516,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1517,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1518,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1519,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1520,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1521,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1522,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1523,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1524,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1525,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1526,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1527,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1528,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1529,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1530,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1531,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1532,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1533,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1534,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1535,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1536,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1537,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1538,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1539,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1540,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1541,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1542,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1543,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1544,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1545,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1546,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1547,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1548,
      "start": 6191.88,
      "end": 6191.88,
      "text": ""
    },
    {
      "id": 1549,
      "start": 6191.88,
      "end": 6197.24,
      "text": "video. LabelBox starts by helping you define your ideal data distribution. Like for example,"
    },
    {
      "id": 1550,
      "start": 6197.24,
      "end": 6202.92,
      "text": "maybe no single task category should occupy more than 1% of trading volume, and at least 10% of"
    },
    {
      "id": 1551,
      "start": 6202.92,
      "end": 6208.28,
      "text": "trajectories should capture failure and recovery states. Next, LabelBox assigns this distribution"
    },
    {
      "id": 1552,
      "start": 6208.28,
      "end": 6213.32,
      "text": "to its massive network of operators. You're not limited to the small range of scenes that you can"
    },
    {
      "id": 1553,
      "start": 6213.32,
      "end": 6218.28,
      "text": "set up in a single warehouse. Instead, each one of LabelBox's operators has access to lots of unique"
    },
    {
      "id": 1554,
      "start": 6218.28,
      "end": 6223.4,
      "text": "physical environments where they can film themselves completing a wide variety of tasks."
    },
    {
      "id": 1555,
      "start": 6223.4,
      "end": 6228.36,
      "text": "LabelBox's tech automatically categorizes each video so that their operators always know"
    },
    {
      "id": 1556,
      "start": 6228.36,
      "end": 6233.639999999999,
      "text": "which tasks will remain and what they need to work on next. For RL data, LabelBox takes a similar"
    },
    {
      "id": 1557,
      "start": 6233.639999999999,
      "end": 6237.639999999999,
      "text": "approach. They work with you to understand the right distribution of tasks, and then their subject"
    },
    {
      "id": 1558,
      "start": 6237.639999999999,
      "end": 6243.48,
      "text": "matter experts build the hyper-realistic digital environments and rubrics that you need to collect"
    },
    {
      "id": 1559,
      "start": 6243.48,
      "end": 6248.2,
      "text": "the highest quality trading data. So whether you're training robots in the real world or agents"
    },
    {
      "id": 1560,
      "start": 6248.2,
      "end": 6254.44,
      "text": "for computer use, LabelBox can help. Go to labelbox.com slash Swarkash to learn more."
    },
    {
      "id": 1561,
      "start": 6254.44,
      "end": 6263.88,
      "text": "One thing we were discussing a lot is kind of your system for managing people. Like you interviewed"
    },
    {
      "id": 1562,
      "start": 6263.88,
      "end": 6266.92,
      "text": "the first few thousand of SpaceX employees and I've seen lots of other companies."
    },
    {
      "id": 1563,
      "start": 6266.92,
      "end": 6268.04,
      "text": "What is this?"
    },
    {
      "id": 1564,
      "start": 6268.04,
      "end": 6268.76,
      "text": "Obviously it doesn't scale."
    },
    {
      "id": 1565,
      "start": 6268.76,
      "end": 6271.0,
      "text": "Well, yes, but what doesn't scale?"
    },
    {
      "id": 1566,
      "start": 6271.0,
      "end": 6271.639999999999,
      "text": "Me."
    },
    {
      "id": 1567,
      "start": 6271.639999999999,
      "end": 6275.96,
      "text": "Sure, sure. I know that, but like what are you looking for?"
    },
    {
      "id": 1568,
      "start": 6275.96,
      "end": 6277.96,
      "text": "I mean, literally there's not enough hours in a day. It's impossible."
    },
    {
      "id": 1569,
      "start": 6277.96,
      "end": 6283.4,
      "text": "But what are you looking for that someone else who's good at interviewing and hiring people?"
    },
    {
      "id": 1570,
      "start": 6284.36,
      "end": 6285.32,
      "text": "What's the je ne sais quoi?"
    },
    {
      "id": 1571,
      "start": 6285.32,
      "end": 6292.6,
      "text": "Well, at this point, I think I've got, I might have more training data on evaluating technical"
    },
    {
      "id": 1572,
      "start": 6292.6,
      "end": 6296.6,
      "text": "talent, especially, but talent of all kinds, I suppose, but technical talent, especially,"
    },
    {
      "id": 1573,
      "start": 6297.4800000000005,
      "end": 6301.16,
      "text": "given that I've done so many technical interviews and then seen the results, technical interviews,"
    },
    {
      "id": 1574,
      "start": 6301.16,
      "end": 6308.92,
      "text": "seen the results. So my, my training set is, is very, is enormous and has a very wide range."
    },
    {
      "id": 1575,
      "start": 6311.5599999999995,
      "end": 6317.4,
      "text": "Generally the thing I ask for are bullet points for evidence of exceptional ability."
    },
    {
      "id": 1576,
      "start": 6318.2,
      "end": 6323.96,
      "text": "So it's, but like it's, it's, and these things can be like pretty off the wall. It doesn't need to be"
    },
    {
      "id": 1577,
      "start": 6323.96,
      "end": 6330.04,
      "text": "uh, in the, in the domain, the specific domain, but evidence that, uh, evidence of exceptional ability."
    },
    {
      "id": 1578,
      "start": 6330.6,
      "end": 6335.88,
      "text": "Um, so if, if, if somebody can like cite like even one thing, but let's say three things where you go,"
    },
    {
      "id": 1579,
      "start": 6335.88,
      "end": 6338.2,
      "text": "wow, wow, wow, then that's, that's a good sign."
    },
    {
      "id": 1580,
      "start": 6338.2,
      "end": 6340.76,
      "text": "But, but, but, but why do you have to be the one to determine that?"
    },
    {
      "id": 1581,
      "start": 6340.76,
      "end": 6342.52,
      "text": "No, I don't. I can't be. It's impossible."
    },
    {
      "id": 1582,
      "start": 6342.52,
      "end": 6342.84,
      "text": "Right."
    },
    {
      "id": 1583,
      "start": 6342.84,
      "end": 6346.2,
      "text": "I mean, total, uh, headcount across all companies, 200,000 people."
    },
    {
      "id": 1584,
      "start": 6346.2,
      "end": 6346.52,
      "text": "Right."
    },
    {
      "id": 1585,
      "start": 6346.52,
      "end": 6354.120000000001,
      "text": "But in the early days, what was it that's that you were looking for that couldn't be delegated in"
    },
    {
      "id": 1586,
      "start": 6354.120000000001,
      "end": 6354.76,
      "text": "those interviews?"
    },
    {
      "id": 1587,
      "start": 6356.76,
      "end": 6363.72,
      "text": "Um, well, I, I guess I, I need to build my training set. So it's not like I had about a thousand here."
    },
    {
      "id": 1588,
      "start": 6363.72,
      "end": 6369.160000000001,
      "text": "Um, I would make mistakes, but then I'd be able to see where I thought somebody would work out well,"
    },
    {
      "id": 1589,
      "start": 6369.160000000001,
      "end": 6374.76,
      "text": "but they didn't. And then why, why did they not work out well? And what can I do to, I guess, RL myself"
    },
    {
      "id": 1590,
      "start": 6374.76,
      "end": 6375.16,
      "text": "Yes."
    },
    {
      "id": 1591,
      "start": 6375.16,
      "end": 6380.4400000000005,
      "text": "To, uh, in the future, um, have a better batting average when interviewing people."
    },
    {
      "id": 1592,
      "start": 6380.4400000000005,
      "end": 6380.84,
      "text": "Mm-hmm."
    },
    {
      "id": 1593,
      "start": 6380.84,
      "end": 6384.4400000000005,
      "text": "So, and my batting average is still not perfect, but it's, it's very high."
    },
    {
      "id": 1594,
      "start": 6384.4400000000005,
      "end": 6386.4400000000005,
      "text": "What are some surprising reasons people don't work out?"
    },
    {
      "id": 1595,
      "start": 6386.4400000000005,
      "end": 6388.4400000000005,
      "text": "Surprising reasons? Um."
    },
    {
      "id": 1596,
      "start": 6388.4400000000005,
      "end": 6391.400000000001,
      "text": "Like, you know, they don't understand techno domain, et cetera, et cetera. But like,"
    },
    {
      "id": 1597,
      "start": 6391.400000000001,
      "end": 6392.04,
      "text": "No, I."
    },
    {
      "id": 1598,
      "start": 6392.04,
      "end": 6395.320000000001,
      "text": "You, you, you, like, you, you've got like the long tail now of like, ah, I was really excited"
    },
    {
      "id": 1599,
      "start": 6395.320000000001,
      "end": 6399.16,
      "text": "that it was about this person. It didn't work out. Curious why that happens."
    },
    {
      "id": 1600,
      "start": 6399.16,
      "end": 6404.68,
      "text": "Uh, yeah. So the, I mean, generally what I tell people,"
    },
    {
      "id": 1601,
      "start": 6405.400000000001,
      "end": 6410.84,
      "text": "I tell myself, I guess, aspirationally, um, is don't look at the resume, just believe,"
    },
    {
      "id": 1602,
      "start": 6410.84,
      "end": 6415.64,
      "text": "believe your interaction. So if the resume may seem very impressive and it's like, wow,"
    },
    {
      "id": 1603,
      "start": 6415.64,
      "end": 6422.04,
      "text": "you know, resume looks good. But if the, if the conversation, uh, after 20 minutes is, is that"
    },
    {
      "id": 1604,
      "start": 6422.04,
      "end": 6426.68,
      "text": "conversation is not wow. Um, you should believe the conversation, not the, not the, not the paper."
    },
    {
      "id": 1605,
      "start": 6426.68,
      "end": 6433.16,
      "text": "I feel like part of your method is that, you know, there was this meme in the media a few"
    },
    {
      "id": 1606,
      "start": 6433.16,
      "end": 6438.12,
      "text": "years back about Tesla being a revolving door of, uh, executive talent. Of course, actually,"
    },
    {
      "id": 1607,
      "start": 6438.12,
      "end": 6443.400000000001,
      "text": "I think when you look at it, Tesla's had a very consistent and internally promoted executive bench"
    },
    {
      "id": 1608,
      "start": 6443.4,
      "end": 6448.12,
      "text": "over the past few years. And then at SpaceX, you have all these folks like Mark Jankosa and Steve"
    },
    {
      "id": 1609,
      "start": 6448.12,
      "end": 6453.16,
      "text": "Davis and Steve Davis runs a sporting company. No, no. Yeah. Yeah. But, uh, uh, Bill Riley and"
    },
    {
      "id": 1610,
      "start": 6453.16,
      "end": 6462.12,
      "text": "folks like that. And it feels like part of has worked well, is having very capable technical deputies."
    },
    {
      "id": 1611,
      "start": 6462.12,
      "end": 6472.44,
      "text": "What do all of those people have in common? Uh, well, so the, I mean, it tells us sort of senior"
    },
    {
      "id": 1612,
      "start": 6472.44,
      "end": 6477.5599999999995,
      "text": "team, uh, at this point, it's probably got average tenure of 10 or 12 years. It's quite,"
    },
    {
      "id": 1613,
      "start": 6477.5599999999995,
      "end": 6486.36,
      "text": "quite a lot of tenure. Yeah. Um, so, um, but there, there are times when Tesla went through"
    },
    {
      "id": 1614,
      "start": 6486.92,
      "end": 6492.36,
      "text": "extremely rapid and extremely rapid growth phase. Um, and so it was somewhat, things were just"
    },
    {
      "id": 1615,
      "start": 6492.36,
      "end": 6497.48,
      "text": "somewhat sped up. Um, and, and when a company, as, as, as you know, a company goes through different"
    },
    {
      "id": 1616,
      "start": 6497.48,
      "end": 6502.679999999999,
      "text": "orders of magnitude of, of size, you, you know, uh, people that who, who could help manage,"
    },
    {
      "id": 1617,
      "start": 6502.679999999999,
      "end": 6508.839999999999,
      "text": "say a 50 person company versus a 500 person company versus a 5,000 person company versus a 50,000"
    },
    {
      "id": 1618,
      "start": 6508.839999999999,
      "end": 6513.0,
      "text": "person company. Yeah. You have a group of people. Yeah. It's just not the same team. It's not,"
    },
    {
      "id": 1619,
      "start": 6513.0,
      "end": 6516.2,
      "text": "it's not always the same team. So if, if a company is growing very rapidly,"
    },
    {
      "id": 1620,
      "start": 6516.2,
      "end": 6521.4,
      "text": "the rate at which, uh, executive positions will change will also be proportionate to the,"
    },
    {
      "id": 1621,
      "start": 6521.4,
      "end": 6529.639999999999,
      "text": "the, the rapidity of the growth generally. Um, then, uh, Tesla had, uh, a further challenge"
    },
    {
      "id": 1622,
      "start": 6529.639999999999,
      "end": 6537.24,
      "text": "where when, when Tesla had very successful periods, um, uh, we would be, um, relentlessly recruited from,"
    },
    {
      "id": 1623,
      "start": 6537.72,
      "end": 6544.84,
      "text": "um, like relentlessly, um, like when Apple had their electric car program, they were copper bombing"
    },
    {
      "id": 1624,
      "start": 6544.84,
      "end": 6549.8,
      "text": "Tesla with recruiting calls. It was, uh, uh, engineers just unplugged their phones. Like,"
    },
    {
      "id": 1625,
      "start": 6549.8,
      "end": 6553.08,
      "text": "like it's just, it's just, I think I'm trying to get work done here. I'm not. Yeah. I, if I get,"
    },
    {
      "id": 1626,
      "start": 6553.08,
      "end": 6557.400000000001,
      "text": "you know, one more call from an Apple recruiter, um, but they were, they were, they were, they're"
    },
    {
      "id": 1627,
      "start": 6557.400000000001,
      "end": 6563.24,
      "text": "opening off without any interview with me, like double the compensation at Tesla. Um, so, um,"
    },
    {
      "id": 1628,
      "start": 6564.360000000001,
      "end": 6570.2,
      "text": "so, so, so, uh, so we had a bit of the Tesla pixie dust, uh, thing where it's like, oh, if you hired a"
    },
    {
      "id": 1629,
      "start": 6570.2,
      "end": 6575.639999999999,
      "text": "Tesla executive, you're suddenly you're gonna, everything's gonna be successful. Um, and, and I"
    },
    {
      "id": 1630,
      "start": 6575.639999999999,
      "end": 6579.32,
      "text": "fall and pray to the pixie dust, uh, you know, thing as well, where it's like, oh, we'll hire"
    },
    {
      "id": 1631,
      "start": 6579.32,
      "end": 6582.84,
      "text": "someone from Google or Apple and they'll be immediately successful, but not that, that's not"
    },
    {
      "id": 1632,
      "start": 6582.84,
      "end": 6587.88,
      "text": "how it works. Um, you know, people are people. It's, it's, it's not like magical pixie dust. Yes."
    },
    {
      "id": 1633,
      "start": 6587.88,
      "end": 6595.24,
      "text": "So when we had the pixie dust problem, um, we would get relentlessly recruited. Um, and, um,"
    },
    {
      "id": 1634,
      "start": 6595.24,
      "end": 6602.5199999999995,
      "text": "and then also being Tesla being, um, engineering, especially being primarily in Silicon Valley,"
    },
    {
      "id": 1635,
      "start": 6602.5199999999995,
      "end": 6607.48,
      "text": "uh, it's, it's easier for people to just like, they don't have to change their life very much."
    },
    {
      "id": 1636,
      "start": 6607.48,
      "end": 6613.639999999999,
      "text": "Yes. They can just get, you know, their commute is going to be the same. Yes. Um, so how do you"
    },
    {
      "id": 1637,
      "start": 6613.639999999999,
      "end": 6617.48,
      "text": "prevent that? How do you prevent the pixie dust effect for everyone's trying to coach all your people?"
    },
    {
      "id": 1638,
      "start": 6618.76,
      "end": 6623.88,
      "text": "Um, I don't think we can, I don't think as much we can do to, to, to stop it."
    },
    {
      "id": 1639,
      "start": 6623.88,
      "end": 6630.68,
      "text": "Um, but that, that's like, that's one of the reasons why Tesla, uh, uh, really being in Silicon Valley,"
    },
    {
      "id": 1640,
      "start": 6631.24,
      "end": 6639.88,
      "text": "um, and, uh, and having the pixie dust thing at the same time, um, meant that, uh, there was just"
    },
    {
      "id": 1641,
      "start": 6640.52,
      "end": 6641.8,
      "text": "a very, very aggressive recruitment."
    },
    {
      "id": 1642,
      "start": 6641.8,
      "end": 6643.64,
      "text": "And being in Austin helps then."
    },
    {
      "id": 1643,
      "start": 6644.4400000000005,
      "end": 6650.84,
      "text": "Uh, Austin. Yeah. It still helps. Uh, I mean, Tesla still has a majority of its engineering in California."
    },
    {
      "id": 1644,
      "start": 6650.84,
      "end": 6658.76,
      "text": "Um, so, um, the, you know, for getting into engineers to move, uh, I called the significant,"
    },
    {
      "id": 1645,
      "start": 6658.76,
      "end": 6664.4400000000005,
      "text": "significant other problem. Yes. So then others have jobs. Yeah. Yeah. Yeah, exactly. So, um,"
    },
    {
      "id": 1646,
      "start": 6665.08,
      "end": 6669.4800000000005,
      "text": "for star base, that was particularly difficult. Yes. Since the odds of, you know, finding a non-spacex job."
    },
    {
      "id": 1647,
      "start": 6669.4800000000005,
      "end": 6671.08,
      "text": "In Brownsville, Texas."
    },
    {
      "id": 1648,
      "start": 6671.08,
      "end": 6675.96,
      "text": "Pretty low. Yeah. Yeah. It's quite, quite difficult. I mean, it's like a technology monastery."
    },
    {
      "id": 1649,
      "start": 6675.96,
      "end": 6679.5599999999995,
      "text": "Yeah. I think, um, you know, remotes and mostly dudes."
    },
    {
      "id": 1650,
      "start": 6682.04,
      "end": 6684.28,
      "text": "But again, if you, if you go back."
    },
    {
      "id": 1651,
      "start": 6684.28,
      "end": 6685.48,
      "text": "It's not much of an improvement over by SF."
    },
    {
      "id": 1652,
      "start": 6686.6,
      "end": 6686.84,
      "text": "Yeah."
    },
    {
      "id": 1653,
      "start": 6687.88,
      "end": 6690.5199999999995,
      "text": "If you go back, but if you go back to these people who've really,"
    },
    {
      "id": 1654,
      "start": 6690.52,
      "end": 6701.320000000001,
      "text": "um, been very effective in a technical capacity at Tesla, at SpaceX and, and those sorts of places,"
    },
    {
      "id": 1655,
      "start": 6701.320000000001,
      "end": 6707.080000000001,
      "text": "what do you think they have in common other than like, is it just that they're very sharp on the,"
    },
    {
      "id": 1656,
      "start": 6707.080000000001,
      "end": 6711.72,
      "text": "you know, rocketry or the, you know, the technical foundations, or do you think it's something"
    },
    {
      "id": 1657,
      "start": 6711.72,
      "end": 6716.84,
      "text": "organizational? It's something about their ability to work with you. Is this their ability to like,"
    },
    {
      "id": 1658,
      "start": 6716.84,
      "end": 6720.68,
      "text": "be, you know, flexible, but not too flexible?"
    },
    {
      "id": 1659,
      "start": 6723.72,
      "end": 6725.56,
      "text": "What makes a good sparring partner for you?"
    },
    {
      "id": 1660,
      "start": 6725.56,
      "end": 6730.84,
      "text": "I don't think of a sparring partner. I mean, if somebody gets things done, I, I, I love them."
    },
    {
      "id": 1661,
      "start": 6730.84,
      "end": 6736.52,
      "text": "And if they don't, I, so it's pretty straightforward. It's not like some idiosyncratic thing."
    },
    {
      "id": 1662,
      "start": 6737.64,
      "end": 6741.32,
      "text": "If somebody executes well, um, I'm a huge fan. And if they don't, I'm not."
    },
    {
      "id": 1663,
      "start": 6742.52,
      "end": 6746.6,
      "text": "Um, but it's, it's not about mapping to my idiosyncratic preferences. I certainly try not to"
    },
    {
      "id": 1664,
      "start": 6746.6,
      "end": 6752.4400000000005,
      "text": "have it be mapping to my idiosyncratic preferences. Um, so yeah. Um,"
    },
    {
      "id": 1665,
      "start": 6754.92,
      "end": 6763.160000000001,
      "text": "yeah, but I, I, generally, I think it's a good idea to hire for, um, uh, talent and drive and"
    },
    {
      "id": 1666,
      "start": 6763.160000000001,
      "end": 6771.88,
      "text": "trustworthiness. Um, and I, I think, uh, goodness of heart is important. Um, I, I'd awaited that at one"
    },
    {
      "id": 1667,
      "start": 6771.88,
      "end": 6779.88,
      "text": "point. Um, so like, are they, are they a good person, trustworthy, uh, sort of smart and talented"
    },
    {
      "id": 1668,
      "start": 6779.88,
      "end": 6785.8,
      "text": "and hardworking? Uh, if so, you can add domain knowledge. Um, but those, those fundamental traits,"
    },
    {
      "id": 1669,
      "start": 6785.8,
      "end": 6791.8,
      "text": "those fundamental properties you cannot change. So most of the people who, um, are at, uh,"
    },
    {
      "id": 1670,
      "start": 6792.92,
      "end": 6796.84,
      "text": "Tesla and SpaceX did not come from the aerospace industry or the order industry."
    },
    {
      "id": 1671,
      "start": 6796.84,
      "end": 6802.52,
      "text": "What is most set to change about your management style as your companies have scaled from 100 to"
    },
    {
      "id": 1672,
      "start": 6802.52,
      "end": 6807.32,
      "text": "1000 to 10,000 people? You're, you know, you're known for this like very micromanagement,"
    },
    {
      "id": 1673,
      "start": 6807.32,
      "end": 6809.96,
      "text": "just getting into the details of things. Nanomanagement, please."
    },
    {
      "id": 1674,
      "start": 6811.4800000000005,
      "end": 6814.76,
      "text": "Pico management. Um, phantom management."
    },
    {
      "id": 1675,
      "start": 6814.76,
      "end": 6816.68,
      "text": "So you're saying,"
    },
    {
      "id": 1676,
      "start": 6816.68,
      "end": 6817.72,
      "text": "keep going."
    },
    {
      "id": 1677,
      "start": 6817.72,
      "end": 6820.68,
      "text": "We're going to go all the way down to Flanks Boston."
    },
    {
      "id": 1678,
      "start": 6820.68,
      "end": 6826.04,
      "text": "We're going to go all the way down to Heisenberg's in Sydney first."
    },
    {
      "id": 1679,
      "start": 6828.200000000001,
      "end": 6832.6,
      "text": "Yeah. Well, how do you, I mean, are you, are you still able to get into details as much as you want?"
    },
    {
      "id": 1680,
      "start": 6832.6,
      "end": 6835.96,
      "text": "Would your companies be more successful if you could, if they were smaller? Like, how do you,"
    },
    {
      "id": 1681,
      "start": 6835.96,
      "end": 6839.400000000001,
      "text": "how do you think about that? Well, because I have a fixed amount of time in the day, uh,"
    },
    {
      "id": 1682,
      "start": 6840.6,
      "end": 6847.400000000001,
      "text": "my time is necessarily, um, diluted as things grow and as the span of activity, uh, increases. So,"
    },
    {
      "id": 1683,
      "start": 6847.4,
      "end": 6853.32,
      "text": "you know, um, it, it, it, it, it's, it's impossible for me to actually be a micromanager because,"
    },
    {
      "id": 1684,
      "start": 6853.32,
      "end": 6859.32,
      "text": "uh, there's that doubt. I would imply I have some like thousands of hours per day."
    },
    {
      "id": 1685,
      "start": 6860.44,
      "end": 6868.12,
      "text": "It is, it is a logical impossibility for me to micromanage things. Um, so now there are times when,"
    },
    {
      "id": 1686,
      "start": 6868.12,
      "end": 6876.599999999999,
      "text": "um, I will drill down into, uh, a specific issue because that's specific issue, uh, is the limiting factor on"
    },
    {
      "id": 1687,
      "start": 6877.4,
      "end": 6885.5599999999995,
      "text": "uh, the progress of the company. Um, and, um, but the reason for drilling into that, that some very"
    },
    {
      "id": 1688,
      "start": 6885.5599999999995,
      "end": 6891.0,
      "text": "detailed item is because it is the, there's a limiting factor, not, it's not arbitrarily drilling"
    },
    {
      "id": 1689,
      "start": 6891.0,
      "end": 6896.92,
      "text": "into the entire tiny things. Um, and, and like I said, obviously from a time standpoint, it is"
    },
    {
      "id": 1690,
      "start": 6896.92,
      "end": 6902.2,
      "text": "physically impossible for you arbitrarily, uh, going to tiny things that don't matter and that would,"
    },
    {
      "id": 1691,
      "start": 6902.2,
      "end": 6908.679999999999,
      "text": "and, and that would result in failure. But sometimes the tiny things, um, are decisive in victory."
    },
    {
      "id": 1692,
      "start": 6908.679999999999,
      "end": 6916.679999999999,
      "text": "Samuelsky, you switched the, uh, starship design from composites to steel."
    },
    {
      "id": 1693,
      "start": 6916.679999999999,
      "end": 6917.08,
      "text": "Yes."
    },
    {
      "id": 1694,
      "start": 6917.08,
      "end": 6920.679999999999,
      "text": "And you made that decision. Like that wasn't, uh, you know, people were going around,"
    },
    {
      "id": 1695,
      "start": 6920.679999999999,
      "end": 6923.8,
      "text": "they're like, oh, we found something better, boss. Like that was you encouraging people to get some"
    },
    {
      "id": 1696,
      "start": 6923.8,
      "end": 6929.5599999999995,
      "text": "resistance. Can you tell us how you came to that whole composite steel switch?"
    },
    {
      "id": 1697,
      "start": 6929.56,
      "end": 6940.6,
      "text": "Uh, yeah. So desperation, I'd say, um, the, um, originally, yeah, we were going to make starship out"
    },
    {
      "id": 1698,
      "start": 6940.6,
      "end": 6948.280000000001,
      "text": "of, uh, carbon fiber. Um, and, um, carbon fiber is pretty expensive. Like the, the, the, the,"
    },
    {
      "id": 1699,
      "start": 6951.0,
      "end": 6955.96,
      "text": "you know, you can generally, uh, when you do volume production, you can get any given thing to be,"
    },
    {
      "id": 1700,
      "start": 6955.96,
      "end": 6961.24,
      "text": "to start to approach its material cost. The problem with, with carbon fibers is that material cost is"
    },
    {
      "id": 1701,
      "start": 6961.24,
      "end": 6969.8,
      "text": "still very high. Um, um, so, um, it's about, it's about 50 times, particularly if you go for a high"
    },
    {
      "id": 1702,
      "start": 6969.8,
      "end": 6976.36,
      "text": "strength specialized carbon fiber that can handle, um, cryogenic oxygen. It's, it's, it's like"
    },
    {
      "id": 1703,
      "start": 6976.36,
      "end": 6983.0,
      "text": "called roughly 50 times the cost of steel. Um, and at least, uh, in theory, it would be lighter."
    },
    {
      "id": 1704,
      "start": 6983.0,
      "end": 6988.12,
      "text": "People don't think of steel as being heavy and carbon fiber as being, uh, light. Um,"
    },
    {
      "id": 1705,
      "start": 6988.12,
      "end": 6993.72,
      "text": "and for room temperature, room temperature applications, um, you know, like say, uh,"
    },
    {
      "id": 1706,
      "start": 6993.72,
      "end": 6998.84,
      "text": "more or less room temperature applications like a Formula One car, uh, static aerostructure, or"
    },
    {
      "id": 1707,
      "start": 6999.4,
      "end": 7004.52,
      "text": "any kind of aerostructure really, uh, is, is gonna, you're gonna probably be better off with, uh, carbon fiber."
    },
    {
      "id": 1708,
      "start": 7004.52,
      "end": 7011.320000000001,
      "text": "Um, now the problem is that we were trying to make this enormous rocket out of carbon fiber and, uh,"
    },
    {
      "id": 1709,
      "start": 7011.320000000001,
      "end": 7015.72,
      "text": "our progress was extremely slow. And it's been picked in the first place just because it's light."
    },
    {
      "id": 1710,
      "start": 7016.84,
      "end": 7025.080000000001,
      "text": "Yes. Um, like at first glance, um, like most people would think that the, the, the choice for making"
    },
    {
      "id": 1711,
      "start": 7025.88,
      "end": 7033.240000000001,
      "text": "something light would be carbon fiber. Um, the, um, now, now the thing is that, um,"
    },
    {
      "id": 1712,
      "start": 7033.24,
      "end": 7041.88,
      "text": "um, when you make something very enormous out of carbon fiber, and then you try to have the carbon"
    },
    {
      "id": 1713,
      "start": 7041.88,
      "end": 7048.679999999999,
      "text": "fiber, um, be efficiently cured, meaning not, not room temperature cured because like you've got,"
    },
    {
      "id": 1714,
      "start": 7049.24,
      "end": 7053.8,
      "text": "you know, sometimes you got like 50 pliers of, of, of carbon fiber and, and a carbon fiber is really"
    },
    {
      "id": 1715,
      "start": 7053.8,
      "end": 7060.2,
      "text": "carbon string and glue. Um, and, uh, and you, in order to have, um, high strength, you need, uh,"
    },
    {
      "id": 1716,
      "start": 7060.2,
      "end": 7066.2,
      "text": "an autoclave. So something that, that can, that's essentially high pressure oven. And if, if, um,"
    },
    {
      "id": 1717,
      "start": 7066.2,
      "end": 7071.48,
      "text": "if you have something that's, uh, a gigantic, uh, the album's gotta be bigger than the rocket."
    },
    {
      "id": 1718,
      "start": 7072.04,
      "end": 7077.8,
      "text": "Um, so we're trying to make the, the autoclave that's bigger than any autoclave that's ever existed,"
    },
    {
      "id": 1719,
      "start": 7078.36,
      "end": 7083.72,
      "text": "uh, or do room temperature cure, which takes a long time and has issues. Um, but, but the final issue"
    },
    {
      "id": 1720,
      "start": 7083.72,
      "end": 7090.84,
      "text": "is that we're just making very slow progress, uh, with, uh, with carbon fiber. Um, so, um,"
    },
    {
      "id": 1721,
      "start": 7090.84,
      "end": 7098.360000000001,
      "text": "I, I, I think the meta question is, uh, why it had to be you who made that decision. There's many"
    },
    {
      "id": 1722,
      "start": 7098.360000000001,
      "end": 7101.320000000001,
      "text": "engineers on your team. Yeah, how did the team not arrive at steel? Yeah, exactly."
    },
    {
      "id": 1723,
      "start": 7101.320000000001,
      "end": 7104.68,
      "text": "Like, this is a part of a broader question of like understanding your comparative advantage at your"
    },
    {
      "id": 1724,
      "start": 7104.68,
      "end": 7111.240000000001,
      "text": "companies. Um, so, it was, because we were making very slow progress with, with carbon fiber,"
    },
    {
      "id": 1725,
      "start": 7111.24,
      "end": 7118.679999999999,
      "text": "I was like, okay, we've got to try something else now for the Falcon 9. The, the primary airframe is"
    },
    {
      "id": 1726,
      "start": 7118.679999999999,
      "end": 7126.12,
      "text": "made of aluminum lithium, which is very, very good strength to weight. Um, and, um, actually it has,"
    },
    {
      "id": 1727,
      "start": 7126.12,
      "end": 7131.48,
      "text": "uh, about the same, maybe, maybe better strength to weight for its application than carbon fiber,"
    },
    {
      "id": 1728,
      "start": 7131.48,
      "end": 7135.0,
      "text": "but aluminum lithium is very difficult to work with in order to weld it. You have to do something called"
    },
    {
      "id": 1729,
      "start": 7135.0,
      "end": 7139.08,
      "text": "friction still welding where you join the, you join the metal without it entering the liquid phase."
    },
    {
      "id": 1730,
      "start": 7139.08,
      "end": 7144.6,
      "text": "Um, so it's kind of wild that you could do that, uh, but with this particular type of welding,"
    },
    {
      "id": 1731,
      "start": 7144.6,
      "end": 7151.32,
      "text": "you can do that. Um, but, uh, it's very difficult to like, say, let's say you want to make a modification"
    },
    {
      "id": 1732,
      "start": 7151.32,
      "end": 7157.16,
      "text": "or attach something to, um, aluminum lithium. You now have to use mechanical attachment with seals."
    },
    {
      "id": 1733,
      "start": 7157.5599999999995,
      "end": 7165.0,
      "text": "Um, you can't, uh, weld it on. Um, so, uh, we want to, I want to avoid using aluminum lithium for the"
    },
    {
      "id": 1734,
      "start": 7165.0,
      "end": 7173.56,
      "text": "primary structure for, uh, for Starship. Um, and, uh, and, and, and there was this very special grade of,"
    },
    {
      "id": 1735,
      "start": 7174.28,
      "end": 7180.36,
      "text": "uh, carbon fiber that, that had very, very good mass properties. So with rocket, you're really trying"
    },
    {
      "id": 1736,
      "start": 7180.36,
      "end": 7185.4,
      "text": "to maximize the percentage of the, of the rocket that is propellant, minimize the, the mass obviously."
    },
    {
      "id": 1737,
      "start": 7185.4,
      "end": 7194.599999999999,
      "text": "And, um, the, but like I said, we were making very slow progress. Um, and, and, and I said,"
    },
    {
      "id": 1738,
      "start": 7194.599999999999,
      "end": 7199.879999999999,
      "text": "at this rate, we're never going to get to Mars. So we better think of something else. Um, I didn't"
    },
    {
      "id": 1739,
      "start": 7199.879999999999,
      "end": 7205.5599999999995,
      "text": "want to use aluminum lithium because of the difficulty of friction still welding. Um, especially doing that"
    },
    {
      "id": 1740,
      "start": 7205.5599999999995,
      "end": 7211.16,
      "text": "at, at, at, at scale was hard enough, um, at 3.6 meters in diameter, let alone at nine meters or above."
    },
    {
      "id": 1741,
      "start": 7211.16,
      "end": 7220.68,
      "text": "Um, then, um, I said, well, what about steel? And so the, the, the, now I, I had a clue here because"
    },
    {
      "id": 1742,
      "start": 7220.68,
      "end": 7228.2,
      "text": "some of the early, um, US rockets had used very thin steel. The Atlas rockets had used a steel balloon"
    },
    {
      "id": 1743,
      "start": 7228.2,
      "end": 7234.76,
      "text": "tank. Um, so it's not like steel had never been used before. It actually had been used. Um, and when"
    },
    {
      "id": 1744,
      "start": 7234.76,
      "end": 7240.76,
      "text": "you look at the, at the material properties of stainless steel, um, especially, uh, very, uh, if it's been,"
    },
    {
      "id": 1745,
      "start": 7241.16,
      "end": 7248.04,
      "text": "uh, very like full hard, uh, strain hardened stainless steel, uh, at cryogenic temperature,"
    },
    {
      "id": 1746,
      "start": 7248.04,
      "end": 7254.92,
      "text": "uh, the, the strength weight is actually similar to carbon fiber. So if you, if you look at the,"
    },
    {
      "id": 1747,
      "start": 7254.92,
      "end": 7259.639999999999,
      "text": "so if you look at material properties at room temperature, um, it looks like the steel is,"
    },
    {
      "id": 1748,
      "start": 7259.639999999999,
      "end": 7264.44,
      "text": "uh, it's going to be twice as heavy, but if you look at the material properties at cryogenic"
    },
    {
      "id": 1749,
      "start": 7264.44,
      "end": 7270.919999999999,
      "text": "temperature of full hard steel stainless of particular grades, uh, then the, the, you actually"
    },
    {
      "id": 1750,
      "start": 7270.919999999999,
      "end": 7277.799999999999,
      "text": "get to a similar strength weight as carbon fiber. And, and in the case of starship, both the fuel and"
    },
    {
      "id": 1751,
      "start": 7277.799999999999,
      "end": 7285.32,
      "text": "the oxidizer are cryogenic. So for, for, uh, Falcon nine, the fuel is rocket propellate grade kerosene,"
    },
    {
      "id": 1752,
      "start": 7285.32,
      "end": 7292.759999999999,
      "text": "basically pure, like a, a very pure form of jet fuel. Um, which is, but, but that is, that is roughly"
    },
    {
      "id": 1753,
      "start": 7292.759999999999,
      "end": 7298.5199999999995,
      "text": "room temperature. Um, although we do action, we do actually chill it slightly below, we chill it like"
    },
    {
      "id": 1754,
      "start": 7298.5199999999995,
      "end": 7305.719999999999,
      "text": "a beer, um, we do chill it, but, um, but, but it's not cryogenic. In fact, if we made it cryogenic,"
    },
    {
      "id": 1755,
      "start": 7305.719999999999,
      "end": 7312.04,
      "text": "it would just turn to wax. So, um, but, but for starship, the it's liquid methane and liquid oxygen,"
    },
    {
      "id": 1756,
      "start": 7312.04,
      "end": 7320.2,
      "text": "they, they, uh, they're liquid at, at similar temperatures. Uh, so, uh, so basically, uh, almost"
    },
    {
      "id": 1757,
      "start": 7320.2,
      "end": 7326.5199999999995,
      "text": "the entire primary structure is a cryogenic temperature. So then you've got, uh, uh, a 300"
    },
    {
      "id": 1758,
      "start": 7326.5199999999995,
      "end": 7334.5199999999995,
      "text": "series stainless that's, that's, um, strain hardened, uh, because it's at almost all things,"
    },
    {
      "id": 1759,
      "start": 7334.5199999999995,
      "end": 7340.6,
      "text": "a cryogenic temperature actually has a similar strength to weight as, uh, carbon fiber."
    },
    {
      "id": 1760,
      "start": 7340.6,
      "end": 7348.68,
      "text": "It costs, uh, 50 times less, normal material and is very easy to work with. You can weld stainless"
    },
    {
      "id": 1761,
      "start": 7348.68,
      "end": 7354.280000000001,
      "text": "steel outdoors. Uh, you could smoke a cigar while welding stainless steel. It's just like, it's,"
    },
    {
      "id": 1762,
      "start": 7354.280000000001,
      "end": 7360.04,
      "text": "it's very resilient. Um, you, you can modify it easily. It's, it's, uh, if you want to,"
    },
    {
      "id": 1763,
      "start": 7360.04,
      "end": 7366.84,
      "text": "if you want to attach something, you just weld it right on. So, um, very easy to work with for a,"
    },
    {
      "id": 1764,
      "start": 7366.84,
      "end": 7374.52,
      "text": "very low cost. Uh, and, um, now, like I said, at cryogenic temperature, similar strength to weight,"
    },
    {
      "id": 1765,
      "start": 7374.52,
      "end": 7381.8,
      "text": "uh, to carbon fiber. Um, then when you factor in that, uh, that we don't need, we don't, we,"
    },
    {
      "id": 1766,
      "start": 7381.8,
      "end": 7387.4800000000005,
      "text": "we have a much reduced, uh, heat shield mass, uh, because the melting point of steel is much greater"
    },
    {
      "id": 1767,
      "start": 7387.4800000000005,
      "end": 7393.400000000001,
      "text": "than the melting point of aluminum. Um, it's about twice the melting point of aluminum. And,"
    },
    {
      "id": 1768,
      "start": 7393.4,
      "end": 7397.48,
      "text": "uh, so you can just run the rocket much hotter. Yes. So, especially for the ship,"
    },
    {
      "id": 1769,
      "start": 7398.28,
      "end": 7404.839999999999,
      "text": "uh, which is coming in like a flame, a blazing meteor. Uh, it is, uh, the, you, you, you can greatly"
    },
    {
      "id": 1770,
      "start": 7404.839999999999,
      "end": 7412.599999999999,
      "text": "reduce the mass of the heat shield. Um, so the, so you can call it cut the mass of the windward,"
    },
    {
      "id": 1771,
      "start": 7413.24,
      "end": 7419.719999999999,
      "text": "uh, part of the heat shield and maybe in half, and you don't need any heat shielding on the,"
    },
    {
      "id": 1772,
      "start": 7419.72,
      "end": 7429.240000000001,
      "text": "on the leeward side. Um, so, um, the, the net, if net result is actually the steel rocket weighs less"
    },
    {
      "id": 1773,
      "start": 7429.240000000001,
      "end": 7434.68,
      "text": "than the carbon fiber rocket because the, the resin in the carbon fiber rocket, uh, uh,"
    },
    {
      "id": 1774,
      "start": 7435.64,
      "end": 7443.64,
      "text": "it, um, starts to melt. Um, so basically carbon fiber and aluminum have about the same operating"
    },
    {
      "id": 1775,
      "start": 7443.64,
      "end": 7450.12,
      "text": "temperature capabilities. Um, and whereas steel can operate at twice temperature. I mean, these are"
    },
    {
      "id": 1776,
      "start": 7450.12,
      "end": 7453.08,
      "text": "very rough approximations. People will, well, you know. I won't go to the rocket base."
    },
    {
      "id": 1777,
      "start": 7453.08,
      "end": 7457.400000000001,
      "text": "What I mean is like people will say, oh, he said it's twice. It's actually, it's actually 0.8."
    },
    {
      "id": 1778,
      "start": 7457.400000000001,
      "end": 7459.64,
      "text": "Shut up, assholes. That's what the main comment's going to be about."
    },
    {
      "id": 1779,
      "start": 7459.64,
      "end": 7465.72,
      "text": "Goddammit. Okay. So the point is that, actually, in retrospect, the, the, the, we should have started,"
    },
    {
      "id": 1780,
      "start": 7465.72,
      "end": 7469.0,
      "text": "we've done steel in the beginning. It was dumb not to do steel. Okay, but to play this back to you,"
    },
    {
      "id": 1781,
      "start": 7469.0,
      "end": 7477.0,
      "text": "what I'm hearing is that steel was a riskier, less proven path other than the early US rockets versus"
    },
    {
      "id": 1782,
      "start": 7477.0,
      "end": 7484.12,
      "text": "carbon fiber was like, uh, worse, but more proven out path. And so you need to be the one to push for,"
    },
    {
      "id": 1783,
      "start": 7484.12,
      "end": 7489.72,
      "text": "hey, we're going to do this riskier path and just figure it out. And so you were fighting like a"
    },
    {
      "id": 1784,
      "start": 7489.72,
      "end": 7495.0,
      "text": "sort of conservatism in a sense. Um, that's why I initially said like that the issue is that we"
    },
    {
      "id": 1785,
      "start": 7495.0,
      "end": 7501.08,
      "text": "weren't making fast enough progress. We were having trouble making even, um, a small barrel section"
    },
    {
      "id": 1786,
      "start": 7501.08,
      "end": 7508.12,
      "text": "of the carbon fiber, um, that didn't have wrinkles in it. Um, so, uh, because at, at, at that large"
    },
    {
      "id": 1787,
      "start": 7508.12,
      "end": 7513.24,
      "text": "scale, you have to have many plies, many sort of layers of the carbon fiber. Um, you've got to cure"
    },
    {
      "id": 1788,
      "start": 7513.24,
      "end": 7518.44,
      "text": "it and you've got to cure it in such a way that it, it doesn't, um, have any wrinkles or, or defects."
    },
    {
      "id": 1789,
      "start": 7518.44,
      "end": 7523.88,
      "text": "The carbon fiber is much less resilient than, than steel. It has much less, it's less toughness."
    },
    {
      "id": 1790,
      "start": 7523.88,
      "end": 7531.08,
      "text": "Um, like stainless steel will, will scratch and, and, and bend and then the carbon fiber will tend to"
    },
    {
      "id": 1791,
      "start": 7531.08,
      "end": 7539.4800000000005,
      "text": "shatter. Um, so, um, so toughness being the area under the stress strain curve, um, so that you're"
    },
    {
      "id": 1792,
      "start": 7539.4800000000005,
      "end": 7544.12,
      "text": "generally going to have to do better with steel. Um, stainless steel to be precise."
    },
    {
      "id": 1793,
      "start": 7544.12,
      "end": 7550.52,
      "text": "One other Starship question. Um, so I visited, um, Starbase, I think it was two years ago,"
    },
    {
      "id": 1794,
      "start": 7550.52,
      "end": 7555.0,
      "text": "um, with Sam Teller and that was awesome. It was very cool to see in a whole bunch of ways."
    },
    {
      "id": 1795,
      "start": 7555.0,
      "end": 7562.4400000000005,
      "text": "One thing I noticed was that people really took pride in the simplicity of things where, you know,"
    },
    {
      "id": 1796,
      "start": 7562.4400000000005,
      "end": 7568.040000000001,
      "text": "everyone wants to tell you how Starship is just a big soda can and, you know, we're hiring welders"
    },
    {
      "id": 1797,
      "start": 7568.040000000001,
      "end": 7573.56,
      "text": "and, you know, if you can weld in any industrial project, you can weld here. But, um, there's a lot"
    },
    {
      "id": 1798,
      "start": 7573.56,
      "end": 7578.52,
      "text": "of pride in the simplicity and... Well, it's, well, it's likely Starship is a very complicated rocket."
    },
    {
      "id": 1799,
      "start": 7578.52,
      "end": 7582.280000000001,
      "text": "So that's what I'm getting at. Is, are things simpler or are they complex?"
    },
    {
      "id": 1800,
      "start": 7582.92,
      "end": 7585.96,
      "text": "Oh, I think maybe they're just, what they're trying to say is that, you know, you don't have"
    },
    {
      "id": 1801,
      "start": 7585.96,
      "end": 7592.360000000001,
      "text": "to have like prior experience in the rocket industry to work on Starship. Um, you know, someone just needs"
    },
    {
      "id": 1802,
      "start": 7592.360000000001,
      "end": 7599.4800000000005,
      "text": "to be, you know, smart and work hard, um, and be trustworthy and they can work on a rocket. They don't,"
    },
    {
      "id": 1803,
      "start": 7599.48,
      "end": 7605.48,
      "text": "they don't need prior rocket experience. Starship is the most complicated machine ever made by humans,"
    },
    {
      "id": 1804,
      "start": 7606.5199999999995,
      "end": 7608.599999999999,
      "text": "by a long shot. In what regards?"
    },
    {
      "id": 1805,
      "start": 7609.959999999999,
      "end": 7613.48,
      "text": "Anything really. I'd say there isn't a more complex machine. Um,"
    },
    {
      "id": 1806,
      "start": 7615.639999999999,
      "end": 7620.44,
      "text": "yeah, I mean, I, I'd say that there's, there's pretty much any, any project I can think of would"
    },
    {
      "id": 1807,
      "start": 7620.44,
      "end": 7628.36,
      "text": "be easier than this. Um, and that's why no one has made a rapidly reusable, nobody has ever made a"
    },
    {
      "id": 1808,
      "start": 7628.36,
      "end": 7636.44,
      "text": "fully reusable over the rocket. It's a very, very hard problem. Um, the, I mean, many smart people"
    },
    {
      "id": 1809,
      "start": 7636.44,
      "end": 7642.759999999999,
      "text": "have tried before, very smart people with immense resources and they failed. Um, so, and we haven't"
    },
    {
      "id": 1810,
      "start": 7642.759999999999,
      "end": 7649.0,
      "text": "succeeded yet. Uh, we're, you know, Falcon is partially reusable, but the upper stage is not. Um,"
    },
    {
      "id": 1811,
      "start": 7649.0,
      "end": 7659.24,
      "text": "um, Starship version three, I think this design that it, it can be fully reusable and that full"
    },
    {
      "id": 1812,
      "start": 7659.24,
      "end": 7665.0,
      "text": "reusability is what will enable us to become a multi-planet civilization. Can you say about the"
    },
    {
      "id": 1813,
      "start": 7665.0,
      "end": 7672.2,
      "text": "circles? So, so I don't, I'm like, I, I said I could, I, any technical problem, even like a hydron"
    },
    {
      "id": 1814,
      "start": 7672.2,
      "end": 7675.96,
      "text": "collider or something like that is, is easier following than this. We, we spent a lot of time on"
    },
    {
      "id": 1815,
      "start": 7675.96,
      "end": 7680.28,
      "text": "bottlenecks. Can you say what the current Starship bottlenecks are even at a high level?"
    },
    {
      "id": 1816,
      "start": 7681.08,
      "end": 7687.4800000000005,
      "text": "I mean, trying to make it not explode generally, that old chestnut really wants to explode."
    },
    {
      "id": 1817,
      "start": 7688.6,
      "end": 7696.04,
      "text": "Um, we've had two boosters explode on the test end. Um, one obliterated, obliterated the entire test"
    },
    {
      "id": 1818,
      "start": 7696.04,
      "end": 7703.16,
      "text": "facility. Um, so it takes like one mistake and, and I mean, the amount of energy contained in, in"
    },
    {
      "id": 1819,
      "start": 7703.16,
      "end": 7708.2,
      "text": "the Starship is insane. And so is that why it's harder than Falcon? That's because it's just more"
    },
    {
      "id": 1820,
      "start": 7708.2,
      "end": 7715.16,
      "text": "energy. It's a lot of new technology. Um, it's, it's, it's pushing, it's pushing the performance envelope."
    },
    {
      "id": 1821,
      "start": 7715.88,
      "end": 7722.28,
      "text": "Um, the Raptor three engine is a very, very advanced engine by far the best recognition ever made."
    },
    {
      "id": 1822,
      "start": 7723.0,
      "end": 7729.5599999999995,
      "text": "Um, but it desperately wants to blow up. I mean, just to put things in perspective here on liftoff,"
    },
    {
      "id": 1823,
      "start": 7729.56,
      "end": 7735.88,
      "text": "um, the, the rocket is generating over a hundred gigawatts of power. It's 20% of us."
    },
    {
      "id": 1824,
      "start": 7737.88,
      "end": 7740.4400000000005,
      "text": "Insane. It's a great comparison. While not exploding."
    },
    {
      "id": 1825,
      "start": 7741.56,
      "end": 7746.92,
      "text": "Sometimes, sometimes, but sometimes, yeah. So I was like, how does it not explode? There's, there's a,"
    },
    {
      "id": 1826,
      "start": 7747.56,
      "end": 7752.200000000001,
      "text": "you know, thousands of ways that it could explode and, and only one way that, that, that it doesn't."
    },
    {
      "id": 1827,
      "start": 7752.2,
      "end": 7761.16,
      "text": "So, so we wanted to merely not really not explore, but fly reliably, uh, on a daily basis, like once"
    },
    {
      "id": 1828,
      "start": 7761.16,
      "end": 7765.639999999999,
      "text": "per hour and obviously, you know, blows up a lot. It's, it's very difficult to maintain that launch"
    },
    {
      "id": 1829,
      "start": 7765.639999999999,
      "end": 7772.2,
      "text": "cadence. Um, and, and then, I'm going to say like, like, what's the, what's the single biggest remaining"
    },
    {
      "id": 1830,
      "start": 7772.2,
      "end": 7780.12,
      "text": "problem for starship? It's, uh, having the heat shield be reusable, um, that such that the, no,"
    },
    {
      "id": 1831,
      "start": 7780.12,
      "end": 7786.44,
      "text": "no one has ever made a reusable orbital heat shield. Um, so the, the, the, the heat shield's got to"
    },
    {
      "id": 1832,
      "start": 7787.24,
      "end": 7793.08,
      "text": "make it through the ascent phase without shocking a bunch of tiles. Um, and then it's going to come"
    },
    {
      "id": 1833,
      "start": 7793.08,
      "end": 7800.76,
      "text": "back in and also not lose a bunch of tiles or, or overheat the, the main, the main, uh, airframe."
    },
    {
      "id": 1834,
      "start": 7800.76,
      "end": 7807.0,
      "text": "Isn't that hard? Cause it's kind of fundamentally a consumable. Uh, well, yes, but your brake pads"
    },
    {
      "id": 1835,
      "start": 7807.0,
      "end": 7810.6,
      "text": "in your car are also consumable, but they last a very long time. Fair. Right. So it just needs to"
    },
    {
      "id": 1836,
      "start": 7810.6,
      "end": 7819.64,
      "text": "last a very long time. Um, but that's just, yeah, try it. I mean, we have brought the ship back and had"
    },
    {
      "id": 1837,
      "start": 7819.64,
      "end": 7826.4400000000005,
      "text": "it do a soft landing in the ocean. I've done that a few times, but, but it lost a lot of tiles, you know,"
    },
    {
      "id": 1838,
      "start": 7826.44,
      "end": 7833.48,
      "text": "and, uh, you know, it was not reusable without a lot of work. Yeah. So even though it did land,"
    },
    {
      "id": 1839,
      "start": 7833.48,
      "end": 7838.28,
      "text": "did, did, did come to soft landing, it was, would not have been reusable without a lot of work."
    },
    {
      "id": 1840,
      "start": 7839.08,
      "end": 7843.639999999999,
      "text": "Um, and, and that, so it's not really reusable in that sense. So that's, that's the biggest problem"
    },
    {
      "id": 1841,
      "start": 7843.639999999999,
      "end": 7849.639999999999,
      "text": "that remains is fully reusable heat shield. Um, so, so like if you want to be able to land it,"
    },
    {
      "id": 1842,
      "start": 7849.64,
      "end": 7856.6,
      "text": "uh, refill propellant and fly again, uh, without good, you know, you can't do this laborious"
    },
    {
      "id": 1843,
      "start": 7856.6,
      "end": 7862.6,
      "text": "inspection of, you know, 40,000 tiles type of thing. I, I, I'm curious how you drive, like when"
    },
    {
      "id": 1844,
      "start": 7862.6,
      "end": 7867.64,
      "text": "you, when I read biographies of yours, it just, uh, it, it, it, it seems like you're just able to"
    },
    {
      "id": 1845,
      "start": 7867.64,
      "end": 7872.52,
      "text": "drive the sense of like urgency and drive the sense of like, this is the, this is the thing that can scale."
    },
    {
      "id": 1846,
      "start": 7873.240000000001,
      "end": 7878.52,
      "text": "Um, and I, I'm curious why you think other organizations of your, like, SpaceX and Tesla are really big"
    },
    {
      "id": 1847,
      "start": 7878.52,
      "end": 7884.120000000001,
      "text": "companies now and you're still able to keep that culture. What goes wrong with other companies"
    },
    {
      "id": 1848,
      "start": 7884.120000000001,
      "end": 7889.88,
      "text": "such that they're not able to do that? I don't know. Um, but like today you said you had like"
    },
    {
      "id": 1849,
      "start": 7889.88,
      "end": 7893.080000000001,
      "text": "a bunch of SpaceX meetings. Like what, what, what is it that you're doing there that's like keeping that?"
    },
    {
      "id": 1850,
      "start": 7893.080000000001,
      "end": 7894.6,
      "text": "That's adding urgency. Yeah, yeah, yeah."
    },
    {
      "id": 1851,
      "start": 7897.400000000001,
      "end": 7904.200000000001,
      "text": "Well, I, I don't know. I guess, uh, the, the urgency is going to come from where I was leading the"
    },
    {
      "id": 1852,
      "start": 7904.2,
      "end": 7909.32,
      "text": "company. So my sense of urgency, I, I have like maniacal sense of urgency. So that maniacal sense"
    },
    {
      "id": 1853,
      "start": 7909.32,
      "end": 7914.12,
      "text": "of urgency projects through the rest of the company. Is it because of consequences? They're like,"
    },
    {
      "id": 1854,
      "start": 7914.12,
      "end": 7919.96,
      "text": "if you know, Elon said a crazy deadline, but if I don't get it, I know what happens to me. Is it just,"
    },
    {
      "id": 1855,
      "start": 7919.96,
      "end": 7923.8,
      "text": "um, you're able to identify bottlenecks and get rid of them so people can move fast? Like, how do you,"
    },
    {
      "id": 1856,
      "start": 7923.8,
      "end": 7925.8,
      "text": "how do you think about why your companies are able to move fast?"
    },
    {
      "id": 1857,
      "start": 7925.8,
      "end": 7937.88,
      "text": "Yeah, I'm constantly addressing the limiting factor. So, um, I mean, I mean, on the deadlines front,"
    },
    {
      "id": 1858,
      "start": 7938.92,
      "end": 7944.360000000001,
      "text": "I mean, I generally actually try to aim for a deadline that, that I at least think is at the"
    },
    {
      "id": 1859,
      "start": 7944.360000000001,
      "end": 7948.68,
      "text": "50th percentile. So it's, it's not, it's not like an impossible deadline, but it's the most aggressive"
    },
    {
      "id": 1860,
      "start": 7948.68,
      "end": 7954.84,
      "text": "deadline I can think of that could be achieved with 50% probability. Um, which means that it will be"
    },
    {
      "id": 1861,
      "start": 7954.84,
      "end": 7964.12,
      "text": "late half the time. Um, and, um, but whatever, like there is like a law of gases expansion that"
    },
    {
      "id": 1862,
      "start": 7964.12,
      "end": 7969.08,
      "text": "applies to schedules, like whatever given, whatever schedule you, you like, if you said,"
    },
    {
      "id": 1863,
      "start": 7969.08,
      "end": 7973.72,
      "text": "we're going to do this something in like five years, which to me is like infinity time. Um,"
    },
    {
      "id": 1864,
      "start": 7974.84,
      "end": 7980.92,
      "text": "it, it will expand to fully available schedule and it will take five years. Um, you know, like,"
    },
    {
      "id": 1865,
      "start": 7980.92,
      "end": 7986.76,
      "text": "there's like, there's, there's a physical limit, like that, like physics will limit how fast you"
    },
    {
      "id": 1866,
      "start": 7986.76,
      "end": 7991.56,
      "text": "can do certain things. Like, so like scaling up manufacturing, there's like, there's a rate at"
    },
    {
      "id": 1867,
      "start": 7991.56,
      "end": 7997.32,
      "text": "which you can move the atoms, um, and scale manufacturing. That's why you can't like instantly"
    },
    {
      "id": 1868,
      "start": 7997.32,
      "end": 8002.04,
      "text": "make, you know, a million or something, millions a year or something. Uh, you've got, you've got to"
    },
    {
      "id": 1869,
      "start": 8002.04,
      "end": 8005.8,
      "text": "design manufacturing line. You could bring it up. You could ride the S curve of production."
    },
    {
      "id": 1870,
      "start": 8005.8,
      "end": 8013.96,
      "text": "Um, so yeah, I guess like, like, what can I say that's, that's, that's actually helpful to people?"
    },
    {
      "id": 1871,
      "start": 8014.6,
      "end": 8025.08,
      "text": "Um, I, I think generally, um, a maniacal sense of urgency is, is, uh, is very big deal. Um, so,"
    },
    {
      "id": 1872,
      "start": 8025.64,
      "end": 8031.08,
      "text": "um, and, and you want to have, you want to have, you want to have an aggressive schedule, um,"
    },
    {
      "id": 1873,
      "start": 8031.08,
      "end": 8035.96,
      "text": "and then you, and you, and you want to figure out what the limiting factor is at any point in time and,"
    },
    {
      "id": 1874,
      "start": 8035.96,
      "end": 8039.16,
      "text": "and help the team address that limiting factor. Can you maybe talk about the,"
    },
    {
      "id": 1875,
      "start": 8039.16,
      "end": 8046.04,
      "text": "so Starlink was slowly in the works for many years, uh, and yeah, we've talked about it all the way in"
    },
    {
      "id": 1876,
      "start": 8046.04,
      "end": 8051.24,
      "text": "the beginning of the company. Yeah. And so then there was a team you had built in Redmond, and then"
    },
    {
      "id": 1877,
      "start": 8051.24,
      "end": 8057.48,
      "text": "at one point you decided this team is just not cutting us, but again, how did you like,"
    },
    {
      "id": 1878,
      "start": 8059.5599999999995,
      "end": 8066.76,
      "text": "it went for a few years slowly. And so why did this, why didn't you act earlier? And why did you"
    },
    {
      "id": 1879,
      "start": 8066.76,
      "end": 8069.5599999999995,
      "text": "act when you did like, why was that the right moment at which to act?"
    },
    {
      "id": 1880,
      "start": 8069.56,
      "end": 8077.160000000001,
      "text": "I mean, I, I have, I have these very detailed, um, engineering reviews weekly. Um, that that's,"
    },
    {
      "id": 1881,
      "start": 8078.76,
      "end": 8084.120000000001,
      "text": "that's maybe a very unusual level of granularity. Um, I don't know anyone who runs a company,"
    },
    {
      "id": 1882,
      "start": 8085.160000000001,
      "end": 8091.080000000001,
      "text": "or at least a manufacturing company that, that goes to the level of detail that, that I go into. Um,"
    },
    {
      "id": 1883,
      "start": 8092.200000000001,
      "end": 8096.4400000000005,
      "text": "so it's, it's, it's not, it's not as though, like I have a pretty good understanding of what's"
    },
    {
      "id": 1884,
      "start": 8097.32,
      "end": 8103.799999999999,
      "text": "actually going on because we, we, we, we go, we go through things in detail. Um,"
    },
    {
      "id": 1885,
      "start": 8104.599999999999,
      "end": 8109.719999999999,
      "text": "and I'm a big believer in skip level meetings where the individuals, instead of having the person that"
    },
    {
      "id": 1886,
      "start": 8109.719999999999,
      "end": 8117.719999999999,
      "text": "reports to me say things, it's everyone that reports to them, um, says something, um, in, in the technical"
    },
    {
      "id": 1887,
      "start": 8117.72,
      "end": 8126.360000000001,
      "text": "review. Um, and, um, and, and there can't be, um, advanced preparation. So otherwise you, you,"
    },
    {
      "id": 1888,
      "start": 8126.360000000001,
      "end": 8131.16,
      "text": "you're going to get, uh, you know, glazed. Um, as I say these days."
    },
    {
      "id": 1889,
      "start": 8131.16,
      "end": 8132.6,
      "text": "Yeah, exactly. Very Gen Z of you."
    },
    {
      "id": 1890,
      "start": 8132.6,
      "end": 8133.320000000001,
      "text": "Very Gen Z."
    },
    {
      "id": 1891,
      "start": 8133.320000000001,
      "end": 8135.400000000001,
      "text": "How do you prevent advanced administration? You just like call them randomly?"
    },
    {
      "id": 1892,
      "start": 8135.400000000001,
      "end": 8138.92,
      "text": "Like, no, just go around the room and everyone provides an update."
    },
    {
      "id": 1893,
      "start": 8138.92,
      "end": 8139.240000000001,
      "text": "Okay."
    },
    {
      "id": 1894,
      "start": 8139.24,
      "end": 8144.12,
      "text": "Yeah. Um, so, uh, I mean, it's, it's a lot of information to keep in your head because,"
    },
    {
      "id": 1895,
      "start": 8144.12,
      "end": 8149.16,
      "text": "um, you've, you've got to, you've, you've, you've got them, say if you have meetings weekly or twice"
    },
    {
      "id": 1896,
      "start": 8149.16,
      "end": 8155.96,
      "text": "weekly, you, you, you've got a snapshot of what that person said. Um, and, and, and you can, and,"
    },
    {
      "id": 1897,
      "start": 8155.96,
      "end": 8163.88,
      "text": "you can then, you know, plot the progress points. Um, you can sort of mentally plot the points on the"
    },
    {
      "id": 1898,
      "start": 8163.88,
      "end": 8172.68,
      "text": "curve and say, are we converging to a solution or not? Um, or, or are we, you know, like I'll,"
    },
    {
      "id": 1899,
      "start": 8172.68,
      "end": 8180.6,
      "text": "I'll take drastic action, uh, only when I conclude that, um, success is not in a set of possible outcomes."
    },
    {
      "id": 1900,
      "start": 8181.4800000000005,
      "end": 8187.8,
      "text": "Um, so when I say, okay, when I finally reached the conclusion that, okay, unless drastic action is"
    },
    {
      "id": 1901,
      "start": 8187.8,
      "end": 8191.32,
      "text": "done, we have no, no chance of success, then I must take drastic action."
    },
    {
      "id": 1902,
      "start": 8191.32,
      "end": 8198.36,
      "text": "Um, and so that's, that's, that's, I came to that conclusion in 2018, took drastic action and, and fixed the problem."
    },
    {
      "id": 1903,
      "start": 8198.92,
      "end": 8205.8,
      "text": "How, how many, um, you know, you, you, you've got many, many companies and in each of them,"
    },
    {
      "id": 1904,
      "start": 8205.8,
      "end": 8210.36,
      "text": "it sounds like you do this kind of deep engineering understanding of what the relevant bottlenecks are."
    },
    {
      "id": 1905,
      "start": 8210.36,
      "end": 8218.279999999999,
      "text": "So you can do these, um, reviews with people. Yeah. Um, you've been able to scale it up to five,"
    },
    {
      "id": 1906,
      "start": 8218.28,
      "end": 8223.480000000001,
      "text": "six, seven companies. Within one of these companies, you have many different mini companies within them."
    },
    {
      "id": 1907,
      "start": 8224.36,
      "end": 8226.6,
      "text": "What determines the maximum here? Could you have like 80 companies?"
    },
    {
      "id": 1908,
      "start": 8226.6,
      "end": 8227.880000000001,
      "text": "80? No."
    },
    {
      "id": 1909,
      "start": 8227.880000000001,
      "end": 8231.960000000001,
      "text": "But like, you can, you have so many already. I'm like, that's, that's already remarkable."
    },
    {
      "id": 1910,
      "start": 8231.960000000001,
      "end": 8233.08,
      "text": "Why this current number? Yeah."
    },
    {
      "id": 1911,
      "start": 8233.08,
      "end": 8233.480000000001,
      "text": "Exactly."
    },
    {
      "id": 1912,
      "start": 8234.36,
      "end": 8235.320000000002,
      "text": "I know, so, um."
    },
    {
      "id": 1913,
      "start": 8235.320000000002,
      "end": 8236.84,
      "text": "We barely keep one company together."
    },
    {
      "id": 1914,
      "start": 8236.84,
      "end": 8249.0,
      "text": "Um, the neural, it's like, so it, it depends on situation. Um, so, um, I actually don't,"
    },
    {
      "id": 1915,
      "start": 8249.0,
      "end": 8254.44,
      "text": "don't have regular meetings, uh, with foreign company. So that foreign company is sort of cruising"
    },
    {
      "id": 1916,
      "start": 8254.44,
      "end": 8259.8,
      "text": "along. But look, basically if something is working well and making good progress, then there's no point"
    },
    {
      "id": 1917,
      "start": 8259.8,
      "end": 8265.4,
      "text": "in me spending time on it. So, uh, I actually, uh, allocate time according to where, where the,"
    },
    {
      "id": 1918,
      "start": 8265.96,
      "end": 8269.08,
      "text": "where the limiting factor or the problem, where, where, where are things problematic?"
    },
    {
      "id": 1919,
      "start": 8269.72,
      "end": 8276.359999999999,
      "text": "And, um, or where, where are we pushing against, uh, like what, what is holding us back? Will it,"
    },
    {
      "id": 1920,
      "start": 8276.359999999999,
      "end": 8281.24,
      "text": "you know, I, I focus at risk of saying the words too many times, the limiting factor."
    },
    {
      "id": 1921,
      "start": 8281.24,
      "end": 8287.96,
      "text": "Um, so, so basically if something's good, like the irony is if something's going really well,"
    },
    {
      "id": 1922,
      "start": 8288.76,
      "end": 8293.72,
      "text": "um, they don't see much of me. But if something is going badly, they'll see a lot of me."
    },
    {
      "id": 1923,
      "start": 8293.72,
      "end": 8295.56,
      "text": "And so if something is-"
    },
    {
      "id": 1924,
      "start": 8295.56,
      "end": 8297.0,
      "text": "Or not, not even badly. It's, it's, it's like-"
    },
    {
      "id": 1925,
      "start": 8297.0,
      "end": 8298.52,
      "text": "If something's the limiting factor."
    },
    {
      "id": 1926,
      "start": 8298.52,
      "end": 8301.32,
      "text": "It's the limiting factor, exactly. It's not exactly going badly, but it's the thing that's,"
    },
    {
      "id": 1927,
      "start": 8301.32,
      "end": 8303.64,
      "text": "it's, it's the thing that we need to make go faster to-"
    },
    {
      "id": 1928,
      "start": 8303.64,
      "end": 8306.68,
      "text": "And so when something's a limiting factor at SpaceX or Tesla,"
    },
    {
      "id": 1929,
      "start": 8306.68,
      "end": 8312.92,
      "text": "are you like talking weekly and daily with the engineer that's working on it? How,"
    },
    {
      "id": 1930,
      "start": 8312.92,
      "end": 8314.12,
      "text": "how does that actually work?"
    },
    {
      "id": 1931,
      "start": 8314.12,
      "end": 8321.720000000001,
      "text": "Most things that are limiting factor are, um, weekly and some things are twice weekly. So the,"
    },
    {
      "id": 1932,
      "start": 8322.52,
      "end": 8328.12,
      "text": "the AI5 chip review is twice weekly. And so it's every Tuesday and Saturdays,"
    },
    {
      "id": 1933,
      "start": 8329.24,
      "end": 8332.44,
      "text": "is the chip review. Is it open-ended in how long it goes?"
    },
    {
      "id": 1934,
      "start": 8334.04,
      "end": 8335.32,
      "text": "Uh, technically yes, but, uh,"
    },
    {
      "id": 1935,
      "start": 8336.68,
      "end": 8338.84,
      "text": "usually it's, it's like two or three hours."
    },
    {
      "id": 1936,
      "start": 8338.84,
      "end": 8339.800000000001,
      "text": "Mm-hmm."
    },
    {
      "id": 1937,
      "start": 8339.800000000001,
      "end": 8345.08,
      "text": "So, I mean, sometimes less. It's, it depends on, on how much information you're going to go through."
    },
    {
      "id": 1938,
      "start": 8345.08,
      "end": 8345.48,
      "text": "Yeah."
    },
    {
      "id": 1939,
      "start": 8345.48,
      "end": 8349.32,
      "text": "Well, that's another thing. I'm just trying to tease out the, the differences, uh, here,"
    },
    {
      "id": 1940,
      "start": 8349.32,
      "end": 8353.4,
      "text": "because the outcomes seem quite different. And so I think it's interesting to know what inputs are"
    },
    {
      "id": 1941,
      "start": 8353.4,
      "end": 8359.32,
      "text": "different. And it feels like the corporate world, one, like you're saying, just the CEO doing"
    },
    {
      "id": 1942,
      "start": 8359.32,
      "end": 8364.28,
      "text": "engineering reviews does not always happen, despite the fact that that is the, you know, what the company is"
    },
    {
      "id": 1943,
      "start": 8364.28,
      "end": 8371.320000000002,
      "text": "doing. Um, but then time is often pretty finely sliced into, you know, half hour meetings or even 15 minute"
    },
    {
      "id": 1944,
      "start": 8371.320000000002,
      "end": 8378.44,
      "text": "meetings. And it seems like you hold more open-ended, we're talking about it until we figure it out"
    },
    {
      "id": 1945,
      "start": 8378.44,
      "end": 8380.6,
      "text": "out. Yeah."
    },
    {
      "id": 1946,
      "start": 8380.6,
      "end": 8380.6,
      "text": ""
    },
    {
      "id": 1947,
      "start": 8380.6,
      "end": 8380.6,
      "text": ""
    },
    {
      "id": 1948,
      "start": 8380.6,
      "end": 8388.44,
      "text": "Sometimes, but most of them seem to more or less stay on time. Um, so, um,"
    },
    {
      "id": 1949,
      "start": 8388.44,
      "end": 8399.24,
      "text": "I mean, today's, uh, Starship engineering review went a bit longer, um, because there were more topics"
    },
    {
      "id": 1950,
      "start": 8399.24,
      "end": 8406.36,
      "text": "to discuss. Um, you know, trying to figure out how to scale to a million plus tons to over per year is"
    },
    {
      "id": 1951,
      "start": 8407.08,
      "end": 8407.720000000001,
      "text": "quite challenging."
    },
    {
      "id": 1952,
      "start": 8407.720000000001,
      "end": 8413.0,
      "text": "Can I ask a question? So you, you said about, um, Optimus and AI that they're going to"
    },
    {
      "id": 1953,
      "start": 8413.64,
      "end": 8417.08,
      "text": "result in double digit growth rates within a matter of years."
    },
    {
      "id": 1954,
      "start": 8417.08,
      "end": 8418.6,
      "text": "Oh, like the economy?"
    },
    {
      "id": 1955,
      "start": 8418.6,
      "end": 8418.84,
      "text": "Yeah."
    },
    {
      "id": 1956,
      "start": 8418.84,
      "end": 8421.72,
      "text": "Um, yes. I think that's right."
    },
    {
      "id": 1957,
      "start": 8421.72,
      "end": 8427.56,
      "text": "What was the point of the doge cuts if the economy is going to grow so much?"
    },
    {
      "id": 1958,
      "start": 8427.56,
      "end": 8431.4,
      "text": "Well, I think like waste and food are not good things to have, you know, um,"
    },
    {
      "id": 1959,
      "start": 8433.0,
      "end": 8441.4,
      "text": "I, I was actually pretty worried about, I guess, uh, I mean, I think in the absence of AI and robotics,"
    },
    {
      "id": 1960,
      "start": 8441.4,
      "end": 8447.24,
      "text": "we're actually totally screwed, uh, because the national debt is piling up like crazy."
    },
    {
      "id": 1961,
      "start": 8447.8,
      "end": 8452.359999999999,
      "text": "Um, now our interest payments, the interest payments, the national debt exceed the military"
    },
    {
      "id": 1962,
      "start": 8452.359999999999,
      "end": 8456.84,
      "text": "budget, which is a trillion dollars. So if over a trillion dollars, just the interest payments,"
    },
    {
      "id": 1963,
      "start": 8457.56,
      "end": 8462.44,
      "text": "um, you know, that was like, I was like, okay, pretty concerned about that. Maybe if I spend some"
    },
    {
      "id": 1964,
      "start": 8462.44,
      "end": 8468.92,
      "text": "time, we can slow down the bankruptcy of the United States, um, and give us enough time for the AI and"
    },
    {
      "id": 1965,
      "start": 8468.92,
      "end": 8476.6,
      "text": "robots to, you know, help solve the national debt or not help solve. It's the only thing that could"
    },
    {
      "id": 1966,
      "start": 8476.6,
      "end": 8482.68,
      "text": "solve the national debt. Like we are 1000% going to go bankrupt as a country and fail as a country"
    },
    {
      "id": 1967,
      "start": 8482.68,
      "end": 8489.64,
      "text": "without AI and robots, nothing else will solve the national debt. Um, and so, so we would like to,"
    },
    {
      "id": 1968,
      "start": 8490.52,
      "end": 8498.36,
      "text": "well, we just need, we need enough time to get, build the AI and robots, uh, to not go bankrupt before"
    },
    {
      "id": 1969,
      "start": 8498.36,
      "end": 8504.36,
      "text": "then. I, I guess the thing I'm curious about is when those starts, you have this enormous, um, ability"
    },
    {
      "id": 1970,
      "start": 8504.36,
      "end": 8511.880000000001,
      "text": "to enact reform and. Not that enormous. Sure, sure. But totally by your point that like, it's important"
    },
    {
      "id": 1971,
      "start": 8511.880000000001,
      "end": 8518.52,
      "text": "that AI and robotics drive product improvements, drive GDP growth, but why not just directly go after"
    },
    {
      "id": 1972,
      "start": 8518.52,
      "end": 8522.44,
      "text": "the things you were pointing out, right? You know, like the, the, the tariffs on certain components,"
    },
    {
      "id": 1973,
      "start": 8522.44,
      "end": 8529.24,
      "text": "or whether it's like permitting. I'm like the president. And, and very hard to cut, to cut, to"
    },
    {
      "id": 1974,
      "start": 8529.24,
      "end": 8536.36,
      "text": "even, even to, to cut things that are obvious waste and fraud, like, like ridiculous waste and fraud."
    },
    {
      "id": 1975,
      "start": 8536.36,
      "end": 8544.76,
      "text": "Um, what I discovered that is it's extremely difficult even to cut very obvious ways and for,"
    },
    {
      "id": 1976,
      "start": 8544.76,
      "end": 8550.04,
      "text": "um, from the government. Um, because the, the, the government has to operate on a, on like,"
    },
    {
      "id": 1977,
      "start": 8550.04,
      "end": 8554.04,
      "text": "who's complaining, like if, if, if, and if you cut off payments to fraudsters,"
    },
    {
      "id": 1978,
      "start": 8554.04,
      "end": 8559.0,
      "text": "they immediately come up with the most sympathetic sounding, uh, reasons to continue the payment."
    },
    {
      "id": 1979,
      "start": 8559.0,
      "end": 8564.44,
      "text": "They don't say, please keep the fraud going. They say, you know, it's, they're like, you're killing"
    },
    {
      "id": 1980,
      "start": 8564.44,
      "end": 8568.84,
      "text": "baby pandas. And then we're like, meanwhile, there's no baby pandas are dying. They're just making it up."
    },
    {
      "id": 1981,
      "start": 8569.400000000001,
      "end": 8575.320000000002,
      "text": "Um, the forces are capable of, of coming up with extremely compelling, sort of heart wrenching stories"
    },
    {
      "id": 1982,
      "start": 8575.32,
      "end": 8580.84,
      "text": "that are false, but nonetheless sound, uh, sympathetic. And that, that's what happened."
    },
    {
      "id": 1983,
      "start": 8580.84,
      "end": 8588.199999999999,
      "text": "Um, and, uh, so it's like, perhaps I should have known better. Um, and, uh,"
    },
    {
      "id": 1984,
      "start": 8589.72,
      "end": 8595.32,
      "text": "that I thought, wait, let's take a, let's, let's, let's try to cut some amount of, of waste and"
    },
    {
      "id": 1985,
      "start": 8595.32,
      "end": 8600.92,
      "text": "fraud from the government. Maybe there shouldn't be, you know, 20 million people, uh, walked as alive"
    },
    {
      "id": 1986,
      "start": 8600.92,
      "end": 8608.84,
      "text": "in social security who are definitely dead and over the age of 115. The oldest American is 114."
    },
    {
      "id": 1987,
      "start": 8609.72,
      "end": 8615.8,
      "text": "So it's safe to say if somebody is 115 and marked as alive in the social security database, um,"
    },
    {
      "id": 1988,
      "start": 8615.8,
      "end": 8620.92,
      "text": "something is there, there's either a typo. So like somebody should call them and say,"
    },
    {
      "id": 1989,
      "start": 8621.88,
      "end": 8627.64,
      "text": "we, we seem to have your birthday wrong or, or, uh, or we need to mark you as dead."
    },
    {
      "id": 1990,
      "start": 8627.64,
      "end": 8628.36,
      "text": "Okay."
    },
    {
      "id": 1991,
      "start": 8628.36,
      "end": 8630.92,
      "text": "One of the two things."
    },
    {
      "id": 1992,
      "start": 8630.92,
      "end": 8632.6,
      "text": "Very intimidating call to get."
    },
    {
      "id": 1993,
      "start": 8632.6,
      "end": 8637.640000000001,
      "text": "Well, so it seems like a reasonable thing. Um, and if, if like, say their birthday is in the future,"
    },
    {
      "id": 1994,
      "start": 8638.2,
      "end": 8645.720000000001,
      "text": "um, and they have, you know, a small business administration loan and their birthday is 2165."
    },
    {
      "id": 1995,
      "start": 8646.28,
      "end": 8653.480000000001,
      "text": "Um, we either again have a typo or we have fraud. Um, so we say we appear to have gotten the"
    },
    {
      "id": 1996,
      "start": 8653.480000000001,
      "end": 8654.92,
      "text": "century of your birth incorrect."
    },
    {
      "id": 1997,
      "start": 8654.92,
      "end": 8656.2,
      "text": "Or a great plot for a movie."
    },
    {
      "id": 1998,
      "start": 8656.2,
      "end": 8661.64,
      "text": "Yes. This is, this, this is what I, when I'm in my ludicrous fraud, this is what I'm in my ludicrous"
    },
    {
      "id": 1999,
      "start": 8661.64,
      "end": 8662.12,
      "text": "fraud."
    },
    {
      "id": 2000,
      "start": 8662.12,
      "end": 8663.56,
      "text": "Were those people getting payments?"
    },
    {
      "id": 2001,
      "start": 8663.56,
      "end": 8668.68,
      "text": "Some were getting payments from social security, but, but, but the main fraud vector, uh, was to mark"
    },
    {
      "id": 2002,
      "start": 8668.68,
      "end": 8675.24,
      "text": "somebody as alive in social security and then use every other government payment system, uh, to, uh,"
    },
    {
      "id": 2003,
      "start": 8676.04,
      "end": 8679.960000000001,
      "text": "basically to, to, to do fraud. Because what those other government payment systems do, would do,"
    },
    {
      "id": 2004,
      "start": 8679.96,
      "end": 8684.279999999999,
      "text": "they would simply do an are you alive check to the social security database."
    },
    {
      "id": 2005,
      "start": 8684.279999999999,
      "end": 8685.08,
      "text": "Hmm."
    },
    {
      "id": 2006,
      "start": 8685.08,
      "end": 8686.119999999999,
      "text": "It's a, it's a bank shot."
    },
    {
      "id": 2007,
      "start": 8686.119999999999,
      "end": 8689.24,
      "text": "What would you estimate as like the total, uh, amount of fraud from this mechanism?"
    },
    {
      "id": 2008,
      "start": 8689.24,
      "end": 8694.119999999999,
      "text": "Um, my guess is, and, and other, but by the way that the government accountability office has"
    },
    {
      "id": 2009,
      "start": 8694.119999999999,
      "end": 8698.039999999999,
      "text": "done these estimates before. I'm not the only one who's coming out of this, you know, in fact,"
    },
    {
      "id": 2010,
      "start": 8698.039999999999,
      "end": 8703.8,
      "text": "I think they, they did, the GAO did analysis, a rough estimate of fraud during the Biden administration,"
    },
    {
      "id": 2011,
      "start": 8703.8,
      "end": 8710.599999999999,
      "text": "and calculated at roughly half a trillion dollars. So don't take my word for it. Take it, a report"
    },
    {
      "id": 2012,
      "start": 8710.599999999999,
      "end": 8713.64,
      "text": "issued during the Biden administration. How about that?"
    },
    {
      "id": 2013,
      "start": 8713.64,
      "end": 8715.48,
      "text": "From this social security mechanism?"
    },
    {
      "id": 2014,
      "start": 8715.48,
      "end": 8721.88,
      "text": "Uh, it's, it's one of many. It's important to appreciate that the, the, the government does not,"
    },
    {
      "id": 2015,
      "start": 8721.88,
      "end": 8728.84,
      "text": "is very ineffective at, at stopping fraud because, uh, it's, it's, it's not like, like if it was a"
    },
    {
      "id": 2016,
      "start": 8728.84,
      "end": 8733.0,
      "text": "company, like, like stopping fraud, you've got a motivation because it's affecting the earnings of your"
    },
    {
      "id": 2017,
      "start": 8733.0,
      "end": 8740.76,
      "text": "company. Uh, but the government just, just, they just print more money. Um, so it's not, uh, like"
    },
    {
      "id": 2018,
      "start": 8740.76,
      "end": 8747.08,
      "text": "you, you, you need, you need caring and competence, and these are in short supply at, uh, at the federal"
    },
    {
      "id": 2019,
      "start": 8747.08,
      "end": 8754.04,
      "text": "level. Um, yeah, I mean, when you go to the DMV, do you think, wow, this is a bastion of competence?"
    },
    {
      "id": 2020,
      "start": 8755.0,
      "end": 8759.32,
      "text": "Um, well now imagine it's worse than the DMV because it's a DMV that can print money."
    },
    {
      "id": 2021,
      "start": 8759.32,
      "end": 8766.039999999999,
      "text": "So, was it not possible? At least the state level DMVs, uh, need to, the states more or"
    },
    {
      "id": 2022,
      "start": 8766.039999999999,
      "end": 8770.039999999999,
      "text": "less need to stay within their budget or they go bankrupt, but the federal government just prints"
    },
    {
      "id": 2023,
      "start": 8770.039999999999,
      "end": 8773.88,
      "text": "full money. Well, was it not possible to cut that, if there's a cashier half a trillion of fraud?"
    },
    {
      "id": 2024,
      "start": 8774.6,
      "end": 8780.6,
      "text": "Why, why was it not possible to cut all that? Uh, because when, when, as soon as you, we did, we,"
    },
    {
      "id": 2025,
      "start": 8780.6,
      "end": 8790.6,
      "text": "we actually, no, you, you, you really have to stand back and recalibrate your expectations for competence."
    },
    {
      "id": 2026,
      "start": 8791.16,
      "end": 8797.56,
      "text": "Uh, because, uh, you, you, you're operating in a world where, you know, you, you've, you've got to"
    },
    {
      "id": 2027,
      "start": 8797.56,
      "end": 8801.16,
      "text": "sort of make ends meet, like, you know, you've got to pay your bills, you've got to, you know,"
    },
    {
      "id": 2028,
      "start": 8801.16,
      "end": 8807.960000000001,
      "text": "buy the microphones. Yeah, yeah, exactly. Um, so, so you, you, you, if you don't have, it's, it's not like"
    },
    {
      "id": 2029,
      "start": 8807.96,
      "end": 8813.88,
      "text": "there's a giant, largely uncaring monster bureaucracy. It's not even, it's an, and, and a"
    },
    {
      "id": 2030,
      "start": 8813.88,
      "end": 8820.119999999999,
      "text": "bunch of, uh, uh, anachronistic computers that are just, they're just sending payments. Um,"
    },
    {
      "id": 2031,
      "start": 8821.16,
      "end": 8823.96,
      "text": "like one of the things that, that, that, that the Doge team did, that there was,"
    },
    {
      "id": 2032,
      "start": 8825.0,
      "end": 8831.72,
      "text": "and it sounds so simple, uh, that, that probably will save, um, let's say a hundred billion,"
    },
    {
      "id": 2033,
      "start": 8831.72,
      "end": 8837.8,
      "text": "maybe 200 billion a year, um, is simply requiring that payments from the main treasury"
    },
    {
      "id": 2034,
      "start": 8837.8,
      "end": 8841.0,
      "text": "computer, which is called PAMs, like payment accounts master or something like that."
    },
    {
      "id": 2035,
      "start": 8841.0,
      "end": 8847.48,
      "text": "There's five trillion PAMs here, um, requiring that any payment go, that goes out, have a payment,"
    },
    {
      "id": 2036,
      "start": 8847.48,
      "end": 8853.08,
      "text": "um, appropriation code, make it mandatory, not optional, and that you have anything at all in"
    },
    {
      "id": 2037,
      "start": 8853.08,
      "end": 8861.56,
      "text": "the comment field. Um, because, uh, you, you have to recalibrate how dumb things are."
    },
    {
      "id": 2038,
      "start": 8861.56,
      "end": 8862.599999999999,
      "text": "But you think,"
    },
    {
      "id": 2039,
      "start": 8862.6,
      "end": 8868.44,
      "text": "PAMs were being sent out with no appropriation code, not, not checking back to any congressional"
    },
    {
      "id": 2040,
      "start": 8868.44,
      "end": 8875.4,
      "text": "appropriation, and no explanation. And this is why the, the Department of War, formerly the Department"
    },
    {
      "id": 2041,
      "start": 8875.4,
      "end": 8879.4,
      "text": "of Defense, cannot pass an audit because the information is literally not there."
    },
    {
      "id": 2042,
      "start": 8881.48,
      "end": 8882.84,
      "text": "Recalibrate your expectations."
    },
    {
      "id": 2043,
      "start": 8882.84,
      "end": 8886.68,
      "text": "I, I, I, I want to better understand this how it's really a number, because there, there's an IG report in 2024."
    },
    {
      "id": 2044,
      "start": 8886.68,
      "end": 8888.84,
      "text": "How, how, you must like, why is it so low?"
    },
    {
      "id": 2045,
      "start": 8888.84,
      "end": 8893.800000000001,
      "text": "Um, maybe, but, uh, which found that like over seven years, this, the social security fraud,"
    },
    {
      "id": 2046,
      "start": 8893.800000000001,
      "end": 8897.08,
      "text": "they estimated was like 70 billions over seven years, so like 10 billion a year."
    },
    {
      "id": 2047,
      "start": 8897.08,
      "end": 8899.48,
      "text": "So I'd be curious to see what like the other 490 billion is."
    },
    {
      "id": 2048,
      "start": 8899.48,
      "end": 8902.44,
      "text": "Federal government expenditures are seven and a half trillion a year."
    },
    {
      "id": 2049,
      "start": 8902.44,
      "end": 8902.76,
      "text": "Yeah."
    },
    {
      "id": 2050,
      "start": 8904.12,
      "end": 8907.800000000001,
      "text": "Um, how, what, what percentage, how competent do you think government is?"
    },
    {
      "id": 2051,
      "start": 8907.800000000001,
      "end": 8913.08,
      "text": "The, the discretionary spending there is like 15%."
    },
    {
      "id": 2052,
      "start": 8913.08,
      "end": 8916.44,
      "text": "Yeah, but, but it doesn't matter. The, the, the, the most of the fraud is non-discretionary. It's,"
    },
    {
      "id": 2053,
      "start": 8916.44,
      "end": 8923.96,
      "text": "it's basically a fraudulent Medicare, Medicaid, uh, social security, uh, uh, uh, you know, um,"
    },
    {
      "id": 2054,
      "start": 8925.64,
      "end": 8929.0,
      "text": "disability, uh, it, it's, there's, there's a zillion government payments."
    },
    {
      "id": 2055,
      "start": 8929.0,
      "end": 8929.4,
      "text": "Yeah."
    },
    {
      "id": 2056,
      "start": 8929.4,
      "end": 8937.0,
      "text": "Um, and, and a bunch of these payments are in fact, uh, they're, they're, they're, uh, block transfers to the"
    },
    {
      "id": 2057,
      "start": 8937.0,
      "end": 8942.68,
      "text": "states. So the federal government doesn't even have the information in a lot of cases to even see,"
    },
    {
      "id": 2058,
      "start": 8942.68,
      "end": 8948.44,
      "text": "know if there's fraud, let's consider, let's like reductio ad absurdum, the government, the government"
    },
    {
      "id": 2059,
      "start": 8948.44,
      "end": 8951.720000000001,
      "text": "is perfect and has no fraud. What is your probability estimate of that?"
    },
    {
      "id": 2060,
      "start": 8953.48,
      "end": 8960.04,
      "text": "I mean, zero. Okay. So then would you say that for a foreign waste that the government, uh, is,"
    },
    {
      "id": 2061,
      "start": 8961.720000000001,
      "end": 8970.28,
      "text": "has, is 90%. That also would be quite generous. But if, if it's only 90%, that means that there's"
    },
    {
      "id": 2062,
      "start": 8970.28,
      "end": 8975.720000000001,
      "text": "$750 billion a year of waste and fraud and it's not 90%. It's not 90% effective."
    },
    {
      "id": 2063,
      "start": 8975.720000000001,
      "end": 8979.640000000001,
      "text": "This seems like a strange rate of first principles, the amount of fraud in the government. Just like,"
    },
    {
      "id": 2064,
      "start": 8979.640000000001,
      "end": 8984.36,
      "text": "how much do you think there is? And then, uh, uh, I, I, anyways, we, we don't know how to do it live,"
    },
    {
      "id": 2065,
      "start": 8984.36,
      "end": 8988.12,
      "text": "but I'd be curious to like, so you know, a lot about fraud at, at Stripe. People are constantly trying"
    },
    {
      "id": 2066,
      "start": 8988.12,
      "end": 8993.320000000002,
      "text": "to do fraud. Yeah. But as you say, it's like a little bit of a, um, we've really grounded down,"
    },
    {
      "id": 2067,
      "start": 8993.320000000002,
      "end": 8998.2,
      "text": "but it's a little bit of a different problem space because we're dealing with a much more heterogeneous"
    },
    {
      "id": 2068,
      "start": 8998.2,
      "end": 9003.16,
      "text": "set of fraud vectors here than we are. Yeah. But I mean, I mean, at Stripe, you, you, you,"
    },
    {
      "id": 2069,
      "start": 9003.16,
      "end": 9008.52,
      "text": "you have high confidence and you try hard. Um, you have high confidence and high caring,"
    },
    {
      "id": 2070,
      "start": 9008.52,
      "end": 9015.400000000001,
      "text": "but still fraud is non, non zero. Um, now, now, now imagine it's at a much bigger scale. Um,"
    },
    {
      "id": 2071,
      "start": 9015.400000000001,
      "end": 9021.880000000001,
      "text": "there's much less competence and much less caring. You know, back to PayPal back in the day, we were"
    },
    {
      "id": 2072,
      "start": 9021.880000000001,
      "end": 9027.640000000001,
      "text": "trying to manage fraud down to about 1% of the, the payment volume. Um, and that was very difficult,"
    },
    {
      "id": 2073,
      "start": 9027.64,
      "end": 9034.199999999999,
      "text": "took a tremendous amount of competence and caring to, uh, get fraud merely to 1%. Um, now imagine"
    },
    {
      "id": 2074,
      "start": 9034.199999999999,
      "end": 9038.119999999999,
      "text": "that the organization where there's much less caring and much less competence,"
    },
    {
      "id": 2075,
      "start": 9038.76,
      "end": 9044.119999999999,
      "text": "it's going to be much more than 1%. How do you feel now looking back on, um,"
    },
    {
      "id": 2076,
      "start": 9045.08,
      "end": 9052.119999999999,
      "text": "kind of politics and, and doing stuff there where it feels like, looking from the outside in, the two,"
    },
    {
      "id": 2077,
      "start": 9052.12,
      "end": 9060.04,
      "text": "you know, two things have been quite impactful, one, the America pack and two, um, the acquisition of,"
    },
    {
      "id": 2078,
      "start": 9060.04,
      "end": 9067.160000000002,
      "text": "of, well, Twitter at the time, but also it seems like there was a bunch of heartache. And so what's"
    },
    {
      "id": 2079,
      "start": 9067.160000000002,
      "end": 9072.84,
      "text": "your, what's your grading of the whole experience? Well, um,"
    },
    {
      "id": 2080,
      "start": 9072.84,
      "end": 9081.56,
      "text": "I think, I think those things needed to be done to maximize the probability that the future is good."
    },
    {
      "id": 2081,
      "start": 9082.6,
      "end": 9092.2,
      "text": "Um, so, um, but politics generally is very tribal. Um, and it's, it's very tribal and it's, and people"
    },
    {
      "id": 2082,
      "start": 9092.2,
      "end": 9098.92,
      "text": "lose their objectivity usually with politics. Like they, they generally have trouble seeing the good on"
    },
    {
      "id": 2083,
      "start": 9098.92,
      "end": 9104.76,
      "text": "the other side or the bad in their own side. That's generally how it goes. Um, I, I, that,"
    },
    {
      "id": 2084,
      "start": 9104.76,
      "end": 9109.24,
      "text": "that I guess was one of the things that surprised me the most is you, you often simply cannot reason"
    },
    {
      "id": 2085,
      "start": 9109.24,
      "end": 9114.28,
      "text": "with people. Um, if they're in one tribe or the other, they, they simply believe that everything"
    },
    {
      "id": 2086,
      "start": 9114.28,
      "end": 9119.64,
      "text": "their tribe does is good and anything the other political tribe does is bad. Um, and persuading them"
    },
    {
      "id": 2087,
      "start": 9119.64,
      "end": 9135.56,
      "text": "is otherwise is almost impossible. Um, so anyway, but, um, I think, I think overall those actions,"
    },
    {
      "id": 2088,
      "start": 9137.16,
      "end": 9144.599999999999,
      "text": "um, acquiring Twitter, getting Trump elected, even though it makes a lot of people angry. Um,"
    },
    {
      "id": 2089,
      "start": 9144.6,
      "end": 9151.08,
      "text": "I think those, I think those actions are good for, we're good for civilization. Um, yeah. How does it feed"
    },
    {
      "id": 2090,
      "start": 9151.08,
      "end": 9157.4,
      "text": "into the future you're excited about? Well, um, America needs to continue, America needs to be strong"
    },
    {
      "id": 2091,
      "start": 9157.4,
      "end": 9166.04,
      "text": "enough to last long enough to, um, extend life to other planets and to kind of get, I guess, AI and"
    },
    {
      "id": 2092,
      "start": 9166.04,
      "end": 9171.960000000001,
      "text": "robotics to the point where we can ensure that the future is good. Um, like on the other hand, if, if,"
    },
    {
      "id": 2093,
      "start": 9171.96,
      "end": 9179.32,
      "text": "if we were to descend into, um, say communism or, or, or some situation where, where the state was"
    },
    {
      "id": 2094,
      "start": 9179.32,
      "end": 9186.519999999999,
      "text": "extremely oppressive, um, that, that would mean that we, we might not be able to become multi-planetary."
    },
    {
      "id": 2095,
      "start": 9187.24,
      "end": 9197.0,
      "text": "Um, and we might, the state might, um, you know, stamp out, um, our progress and AI and robotics."
    },
    {
      "id": 2096,
      "start": 9197.0,
      "end": 9206.44,
      "text": "How do you feel about, um, uh, you know, Optimus, Grok, et cetera, are going to be leveraged by,"
    },
    {
      "id": 2097,
      "start": 9206.44,
      "end": 9210.44,
      "text": "and not just yours, any revenue maximizing company's products will be leveraged by the government"
    },
    {
      "id": 2098,
      "start": 9211.08,
      "end": 9218.6,
      "text": "over time. Um, how does this concern manifest in what private companies should be willing to"
    },
    {
      "id": 2099,
      "start": 9219.56,
      "end": 9223.72,
      "text": "give governments, what kinds of guardrails should, like, should, you know, should, um,"
    },
    {
      "id": 2100,
      "start": 9223.72,
      "end": 9232.199999999999,
      "text": "um, AI models be, uh, um, made to do whatever the government that has contracted them out to do,"
    },
    {
      "id": 2101,
      "start": 9232.199999999999,
      "end": 9237.64,
      "text": "ask them to do, um, should, like, should, should, should Grok get to say, like, actually, even the"
    },
    {
      "id": 2102,
      "start": 9237.64,
      "end": 9244.359999999999,
      "text": "military wants to do X, no, Grok will not do that. I think probably the biggest danger of AI,"
    },
    {
      "id": 2103,
      "start": 9244.359999999999,
      "end": 9249.4,
      "text": "well, maybe the biggest danger of AI, of, for, for AI and robotics going wrong, wrong is, is government."
    },
    {
      "id": 2104,
      "start": 9249.4,
      "end": 9257.4,
      "text": "Interesting. You know, um, I mean, the, the way you think, like, like, like people who are opposed"
    },
    {
      "id": 2105,
      "start": 9257.4,
      "end": 9262.68,
      "text": "to corporations or, or, or worried about corporations should, um, really worry about,"
    },
    {
      "id": 2106,
      "start": 9262.68,
      "end": 9267.48,
      "text": "the most about government, because government is just a corporation in the limit. It's a government,"
    },
    {
      "id": 2107,
      "start": 9267.48,
      "end": 9272.359999999999,
      "text": "it is, it is, it is, the government is just the biggest corporation with a monopoly on violence."
    },
    {
      "id": 2108,
      "start": 9272.36,
      "end": 9279.880000000001,
      "text": "Um, so, I always find it, like, a strange dichotomy where, where people would think corporations are"
    },
    {
      "id": 2109,
      "start": 9279.880000000001,
      "end": 9284.04,
      "text": "bad, but the government is good, when the government is simply the biggest and, and, and worst corporation."
    },
    {
      "id": 2110,
      "start": 9287.640000000001,
      "end": 9291.400000000001,
      "text": "But people have that dichotomy. They somehow think, at the same time,"
    },
    {
      "id": 2111,
      "start": 9291.400000000001,
      "end": 9296.36,
      "text": "that government can be good, but corporations, bad, and this is not true. Corporations are,"
    },
    {
      "id": 2112,
      "start": 9296.36,
      "end": 9302.52,
      "text": "are, have better morality than the government. So, I, I, I actually think it's, uh, you know,"
    },
    {
      "id": 2113,
      "start": 9303.0,
      "end": 9307.880000000001,
      "text": "that's, uh, that's, uh, that, that is the thing to be worried about. It's like, if, uh, you know,"
    },
    {
      "id": 2114,
      "start": 9307.880000000001,
      "end": 9312.52,
      "text": "should, should, if the government should not, like, if the government could potentially use AI and"
    },
    {
      "id": 2115,
      "start": 9312.52,
      "end": 9319.24,
      "text": "robotics to suppress the population. Like, that is a serious concern. I mean, as, as a guy building AI and"
    },
    {
      "id": 2116,
      "start": 9319.24,
      "end": 9324.28,
      "text": "robotics, how do you, how do you, like, how do you prevent that? Uh, well, I think that, like, if,"
    },
    {
      "id": 2117,
      "start": 9324.28,
      "end": 9330.84,
      "text": "if you have a limited government, um, if you limit the powers of government, which is like,"
    },
    {
      "id": 2118,
      "start": 9330.84,
      "end": 9334.2,
      "text": "really what the US constitution is intended to do, is intended to limit the powers of government,"
    },
    {
      "id": 2119,
      "start": 9335.24,
      "end": 9338.84,
      "text": "then, then, uh, you're probably gonna have a better outcome than if you have more government."
    },
    {
      "id": 2120,
      "start": 9340.04,
      "end": 9345.960000000001,
      "text": "So, but robotics will be available to all governments, right? Yeah, not about all governments."
    },
    {
      "id": 2121,
      "start": 9345.96,
      "end": 9353.8,
      "text": "Um, I mean, it's difficult to predict the, like I can say, like, what, what's, what's, what's,"
    },
    {
      "id": 2122,
      "start": 9353.8,
      "end": 9357.96,
      "text": "what's the end, end point or like, what is, what is many years in the future, but it's difficult to"
    },
    {
      "id": 2123,
      "start": 9357.96,
      "end": 9367.16,
      "text": "predict the, the sort of path along, along that way. Um, like if civilization progresses, AI will"
    },
    {
      "id": 2124,
      "start": 9368.279999999999,
      "end": 9373.64,
      "text": "vastly exceed the symbol human intelligence and, and there will be far more robots than humans."
    },
    {
      "id": 2125,
      "start": 9373.64,
      "end": 9379.96,
      "text": "Um, along the way, what happens? It's very difficult to predict."
    },
    {
      "id": 2126,
      "start": 9379.96,
      "end": 9384.76,
      "text": "I mean, it seems like one thing you could do is just say, um, uh, you are not allowed to,"
    },
    {
      "id": 2127,
      "start": 9385.56,
      "end": 9389.8,
      "text": "whatever government decks, you're not allowed to use Optimus to do X, Y, Z, just write out like a policy."
    },
    {
      "id": 2128,
      "start": 9389.8,
      "end": 9392.599999999999,
      "text": "I mean, you, you, I think you treated recently that Grok should have a moral constitution."
    },
    {
      "id": 2129,
      "start": 9393.24,
      "end": 9398.439999999999,
      "text": "Um, and one of those things could be that we, we limit what governments are allowed to do with"
    },
    {
      "id": 2130,
      "start": 9398.44,
      "end": 9404.92,
      "text": "this advanced technology. I mean, yeah, we, we, we, we can do what is, what, what, I mean,"
    },
    {
      "id": 2131,
      "start": 9407.16,
      "end": 9413.08,
      "text": "if, if, if, if, if the politicians pass a law, uh, then, and they can enforce that law,"
    },
    {
      "id": 2132,
      "start": 9413.08,
      "end": 9419.960000000001,
      "text": "then it's hard to not do that law. You know, the, the best thing we can have is, is, is limited government,"
    },
    {
      "id": 2133,
      "start": 9419.96,
      "end": 9427.0,
      "text": "uh, where, um, you know, you have, you have the appropriate cross checks between the executive,"
    },
    {
      "id": 2134,
      "start": 9427.0,
      "end": 9430.359999999999,
      "text": "judicial, and, um, legislative branches."
    },
    {
      "id": 2135,
      "start": 9430.359999999999,
      "end": 9434.199999999999,
      "text": "I, I, I guess the, the reason I'm curious about it is this, like, at some point,"
    },
    {
      "id": 2136,
      "start": 9434.199999999999,
      "end": 9438.279999999999,
      "text": "it seems like the limits will come from you, right? Like, you've got the Optimus,"
    },
    {
      "id": 2137,
      "start": 9438.279999999999,
      "end": 9440.199999999999,
      "text": "you've got the space GPUs, you've got the..."
    },
    {
      "id": 2138,
      "start": 9440.199999999999,
      "end": 9441.72,
      "text": "You think I'll be the boss of the government."
    },
    {
      "id": 2139,
      "start": 9441.72,
      "end": 9446.039999999999,
      "text": "Or you will get the, you will, like the, I mean, already it's the case with SpaceX,"
    },
    {
      "id": 2140,
      "start": 9446.599999999999,
      "end": 9452.92,
      "text": "that for things that are crucial to the, um, uh, like the government really cares about getting"
    },
    {
      "id": 2141,
      "start": 9452.92,
      "end": 9457.32,
      "text": "certain satellites up in space, whatever, like it needs SpaceX. Uh, it is the, it is the, um,"
    },
    {
      "id": 2142,
      "start": 9457.32,
      "end": 9464.92,
      "text": "a necessary contractor. And you are in the process of building more and more of the, um, uh, the"
    },
    {
      "id": 2143,
      "start": 9464.92,
      "end": 9470.039999999999,
      "text": "technological components of the future that, that, that will have an analogous role in different industries."
    },
    {
      "id": 2144,
      "start": 9470.04,
      "end": 9476.36,
      "text": "And you could have this ability to like set some policy that, um, you know, suppressing"
    },
    {
      "id": 2145,
      "start": 9477.240000000002,
      "end": 9481.880000000001,
      "text": "classical liberalism in any way. I, my companies will not help in, in any way with that. Or,"
    },
    {
      "id": 2146,
      "start": 9481.880000000001,
      "end": 9487.080000000002,
      "text": "you know, some policy like that. Um, I, I will do my best to ensure that anything"
    },
    {
      "id": 2147,
      "start": 9487.080000000002,
      "end": 9491.160000000002,
      "text": "that's within my control maximizes the good outcome for humanity."
    },
    {
      "id": 2148,
      "start": 9495.400000000001,
      "end": 9499.560000000001,
      "text": "I think anything else would be short-sighted. Um, because obviously I'm part of humanity, so."
    },
    {
      "id": 2149,
      "start": 9500.04,
      "end": 9511.560000000001,
      "text": "Um, I like humans, um, pro-human, pro-human. Um, you, you, you mentioned that Dojo 3 will be used"
    },
    {
      "id": 2150,
      "start": 9511.560000000001,
      "end": 9516.36,
      "text": "for space-based compute. Um, you really read my, uh, what I say."
    },
    {
      "id": 2151,
      "start": 9516.36,
      "end": 9519.720000000001,
      "text": "I don't know if you know Twitter, but I know you a lot."
    },
    {
      "id": 2152,
      "start": 9519.72,
      "end": 9521.4,
      "text": "I'm like, there's a lot of followers."
    },
    {
      "id": 2153,
      "start": 9521.4,
      "end": 9522.599999999999,
      "text": "Did giveaway."
    },
    {
      "id": 2154,
      "start": 9523.64,
      "end": 9526.92,
      "text": "Um, how do you, how do you have discerned my secrets? I've lost them."
    },
    {
      "id": 2155,
      "start": 9526.92,
      "end": 9532.84,
      "text": "How do you design this chip for space? What do you, like, yeah, what, what, what changes?"
    },
    {
      "id": 2156,
      "start": 9533.64,
      "end": 9539.8,
      "text": "Well, I guess you want to design it to be, um, more radiation tolerant and run at a higher temperature."
    },
    {
      "id": 2157,
      "start": 9539.8,
      "end": 9546.679999999998,
      "text": "Uh, so you could, um, you know, roughly if you increase the, um, operating temperature by 20th set"
    },
    {
      "id": 2158,
      "start": 9546.679999999998,
      "end": 9555.08,
      "text": "in degrees Kelvin, you can cut your radiator mass in half. Um, so running at a higher temperature is,"
    },
    {
      "id": 2159,
      "start": 9555.08,
      "end": 9563.4,
      "text": "is helpful in, in space. Um, there's, I mean, there's various things you can do for shielding the memory and,"
    },
    {
      "id": 2160,
      "start": 9563.4,
      "end": 9567.96,
      "text": "um, but like neural nets are going to be very resilient to bit flips. Yeah."
    },
    {
      "id": 2161,
      "start": 9567.96,
      "end": 9574.039999999999,
      "text": "So like most of what, what happens for radiation is like random bit flips. Um, but like, if you've got"
    },
    {
      "id": 2162,
      "start": 9574.039999999999,
      "end": 9579.88,
      "text": "like, you know, a multi-trilling parameter model and you get a few bit flips, it doesn't matter. Um,"
    },
    {
      "id": 2163,
      "start": 9580.44,
      "end": 9584.119999999999,
      "text": "it's, it's much like curiosity programs are going to be much more sensitive to bit flips than, um,"
    },
    {
      "id": 2164,
      "start": 9584.84,
      "end": 9592.52,
      "text": "some giant parameter file. Um, so I just designed it to run hard and, um,"
    },
    {
      "id": 2165,
      "start": 9593.4,
      "end": 9599.88,
      "text": "I think you pretty much do it the same way that you do things on earth apart from make it run hotter."
    },
    {
      "id": 2166,
      "start": 9599.88,
      "end": 9605.4,
      "text": "Hmm. Um, I mean, the solar array is most of the weight on the satellite. Is there a way to make the,"
    },
    {
      "id": 2167,
      "start": 9605.4,
      "end": 9611.88,
      "text": "um, the GPUs even more power dense than what NVIDIA and TPUs and et cetera are planning on doing that"
    },
    {
      "id": 2168,
      "start": 9611.88,
      "end": 9619.64,
      "text": "would, you know, be especially privileged in the space-based world? Well, I mean, the basic math is like,"
    },
    {
      "id": 2169,
      "start": 9619.64,
      "end": 9628.519999999999,
      "text": "like, um, if you can do about a kilowatt per reticle, um, and then you'd need, um,"
    },
    {
      "id": 2170,
      "start": 9630.199999999999,
      "end": 9635.08,
      "text": "you know, a hundred million full reticle chips, uh, to do a hundred gigawatts."
    },
    {
      "id": 2171,
      "start": 9635.08,
      "end": 9635.48,
      "text": "Yeah."
    },
    {
      "id": 2172,
      "start": 9637.8,
      "end": 9645.64,
      "text": "So yeah, depending on what your yield assumptions are, you know, um, that, that tells you how many"
    },
    {
      "id": 2173,
      "start": 9645.64,
      "end": 9652.279999999999,
      "text": "chips you need to make, um, but cool. You need, if you want, if you're, if you're gonna have a hundred"
    },
    {
      "id": 2174,
      "start": 9652.279999999999,
      "end": 9659.24,
      "text": "gigawatts of power, you need, you know, a hundred million chips running that are running a kilowatt"
    },
    {
      "id": 2175,
      "start": 9659.24,
      "end": 9668.519999999999,
      "text": "sustained output per reticle. Um, a hundred, basic math. A hundred million chips, uh, it depends on,"
    },
    {
      "id": 2176,
      "start": 9669.8,
      "end": 9674.519999999999,
      "text": "yeah, if, if, if you, if you look at the die size of something like black ball GPUs or something,"
    },
    {
      "id": 2177,
      "start": 9674.52,
      "end": 9680.6,
      "text": "and how many you can get out of a wafer, you can get like, um, on the order of dozens or less,"
    },
    {
      "id": 2178,
      "start": 9680.6,
      "end": 9686.2,
      "text": "uh, per wafer. So you're basically you're, this is a world where if we're putting that out"
    },
    {
      "id": 2179,
      "start": 9687.08,
      "end": 9690.84,
      "text": "every single year, you're producing millions, millions of wafers a month."
    },
    {
      "id": 2180,
      "start": 9692.68,
      "end": 9697.880000000001,
      "text": "Um, that's the plan with TerraFab. Millions of wafers a month of advanced process notes."
    },
    {
      "id": 2181,
      "start": 9697.880000000001,
      "end": 9701.24,
      "text": "It's, it's, it could be some number north of a million, I think. You gotta do the memory too."
    },
    {
      "id": 2182,
      "start": 9701.24,
      "end": 9706.44,
      "text": "Yeah. You're gonna make a memory fab? I think the TerraFab's gotta do memory. It's"
    },
    {
      "id": 2183,
      "start": 9706.44,
      "end": 9710.199999999999,
      "text": "gotta do logic memory and packaging. I'm very curious how somebody like,"
    },
    {
      "id": 2184,
      "start": 9710.199999999999,
      "end": 9715.24,
      "text": "get start, this is like the most complicated thing man has ever made. And obviously, like,"
    },
    {
      "id": 2185,
      "start": 9715.24,
      "end": 9719.24,
      "text": "if anybody's up to the task, you're up to the task. Like, what do you, so you realize this is a"
    },
    {
      "id": 2186,
      "start": 9719.24,
      "end": 9723.0,
      "text": "bottleneck and you go to your engineers and like, what is the next, like, what, what do you tell them"
    },
    {
      "id": 2187,
      "start": 9723.0,
      "end": 9729.8,
      "text": "to do? I want a million wafers a month in 2030. What is the next, like, what do you, do you like call"
    },
    {
      "id": 2188,
      "start": 9729.8,
      "end": 9733.88,
      "text": "ASML? Like, what is it? Ask the right one. What is the next step?"
    },
    {
      "id": 2189,
      "start": 9733.88,
      "end": 9741.24,
      "text": "Not so much to ask. Well, um, we make a little fab, uh, and see what happens."
    },
    {
      "id": 2190,
      "start": 9742.199999999999,
      "end": 9744.92,
      "text": "Uh, make our mistakes at a small scale and then make a big one."
    },
    {
      "id": 2191,
      "start": 9745.8,
      "end": 9747.8,
      "text": "Is a little fab done or is it? No, it's not done."
    },
    {
      "id": 2192,
      "start": 9747.8,
      "end": 9751.56,
      "text": "I mean, we're not going to keep that cat in the bag."
    },
    {
      "id": 2193,
      "start": 9753.16,
      "end": 9757.0,
      "text": "That cat's going to come out of the back room. It'll be like drones hovering over the bloody thing."
    },
    {
      "id": 2194,
      "start": 9757.0,
      "end": 9761.56,
      "text": "You know, you'll be able to see its construction progress on X, right? You know, in real time."
    },
    {
      "id": 2195,
      "start": 9762.359999999999,
      "end": 9769.8,
      "text": "Um, so, no, we, I mean, like, I don't know, we could just flounder and failure to be clear."
    },
    {
      "id": 2196,
      "start": 9769.8,
      "end": 9778.679999999998,
      "text": "It's like not, uh, success is not guaranteed, but, um, since we want to try to make, uh, you know,"
    },
    {
      "id": 2197,
      "start": 9779.96,
      "end": 9785.8,
      "text": "something like a hundred million. Yeah. We would, if we, we need, we need, we want a hundred gigawatts"
    },
    {
      "id": 2198,
      "start": 9785.8,
      "end": 9791.16,
      "text": "of power and a hundred, a hundred that chips that can take a hundred gigawatts, right? So call it,"
    },
    {
      "id": 2199,
      "start": 9791.16,
      "end": 9795.32,
      "text": "you know, but yeah, by, by 2030. So then, um,"
    },
    {
      "id": 2200,
      "start": 9795.32,
      "end": 9801.24,
      "text": "um, it will take as many chips as our suppliers will give us. I've said this to,"
    },
    {
      "id": 2201,
      "start": 9801.24,
      "end": 9806.76,
      "text": "I've actually said this to TSMC and Samsung and micro and it's like, please build your more fabs"
    },
    {
      "id": 2202,
      "start": 9806.76,
      "end": 9812.92,
      "text": "faster. Um, and we will guarantee you to buy the output of those fabs. Um, so, so they're already"
    },
    {
      "id": 2203,
      "start": 9812.92,
      "end": 9817.72,
      "text": "like moving as fast as they, as they can. Like it's, it's not like, to be clear, it's not like us,"
    },
    {
      "id": 2204,
      "start": 9817.72,
      "end": 9826.519999999999,
      "text": "you know, it's not like, uh, either it's, it's, it's not like it's us plus them, you know,"
    },
    {
      "id": 2205,
      "start": 9826.519999999999,
      "end": 9831.96,
      "text": "there's a narrative that the people doing AI want a very large number of, you know, chips as quickly"
    },
    {
      "id": 2206,
      "start": 9831.96,
      "end": 9838.679999999998,
      "text": "as possible. And then many of the input suppliers, the fabs, but also, you know, the turbine manufacturers"
    },
    {
      "id": 2207,
      "start": 9839.8,
      "end": 9845.48,
      "text": "are not ramping up production very quickly. No, they actually, yeah. The explanation you hear is that"
    },
    {
      "id": 2208,
      "start": 9845.48,
      "end": 9851.0,
      "text": "they're dispositionally conservative, you know, they're Taiwanese or German as the, you know,"
    },
    {
      "id": 2209,
      "start": 9851.0,
      "end": 9855.4,
      "text": "story may be, and they just like, don't believe the same, like, is that really the explanation or is"
    },
    {
      "id": 2210,
      "start": 9855.4,
      "end": 9861.8,
      "text": "there something else? Well, I mean, it's reasonable. Like if somebody's been in, say, the computer memory"
    },
    {
      "id": 2211,
      "start": 9861.8,
      "end": 9869.88,
      "text": "business for, uh, 30 or 40 years, and they've seen cycles, they've seen like boom and bust like 10 times."
    },
    {
      "id": 2212,
      "start": 9869.88,
      "end": 9874.76,
      "text": "Yeah. You know, so, so like, that's a lot of layers of scar tissue, you know? So it's like,"
    },
    {
      "id": 2213,
      "start": 9874.76,
      "end": 9879.48,
      "text": "it's like during the boom times, it looks like everything is going to be great forever. And then,"
    },
    {
      "id": 2214,
      "start": 9879.48,
      "end": 9882.84,
      "text": "then, then, then the crash happens and then they desperately try to avoid bankruptcy."
    },
    {
      "id": 2215,
      "start": 9883.56,
      "end": 9887.16,
      "text": "Um, and, and then there's another boom and another crash. Are there other,"
    },
    {
      "id": 2216,
      "start": 9888.2,
      "end": 9893.56,
      "text": "are there other ideas you think others should go pursue that you're not for whatever reasons right now?"
    },
    {
      "id": 2217,
      "start": 9894.44,
      "end": 9899.64,
      "text": "Um, I mean, there are a few companies that are, that are pursuing like, uh, new ways of doing jobs."
    },
    {
      "id": 2218,
      "start": 9899.64,
      "end": 9903.0,
      "text": "Mm-hmm. Um, uh, but there, there's just not scaling fast."
    },
    {
      "id": 2219,
      "start": 9903.0,
      "end": 9905.56,
      "text": "I, I mean, within AI, I mean, just generally."
    },
    {
      "id": 2220,
      "start": 9905.56,
      "end": 9911.88,
      "text": "I, I'd say like people should, should do the thing that, where they find that they're highly motivated to"
    },
    {
      "id": 2221,
      "start": 9911.88,
      "end": 9913.08,
      "text": "do that thing. Mm-hmm."
    },
    {
      "id": 2222,
      "start": 9913.08,
      "end": 9919.56,
      "text": "As opposed to, you know, something, something, some idea that, that I suggest, but they should do the"
    },
    {
      "id": 2223,
      "start": 9919.56,
      "end": 9923.4,
      "text": "thing that they find personally interesting and motivating to do."
    },
    {
      "id": 2224,
      "start": 9923.4,
      "end": 9925.4,
      "text": "Mm-hmm."
    },
    {
      "id": 2225,
      "start": 9925.4,
      "end": 9933.0,
      "text": "Um, but, but, but, you know, going back to the limiting factor, yeah, use that phrase about"
    },
    {
      "id": 2226,
      "start": 9933.0,
      "end": 9941.56,
      "text": "a hundred times. Um, the, the current limiting factor that I see in the timeframe, you know,"
    },
    {
      "id": 2227,
      "start": 9941.56,
      "end": 9951.32,
      "text": "in the, in the sort of 20, 29, 20, like in the, in the three, three to four year timeframe, um, it's chips."
    },
    {
      "id": 2228,
      "start": 9951.32,
      "end": 9957.08,
      "text": "Um, in, in the, in the one year timeframe, it's, it's energy, power production, electricity."
    },
    {
      "id": 2229,
      "start": 9958.279999999999,
      "end": 9964.92,
      "text": "Like, it's, it's not clear to me that there's enough, uh, usable electricity to turn on all the,"
    },
    {
      "id": 2230,
      "start": 9964.92,
      "end": 9971.32,
      "text": "the air chips that are being made. Um, so towards the end of this year, I think people are going to"
    },
    {
      "id": 2231,
      "start": 9971.32,
      "end": 9976.92,
      "text": "have real trouble turning on, like chip output will exceed the, the ability to turn chips on."
    },
    {
      "id": 2232,
      "start": 9976.92,
      "end": 9978.44,
      "text": "What, what's your plan to deal with that world?"
    },
    {
      "id": 2233,
      "start": 9978.44,
      "end": 9986.2,
      "text": "Well, we're trying to accelerate electricity production. Um, I, I guess that's, that's maybe"
    },
    {
      "id": 2234,
      "start": 9986.2,
      "end": 9992.84,
      "text": "one of the reasons that, um, XAI will, will be maybe the leader, hopefully the leader, um,"
    },
    {
      "id": 2235,
      "start": 9993.560000000001,
      "end": 9999.960000000001,
      "text": "is that we'll be able to turn on more chips than other people can turn on faster. Um, because we're,"
    },
    {
      "id": 2236,
      "start": 9999.960000000001,
      "end": 10005.880000000001,
      "text": "we're, we're good at hardware. And, and, and, and generally the, the innovations from the"
    },
    {
      "id": 2237,
      "start": 10006.599999999999,
      "end": 10011.8,
      "text": "corporations that mess that call themselves labs, um, the, the ideas tend to flow."
    },
    {
      "id": 2238,
      "start": 10012.92,
      "end": 10016.039999999999,
      "text": "Like it's, it's rare to see that there's like more than about a six month difference,"
    },
    {
      "id": 2239,
      "start": 10016.679999999998,
      "end": 10023.08,
      "text": "um, between, um, I, like the ideas, uh, travel back and forth, um, with the people."
    },
    {
      "id": 2240,
      "start": 10023.08,
      "end": 10031.0,
      "text": "So, so I think you, you sort of hit the hardware wall and, um, and then whatever, whichever company"
    },
    {
      "id": 2241,
      "start": 10031.0,
      "end": 10037.88,
      "text": "can scale hardware, the fastest will be the leader. And so I think XAI will be able to scale hardware"
    },
    {
      "id": 2242,
      "start": 10037.88,
      "end": 10040.12,
      "text": "the fastest and therefore most likely will be the leader."
    },
    {
      "id": 2243,
      "start": 10040.12,
      "end": 10046.2,
      "text": "Yeah. You, you, you joked or, you know, um, we're self-conscious about, uh, you know, using the,"
    },
    {
      "id": 2244,
      "start": 10046.2,
      "end": 10050.04,
      "text": "uh, the limiting factor phrase again, but I actually think there's something deep here."
    },
    {
      "id": 2245,
      "start": 10050.04,
      "end": 10053.800000000001,
      "text": "And if you look at a lot of things we've touched on over the course of it, maybe kind of a good note"
    },
    {
      "id": 2246,
      "start": 10053.8,
      "end": 10065.16,
      "text": "to end on. Like if you think of a senescent lower agency company, it would have some bottleneck and"
    },
    {
      "id": 2247,
      "start": 10065.16,
      "end": 10069.88,
      "text": "not really be doing anything about us. Um, you know, Mark Andreessen had the line of, uh, most"
    },
    {
      "id": 2248,
      "start": 10069.88,
      "end": 10075.0,
      "text": "people are willing to endure any amount of chronic pain to avoid acute pain. Uh, and it feels like a"
    },
    {
      "id": 2249,
      "start": 10075.0,
      "end": 10080.519999999999,
      "text": "lot of the cases we're talking about are just leaning into the acute pain, whatever it is. It's like,"
    },
    {
      "id": 2250,
      "start": 10080.52,
      "end": 10085.640000000001,
      "text": "okay, we gotta figure out how to, you know, work with steel, or we gotta figure out how to run the"
    },
    {
      "id": 2251,
      "start": 10085.640000000001,
      "end": 10091.560000000001,
      "text": "chips in space, or like we'll take some near term acute pain to actually solve the bottleneck. And so"
    },
    {
      "id": 2252,
      "start": 10091.560000000001,
      "end": 10097.08,
      "text": "that's kind of a unifying thing. I have a high pain threshold. That's helpful."
    },
    {
      "id": 2253,
      "start": 10097.08,
      "end": 10102.6,
      "text": "To solve the bottlenecks. Yes. Um, so,"
    },
    {
      "id": 2254,
      "start": 10105.24,
      "end": 10107.32,
      "text": "you know, one thing I can say is like, uh,"
    },
    {
      "id": 2255,
      "start": 10107.32,
      "end": 10116.84,
      "text": "I think the future is going to be very interesting. Um, and, um, and as I said,"
    },
    {
      "id": 2256,
      "start": 10117.96,
      "end": 10121.96,
      "text": "the DAW was up only been to, I was literally at DAW was on the ground for like three hours or something."
    },
    {
      "id": 2257,
      "start": 10122.68,
      "end": 10130.279999999999,
      "text": "Um, it's better to be, it's better to err on the side of optimism and be wrong than err on the side of"
    },
    {
      "id": 2258,
      "start": 10130.28,
      "end": 10137.800000000001,
      "text": "pessimism and be right, uh, for quality of life. So, you know, your, your, your happiness will be,"
    },
    {
      "id": 2259,
      "start": 10138.84,
      "end": 10143.400000000001,
      "text": "you'll, you'll be happier if you, if you are on the side of optimism rather than erring on the side of"
    },
    {
      "id": 2260,
      "start": 10143.400000000001,
      "end": 10147.480000000001,
      "text": "pessimism. And so I recommend erring on the side of optimism."
    },
    {
      "id": 2261,
      "start": 10147.480000000001,
      "end": 10151.0,
      "text": "Nice to that. Cool. Yelan, thanks for doing this."
    },
    {
      "id": 2262,
      "start": 10151.0,
      "end": 10151.640000000001,
      "text": "Thank you."
    },
    {
      "id": 2263,
      "start": 10151.640000000001,
      "end": 10152.36,
      "text": "All right. Thanks guys."
    },
    {
      "id": 2264,
      "start": 10152.36,
      "end": 10155.32,
      "text": "Great stamina."
    },
    {
      "id": 2265,
      "start": 10157.720000000001,
      "end": 10159.480000000001,
      "text": "Hopefully this encounters the pain and the pain tolerance."
    },
    {
      "id": 2266,
      "start": 10160.92,
      "end": 10165.640000000001,
      "text": "Hey everybody. I hope you enjoyed that episode. If you did, the most helpful thing you can do is"
    },
    {
      "id": 2267,
      "start": 10165.640000000001,
      "end": 10171.24,
      "text": "just share it with other people who you think might enjoy it. It's also helpful if you leave a rating"
    },
    {
      "id": 2268,
      "start": 10171.24,
      "end": 10176.52,
      "text": "or a comment on whatever platform you're listening on. If you're interested in sponsoring the podcast,"
    },
    {
      "id": 2269,
      "start": 10176.52,
      "end": 10192.44,
      "text": "you can reach out at dhwarkesh.com slash advertise. Otherwise, I'll see you on the next one."
    }
  ]
}