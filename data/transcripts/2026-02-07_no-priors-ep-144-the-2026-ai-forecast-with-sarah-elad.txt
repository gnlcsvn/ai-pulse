Hi listeners, welcome to KnowPriors. How can we even begin to wrap this year up? The AI field has grown, breaking out into the mainstream and taking center stage with policymakers. ChatGPT shipped massive numbers and asked for massive dollars. Gemini and Google roared back strong. And on the application front, AI coding has shifted to agents and is eating up all of our inference capacity. Doctors are adopting clinical decision support en masse and in law and customer support, enterprise adoption is accelerating. What's next? On the research front, the race has multiple live players with open source closing the gap too. A handful of neo labs, new research labs got funded this year and the narrative is changing. Ilya is calling it the age of research. People are trying different ideas around diffusion, self-improvement, data efficiency, eq, large-scale Asian collaboration, continual learning, energy transformers. It's more open than it's ever been. Finally, we had a lot of attempts to make AI reach into the real world with renewed optimism around robotics. Next year, those companies are going to start making contact with reality. From a prediction standpoint, personally, I think we're going to see somebody make a lot of money, hundreds of millions of dollars, trading markets with LLMs next year. It's inevitable. So we're in the second or third inning. Markets are running a little hot and a little volatile. It's hot in the hot tub. So get into it with me and Elad. Okay, Elad, it's been a year. I know, how's it going? It's 2026, baby. Are you feeling the AGI? Are you feeling AI winter in a good way? I think I'm actually just feeling microplastics. I think I'm now 80% microplastics. I'm just increasing my microplastic consumptions. A friend of mine actually launched a new water brand that has their microplastics, by the way. It's called Lute. It's got like glass bottles and also the cap doesn't have plastic. Does it come with continual testing? No, that's a good idea. Does it come with continual testing for you? They did actually try to take out all the microplastics. And so they, I guess bottled water in actual bottles have more microplastics than plastic bottles because of the cap. Okay, we'll check back in with you in 27 to see if you feel. Yeah, I'm just completely ossified out of plastic. I'm actually really worried about microplastics. What about all the little glass particles? Aren't you worried about that? People talk about microplastics, but not microplastics. I'm much more concerned about that. I don't think those particles end up embedded for you permanently. Silicon? You're not worried about silicons. I go to the beach. I'm like, oh no, microplastics everywhere. I'm actually very willing to insert silicon in my body eventually in my. Wow. That was, yeah, I'm not going to say anything. We can keep going. What's what's happening in AI a lot? What do you, where are we and what are you most excited about? Yeah, I guess for 26 years about this stuff, I think I will be interesting this coming. I think we will. I think there's probably four or five things. One is I think people will proclaim yet again that AI is not doing much and it's overhyped and like that MIT report that people were quoting that I thought really didn't matter. And the reality of the technology always take like 10 years to propagate and people are getting enormous value out of the AI already and they're going to get way more out of it in the future. You know, there's these undoubtedly next year there'll be these overstated but bubble claims as well as, um, hey, I actually isn't working that well kind of claims and that happens every technology cycle and we'll just hear it again next year. And there'll be pundits and discussions and just a bunch of waste of time on it. So I think that'll happen. I think another prediction for 26 is the next set of verticals will hit massive scale. I think this year we saw consolidation of coding into a handful of players and medical ascribing into a handful of players, legal into a handful of players like RV and others. And so I think we'll see that next set of consolidated verticals happening. So I think I'll be interesting. I can keep going. I have like a bunch of these. Do you want to go next? We can alternate as to two. Why don't you do two? Maybe I'll react or react or react and then I'll and then I'll give you two predictions. I have to think of my predictions while I'm reacting. So I'm glad I have at least two threads. Yes. I think that the overall sentiment on AI in the investing landscape is a lot of people getting stressed about the amount of capital they have at work and then just a level of uncertainty around the adoption cycle and technical bets that people are making that they don't have full first principles confidence on coming to risk. So I think like any number of exogenous factors plus noise about the speed of adoption, which, by the way, seems like blinding overall and we can talk about what the constraints are so fast. I don't know what people are talking about. I just saw a report that talked about it's from this group called off call that talked about adoption of AI by doctors. And look, there is just amazing adoption of, of course, you know, several different categories like documentation, clinical decision and support with things like a bridge and open evidence and obviously the general models. But there's like massive enthusiasm for most of the physician profession here. And I'm like, okay, of all of the domains that were professional and considered more conservative, the fact that there is this like, you know, desire to have things that make work better seems like obviously to continue in the other professions. I think this is, by the way, super under discussed that the people who have tended to be the slowest adopters of technology love AI. That's physicians, that's lawyers, that's certain accounting types. It's, you know, it's, it's actually kind of fascinating. It's compliance. You know, it's all the people who always never adopt technology are now adopting this stuff fast. So I do think that's really notable and very under discussed. It will keep happening. There are actually lots of professions where like being able to reason and interact with unstructured data is very useful. Like I expect that there's going to be some like negative market current, like, you know, if Nvidia doesn't over perform by some massive amount, one quarter, everybody's going to freak out. But I, I think that has very little to do with the fundamental secular change. Yeah, it has to do with microplastics and Nvidia. It has to do with microglastics, as you said. Yeah, that's true. Actually, the silicon there is in the air, I bet. I bet that microglastics all over the place. It's messed up, Sarah. It's part of the trade. If you make $20 million as an average Nvidia employee, you also have to have microglastics in your blood. I know, it's awful. Don't listen to this, Jensen. Jensen's our next guest. It's 1% microglastics in the blood. I think, you know, a third area is the next set of foundation models are going to come. And by that, I don't mean the Neo labs and the next gen LLM, which of course will happen. But I mean, physics and materials, science progress by models, math progress. And I think what will happen is there'll be one or two cases where it works really well for something, the lumpents in the material, there'll be some conjecture proved or something. And then it'll fall into this overstated hype cycle of it's going to change everything about physical sciences or whatever. And that one off will be overstated. And in the long run, the trend will be understated and will be incredibly important. So that's what that's another prediction for next year is there'll be a couple anecdotal one offs in science that will make people say, look, science is solved and they'll realize science isn't solved. And then later, science will be solved. I have, okay, fine. Three, three quick predictions for you. One is there's going to be like some collapse of sentiment around a set of robotics companies next year, not because it like actually isn't as a field going to progress, but because, you know, people are beginning to project timelines and, you know, not everybody is going to deliver on those timelines. What's your timeline? I think that we will see humanoid and semi-humanoid robots get deployed at small scale in environments, be the consumer or industrial next year, and not everything will work. And that like the, because there's this, you know, hype cycle around human rights overall, as soon as something doesn't perfectly work, which it will not, people are going to freak out. Right. And then there's going to be some bifurcation about people investing. Yeah. I mean, we're in the year 15, 17, whatever self-driving something around there. And it's really working now, but it took a long time. So it seems like robotics should have maybe a faster curve, but a similar curve, right? It's going to take some time to figure all this stuff out. And then once it's figured out, it's going to be really valuable. And the big question for me on robotics. Now, it's interesting. If you look at self-driving, there's like two dozen, three dozen, whatever legitimate self-driving companies, really good teams and good approaches and all the rest. And then arguably the two biggest winners, at least now are Waymo and Tesla, which were two incumbents, right? Waymo is Google, Tesla is Tesla. So I wonder what will happen in robotics. It feels to me like Optimus or some form of like Tesla robot will be one of the winners, most likely, right? High probability. And then the question is, does Waymo just adopt what it's doing for cars to robots as well? There's some similar problems there. Is it some other big industrial company that startups like who are the winners and why? And structurally, when you have a lot of capital needs, but also a lot of hardware and manufacturing needs, that's going to favor incumbents, which is self-driving, right? I guess arguably the other winners in self-driving are Chinese companies, right? Chinese car companies, which are banned from coming into the US market. And those will probably also be winners in robotics, right? The most likely global winners in robotics will be some subset of China plus Tesla plus something else, right? Maybe one of the startups. I think that's right. But that's like saying, I think in most industries, like, you know, the incumbents are more likely to win than the startups, if you're just looking at it, like as a numbers game. I don't know. Yeah, I don't know. I don't think so. I think there's startup industries where startups should win. And there's incumbent industries where incumbents should win. And they have different characteristics in terms of market structure, in terms of capital needs, in terms of expertise and supply chain. You know, so I do think there are markets where incumbents should definitionally do better. They don't always, but they typically do. And then I think there are markets where startups will do better. Sure. But I don't argue that like some markets are struck, like the moats are structurally deeper, right? But one way that you might look at autonomous vehicles is this one very complex single use case robot. And it mostly does locomotion. It does lots of other necessary types of prediction, defense, and whatever else. But it's a single use case robot. Yeah. And we forget there's a lot of good ones like that. Dishwashers are great single use robots, vacuum cleaners are great. You know, like, there's all these things that we actually have that are robots in the home that we pretend aren't, right? We forgot that they're robots. Elevators are robots. No, seriously. Escalators are robots. I'm going to use the language of like, for a robot to be a robot, it has to be somewhat intelligent, right? And so dishwasher doesn't count as an appliance. A self-driving car does count as a robot. Not just like, Where's the border of intelligence for you? I think like, it's probably some level of generalization, right? It can work in different environments. It can work on different tasks. It can work on different objects. Otherwise, you know, self-driving car is, program. Yeah, I don't know. I didn't have that complex of a definition. I just had it as like something that will do certain pre-programmed types of labor for you. Maybe you have a better definition. Let me look up what the definition of robot is. A machine capable of carrying out a complex series of actions automatically, especially when programmable by a computer. But you know, all these things have chips in them now. Your dishwasher has a chip in it, right? Or the computer in it. Okay. Yes. But like, I would argue that robotics has not been an interesting area of innovation without intelligence. And so that's the relevant set for maybe you and me, and many people that are looking for something that changes quickly. Yeah, that's cool. I mean, I do think that on the on the topic of robots, the biggest trend perhaps, or one of the biggest trends of 2026, 100% will be that self-driving will really begin to matter. And that'll be both in terms of your own car, it'll be in terms of Waymo and Tesla cabs. It's going to be, I think one of the big things that's talked about next year. So I think I think on the robotics team, that's the biggie. I think if you look at all of the potential use cases for robots besides self-driving and say like self-driving, I mean, the Optimus team actually proves this. Like if you take if you take a model that is powering Tesla self-driving and you put it in Optimus, it can do locomotion, but it can't do many other things and you still have to do the hardware. Right. Like manipulation. And so I think that the advantages here are not as strong as you believe they are. And like startups, some sort of startups. Yeah. The scary competition is the Chinese, but I do think that there is opportunity here. Oh, I totally think there's opportunity for startups that don't misinterpret me. I just think that it's not just the fact that you have a model or a base model, you have the expertise to build the model, but then you also have all the supply chain. And I think that's really important because a lot of the same sensors that you need to use are there and how you think about actually procuring and scaling things are there. There's good overlap actually in terms of some of the other skill sets that are needed that take a long time to build usually at a startup that are a little bit painful to build and people do it. It's fine. It's not. I mean, Anderil did it and SpaceX did it. And all these companies have done it. It's extra stuff. So that makes sense. I do think I do think some startups will succeed here. I just trying to think through besides the startups, who's going to be big. And then also, I think there are one or two like income and loss that will just default happen unless something very strange happens. And one could have argued that should have happened in foundation models where Google should have had a default slot. And in the end, it did. It got there. And I think that was very predictable that the Google models will get there. I think I even may have read a post about this like two, three years ago that Google would be relevant, right? Because they just had all the assets that were needed for them to be a really important foundation model company. They obviously invented transformers, but they had all the data, they had all the capital, they had TPUs and GPs, but the best people for all sorts of things are some of the best people. So it felt inevitable. And I think this feels the same to me, but it's right. Do you want to talk about IP as an M&A next year? What do you think will happen there? I think that's another big, that's the number four, five, I guess, you know, three was different types of models, four was robots and self-driving, and then five would be IP as an M&A. What do you think? More IPOs, less IPOs, more M&A, less M&A, different types of M&A? It depends on whether or not the bottom of falls out of the AI market at some point, right? What do you mean by the bottom falls out? What does that translate into? I think people just get skittish about, you know, the cycle here is like, what are people scared of? They are concerned that demand isn't real. No, demand isn't real for AI to support the CapEx cycle, that there is systemic risk from people passing the ball around in terms of who is actually responsible for the CapEx build out and these credit agreements, right? Or, you know, pay on delivery contracts for data centers and for chips. What else are they afraid of? They're afraid of like the microglastics, AKA, too much concentration in NVIDIA and a small number of other players. If you're like a big public markets investor, you're just like, you know, you... Too much silicon. It's too much silicon. It's too much silicon. You're damned if you do, you're damned if you don't. I was talking to a friend of mine who runs a large tech hedge fund, and they're already like a foundation model investor in like multiple significant labs that may or may not go public in the next couple of years. Yeah. And they're like, okay, well, the question is, do you buy the IPO? Their game theory on it was like, actually, no matter what I think about it, I have to do it because retail will want it. Because they like want to be part of the AI revolution. And then if you're a hedge fund, you get benchmarked on annual performance. And because of the retail pop and some set of investors wanting to buy into it as a pure play where you're like, oh, I can't miss it. Like I missed NVIDIA, then you have to buy it. And so his view was like, you buy the IPO, regardless of your fundamental view of the company. And I was like, wow, this is not the investing job I know how to do. Yeah. What do you think happens? I think there'll definitely be a lot more IPOs next year. I think if one of the main AI companies goes out, it'll be... Probably do extremely well, depending where they price. I mean, obviously, if they're overly aggressive, it won't. But in general, I think there's so much retail appetite to actually participate in AI besides NVIDIA. And then that'll just get a lot of other people to go public just as followers on it. So I do expect there'll be a lot of them. It's just one that even goes out. And then also, it's a great way to raise huge amounts of money for some of these labs, potentially. So it'll be interesting to watch what happens there. Any other predictions for 26? Yeah, I think that I did not believe that we were going to see that many like unique consumer experiences besides like ChatGPT. I think we are going to see like a slate of consumer hardware that mostly fails, but I'm still open minded to it. And then definitely actually like, it remains to be see of any of these scales, but I am seeing magical experiences of like really different consumer agent software that I like, I actually want and will use. And I think people are barely beginning to... Well, these companies are in sales right now. But I do think that like, there's going to be a lot more product people that experiment with this and model companies experiment with this next year. And so I'm pretty optimistic about that. Yeah, I agree with that 100%. And I think the big question is what will end up being a breakout startup and undoubtedly be some. And then what will be a startup that will grow really fast and then it'll get copied by the main lab slash Google, and then it just gets incorporated into the core product. And the interesting thing is unless a company truly hits escape velocity and build a network effect or something else that's really defensible, using comments can launch two, three years later and catch up. And so if they have the distribution and have a product and that, but to your point, I think it's very exciting. And I've been waiting for this for a while. I think two years ago, three years ago, this guy, David Song, who was on my team at the time, ran a two quarter thing at Stanford, where we had different team supply from the engineering programs there. And it was like groups of people building consumer apps using AI because we said, this wave of AI is so fascinating. Why isn't anybody building anything consumer? So we basically just gave people free GPU to go and try stuff. And there was no obligation on their side to do anything with it, in terms of us getting involved. It was just go do cool stuff because this is such a good playground. And those really neat experiences are being prototypes. And then I was just shocked that nothing happened for a couple years in terms of really interesting consumer products. So I agree with you. There's so much room for that. And I always wonder, is it because there's a different generation of founders who don't want to work on consumer or forgotten how? Because the big consumer companies have kind of aged out. Is it the incumbents are just too scary? Is it like, why is there so little innovation actually on the consumer side of AI? I still don't quite understand what the issue is. Okay. Let's list the reasons. I do think that the incumbents are pretty scary. And anybody who was around for the last generation of interesting consumer ideas saw actually the ingestion of those ideas into the existing platform, as you put out. Yeah. So there's that. I also think like the first instinct that I've seen from companies, from founders working on like new consumer experiences is essentially building like a better version of like last generation experiences with this generation technology. And that ends up like not being that interesting. And so I actually think you have to be like either quite close to research or pretty creatively ambitious to build like something very different that has any chance. And so I think like, I think like there's just not that many people who have had that experience set or that creativity. And now we're going to see it. Yeah, I think it's pretty exciting. The other thing is, I was talking to a really well known consumer founder who's running a giant public company. And his view is that perhaps in the entire world, there's a few hundred great product people for consumer, at least in terms of who are actually working on it. Obviously, there's enormous human potential and people who aren't working in consumer products could, you know, but of the people working in consumer products, he thinks that most of the few hundred people who are exceptional who could actually come up with and launch their own product that would be interesting or good. And so you could also just say that maybe there's just a limitation on how many of these things can exist, just given human potential within the set of people who are already doing it, which I think is kind of an interesting argument. I don't know if I agree with it, but I thought it was an interesting argument. I would limit myself to that number if it's also the set of people who like have the context of like what is possible now. If you've got great consumer product instinct, but you're like work, you're like grinding away on the like 50th iteration of an existing product. Like, yeah, you're working on the little sub button in Gmail or whatever, instead of actually going off and doing this 100%. Yeah. Well, anything else we should talk about or any other big predictions for 26? I feel like a very big emergent thing that happened this year was the surprising funding of like Neo labs, like three through eight. What do you think of that? What do you think about alternative architectures? Like, do you have any point of view on all of the effort around like getting reinforcement learning to be more general, continual learning, some of the research directions? You know, I think there's enormous amounts of really interesting research being done. So I you know, there's a lot of juice to be squeezed out of these models still in different ways. And I think that's really exciting. Ultimately, these things become capital gains for certain types of approaches or models. Because we know scale really matters, which means that eventually you have to collapse into a handful of players because capital aggregate to things that are working the most, no generating revenue. And so then the question is, what are those things? At what point do things to say get kind of locked in from a usage perspective for whatever reason? And there's all sorts of ways you can imagine this being built over time against some of the models. So I think it's interesting. I think it's exciting. I think we'll see how it plays out. I think to articulate what like the the arguments could be for, you know, new research directions is like Ilya, you know, did this interview recently, where he describes it as the age of research. And to paraphrase, he like basically says that, yes, I believe in scaling, of course, but you know, there's there's some floor of compute that is not infinite, where we can test ideas at scale. And then if we have, let's say, secret ideas around like how to get to more rapid or more compute efficient improvement, then it actually isn't just a straight resource battle, which like the rat race does feel a little bit like today. I think the other argument you could take is actually like multiple architectures and people have done some research on this, but multiple architectures are really relevant at big domains of of usefulness. They just haven't been scaled. Right. And like there's enough capital out there to test them, be they like diffusion or SSMs or whatever. And that's going to happen this next year. And then I think there's like a like a resource focus argument, right? If Ilya is describing that some set of labs, they have an enormous amount of compute, but they have to spend a lot of that compute on inference today, then how much do you spend on your particular research direction? Yeah, be it self-improvement or post training or emotional intelligence or very large scale out agent stuff. Yeah, it depends on what you're doing, because the inference is what ends up then raising you money to pay for everything else because you're generating revenue. So I think sure, but it's effectively your way to bootstrap into more and more scale. So I always thought perhaps incorrectly, I actually probably think it's incorrect, but I always thought that eventually you end up with evolutionary systems is really how you build AI because maybe I'm over extrapolating up a biology where effectively your brain has a series of modules that have different functions or tasks, right? You have a visual system that's highly sort of pre-wired to deal with vision really effectively. You have different areas of higher thought and learning. You have memory, you have mirror neurons that are involved with empathy, right? Your brain is actually very specialized in some ways, although obviously, as people were born with literally like half a brain hemisphere and the brain rewires and sort of covers all the functionality. But there's a few famous cases like that. But, you know, fundamentally, you have a lot of stuff that evolves into very specialized tasks. It's almost like a MOE or something, you know. And the question is the degree to which you recapitulate that as you're doing further development of AI. And when do you start just spawning off a bunch of instances of something and just have some utility function they're evolving against that you then have some selection and recombining and all the other stuff that you kind of do to try and make some of that work versus how much of it is a more analytical approach or a more experimental and iterative approach or, you know, so it's in a directed way. And so I think it's really interesting to ask because if you look again at biology as a as a potential precedent, although maybe a very bad one, you look at protein design. And for a long time, there are these like super analytically designed proteins and then they came up with all these systems that's involved as shit, you know, like phase display and like mutagenic scans and all sorts of things that give you dramatically better results than if you just sat and thought about it. And now, of course, we kind of solved it with AI where you have all these 3D structural predictions that are actually very good. That was AlphaFold and a few other things that really were breakthroughs there. So it feels like in the context of AI, maybe eventually we end up there as well, right? Where you just involve these systems. And then that may be a very different type of approach and training. You know, that may be where I think things really have an interesting break. And that's one of the the reasons that arguably people are so focused on code because code is arguably a bootstrap into moving faster on development of a GI. But I think it's kind of code plus self-evolution is really the the potential really interesting approach to it to get some really fast lift off. But maybe not. Right. We'll see. What is the one prediction you have for 26 that has nothing to do with AI? Do you think about anything else, Sarah? I do. I'm joking. Really? I mean, the other thing, by the way, one other prediction that doesn't have to do with AI is I do think defense will accelerate in terms of startups and defense tech and the shift to autonomous or not autonomous, but to drone based systems in general. The massive reworking of how you think about war and defense. And I think that's going to be a shoot shot that we'll see go even faster this coming year. I think this is accelerating in part to how the Trump administration has been approaching it and the secretary of war and everybody there have been thinking about it. I think in part, just you have enough density now startups doing interesting things. So I think that's the other thing that's like a huge shift that, you know, it's a hype cycle right now. And I actually think again, it's a little bit under thought about because it's, it's going to be so big outside of the AI. I mean, I think there's obvious really interesting things happening in space with SpaceX and Starlink and I think about communications and telephony. So that's a big shift. There's really interesting things in my opinion happening in energy and mining. And, you know, I think there's a lot going on in the world. I agree on defense with some like concern that, you know, we have to wait for budget to actually shift from contracts to primes to some of these new companies at scale. But the demands like the need to be competitive in a world that's increasingly autonomy driven is like so obvious. Right. And I think, you know, hype cycles and booms are good in that they bring a lot of people to the table, you know, capital founders, people who want to work in the industry. And so you can make a lot of progress in a quick amount of time, even if a lot of companies die and there's, there's more enthusiasm over a short period of time. So I agree with that. And I also don't think that's necessarily bad. Right. What's your prediction? I think that like, I'm not the only one, but I think that the like GLP one thing is just, despite all of the enthusiasm, like still underrated for how much impact it has happened. Right. And so I think that the continual adoption of these is like inexorable. I actually think it creates a path that is interesting for like other peptide and hormone therapies. I think the fact that it has been so effective has like lots of second order effects, both from people way, like just being a lot less overweight, like directly and the willingness to look at other engineered peptides or like, I think it, like everybody understands now that like delivery matters. There are these really incredible medicines. And I think that the impact of that is going to like fuel much more investment in anything that looks like that type of opportunity. And so I think that's exciting. Yeah, I actually think one thing that you mentioned is really interesting, where if you look at the sort of biohacking community, there's a lot of peptide use now, different, you know, different peptides that will do different things in terms of, you know, somebody will have some chronic carpal tunnel thing and they'll fly to Dubai to get peptides injected or whatever. And usually those are sort of early indicators of potential larger scale adoption societally. And so I think that's a really interesting trend right now, in general, like this whole like world of peptides and their uses. And is there a hymns of peptides? Like what's the what's coming there? So I think that's super interesting. Yeah, I also think like the biohacking community, as you said, it like the set of people who were really, really early off label GLP one adopters interested in longevity neuromodulation with ultrasound stem cell injection, for example, like that has been like a fringe small community. And I think that like, I think it's going to get less French. And a lot of these things traditionally 10 years ago came out of the bodybuilding community, right? The bodybuilding community was like creatine and all these things that are more broadly used now, but also other other things for sleep aids or other, you know, magnesium and all this stuff. And to round out this year end episode, we've asked some of our friends for their predictions for 2026. I'm so curious. My prediction for next year is that the reasoning systems are going to translate directly to AI's that are much, much more versatile, much, much more robust. And reasoning is going to impact is going to revolutionize not just not just language models, but reasoning is going to impact every single industry from biology to self-driving cars to robotics. And so reasoning, I think is, is the big, huge breakthrough that, that is going to transform a lot of different applications and industries. In 2026, AI will stop being a reactive tool that waits for us to prompt it. Instead, it will become very proactive and get deeply integrated in our work life. It will go where we go, hear what we hear, know what tasks we need to work on. And in fact, most of the times complete those for us before we even ask it to do so. It will be a coach that helps us improve our skills. It will be a manager who helps us prioritize our work and manage our time. In short, it's going to be the best work companion we could wish for. I think the main AI prediction that I have for next year is I think context is just going to be the most important part of every single product. And honestly, like one of the best experiences I've had with it so far is just memory and ChatGPT. Like, I think that there are going to be a lot more features that basically their goal is to extract the user intent and make the onus less on the user to basically give all of the models or the system or the product more and more context. So in other words, how do you put the onus on the product to actually extract that from the user instead of the user having to do all of the work to do this upfront? My prediction for 2026 is there will be a whole new suite of product experiences that run on much faster inference. My prediction for 2026 is that we'll finally stop copy pasting stuff into chat boxes. Instead, I think we're going to have applications that have better use of screen sharing and context management across the sources that matter the most. One prediction for 2026. There's so much talk of agents right now and there has been for a while, but no one has truly created a mass scale consumer agentic AI. I think the models are there today for this to be possible. And in 2026, we will see the group that figures out the right interface and system and product that creates as big a step function and overall experience as ChatGPT when it first came out. And I think this area is not nearly as seated to labs as people assume. It really is anyone's ballgame. Hello, Aaron here. First of all, I get quite awkward around doing selfie videos. This is my ninth take of this video. So I hope it goes okay. But 2026 prediction would be that this is going to be certainly the continued year number two of AI agents, but in particular, AI agents in the enterprise in either deep vertical or domain specific areas. I think this is going to be the main way that we actually take all of the progress that we're seeing in AI models and actually deliver them into the enterprise. You have to be able to tie to the workflow of the organization. You have to get access to the data that they have. You have to have the right context engineering to make the agents actually work. And then you have to do the change management that makes the agents effective. So this is going to be a year where we start to see this pattern emerge more and more, which equally means that we need to ensure that we have a lot more happening on agent harnesses. So shout out to Akorva, Suhail and Dex for that answer. But it's definitely going to be the year of the agent harness and seeing how do you start to get, you know, an order of magnitude improvement on the model's capabilities by having all the right scaffolding around the model. And then finally, it will be the year of economically useful evals. So really starting to figure out how these models end up doing a lot more knowledge worker tasks in the economy. And that's going to, we're going to see a lot more of that in 2026. We saw some previews of that this year with APEX and GDPVAL and a handful of others. We're going to see way more of that. So those are the predictions and we'll see you in 2026. I think 2026 is going to be a very interesting year for American open models. Over the last year, the frontier of open intelligence shifted from America to China, starting with the release of DT at the end of 2024. And American institutions were slow to notice this erosion of American leadership and open intelligence. But I think they've noticed in a big way over the last half year, both from the government level, from the enterprise level. And there are some really interesting neolabs starting to come out with open intelligence as their directive. And there are a few of these, not just reflection. And these companies are starting to produce some very interesting small open models. And next year, I think we'll see the US regaining leadership at the open weight frontier at the largest scale. And I'm really excited to see that. Hey folks, my prediction for 2026 is that I think we will see AI become much more politicized. I think we'll see it become a major point of discussion for the 2026 midterm elections. And some people will come out strongly against it. Some people will come out strongly supportive of it. And I'm not sure which side is going to win out. 2025 has marked an incredible year in AI drug discovery. In the past year alone, we've gone from being able to design simple molecules on the computer to designing simple antibodies, and now most recently, full-length antibodies with drug-like properties, zero shot on the computer. If 2025 has been the year of research in AI drug discovery, 2026 will be the year of deployment. The models have finally entered an era where they're becoming really useful for drug discovery. Not only do they make things faster, but they're also allowing us to go after really challenging targets, which have been traditionally really difficult to do with traditional techniques. I'm really excited to see what comes next because the models show no signs of slowing down. Okay, my prediction for 2026 is it will be the year that YOLO dies. We will begin transforming ourselves from a you only live once to don't die. I think right now we're kind of a suicidal species. We do very primitive things. We poison ourselves with what we eat. We design our lives so that we slowly kill ourselves. Companies make profits by making us addicted and miserable. We destroy the only home we have and somehow we celebrate these things as virtue. I think it's all backwards. I think one day we'll look back and we'll be pretty astonished that we behaved like this. I think the shift coming is going to be simple and radical. That we say yes to life and no to death. It's simple, but I think it could be in response to AI's progress. And we do this defiantly as a form of unification. I think it does require a lot of courage for us though to say we recognize how sacred our existence is. We don't want to throw it away and we want to defend it with every bit of courage and strength we have because it is so precious. I think it's going to be the year we end YOLO and the beginning of don't die. The most striking thing about next year is that the other forms of knowledge work are going to experience what software engineers are feeling right now. Where they went from typing you know most of their lines of code at the beginning of the year to typing barely any of them at the end of the year. I think of this as the Claude code experience but for all forms of knowledge work. I also think that probably continual learning gets sold in a satisfying way. That we see the first test deployments of home robots and the software engineering itself goes utterly wild next year. My prediction for 2026 is that it's the year where everyone's perceptions are flipped. Currently everyone believes that you can only use Nvidia outside of Google and that will be obvious that that's not the case. Currently about a third of Americans hate AI and think it's really bad. That number will increase. Currently most Americans think AI is not useful. That will flip as well. And so everyone's priors will be flipped. That's because the transformative use of AI will be so prevalent. The obvious utility of it will be so high that there is no way for anyone's priors. You know cognitive dissonance will be wiped away. Hey I'm Benger Inspector. I'm Asher Spector. And our prediction is that 2026 is the year of energy efficient AI. Data center build-ups are primarily constrained by energy. Power available, the great interconnects, high voltage equipment, things like that. Which is why XAI's Colossus was initially powered by on-site gas turbines. The thing is the demand for compute is continuing to grow. Labs, neolabs like us, and startups like Cursor have a pretty remarkably sensational demand for both training and compute. And this demand is currently outstripping our ability to push lots onto the grid. This means that in 2026 it will be really important to squeeze every available bit of tons out of every wallet. That said, in the long term chips probably matter more than power because chips depreciate much more quickly than the underlying power infrastructure. So for example with data center power supplies at 10 per kilowatt hour, the chips cost actually order amounted more than the power in the five year depreciation cycle. So in 2026 we think intelligence per watt is really important to squeeze as much intelligence you can out of every unit of energy. But in the long term we think it's the chips that matter more. Happy holidays. Happy New Year. Thanks for the year. Happy 2026. Happy 2026 listeners. Thank you. Find us on Twitter at NoPriorsPod. Subscribe to our YouTube channel if you want to see our faces. Follow the show on Apple Podcasts, Spotify, or wherever you listen. That way you get a new episode every week. And sign up for emails or find transcripts for every episode at no-priors.com.