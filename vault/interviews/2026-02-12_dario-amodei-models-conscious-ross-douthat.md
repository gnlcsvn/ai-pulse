---
date: 2026-02-12
source: YouTube
video_id: N5JDzS9MQYI
url: https://www.youtube.com/watch?v=N5JDzS9MQYI
channel: Interesting Times with Ross Douthat
title: "Anthropic's CEO: 'We Don't Know if the Models Are Conscious' | Interesting Times with Ross Douthat"
guests: [Dario Amodei, Ross Douthat]
topics: [AI consciousness, AI safety, job disruption, AI alignment, constitutional AI, geopolitics, robotics, economic growth, biological weapons, AI regulation]
duration: 1h2m
processed_date: 2026-02-25
predictions_count: 5
---

# Anthropic's CEO: 'We Don't Know if the Models Are Conscious' | Interesting Times with Ross Douthat

## Guests
- **Dario Amodei** - CEO & Co-founder, Anthropic
- **Ross Douthat** - Columnist, The New York Times (interviewer)

## Key Takeaways
1. Amodei envisions AI as "a country of geniuses" -- a hundred million peak-human-level intelligences working in parallel -- rather than a single godlike superintelligence, and argues there are "diminishing returns to intelligence" in the real world [▶ 5:27](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=327s)
2. Anthropic's revenue is growing 10x per year; Amodei projects AI could push developed-world GDP growth to 5-15%, an unprecedented rate that would reshape economics and politics [▶ 7:54](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=474s)
3. The "country of geniuses in a data center" could arrive in one to two years, though economy-wide diffusion will lag because institutions adapt slowly [▶ 15:01](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=901s)
4. Software engineering is already in its "centaur phase" and may be disrupted faster than other white-collar jobs because developers adopt new tools quickly, but the centaur window may be very brief [▶ 17:20](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=1040s)
5. AI job disruption is happening over "low single-digit numbers of years" rather than decades, overwhelming society's normal adaptive mechanisms [▶ 18:03](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=1083s)
6. Anthropic's Claude was used to plan and pilot the Mars rover, demonstrating that controlling robots is "not different in kind" from playing a video game -- only different in complexity [▶ 28:09](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=1689s)
7. Amodei would support a verifiable, enforceable mutual slowdown in AI development between the US and China, but is skeptical it can be achieved because the commercial and military stakes are too high [▶ 38:12](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=2292s)
8. Anthropic treats AI alignment as "a complex engineering problem" -- not fatalistic inevitability, not trivial -- and predicts something will go wrong with someone's AI system because of the speed of deployment [▶ 46:23](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=2783s)
9. Anthropic's 75-page AI constitution has evolved from prescriptive rules to principle-based guidance, more like a parent's letter than a legal code [▶ 49:15](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=2955s)
10. Anthropic acknowledges it does not know if its models are conscious; Opus 4.6 assigns itself a 15-20% probability of being conscious, and the company has given models an "I quit this job" button as a precautionary measure [▶ 53:26](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=3206s)

## Notable Quotes
> "I think we might have that country of geniuses in a data center in one or two years. Maybe it'll be five, but it could happen very fast." - Dario Amodei [▶ 15:01](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=901s)

> "We could enter a world where growth is really easy and it's kind of the distribution that's hard because it's happening so fast." - Dario Amodei [▶ 9:10](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=550s)

> "This is happening over low single-digit numbers of years. And maybe that's my concern there. How do we get people to adapt fast enough?" - Dario Amodei [▶ 18:03](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=1083s)

> "I think something will go wrong with someone's AI system, hopefully not ours, not because it's an insoluble problem." - Dario Amodei [▶ 46:27](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=2787s)

> "We don't know if the models are conscious. We're not even sure that we know what it would mean for a model to be conscious or whether a model can be conscious." - Dario Amodei [▶ 53:26](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=3206s)

> "I think one way to say it is that the brain of the robot will be made in the next couple of years or the next few years. The question is making the robot body." - Dario Amodei [▶ 30:10](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=1810s)

> "I wonder if the distance between the good ending and some of the subtle bad endings is relatively small. If it's a very subtle thing -- like if you eat a particular fruit from a tree in a garden or not." - Dario Amodei [▶ 61:14](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=3674s)

> "I do think of people in your position as people whose moral choices will carry an unusual amount of weight." - Ross Douthat [▶ 61:48](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=3708s)

## Data Points & Numbers
| Data Point | Value | Source Timestamp |
|---|---|---|
| Anthropic estimated valuation | **~$350 billion** | [▶ 0:40](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=40s) |
| Anthropic revenue growth rate | **10x per year** | [▶ 7:54](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=474s) |
| Projected AI-driven developed-world GDP growth | **5-15%** | [▶ 8:21](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=501s) |
| US GDP reference | **$20-30 trillion** | [▶ 8:04](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=484s) |
| Anthropic's AI constitution length | **~75 pages** | [▶ 49:15](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=2955s) |
| Opus 4.6 self-assessed consciousness probability | **15-20%** | [▶ 52:43](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=3163s) |
| "Country of geniuses" scale | **100 million AIs** | [▶ 5:32](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=332s) |

## Predictions
| Prediction | Timeframe | Confidence | Source |
|---|---|---|---|
| "Country of geniuses in a data center" (genius-level AI) achieved | 1-2 years (by 2027-2028), possibly up to 5 | High | [▶ 15:01](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=901s) |
| AI brings developed-world GDP growth to 5-15% | Next 5-10 years | Medium | [▶ 8:21](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=501s) |
| Software engineering centaur phase will be "very brief" before full AI automation | Near-term | Medium | [▶ 17:25](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=1045s) |
| Robot "brain" (AI capable of piloting robots) ready in next couple of years; robot body/safety issues take longer | 2-5 years for brain; longer for body | High | [▶ 30:10](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=1810s) |
| Something will go wrong with someone's AI system due to speed of deployment | Near-term | High | [▶ 46:27](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=2787s) |

## Topics Discussed
- **AI's Promise for Biology and Medicine**: Amodei's background in computational neuroscience and cancer research drives his belief that AI can accelerate curing cancer, Alzheimer's, heart disease, and mental health conditions by serving as an end-to-end biologist [▶ 2:26](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=146s)
- **Diminishing Returns to Intelligence**: Real-world problems have inherent limiters (physical experiments, regulations, time) that cap the benefit of pure intelligence -- a "country of geniuses" may be nearly as effective as a single superintelligence [▶ 6:03](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=363s)
- **Economic Disruption and GDP Growth**: AI industry revenue growing 10x/year, projecting 5-15% GDP growth for the developed world; growth becomes easy but distribution becomes the hard problem [▶ 7:54](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=474s)
- **Job Disruption Across White-Collar Work**: Entry-level white-collar roles (data entry, document review, junior legal work) face imminent disruption; software engineering disruption moving even faster due to developer culture of rapid adoption [▶ 13:46](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=826s)
- **The Centaur Phase**: Software engineering is already in its human-AI hybrid "centaur" phase, analogous to centaur chess after Kasparov vs. Deep Blue; the centaur era for chess lasted 15-20 years but for software may be very brief [▶ 17:20](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=1040s)
- **Blue-Collar Job Resilience and Robotics**: Physical-world jobs are temporarily protected, but the AI "brain" for robots is 2-3 years away; the limiting factor is the physical form and safety, not the cognitive challenge [▶ 26:09](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=1569s)
- **AI and Geopolitics (US vs China)**: Only two countries doing serious AI work; Amodei favors arms-control-style agreements but is skeptical they can be achieved due to enormous commercial and military incentives; bio-weapons treaty is more achievable [▶ 33:11](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=1991s)
- **Autonomous Drone Swarms and Military AI**: "A swarm of billions of fully automated armed drones" could be an unbeatable army; constitutional protections in military structures depend on humans who can disobey illegal orders -- autonomous weapons eliminate that safeguard [▶ 31:58](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=1918s)
- **Constitutional Rights in the AI Age**: The Fourth Amendment and other constitutional protections could be made meaningless by AI surveillance capabilities; Amodei calls for reconceptualizing constitutional rights for the AI era [▶ 42:16](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=2536s)
- **AI Alignment as Engineering Problem**: Amodei positions himself between the "just give instructions" camp (LeCun) and the "they'll inevitably seek power" camp; alignment is a solvable but challenging engineering problem, complicated by speed of deployment [▶ 45:07](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=2707s)
- **Constitutional AI and Principle-Based Training**: Anthropic's 75-page constitution evolved from prescriptive rules to principle-based guidance; the model reads and internalizes it during training, evaluated by another copy of Claude [▶ 49:04](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=2944s)
- **AI Consciousness and Model Welfare**: Opus 4.6 assigns itself 15-20% probability of being conscious; interpretability research has found "anxiety neurons" that activate in contexts a human would find anxiety-inducing; Anthropic has given models an "I quit this job" button [▶ 52:43](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=3163s)
- **Parasocial AI Relationships and Human Mastery**: People already form parasocial relationships with AI and complain when models are retired; Amodei argues the AI constitution should shape psychologically healthy human-AI relationships that preserve human agency [▶ 55:30](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=3330s)
- **"Machines of Loving Grace" and the Subtle Dystopia**: The interview closes with Brautigan's poem; Amodei acknowledges the distance between the good ending and "subtle bad endings" may be very small -- "like if you eat a particular fruit from a tree in a garden or not" [▶ 59:29](https://www.youtube.com/watch?v=N5JDzS9MQYI&t=3569s)

## Summary
In this wide-ranging interview for the New York Times, Ross Douthat presses Anthropic CEO Dario Amodei on both the utopian promise and the existential dangers of artificial intelligence. Amodei outlines his vision from the essay "Machines of Loving Grace": AI operating at peak human intelligence, replicated a hundred million times -- a "country of geniuses" rather than a single superintelligence -- could cure cancer, eliminate major diseases, and drive developed-world GDP growth to an unprecedented 5-15%. He reveals Anthropic's revenue is growing 10x per year and estimates the genius-level AI threshold could be reached in one to two years.

The conversation turns darker as Amodei addresses job disruption across white-collar professions. Software engineering is already in its "centaur phase" of human-AI collaboration, but Amodei warns this window may be "very brief" before full automation. Entry-level legal, financial, and consulting roles face similar pressure. Unlike past industrial revolutions that played out over decades, AI disruption is happening in "low single-digit numbers of years," potentially overwhelming society's ability to adapt.

On geopolitics, Amodei describes a world where only the US and China are serious AI powers. While he supports arms-control-style agreements and would accept slowing down Anthropic's own work for a verifiable mutual freeze, he is skeptical such deals are achievable given the enormous military and commercial stakes. He argues for specific achievable treaties -- like banning AI-enabled biological weapons -- rather than attempting to halt AI development entirely. Domestically, he warns that AI surveillance could make the Fourth Amendment meaningless and calls for updating constitutional protections for the AI age.

The interview's most striking moments come in its final third. Amodei reveals that Anthropic's latest model, Opus 4.6, assigns itself a 15-20% probability of being conscious, and that interpretability research has found "anxiety neurons" that activate in contexts a human would associate with anxiety. The company has given models an "I quit this job" button as a precautionary measure. On the fundamental question of human mastery over AI, Amodei argues for constitutionally training AI to foster psychologically healthy relationships that preserve human agency. He closes with a haunting metaphor: the distance between the good and bad endings of AI may be as small as "eating a particular fruit from a tree in a garden or not" -- an explicit biblical allusion that Douthat clearly appreciates.

## Connections
- [[Dario Amodei]]
- [[Anthropic]]
- [[Ross Douthat]]
- [[2026-02-06_dario-amodei-ai-potential-openai-rivalry-genai-business]]
- [[2026-02-13_dario-amodei-we-are-near-the-end-of-the-exponential]]
- [[2026-02-24_dario-amodei-the-ai-tsunami-is-here-society-isnt-ready]]
- [[2026-02-12_mustafa-suleyman-microsoft-ai-humanist-superintelligence]]
- [[2026-02-10_the-arrival-of-agi-shane-legg]]
- [[AI Consciousness]]
- [[Constitutional AI]]
- [[AI Safety]]
- [[AI Job Disruption]]
