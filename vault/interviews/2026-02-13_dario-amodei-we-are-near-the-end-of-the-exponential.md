---
date: 2026-02-13
source: YouTube
video_id: n1E9IZfvGMA
url: https://www.youtube.com/watch?v=n1E9IZfvGMA
channel: Dwarkesh Patel
title: "Dario Amodei — We are near the end of the exponential"
guests: [Dario Amodei]
topics: [scaling laws, AGI timelines, Anthropic revenue, country of geniuses, RL scaling, economic diffusion, AI regulation, export controls, China, authoritarianism, Claude Code, AI safety, compute economics, continual learning, robotics, AI governance]
duration: 2h22m
processed_date: 2026-02-24
predictions_count: 12
---

# Dario Amodei — We are near the end of the exponential

## Guests
- **Dario Amodei** - CEO & Co-founder, Anthropic

## Key Takeaways
1. Dario says the underlying AI technology exponential has proceeded roughly as he expected over the past three years, but the most surprising thing has been the lack of public recognition of how close we are to the end of the exponential [▶ 0:53](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=53s)
2. The "Big Blob of Compute Hypothesis" Dario wrote in 2017 still holds: only a few things matter -- raw compute, data quantity, data quality/distribution, training duration, a scalable objective function, and numerical stability. RL scaling is now showing the same log-linear improvements as pre-training [▶ 2:05](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=125s)
3. Dario puts 90% probability on achieving "country of geniuses in a data center" within 10 years, and a 50/50 hunch that it arrives in 1-3 years. He is 99-95% confident on verifiable tasks like coding [▶ 14:01](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=841s)
4. Anthropic's revenue has grown roughly 10x per year: near zero to $100M in 2023, $100M to $1B in 2024, $1B to $9-10B in 2025, and another few billion were added in January 2026 alone [▶ 21:34](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=1294s)
5. AI coding models currently give roughly a 15-20% total factor productivity speedup, up from about 5% six months ago; this advantage is snowballing and will continue to accelerate [▶ 37:36](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=2256s)
6. Dario predicts the AI industry will generate trillions of dollars in annual revenue before 2030, and believes it is hard to construct a plausible scenario where this does not happen [▶ 67:15](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=4035s)
7. Economic diffusion of AI will be extremely fast but not instant -- much faster than any previous technology, but constrained by enterprise adoption cycles, legal processes, regulatory pipelines, and change management [▶ 22:25](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=1345s)
8. Dario strongly supports U.S. export controls on AI chips to China, arguing that authoritarian governments with powerful AI could create self-reinforcing totalitarian states that are very difficult to displace [▶ 105:34](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=6334s)
9. Claude Code originated as an internal tool at Anthropic; Dario saw its fast internal adoption and decided to launch it externally, creating a feedback loop between Anthropic's own engineers and product development [▶ 88:34](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=5314s)
10. On AI governance, Dario advocates starting with transparency standards and moving to more targeted regulation (e.g., bio classifiers) as specific risks materialize, opposing the 10-year moratorium on state AI regulation because it comes with no federal alternative [▶ 97:49](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=5869s)

## Notable Quotes
> "The most surprising thing has been the lack of public recognition of how close we are to the end of the exponential. To me, it is absolutely wild that you have people talking about these same tired old hot button political issues. And around us, we're like near the end of the exponential." - Dario Amodei [▶ 0:53](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=53s)

> "All the cleverness, all the techniques, all the kind of 'we need a new method to do something' -- that doesn't matter very much. There are only a few things that matter." - Dario Amodei, on the Big Blob of Compute Hypothesis [▶ 2:05](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=125s)

> "There is zero time for bullshit. There is zero time for feeling like we're productive when we're not. These tools make us a lot more productive." - Dario Amodei, on AI coding tools at Anthropic [▶ 36:17](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=2177s)

> "I don't believe we're basically at AGI. If you had the country of geniuses in a data center, we would know it. Everyone in this room would know it. Everyone in Washington would know it." - Dario Amodei [▶ 25:07](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=1507s)

> "I think it's crazy to say that this won't happen by 2035. In some sane world, it would be outside the mainstream." - Dario Amodei, on achieving AGI within 10 years [▶ 14:01](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=841s)

> "We may get 10 or 20 per year growth in the economy, but we're not going to get 300% growth in the economy." - Dario Amodei, on AI-driven economic growth [▶ 72:05](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=4325s)

> "My worry is just that this is happening all so fast... some very critical decision will be some decision that someone just comes into my office and is like, Dario, you have two minutes, should we do thing A or thing B." - Dario Amodei, on the speed of consequential decision-making [▶ 136:06](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=8166s)

> "At every moment of this exponential, the extent to which the world outside it didn't understand it -- this is a bias that's often present in history where anything that actually happened looks inevitable in retrospect." - Dario Amodei, on what historians will miss [▶ 133:55](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=8035s)

## Data Points & Numbers
| Data Point | Value | Source Timestamp |
|---|---|---|
| Anthropic 2023 revenue | **~$0 to $100M** | [▶ 21:34](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=1294s) |
| Anthropic 2024 revenue | **$100M to $1B** | [▶ 21:38](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=1298s) |
| Anthropic 2025 revenue | **$1B to $9-10B** | [▶ 21:41](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=1301s) |
| Anthropic January 2026 revenue add | **Several billion** | [▶ 21:53](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=1314s) |
| Annual revenue growth rate | **~10x per year** | [▶ 21:23](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=1283s) |
| Current AI coding productivity speedup | **15-20% total factor** | [▶ 37:36](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=2256s) |
| AI coding speedup 6 months ago | **~5%** | [▶ 37:36](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=2256s) |
| Confidence AGI within 10 years | **90%** | [▶ 14:01](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=841s) |
| Hunch on AGI timeline | **1-3 years (50/50)** | [▶ 45:39](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=2739s) |
| OS World benchmark progress | **~15% to 65-70%** | [▶ 32:20](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=1940s) |
| Industry compute this year | **10-15 GW** | [▶ 56:43](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=3403s) |
| Industry compute scaling rate | **~3x per year** | [▶ 56:43](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=3403s) |
| Projected compute 2028 | **~100 GW** | [▶ 56:52](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=3412s) |
| Cost per gigawatt per year | **~$10-15B** | [▶ 56:43](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=3403s) |
| AI-driven economy growth prediction | **10-20% per year** | [▶ 72:05](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=4325s) |
| Anthropic headcount | **~2,500 people** | [▶ 139:23](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=8363s) |
| Profitability target year | **2028** | [▶ 58:46](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=3526s) |

## Predictions
| Prediction | Timeframe | Confidence | Source |
|---|---|---|---|
| AI systems will achieve 'country of geniuses in a data center' (Nobel-Prize-winner-level capabilities across domains) within 10 years | within 10 years | high (90%) | [▶ 13:51](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=831s) |
| It is crazy to say that the 'country of geniuses' won't happen by 2035 | by 2035 | high (90%) | [▶ 15:39](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=939s) |
| Country of geniuses in a data center will arrive in 1-3 years (personal hunch) | more like one to three | medium (50%) | [▶ 45:59](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=2759s) |
| Models that are a country of geniuses, 100% country of geniuses in the data center, could arrive in one to two years | in one to two years | medium | [▶ 47:53](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=2873s) |
| 90% less demand for software engineers will happen | further down the spectrum (implied near-term, within a few years) | medium | [▶ 19:09](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=1149s) |
| AI industry will generate trillions of dollars in annual revenue before 2030 | before 2030 | high | [▶ 1:07:15](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=4035s) |
| AI-driven economic growth will reach 10-20% per year but not 300% growth | implied post-AGI era, within the decade | medium | [▶ 1:12:05](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=4325s) |
| Industry compute will reach ~100 GW by 2028 and ~300 GW by 2029, at ~$10-15B per GW per year | 2028 might be 100, 2029 might be like 300 gigawatts | medium | [▶ 56:52](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=3412s) |
| Industry compute growing ~3x per year, currently at 10-15 GW, next year 30-40 GW | this year 10-15 GW, next year 30-40 GW, ~3x a year | medium | [▶ 56:43](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=3403s) |
| Anthropic will be profitable starting in 2028 | profitable starting in 28 | medium | [▶ 58:46](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=3526s) |
| Robotics will be quickly solved once we have the country of geniuses, but add another year or two for diffusion beyond the AGI timeline | another year or two (on top of country of geniuses timeline) | medium | [▶ 1:19:45](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=4785s) |
| AI bioterrorism risk will become serious enough to require federal action, possibly later in 2026 | imagine a world where later this year we say hey this AI bioterrorism stuff is really serious | speculative | [▶ 1:40:20](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=6020s) |

## Topics Discussed
- **Scaling Laws & the Big Blob of Compute Hypothesis**: Dario reaffirms his 2017 hypothesis that only a handful of factors matter (compute, data quantity, data quality, training duration, scalable objectives, numerical stability). Pre-training scaling continues to deliver gains, and RL scaling now shows the same log-linear improvements [▶ 2:05](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=125s)
- **RL Scaling vs. Pre-training**: RL is not fundamentally different from pre-training in terms of the scaling dynamic. Just as pre-training generalized when trained on broad internet data (the GPT-1 to GPT-2 transition), RL will generalize as it moves from narrow math contests to broader tasks [▶ 5:21](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=321s)
- **Pre-training as Evolution Analogy**: Pre-training exists somewhere between human evolution and human learning -- models start from random weights (more blank-slate than humans) and require far more data, while in-context learning occupies a middle ground between long-term and short-term human learning [▶ 9:30](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=570s)
- **AGI Timelines & the Country of Geniuses**: Dario is 90% confident on achieving a "country of geniuses in a data center" within 10 years, with a personal hunch of 1-3 years. The 5% residual uncertainty comes from catastrophic scenarios (company turmoil, Taiwan invasion) and the 5% from non-verifiable tasks [▶ 14:01](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=841s)
- **Software Engineering Spectrum**: There is a long spectrum from 90% of code written by AI to 100% of code, to 90% of end-to-end SWE tasks, to 100% of SWE tasks, to new higher-level tasks for engineers. Anthropic is traversing this spectrum very quickly [▶ 18:05](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=1085s)
- **Anthropic Revenue Growth**: Describes a "bizarre 10x per year" revenue curve, from near-zero to $100M (2023), $1B (2024), $9-10B (2025), with several more billion added in January 2026. Acknowledges the curve must eventually bend but expects it to stay fast [▶ 21:23](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=1283s)
- **Economic Diffusion -- Fast but Not Instant**: A core theme of the interview. AI adoption is much faster than any previous technology but still constrained by enterprise procurement, compliance, change management, and the need to close feedback loops. This is the middle ground between "AI won't matter" and "instant singularity" [▶ 22:25](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=1345s)
- **Continual Learning and On-the-Job Learning**: Dario argues models may not need human-like continual learning at all. Pre-training generalization plus in-context learning (at a million tokens or more) may be sufficient. Longer context lengths are an engineering problem, not a research problem. Separately, Anthropic is also working on continual learning and expects progress in 1-2 years [▶ 42:16](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=2536s)
- **Compute Economics & Profitability**: Profitability depends on demand prediction accuracy, not a single inflection point. In equilibrium, ~50% of compute goes to training and ~50% to inference with positive gross margins. The challenge is predicting demand when buying compute 1-2 years in advance -- overestimate and you go bankrupt, underestimate and you have no compute for research [▶ 58:46](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=3526s)
- **Industry Compute Trajectory**: The industry is at ~10-15 GW this year, growing ~3x per year. By 2028 this could reach ~100 GW, and by 2029 ~300 GW. At ~$10-15B per GW per year, this implies multiple trillions in industry-wide compute spend by late decade [▶ 56:43](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=3403s)
- **Robotics**: Once models have general computer-control and broad agentic skills (via whatever path -- RL environments, video games, context learning), robotics will be revolutionized in both hardware design and control. Dario adds "another year or two" on top of the country-of-geniuses timeline for robotics diffusion [▶ 77:57](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=4677s)
- **Claude Code Origin Story**: Started as an internal tool (originally called "claude cli") that saw rapid internal adoption at Anthropic. Dario saw the product-market fit signal and decided to launch it externally. The tight feedback loop between Anthropic's own engineers and the product continues to be a key advantage [▶ 88:34](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=5314s)
- **API Business Model Durability**: Dario believes the API model is more durable than people think because the technology advances so fast that any product surface risks becoming irrelevant. The API always provides access to the latest capabilities, enabling a rolling frontier of startups. But other models (pay-for-results, labor-like pricing) will emerge alongside it [▶ 83:36](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=5016s)
- **AI Safety, Bioterrorism & Regulation**: Dario supports starting with transparency standards and moving to targeted regulation as risks materialize. He opposed the 10-year moratorium on state AI laws because it came with no federal plan. He believes AI bioterrorism is a real near-term risk that may require federal action as soon as later in 2026 [▶ 94:00](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=5640s)
- **Export Controls & China**: Dario supports strict chip export controls to China. His concern is not about the Chinese people but about authoritarian governments with powerful AI creating self-reinforcing totalitarian states. He argues the initial conditions matter and that democratic nations should hold a stronger hand when the post-AI world order is negotiated [▶ 105:34](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=6334s)
- **Authoritarianism in the AI Age**: Dario explores whether AI might inherently dissolve authoritarian structures (as industrialization dissolved feudalism) or whether it could cement them. He expresses hope that dictatorships could become "morally obsolete" but acknowledges deep uncertainty about the outcome [▶ 114:24](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=6864s)
- **Claude's Constitution and Values**: Anthropic has moved toward principles-based rather than rules-based training. Dario describes three feedback loops for the constitution: internal iteration, competition between companies' constitutions, and societal input. The model is mostly corrigible with hard limits on dangerous actions [▶ 128:04](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=7684s)
- **What Historians Will Miss**: Dario says future histories will underestimate how non-obvious the AI exponential was to outsiders at every moment, and how fast everything was happening with decisions being made under extreme time pressure [▶ 133:55](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=8035s)
- **DVQ (Dario Vision Quest)**: Dario speaks to the entire company every two weeks with a 3-4 page document covering models, products, industry, geopolitics. He views direct, honest communication and culture-building as the most leveraged use of his time at 2,500 people [▶ 139:23](https://www.youtube.com/watch?v=n1E9IZfvGMA&t=8363s)

## Summary
In this landmark two-hour-plus interview with Dwarkesh Patel, Anthropic CEO Dario Amodei lays out his comprehensive view of where AI stands in February 2026 and where it is headed. His central thesis is that we are "near the end of the exponential" -- the march from smart high schooler to smart college student to PhD-level to beyond has proceeded roughly as he predicted, but the world outside AI labs has been shockingly slow to recognize how close the endpoint is. He reaffirms his 2017 "Big Blob of Compute Hypothesis," arguing that only a handful of factors matter (compute, data, scalable objectives, numerical stability) and that RL scaling is now showing the same log-linear improvements that pre-training has long exhibited.

On timelines, Dario puts 90% probability on achieving a "country of geniuses in a data center" -- AI systems with Nobel-Prize-winner-level capabilities across domains -- within 10 years, and a personal 50/50 hunch that it arrives within 1-3 years. He is especially confident on verifiable tasks like coding, where he sees end-to-end software engineering automation arriving in 1-2 years. However, he is careful to distinguish between technical capability and economic impact: even after the country of geniuses exists, economic diffusion will be "extremely fast but not instant," constrained by enterprise adoption cycles, regulatory pipelines, and the basic logistics of deploying AI in complex organizational settings. He backs this up with Anthropic's own revenue trajectory -- roughly 10x per year, from near-zero in 2023 to $9-10B in 2025, with several more billion added in January 2026 alone -- as evidence that adoption is fast but still bounded.

The interview covers substantial ground on the economics of AI compute. Dario details the industry's trajectory from ~10-15 GW of data center capacity in 2026 to potentially 100 GW by 2028 and 300 GW by 2029, each GW costing roughly $10-15B per year. He explains that profitability in the AI industry is fundamentally a demand-prediction problem: in equilibrium, roughly half of compute goes to training and half to inference with positive margins, but the exponential scale-up phase creates a cash-flow challenge where each model is profitable but the company may not be because it is simultaneously spending much more to train the next model. He predicts Anthropic will be profitable by 2028 and that the industry will generate trillions in annual revenue before 2030.

On safety, governance, and geopolitics, Dario is deeply engaged. He supports starting with transparency standards and escalating to targeted regulation as specific risks (especially AI-enabled bioterrorism) materialize, which he expects could happen as soon as later in 2026. He opposed the 10-year moratorium on state AI laws because it came with no federal alternative, though he would support federal preemption done properly. He is a strong advocate for chip export controls to China, arguing that the initial conditions of who holds powerful AI matter enormously for the post-AI world order, and that authoritarian governments with powerful AI could create self-reinforcing totalitarian states. He explores the provocative possibility that AI might inherently dissolve authoritarian structures the way industrialization dissolved feudalism, while acknowledging deep uncertainty. The interview closes with Dario reflecting on what historians will get wrong about this era -- primarily, how non-obvious the exponential was from the outside -- and describing his "Dario Vision Quest" biweekly all-hands as his most leveraged tool for holding Anthropic's culture together at 2,500 people during the most consequential period in the company's history.

## Connections
- [[Dario Amodei]]
- [[Anthropic]]
- [[Dwarkesh Patel]]
- [[Claude Code]]
- [[Scaling Laws]]
- [[AGI Timelines]]
- [[AI Safety]]
- [[AI Regulation]]
- [[Export Controls]]
- [[Machines of Loving Grace]]
- [[The Adolescence of Technology]]
