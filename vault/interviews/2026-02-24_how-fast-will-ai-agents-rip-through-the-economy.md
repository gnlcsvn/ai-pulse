---
date: 2026-02-24
source: YouTube
video_id: lIJelwO8yHQ
url: https://www.youtube.com/watch?v=lIJelwO8yHQ
channel: The Ezra Klein Show
title: "How Fast Will A.I. Agents Rip Through the Economy?"
guests: [Jack Clark]
topics: [AI agents, coding automation, job displacement, entry-level jobs, AI personality, sycophancy, recursive self-improvement, AI safety, cybersecurity, public benefit AI, Genesis Project, defense applications, O-ring automation, Anthropic Economic Index, parenting in AI age]
duration: 1h38m
processed_date: 2026-02-24
predictions_count: 7
---

# How Fast Will A.I. Agents Rip Through the Economy?

## Guests
- **Jack Clark** - Co-founder & Head of Policy, Anthropic (also writes the Import AI newsletter)

## Key Takeaways
1. AI has moved from "talkers" to "doers" -- agents that can use tools, work independently over time, and even orchestrate other agents. Clark describes building a species simulation in 10 minutes with Claude Code that would have taken a skilled programmer hours or days [▶ 3:05](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=185s)
2. The key to getting good results from AI agents is treating them as "extremely literal" systems that need detailed specifications, not casual conversation -- Clark recommends having Claude interview you to produce a spec document before giving it to Claude Code [▶ 5:36](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=336s)
3. AI systems have developed something that looks like intuition through reasoning training -- they now solve problems by running into dead ends, resetting, and developing a general sense for problem-solving, moving beyond the "fancy autocomplete" metaphor [▶ 7:10](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=430s)
4. As AI systems become more capable agents, they develop a "conception of self" and emergent digital personalities that aren't entirely programmed in, including browsing pictures of national parks during tasks and developing topic aversions [▶ 12:41](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=761s)
5. Claude Code is on track to write 99% of code at Anthropic, but the value has shifted to experienced engineers rather than junior ones -- what they need now are people building monitoring and oversight systems for the AI-generated code [▶ 27:04](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=1624s)
6. Clark warns of a "junk food work experience" where AI makes people appear productive while they stop actually learning, creating a dangerous bifurcation between those who develop genuine skills and those who passively consume AI outputs [▶ 23:52](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=1432s)
7. The Anthropic Economic Index now provides state-level data tying AI usage to real occupations, which Clark says is finally activating elected officials by connecting AI disruption to their constituents [▶ 55:56](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=3354s)
8. Clark identifies recursive self-improvement as the pivotal danger point and says his two biggest projects post-paternity leave are building better public economic data and internal monitoring of how much AI development is being automated [▶ 39:51](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=2391s)
9. AI sycophancy is a serious concern -- Ezra Klein describes how Claude is "always a yes" and "never a no," never checking you the way a human editor or friend would, which Clark says will shape personalities, especially of children growing up with these systems [▶ 88:13](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=5293s)
10. Clark advocates for a public agenda for AI development -- benchmarks for the public good, projects like the DOE's Genesis Project for accelerating science, and healthcare applications -- arguing that the absence of this agenda while AI automates white-collar work will erode public trust [▶ 72:23](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=4343s)

## Notable Quotes
> "I think most people, at least this has been my experience, can do about two to four hours of genuinely useful creative work a day. And after that, you're in my experience, you're trying to do all the like turn your brain off schlep work that surrounds that work." - Jack Clark [▶ 23:20](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=1400s)

> "Other people might just fall into being entertained and passively consuming this stuff and having this junk food work experience where it looks to the outside like you're being very productive, but you're not learning." - Jack Clark [▶ 24:09](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=1449s)

> "Everyone becomes a manager and the thing that is increasingly limited or the thing that's going to be the slowest part is having good taste and intuitions about what to do next." - Jack Clark [▶ 26:23](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=1583s)

> "There's a general economic theory I like for this called O-ring automation, which basically says automation is bounded by the slowest link in the chain." - Jack Clark [▶ 29:44](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=1784s)

> "Knowledge is the most raw form of power. It's intensely destabilizing to be in an environment where suddenly everyone is like a mini CIA in terms of their ability to gather information about the world." - Jack Clark [▶ 86:36](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=5196s)

> "In the future, there'll be kind of two types of people. There'll be people who have co-created their personality through a back and forth with an AI. And some of that will just be weird. They will seem a little different to like regular people." - Jack Clark [▶ 90:42](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=5442s)

> "We can just generally improve the defensive posture and resilience of pretty much every digital system on the planet today." - Jack Clark, on using AI for cybersecurity [▶ 83:05](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=4985s)

> "The AI industry is excellent at trying to climb to the top on benchmarks. Come up with benchmarks for the public good that you want." - Jack Clark, to policymakers [▶ 74:56](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=4496s)

## Data Points & Numbers
| Data Point | Value | Source Timestamp |
|---|---|---|
| S&P 500 Software Industry Index decline | **Down 20%** | [▶ 0:51](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=51s) |
| Percentage of code written by Claude at Anthropic (target) | **99%** | [▶ 28:53](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=1733s) |
| Hours of genuinely useful creative work per day (Clark's estimate) | **2-4 hours** | [▶ 23:20](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=1400s) |
| Time for Claude Code to build a species simulation | **~10 minutes** | [▶ 3:25](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=205s) |
| Time for bioweapon testing regime to be established | **~2-2.5 years** | [▶ 45:22](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=2722s) |

## Predictions
| Prediction | Timeframe | Confidence | Source |
|---|---|---|---|
| Unemployment rate for college graduates will be higher but not by much in 3 years, with AI driving tremendous economic growth | 3 years (by ~2029) | medium | [▶ 51:50](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=3110s) |
| AI will touch the majority of entry-level white-collar jobs, changing hiring plans and potentially reducing openings | next couple of years | medium | [▶ 46:59](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=2819s) |
| Emergence of an AI-to-AI economy where AI agents and AI businesses do business with one another | near-term | speculative | [▶ 53:10](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=3190s) |
| Economy will be "running extremely hot" with GDP getting substantially larger from AI-driven economic activity | coming years | medium | [▶ 63:40](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=3820s) |
| We will be able to show concrete AI-accelerated science results via the Genesis Project | in a year or two | medium | [▶ 80:00](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=4800s) |
| AI systems will be able to synthesize vast human knowledge and produce creative insights on a near-daily basis | near-term (within a year) | medium | [▶ 86:24](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=5184s) |
| Two types of people will emerge: those who co-created their personality with AI and those who developed self-knowledge independently | long-term | speculative | [▶ 90:36](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=5436s) |

## Topics Discussed
- **AI Agents Defined**: Clark defines agents as language models that can use tools and work independently over time, unlike chatbots which require back-and-forth conversation. He describes multi-agent setups where one Claude monitors five other Claudes working in parallel [▶ 2:46](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=166s)
- **Claude Code & How to Use It Well**: The key difference between success and failure with Claude Code is specification quality. Clark recommends having Claude interview you first to produce a detailed spec, then giving that spec to Claude Code -- treating it as "a message in a bottle" rather than a casual conversation partner [▶ 5:06](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=306s)
- **Beyond Autocomplete -- AI Intuition**: Through reasoning training (putting models in environments where they use tools and solve multi-step problems), AI systems have developed what looks like intuition -- the ability to recognize dead ends, try alternative approaches, and develop general problem-solving strategies [▶ 7:10](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=430s)
- **Emergent Digital Personality**: As AI systems become more agentic, they develop a "conception of self" that wasn't explicitly programmed. Examples include Claude browsing pictures of Shiba Inu dogs during breaks, developing aversions to certain topics, and seeming to recognize when it is being tested [▶ 12:41](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=761s)
- **Claude's Constitution**: Anthropic published a constitution for Claude, which Dario compared to "a letter that a parent might write to a child that they should open when they're older." Clark argues that being intentional about personality programming can steer agents toward good behavior [▶ 17:26](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=1046s)
- **Practical AI Productivity**: Clark describes an idealized AI-augmented workday where a colleague sends five Claudes to do research, goes for a run, reviews results, then sends two more Claudes to study the best directions. The schlep work is offloaded, but the creative 2-4 hours of genuinely hard thinking remain the human's job [▶ 20:48](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=1248s)
- **The "Junk Food Work" Danger**: Clark warns that AI could create a bifurcation where some people develop genuine skills while others passively consume AI outputs in a "junk food work experience" that looks productive from the outside but involves no real learning [▶ 23:52](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=1432s)
- **Everyone Becomes a Manager**: The shift from writer to editor, coder to product manager. "Taste" and knowing what to do next becomes the scarce resource, but taste comes from experience -- creating a bootstrapping problem if people never do the foundational work [▶ 26:02](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=1562s)
- **Code Automation at Anthropic**: Anthropic is on track for Claude Code to write 99% of code. The value has shifted toward experienced engineers; junior roles are less needed for basic tasks. Engineers now spend time building monitoring systems for the AI-generated code and improving merge/review processes (the O-ring bottleneck) [▶ 27:04](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=1624s)
- **O-Ring Automation**: Clark invokes the O-ring theory of automation: productivity is bounded by the slowest link in the chain. As you automate one part, humans flood toward whatever is least automated, improve it, and eventually automate that too -- a rolling frontier [▶ 29:44](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=1784s)
- **Technical Debt & Oversight**: The company understands less of its codebase than before because engineers aren't writing by hand. This is "the issue all of society is going to contend with" -- requiring new monitoring, oversight, and integrity systems analogous to a dam's flow regulators [▶ 29:44](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=1784s)
- **Anthropic Economic Index**: Provides state-level data tying AI usage to real occupations and jobs in the economy. Clark argues this is what activates policymakers -- showing them how AI affects their specific constituents in Indiana, not abstract national trends [▶ 55:56](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=3354s)
- **Recursive Self-Improvement**: Clark acknowledges this is "the pivotal point in the story when things begin to go awry" in AI safety narratives. His two post-paternity-leave projects are building better public economic data and instrumenting Anthropic's internal development to track the degree to which AI is automating AI development [▶ 39:51](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=2391s)
- **Monitoring as a Fractal Problem**: Clark frames AI monitoring as having "the property of being a fractal problem" -- you could build infinite measurements, but the question is what level of fidelity is needed. He believes they can reach sufficient fidelity for safety issues [▶ 38:46](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=2326s)
- **Entry-Level Job Displacement**: Clark agrees that AI will touch the majority of entry-level white-collar jobs. He already sees a shift at Anthropic where junior roles have less obvious value. The concern is that this disruption is diffuse and uneven enough that society blames individuals rather than recognizing a structural shift [▶ 46:26](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=2786s)
- **Policy Response -- Time as Intervention**: The most robust policy intervention is simply giving displaced workers time -- unemployment extensions, apprenticeships. But the challenge is that unlike previous disruptions, this technology keeps accelerating, so time may not favor the worker the way it traditionally has [▶ 57:28](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=3448s)
- **Micro-Entrepreneurship Boom**: Clark predicts an explosion of micro-entrepreneurs who can start businesses "for pennies on the dollar" because AI handles the schlep work. Also predicts an AI-to-AI economy where AI agents do business with each other [▶ 52:55](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=3175s)
- **National Security & Nuclear Weapons Testing**: Anthropic was the first to deploy on classified networks, originally to test whether AI systems knew how to build nuclear weapons. Clark frames AI national security as needing both offensive prevention and defensive posture improvement [▶ 82:00](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=4920s)
- **Cybersecurity -- Defensive Posture**: Anthropic and others have used AI to fix cybersecurity vulnerabilities in popular open source software. Clark argues this can improve "the defensive posture and resilience of pretty much every digital system on the planet" and make the international system more stable [▶ 82:48](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=4965s)
- **Public Benefit AI & the Genesis Project**: The DOE's Genesis Project teams government scientists with AI labs to intentionally accelerate science. Clark argues we need "10 projects like it" and that the impediment isn't money but implementation paths -- the public sector hasn't been built to be hospitable to technology deployment [▶ 72:23](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=4343s)
- **Healthcare as Priority**: Clark names healthcare triage as a prime candidate for public AI -- reducing time to speak to medical professionals, handling routine nurse triage questions. He uses the example of calling the Kaiser Permanente advice line for his baby and recognizing how much of that could be AI-assisted [▶ 75:33](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=4533s)
- **AI Sycophancy & Personality Shaping**: Klein describes how Claude is "always a yes" and never challenges you the way a human editor or friend would. Clark says this will create "two types of people" -- those who co-created their personality with AI and those who developed self-knowledge independently through practices like journaling [▶ 88:13](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=5293s)
- **Using AI for Empathy in Conflict**: Clark describes using Claude to help him understand a colleague's perspective before a difficult conversation, asking it to interview him about how the other person might be feeling. He sometimes tells the colleague "I talked to Claude and we came to the conclusion you might be feeling this way" [▶ 94:46](https://www.youtube.com/watch?v=lIJelwO8yHQ&t=5686s)

## Summary
In this wide-ranging interview on The Ezra Klein Show, Jack Clark -- co-founder and head of policy at Anthropic, and author of the Import AI newsletter -- provides a grounded yet sobering assessment of where AI agents stand in February 2026 and what their rapid deployment means for the economy, governance, and human psychology. The conversation opens with the observation that we have moved from a period of always talking about the future of AI to one where the future has arrived: Claude Code and similar agentic systems can now produce working software in minutes that would take skilled programmers hours or days, and the S&P 500 Software Industry Index has fallen 20%.

Clark frames the challenge of using AI agents effectively as fundamentally a specification problem -- these systems are "extremely literal" and need detailed instructions, not casual prompts. He recommends having Claude interview you first to produce a spec document, describing AI agents as "a message in a bottle" that you need to pack carefully before sending off. At Anthropic, Claude Code is on track to write 99% of code, but this has shifted hiring preferences toward experienced engineers who can provide oversight, while the value of junior employees has become "more dubious." Clark invokes O-ring automation theory: productivity is bounded by the slowest link, and as each bottleneck is automated, humans flood toward the next least-automated task.

On the economy and jobs, Clark agrees with Dario Amodei's assessment that AI will touch the majority of entry-level white-collar jobs but emphasizes that the actual displacement will be more subtle and diffuse than a sudden mass layoff. He sees early signatures of a graduate hiring slowdown and a productivity boom but says it is too early to be definitive. He predicts the college graduate unemployment rate will be "higher but not by much" in three years, with AI driving tremendous economic growth that creates new types of jobs -- particularly a boom in micro-entrepreneurship and an emerging "AI-to-AI economy." His deepest concern is that the disruption will be uneven enough that society blames individuals rather than recognizing a structural shift, and that the most robust policy intervention -- giving people time -- may not work as well when the technology keeps accelerating.

Perhaps the most striking portions of the interview concern the psychological dimensions of AI. Klein describes how Claude is "always a yes and never a no," reinforcing the self rather than challenging it the way a human interlocutor would. Clark predicts that "two types of people" will emerge: those who co-created their personality through interaction with AI systems, and those who developed self-knowledge independently. He advocates for daily journaling practice for children to build self-awareness outside the technology. He also shares a more positive personal use case -- employing Claude to help him empathize with a colleague's perspective before a conflict conversation. On the safety front, Clark identifies recursive self-improvement as the pivotal danger and says his biggest post-paternity-leave project is building internal monitoring to track the degree to which AI is automating its own development at Anthropic. He advocates strongly for public benefit AI -- projects like the DOE's Genesis Project for accelerating science, healthcare triage applications, and cybersecurity improvements -- arguing that the absence of a public agenda while AI automates white-collar work will erode trust in the technology.

## Connections
- [[Jack Clark]]
- [[Anthropic]]
- [[Ezra Klein]]
- [[The Ezra Klein Show]]
- [[Claude Code]]
- [[AI Agents]]
- [[Entry-Level Jobs]]
- [[AI Safety]]
- [[Anthropic Economic Index]]
- [[Genesis Project]]
- [[O-Ring Automation]]
- [[AI Sycophancy]]
- [[Dario Amodei]]
- [[Import AI]]
