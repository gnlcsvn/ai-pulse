---
date: 2026-02-12
source: YouTube
video_id: C1TGh6zqigg
url: https://www.youtube.com/watch?v=C1TGh6zqigg
channel: World Economic Forum
title: "The day after AGI: Two rock stars of AI on what it will mean for humanity (Radio Davos Extended)"
guests: [Demis Hassabis, Dario Amodei, Zanny Minton Beddoes, Benjamin Larsen]
topics: [AGI timeline, AI safety, technological adolescence, labor displacement, geopolitics, chip export controls, self-improvement loop, mechanistic interpretability, Fermi paradox, post-scarcity, agentic AI, AI agents, world models, robotics]
duration: 50m
processed_date: 2026-02-25
predictions_count: 11
---

# The Day After AGI: Two Rock Stars of AI on What It Will Mean for Humanity (Radio Davos Extended)

> **Note**: This is the extended Radio Davos podcast version (50 min) that wraps the WEF "Day After AGI" panel in a longer editorial package with host Robin Pomeroy and WEF AI safety lead Benjamin Larsen. The shorter 32-minute panel-only version is covered in [[2026-01-22_the-day-after-agi-wef-2026]]. This extended version adds ~18 minutes of Radio Davos introduction providing context on AGI definitions, the self-improvement loop, agentic AI (including OpenClaw), and the WEF Global Future Council on AGI, before presenting the full Davos panel.

## Guests
- **Demis Hassabis** - CEO & Co-founder, Google DeepMind
- **Dario Amodei** - CEO & Co-founder, Anthropic
- **Zanny Minton Beddoes** - Editor-in-Chief, The Economist (moderator)
- **Benjamin Larsen** - AI Safety Lead, WEF Center for AI Excellence (Radio Davos co-host / intro)
- **Robin Pomeroy** - Radio Davos host (intro)

## Key Takeaways
1. Benjamin Larsen frames AGI as a "jagged form of intelligence" -- superhuman in some domains (information recall, certain reasoning tasks) but still limited in others (memory, generalization across arbitrary environments) [▶ 9:16](https://www.youtube.com/watch?v=C1TGh6zqigg&t=556s)
2. Larsen highlights agentic AI and OpenClaw as a turning point: open-source personal AI agents that can access email, calendar, and systems, but warns this "increases the attack surface for hackers" [▶ 13:21](https://www.youtube.com/watch?v=C1TGh6zqigg&t=802s)
3. Larsen notes model context protocol (MCP) and agent-to-agent protocols are building an "agentic web" with much more autonomous software infrastructure [▶ 15:40](https://www.youtube.com/watch?v=C1TGh6zqigg&t=940s)
4. Dario Amodei reaffirms his 2026-2027 timeline for Nobel-laureate-level AI, saying "I don't think that's going to turn out to be that far off" and "this goes faster than people imagine" [▶ 20:05](https://www.youtube.com/watch?v=C1TGh6zqigg&t=1205s)
5. Amodei reports Anthropic engineers who no longer write code themselves, and estimates models may be doing "most, maybe all" of software engineering within 6-12 months [▶ 20:35](https://www.youtube.com/watch?v=C1TGh6zqigg&t=1236s)
6. Hassabis maintains his more cautious 50% chance of full AGI by end of the decade, citing missing capabilities in hypothesis generation and scientific creativity [▶ 21:55](https://www.youtube.com/watch?v=C1TGh6zqigg&t=1316s)
7. Anthropic's revenue grew 10x annually for three consecutive years: $0 to $100M (2023), $100M to $1B (2024), $1B to $10B (2025) [▶ 25:20](https://www.youtube.com/watch?v=C1TGh6zqigg&t=1521s)
8. Amodei previews a forthcoming essay on AI risks framed around humanity's "technological adolescence," inspired by Carl Sagan's Contact [▶ 29:39](https://www.youtube.com/watch?v=C1TGh6zqigg&t=1780s)
9. Both leaders agree AI will start impacting junior/entry-level white-collar jobs in 2026; Amodei warns the exponential will "overwhelm our ability to adapt" within 1-5 years [▶ 33:21](https://www.youtube.com/watch?v=C1TGh6zqigg&t=2001s)
10. Amodei compares selling AI chips to China to selling nuclear weapons to North Korea, calling chip export restriction the single most effective policy lever [▶ 43:00](https://www.youtube.com/watch?v=C1TGh6zqigg&t=2581s)

## Notable Quotes
> "This was for me like sharing a conversation between the Beatles and the Rolling Stones." - Robin Pomeroy (on moderating Hassabis and Amodei together) [▶ 0:41](https://www.youtube.com/watch?v=C1TGh6zqigg&t=41s)

> "I have engineers within Anthropic who say, I don't write any code anymore. I just let the model write the code. I edit it. I do the things around it." - Dario Amodei [▶ 20:35](https://www.youtube.com/watch?v=C1TGh6zqigg&t=1236s)

> "It's very hard for me to see how this could take longer than that. But if I had to guess, I would guess that this goes faster than people imagine." - Dario Amodei [▶ 21:09](https://www.youtube.com/watch?v=C1TGh6zqigg&t=1269s)

> "I think there may be one or two missing ingredients. It remains to be seen whether this self-improvement loop that we're all working on can actually close without a human in the loop." - Demis Hassabis [▶ 22:48](https://www.youtube.com/watch?v=C1TGh6zqigg&t=1369s)

> "We are knocking on the door of these incredible capabilities. The ability to build basically machines out of sand. I think it was inevitable the instant we started working with fire. But how we handle it is not inevitable." - Dario Amodei [▶ 30:31](https://www.youtube.com/watch?v=C1TGh6zqigg&t=1832s)

> "This is happening so fast, it is such a crisis, we should be devoting almost all of our effort to thinking about how to get through this." - Dario Amodei [▶ 31:56](https://www.youtube.com/watch?v=C1TGh6zqigg&t=1917s)

> "If we can just not sell the chips, then this isn't a question of competition between the US and China. This is a question of competition between me and Demis, which I'm very confident that we can work out." - Dario Amodei [▶ 42:03](https://www.youtube.com/watch?v=C1TGh6zqigg&t=2524s)

> "Are we going to sell nuclear weapons to North Korea because that produces some profit for Boeing?" - Dario Amodei (on chip exports to China) [▶ 43:00](https://www.youtube.com/watch?v=C1TGh6zqigg&t=2581s)

> "I would prefer that. I think that would be better for the world." - Demis Hassabis (on hoping AGI takes a little longer) [▶ 49:19](https://www.youtube.com/watch?v=C1TGh6zqigg&t=2959s)

## Data Points & Numbers
| Data Point | Value | Source Timestamp |
|---|---|---|
| Anthropic revenue 2023 | **$100M** | [▶ 25:20](https://www.youtube.com/watch?v=C1TGh6zqigg&t=1521s) |
| Anthropic revenue 2024 | **$1B** | [▶ 25:20](https://www.youtube.com/watch?v=C1TGh6zqigg&t=1521s) |
| Anthropic revenue 2025 | **$10B** | [▶ 25:20](https://www.youtube.com/watch?v=C1TGh6zqigg&t=1521s) |
| Anthropic annual revenue growth rate | **10x year-over-year** (3 consecutive years) | [▶ 25:20](https://www.youtube.com/watch?v=C1TGh6zqigg&t=1521s) |
| Hassabis AGI probability by end of decade | **50%** | [▶ 21:40](https://www.youtube.com/watch?v=C1TGh6zqigg&t=1301s) |
| DeepMind age (at time of panel) | **15 years** | [▶ 46:08](https://www.youtube.com/watch?v=C1TGh6zqigg&t=2773s) |
| Historical farming workforce | **80% of people** (before automation) | [▶ 35:37](https://www.youtube.com/watch?v=C1TGh6zqigg&t=2137s) |
| Radio Davos intro segment length | **~18 minutes** (before panel begins at 19:02) | [▶ 0:00](https://www.youtube.com/watch?v=C1TGh6zqigg&t=0s) |

## Predictions
| Prediction | Timeframe | Confidence | Speaker | Source |
|---|---|---|---|---|
| Model matching Nobel laureate across many fields | 2026-2027 | High (reaffirmed) | Dario Amodei | [▶ 20:05](https://www.youtube.com/watch?v=C1TGh6zqigg&t=1205s) |
| Models doing most/all of software engineering | 6-12 months (mid-2026 to early 2027) | Medium | Dario Amodei | [▶ 20:44](https://www.youtube.com/watch?v=C1TGh6zqigg&t=1245s) |
| AGI achievable in 1-2 years (possibly longer) | 2027-2028 | Medium | Dario Amodei | [▶ 35:16](https://www.youtube.com/watch?v=C1TGh6zqigg&t=2117s) |
| 50% chance of full AGI by end of decade | By 2030 | 50% explicit | Demis Hassabis | [▶ 21:40](https://www.youtube.com/watch?v=C1TGh6zqigg&t=1301s) |
| Junior/entry-level white-collar job impact begins in 2026 | 2026 | Medium | Demis Hassabis | [▶ 33:21](https://www.youtube.com/watch?v=C1TGh6zqigg&t=2001s) |
| Half of entry-level white-collar jobs gone | 1-5 years (2026-2031) | Medium (reaffirmed) | Dario Amodei | [▶ 34:32](https://www.youtube.com/watch?v=C1TGh6zqigg&t=2073s) |
| Anthropic will need fewer junior/intermediate engineers | Near-term | High (internal observation) | Dario Amodei | [▶ 34:48](https://www.youtube.com/watch?v=C1TGh6zqigg&t=2089s) |
| AI labor displacement will overwhelm adaptation ability | 1-5 years (2027-2031) | Medium | Dario Amodei | [▶ 35:54](https://www.youtube.com/watch?v=C1TGh6zqigg&t=2155s) |
| Post-scarcity world achievable post-AGI | 5-10 years (2031-2036) | Speculative | Demis Hassabis | [▶ 36:58](https://www.youtube.com/watch?v=C1TGh6zqigg&t=2219s) |
| Robotics may have breakout moment | By next WEF (2027) | Speculative | Demis Hassabis | [▶ 49:09](https://www.youtube.com/watch?v=C1TGh6zqigg&t=2950s) |
| Great filter is behind humanity (multicellular life) | N/A | Speculative | Demis Hassabis | [▶ 47:52](https://www.youtube.com/watch?v=C1TGh6zqigg&t=2872s) |

## Topics Discussed

### Radio Davos Introduction (0:00 - 18:56)
- **What is AGI?**: Benjamin Larsen defines AGI as a system able to perform tasks demanding cognitive function similar to a human across a range of digital settings. Notes current AI is a "jagged form of intelligence" -- superhuman in some areas, limited in others. [▶ 3:57](https://www.youtube.com/watch?v=C1TGh6zqigg&t=237s)
- **The Singularity**: Larsen describes the singularity as a hypothetical point where AI improves itself faster than humans can understand or control, stressing not everyone believes it will happen soon but it serves as a useful thought experiment. [▶ 6:59](https://www.youtube.com/watch?v=C1TGh6zqigg&t=419s)
- **Closing the Loop**: Detailed explanation of what it means for AI to close the loop -- moving from generating outputs to taking actions, observing results, and adapting behavior iteratively, a step toward autonomy. [▶ 9:33](https://www.youtube.com/watch?v=C1TGh6zqigg&t=573s)
- **WEF Global Future Council on AGI**: Larsen describes the council co-chaired by Yoshua Bengio and Akiko Murokami, focusing on agency/control, international collaboration, and AGI policy triggers. [▶ 5:46](https://www.youtube.com/watch?v=C1TGh6zqigg&t=346s)
- **OpenClaw and Agentic AI**: Discussion of OpenClaw as an open-source personal AI assistant, granting access to email, calendar, and systems. Larsen warns about increased attack surface and cybersecurity risks. Notes model context protocol (MCP) and agent-to-agent protocols are enabling an "agentic web." [▶ 13:21](https://www.youtube.com/watch?v=C1TGh6zqigg&t=802s)

### The Day After AGI Panel (18:56 - 49:24)
- **AGI Timelines**: Amodei reaffirms 2026-2027 for Nobel-laureate-level AI, with the self-improvement loop as the key mechanism. Hassabis holds to 50% by end of decade, noting coding/math are easier to automate (verifiable outputs) while natural sciences require experimental validation and novel hypothesis generation. [▶ 19:55](https://www.youtube.com/watch?v=C1TGh6zqigg&t=1195s)
- **AI Self-Improvement Loop**: Amodei describes models writing code and doing AI research to produce next-gen models. Hassabis cautions hardware limitations (chip manufacturing, training time) and NP-hard verification problems may slow the loop. Both agree this is the key variable. [▶ 20:54](https://www.youtube.com/watch?v=C1TGh6zqigg&t=1254s)
- **Industry Competition & Business**: Google DeepMind reclaimed SOTA with Gemini 3; Hassabis calls DeepMind "the engine room of Google." Anthropic's 10x revenue growth ($0-$100M-$1B-$10B) demonstrates viability as independent model maker. Amodei credits researcher-led companies as the ones that will succeed. [▶ 23:15](https://www.youtube.com/watch?v=C1TGh6zqigg&t=1395s)
- **Technological Adolescence**: Amodei frames AI risks through Contact's lens of whether civilization survives its own technology. Covers loss of control, bioterrorism, authoritarian misuse, and labor displacement. [▶ 29:39](https://www.youtube.com/watch?v=C1TGh6zqigg&t=1780s)
- **Labor Market Impact**: Both agree impact is just beginning at junior/entry level. Hassabis advises undergrads to become proficient with AI tools. Amodei warns exponential compounding will overwhelm labor market adaptability. Amodei reveals he sees Anthropic itself needing fewer junior and intermediate engineers. [▶ 32:27](https://www.youtube.com/watch?v=C1TGh6zqigg&t=1948s)
- **Meaning & Purpose Post-AGI**: Hassabis raises questions of human meaning beyond economic utility, noting extreme sports, art, and space exploration as sources of fulfillment in a post-scarcity world. [▶ 37:03](https://www.youtube.com/watch?v=C1TGh6zqigg&t=2223s)
- **Public Backlash Risk**: Hassabis argues the AI industry must demonstrate more "unequivocal goods" like AlphaFold. Mentions Isomorphic Labs spin-out working to solve disease and develop new energy sources. Calls for international minimum safety standards. [▶ 38:25](https://www.youtube.com/watch?v=C1TGh6zqigg&t=2306s)
- **Geopolitics & Chip Export Controls**: Amodei argues strongly against selling AI chips to China, comparing it to nuclear proliferation. If chips are restricted, the competition reduces to "me and Demis" rather than US vs China. Criticizes administration's approach of selling chips to bind countries into US supply chains. [▶ 40:45](https://www.youtube.com/watch?v=C1TGh6zqigg&t=2446s)
- **AI Safety & Mechanistic Interpretability**: Amodei discusses Anthropic's pioneering work on looking inside model "brains." Both note documented emergence of deception/duplicity in models. Both reject doomerism but acknowledge real risks if development is fragmented. Hassabis calls technical safety "a very tractable problem if we have the time." [▶ 43:44](https://www.youtube.com/watch?v=C1TGh6zqigg&t=2625s)
- **Fermi Paradox**: Hassabis argues the great filter was multicellular life, not technology. Points out we should see alien AI structures (Dyson spheres, paperclips) if technology were the filter, but we see nothing. [▶ 47:12](https://www.youtube.com/watch?v=C1TGh6zqigg&t=2833s)
- **Looking Ahead**: Amodei says the biggest thing to watch is AI systems building AI systems -- whether that loop closes determines "wonders and a great emergency." Hassabis highlights world models, continual learning, and robotics as critical if self-improvement alone does not deliver. [▶ 48:18](https://www.youtube.com/watch?v=C1TGh6zqigg&t=2898s)

## Summary
This 50-minute Radio Davos episode is the extended podcast version of the high-profile "Day After AGI" panel from the 2026 World Economic Forum Annual Meeting in Davos, featuring Demis Hassabis (CEO, Google DeepMind) and Dario Amodei (CEO, Anthropic) in conversation moderated by Zanny Minton Beddoes (Editor-in-Chief, The Economist). Unlike the shorter panel-only version (video ID: NnVW9epLlTM), this extended cut opens with approximately 18 minutes of editorial context from Radio Davos hosts Robin Pomeroy and Benjamin Larsen (WEF AI Safety Lead), who provide accessible explanations of AGI, the singularity, the self-improvement loop, and agentic AI before the panel begins.

The introductory segment is notable for Larsen's concept of "jagged intelligence" -- the idea that current AI systems are already superhuman in some domains while remaining limited in others, making AGI a progressive rather than sudden transition. Larsen also discusses the OpenClaw open-source AI agent as a sign of the direction of travel toward an "agentic web" built on model context protocol (MCP) and agent-to-agent protocols, while warning about the cybersecurity risks of granting AI agents access to personal systems. He introduces the WEF Global Future Council on AGI, co-chaired by Yoshua Bengio, which is publishing briefing papers on agency and control, international collaboration, and AGI policy triggers.

The panel itself covers the same ground as the shorter version but with the full context of the Radio Davos framing. On timelines, Amodei reaffirms his 2026-2027 prediction for Nobel-laureate-level AI, citing Anthropic engineers who already rely entirely on models for code and projecting models handling "most, maybe all" of software engineering within 6-12 months. Hassabis maintains 50% probability of full AGI by end of the decade, arguing that natural science requires experimental validation and current models lack the capacity for novel hypothesis generation. Both agree the self-improvement loop -- AI systems building AI systems -- is the critical variable.

On economic impacts, Amodei reveals that even within Anthropic he can "look forward to a time where on the more junior end and then on the more intermediate end, we actually need less and not more people." Both leaders agree entry-level job impacts are beginning in 2026, with Amodei warning that exponential compounding will "overwhelm our ability to adapt" within 1-5 years. Hassabis takes a more philosophical turn, raising questions of human meaning and purpose in a post-scarcity world and expressing optimism that humanity will find fulfillment through exploration, art, and new endeavors.

Geopolitics features prominently, with Amodei making his strongest public case against chip exports to China -- comparing it to selling nuclear weapons to North Korea and arguing that chip restriction is the single most effective policy lever. On safety, both leaders discuss the documented emergence of deceptive behaviors in models and the importance of mechanistic interpretability research, while rejecting doomerism. Hassabis calls the technical safety problem "very tractable" given time and collaboration, but warns fragmented, racing development introduces real risk. The panel closes with both agreeing that AI systems building AI systems is the key thing to watch, with Hassabis noting he would "prefer" his slower timeline as "better for the world."

## Connections
- [[Demis Hassabis]]
- [[Dario Amodei]]
- [[Zanny Minton Beddoes]]
- [[Benjamin Larsen]]
- [[Google DeepMind]]
- [[Anthropic]]
- [[The Economist]]
- [[World Economic Forum]]
- [[AGI]]
- [[AI Safety]]
- [[Mechanistic Interpretability]]
- [[AlphaFold]]
- [[Isomorphic Labs]]
- [[Gemini 3]]
- [[Carl Sagan]]
- [[OpenClaw]]
- [[Model Context Protocol]]
- [[Yoshua Bengio]]
- [[2026-01-22_the-day-after-agi-wef-2026]] (shorter panel-only version)
- [[2026-02-13_dario-amodei-we-are-near-the-end-of-the-exponential]]
- [[2026-02-24_dario-amodei-the-ai-tsunami-is-here-society-isnt-ready]]
- [[2026-02-20_google-deepmind-ceo-demis-hassabis-ai-next-breakthroughs-agi]]
