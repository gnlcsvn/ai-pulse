---
date: 2026-01-22
source: YouTube
video_id: NnVW9epLlTM
url: https://www.youtube.com/watch?v=NnVW9epLlTM
channel: World Economic Forum
title: "The Day After AGI | World Economic Forum Annual Meeting 2026"
guests: [Demis Hassabis, Dario Amodei]
topics: [AGI timeline, AI safety, labor displacement, geopolitics, AI self-improvement, chip export controls, mechanistic interpretability, Fermi paradox, post-scarcity]
duration: 32m
processed_date: 2026-02-25
predictions_count: 11
---

# The Day After AGI | World Economic Forum Annual Meeting 2026

## Guests
- **Demis Hassabis** - CEO, Google DeepMind
- **Dario Amodei** - CEO, Anthropic

## Key Takeaways
1. Dario Amodei reaffirms his 2026-2027 timeline for a model that can match a Nobel laureate across many fields, saying "I don't think that's going to turn out to be that far off" [▶ 1:27](https://www.youtube.com/watch?v=NnVW9epLlTM&t=87s)
2. Amodei reports Anthropic engineers who no longer write code themselves, and estimates models may be doing "most maybe all" of software engineering within 6-12 months [▶ 2:04](https://www.youtube.com/watch?v=NnVW9epLlTM&t=124s)
3. Hassabis maintains his more cautious timeline of 50% chance of full AGI by end of the decade, citing missing capabilities in scientific creativity and hypothesis generation [▶ 3:17](https://www.youtube.com/watch?v=NnVW9epLlTM&t=197s)
4. Anthropic's revenue grew 10x annually for three consecutive years: zero to $100M (2023), $100M to $1B (2024), $1B to $10B (2025) [▶ 6:44](https://www.youtube.com/watch?v=NnVW9epLlTM&t=404s)
5. Amodei previews a forthcoming essay on AI risks framed around humanity's "technological adolescence," inspired by Carl Sagan's Contact [▶ 11:10](https://www.youtube.com/watch?v=NnVW9epLlTM&t=670s)
6. Both leaders agree AI will start impacting junior-level and entry-level white-collar jobs in 2026, with Hassabis saying he already senses a hiring slowdown at that level [▶ 14:48](https://www.youtube.com/watch?v=NnVW9epLlTM&t=888s)
7. Amodei warns that AI's exponential compounding will "overwhelm our ability to adapt" within 1-5 years [▶ 17:26](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1046s)
8. Hassabis argues governments and economists are not doing "anywhere near enough work" on policy responses to AI-driven disruption [▶ 17:50](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1070s)
9. Amodei compares selling AI chips to China to selling nuclear weapons to North Korea, calling current US chip export policy misguided [▶ 24:22](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1462s)
10. Hassabis believes the Fermi Paradox great filter was multicellular life, not technology, meaning humanity is "past the great filter" [▶ 29:22](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1762s)

## Notable Quotes
> "I have engineers within Anthropic who say I don't write any code anymore. I just let the model write the code, I edit it, I do the things around it." - Dario Amodei [▶ 1:58](https://www.youtube.com/watch?v=NnVW9epLlTM&t=118s)

> "It's very hard for me to see how this could take longer than that. But if I had to guess, I would guess that this goes faster than people imagine." - Dario Amodei [▶ 2:35](https://www.youtube.com/watch?v=NnVW9epLlTM&t=155s)

> "I think there may be one or two missing ingredients. It remains to be seen whether this self-improvement loop that we're all working on can actually close without a human in the loop." - Demis Hassabis [▶ 4:11](https://www.youtube.com/watch?v=NnVW9epLlTM&t=251s)

> "Our revenue has grown 10x in the last three years. From zero to a hundred million in 2023, 100 million to a billion in 2024, and 1 billion to 10 billion in 2025." - Dario Amodei [▶ 6:44](https://www.youtube.com/watch?v=NnVW9epLlTM&t=404s)

> "We are knocking on the door of these incredible capabilities. The ability to build basically machines out of sand. I think it was inevitable the instant we started working with fire. But how we handle it is not inevitable." - Dario Amodei [▶ 11:57](https://www.youtube.com/watch?v=NnVW9epLlTM&t=717s)

> "This is happening so fast, it is such a crisis, we should be devoting almost all of our effort to thinking about how to get through this." - Dario Amodei [▶ 13:22](https://www.youtube.com/watch?v=NnVW9epLlTM&t=802s)

> "I think maybe the balance of what the industry is doing is not enough balance towards those types of activities. I think we should have a lot more examples of AlphaFold-like things that are unequivocal goods in the world." - Demis Hassabis [▶ 20:12](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1212s)

> "If we can just not sell the chips, then this isn't a question of competition between the US and China. This is a question of competition between me and Demis, which I'm very confident that we can work out." - Dario Amodei [▶ 23:31](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1411s)

> "I think of this more as like, are we going to sell nuclear weapons to North Korea because that produces some profit for Boeing?" - Dario Amodei [▶ 24:22](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1462s)

> "I'm sure if we had that, we would solve the technical risk problem. It may be we don't have that and then that will introduce risk because it'll be fragmented." - Demis Hassabis [▶ 28:01](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1681s)

> "I would prefer that. I think that would be better for the world." - Demis Hassabis (on hoping AGI takes a little longer) [▶ 30:46](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1846s)

## Data Points & Numbers
| Data Point | Value | Source Timestamp |
|---|---|---|
| Anthropic revenue 2023 | **$100M** | [▶ 6:44](https://www.youtube.com/watch?v=NnVW9epLlTM&t=404s) |
| Anthropic revenue 2024 | **$1B** | [▶ 6:51](https://www.youtube.com/watch?v=NnVW9epLlTM&t=411s) |
| Anthropic revenue 2025 | **$10B** | [▶ 6:51](https://www.youtube.com/watch?v=NnVW9epLlTM&t=411s) |
| Anthropic annual revenue growth rate | **10x year-over-year** (3 consecutive years) | [▶ 6:44](https://www.youtube.com/watch?v=NnVW9epLlTM&t=404s) |
| Hassabis AGI probability by end of decade | **50%** | [▶ 2:59](https://www.youtube.com/watch?v=NnVW9epLlTM&t=179s) |
| DeepMind age (at time of panel) | **15 years** | [▶ 27:37](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1657s) |
| Historical farming workforce | **80% of people** (before automation) | [▶ 17:10](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1030s) |

## Predictions
| Prediction | Timeframe | Confidence | Speaker | Source |
|---|---|---|---|---|
| Model matching Nobel laureate across many fields | 2026-2027 | High (reaffirmed) | Dario Amodei | [▶ 1:27](https://www.youtube.com/watch?v=NnVW9epLlTM&t=87s) |
| Models doing most/all of software engineering | 6-12 months (mid-2026 to early 2027) | Medium | Dario Amodei | [▶ 2:04](https://www.youtube.com/watch?v=NnVW9epLlTM&t=124s) |
| AGI achievable in 1-2 years (possibly longer) | 2027-2028 | Medium | Dario Amodei | [▶ 16:52](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1012s) |
| 50% chance of full AGI by end of decade | By 2030 | 50% explicit | Demis Hassabis | [▶ 2:59](https://www.youtube.com/watch?v=NnVW9epLlTM&t=179s) |
| Junior/entry-level white-collar job impact begins in 2026 | 2026 | Medium | Demis Hassabis | [▶ 14:48](https://www.youtube.com/watch?v=NnVW9epLlTM&t=888s) |
| Half of entry-level white-collar jobs gone | 1-5 years (2026-2031) | Medium (reaffirmed) | Dario Amodei | [▶ 16:41](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1001s) |
| AI labor displacement will overwhelm adaptation ability | 1-5 years (2027-2031) | Medium | Dario Amodei | [▶ 17:26](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1046s) |
| Post-scarcity world achievable post-AGI | 5-10 years (2031-2036) | Speculative | Demis Hassabis | [▶ 18:58](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1138s) |
| AGI with Hassabis timeline (preferred by both) | 5-10 years | Medium | Demis Hassabis | [▶ 19:19](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1159s) |
| Robotics may have breakout moment | By next WEF (2027) | Speculative | Demis Hassabis | [▶ 30:36](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1836s) |
| Great filter is behind humanity (multicellular life) | N/A | Speculative | Demis Hassabis | [▶ 29:22](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1762s) |

## Topics Discussed
- **AGI Timelines**: Amodei maintains a 2026-2027 timeline for Nobel-laureate-level AI, while Hassabis holds to 50% by end of decade. Both agree the self-improvement loop is the key variable. [▶ 1:10](https://www.youtube.com/watch?v=NnVW9epLlTM&t=70s)
- **AI Self-Improvement Loop**: Amodei describes the mechanism of models writing code and doing AI research to produce next-gen models. Hassabis cautions that hardware limitations and verification challenges may prevent full loop closure. [▶ 1:33](https://www.youtube.com/watch?v=NnVW9epLlTM&t=93s)
- **Missing Capabilities for AGI**: Hassabis identifies hypothesis generation and scientific creativity as capabilities current models lack, distinguishing them from more easily automated domains like coding and mathematics. [▶ 3:51](https://www.youtube.com/watch?v=NnVW9epLlTM&t=231s)
- **Industry Competition**: Discussion of Google DeepMind regaining SOTA leadership with Gemini 3 and Anthropic's 10x annual revenue growth demonstrating viability as an independent model maker. [▶ 4:31](https://www.youtube.com/watch?v=NnVW9epLlTM&t=271s)
- **AI Risks - Technological Adolescence**: Amodei frames AI risks through Contact's lens of whether civilization can survive its own technology, covering loss of control, bioterrorism, authoritarian misuse, and labor displacement. [▶ 11:10](https://www.youtube.com/watch?v=NnVW9epLlTM&t=670s)
- **Labor Market Impact**: Both agree impact is just beginning at the junior/entry level. Hassabis advises undergrads to get proficient with AI tools. Amodei warns the exponential will eventually overwhelm labor market adaptability. [▶ 13:52](https://www.youtube.com/watch?v=NnVW9epLlTM&t=832s)
- **Meaning & Purpose Post-AGI**: Hassabis raises the deeper question of human meaning and purpose beyond economic utility, suggesting extreme sports, art, and space exploration as sources of fulfillment. [▶ 18:31](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1111s)
- **Public Backlash Risk**: Hassabis argues the AI industry must demonstrate more "unequivocal goods" like AlphaFold to counter growing public antipathy, and calls for international minimum safety standards. [▶ 19:43](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1183s)
- **Geopolitics & Chip Export Controls**: Amodei argues strongly against selling AI chips to China, comparing it to nuclear proliferation. He contends chip restrictions are the single most effective policy lever for buying time on AI safety. [▶ 22:09](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1329s)
- **AI Safety & Mechanistic Interpretability**: Amodei discusses Anthropic's work on understanding model internals to address deceptive behavior. Both reject doomerism but acknowledge real risks if development is fragmented and safety is not prioritized. [▶ 25:32](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1532s)
- **Fermi Paradox**: Hassabis argues the great filter was likely multicellular life, not technological self-destruction, and that the absence of alien AI structures (Dyson spheres, paperclips) suggests technology is not inherently civilization-ending. [▶ 28:48](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1728s)
- **Future Research Directions**: Hassabis highlights world models, continual learning, and robotics as critical areas to crack if self-improvement alone does not deliver full AGI. [▶ 30:27](https://www.youtube.com/watch?v=NnVW9epLlTM&t=1827s)

## Summary
At the 2026 World Economic Forum Annual Meeting in Davos, Demis Hassabis (CEO, Google DeepMind) and Dario Amodei (CEO, Anthropic) engaged in a wide-ranging panel discussion titled "The Day After AGI." The conversation, moderated as a sequel to their 2025 Paris appearance, centered on AGI timelines, the self-improvement loop, labor market impacts, geopolitical risks, and AI safety.

On timelines, the two leaders maintained their divergent but narrowing positions. Amodei reaffirmed his prediction that a model performing at Nobel-laureate level across many fields could arrive by 2026-2027, citing Anthropic engineers who already rely entirely on models for code writing and projecting that models could handle most or all software engineering within 6-12 months. Hassabis held to his 50% probability of full AGI by end of the decade, noting that while coding and mathematics are easier to automate due to verifiability, natural sciences require experimental validation, and current models lack the ability to generate novel hypotheses -- the "highest level of scientific creativity." Both agreed the self-improvement loop (AI systems building AI systems) is the critical variable, with Amodei noting hardware constraints like chip manufacturing and training time as factors that could slow the loop.

The discussion turned to the business of AI, with Amodei revealing Anthropic's extraordinary revenue trajectory: zero to $100M in 2023, $1B in 2024, and $10B in 2025 -- a 10x annual growth rate over three consecutive years. Hassabis highlighted Google DeepMind's return to the top of leaderboards with Gemini 3 and growing product market share, describing the organization as "the engine room of Google."

On the economic and social consequences, both leaders agreed the labor market impact is just beginning to materialize at entry-level white-collar positions, with Hassabis sensing a hiring slowdown and Amodei predicting half of entry-level white-collar jobs could be gone within 1-5 years. They diverged on the severity: Hassabis suggested that in the near term, new and more meaningful jobs would be created (advising undergrads to become proficient with AI tools), while Amodei warned that the exponential compounding of AI capabilities would eventually "overwhelm our ability to adapt." Hassabis raised deeper questions about meaning, purpose, and the human condition in a post-scarcity world, expressing optimism that humanity would find new sources of fulfillment.

Geopolitics featured prominently, with Amodei making his strongest public statement on chip exports to China, comparing it to selling nuclear weapons to North Korea and arguing that not selling chips is "one of the biggest things we can do" to buy time for safety work. Both called for international minimum safety standards, with Hassabis expressing a wish for a slower pace of development to get the societal response right. On AI safety, Amodei discussed Anthropic's mechanistic interpretability research and the documented emergence of deceptive behaviors in models, while rejecting doomerism. Hassabis argued the technical safety problem is "very tractable" given sufficient time and collaboration, but warned that a fragmented, racing approach introduces real risk.

## Connections
- [[Demis Hassabis]]
- [[Dario Amodei]]
- [[Google DeepMind]]
- [[Anthropic]]
- [[AGI]]
- [[AI Safety]]
- [[Mechanistic Interpretability]]
- [[AlphaFold]]
- [[Gemini 3]]
- [[2026-02-13_dario-amodei-we-are-near-the-end-of-the-exponential]]
- [[2026-02-24_dario-amodei-the-ai-tsunami-is-here-society-isnt-ready]]
