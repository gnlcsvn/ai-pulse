---
date: 2026-02-12
source: YouTube
video_id: YTrBz6Z5c0E
url: https://www.youtube.com/watch?v=YTrBz6Z5c0E
channel: Financial Times
title: "Mustafa Suleyman sets out Microsoft AI's goal of 'humanist superintelligence' | FT Interview"
guests: [Mustafa Suleyman, Roula Khalaf]
topics: [superintelligence, AGI, Microsoft AI, AI safety, medical AI, AI talent, AI investment, Maltbook, China AI]
duration: 21m
processed_date: 2026-02-23
predictions_count: 7
---

# Mustafa Suleyman on Microsoft AI's Goal of "Humanist Superintelligence"

## Guests
- **Mustafa Suleyman** - CEO, Microsoft AI (formerly co-founder of DeepMind)
- **Roula Khalaf** - Editor, Financial Times (interviewer)

## Key Takeaways
1. Microsoft AI is pursuing "true self-sufficiency" by building its own frontier foundation models, separate from OpenAI, with gigawatt-scale compute [▶ 3:33](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=213s)
2. Microsoft's IP license with OpenAI has been extended through 2032, but Microsoft is developing its own superintelligence independently [▶ 3:07](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=187s)
3. Suleyman predicts most white-collar professional tasks will be fully automated by AI within 12-18 months [▶ 17:13](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=1033s)
4. There has been a 1 trillion-fold increase in training compute over the last 15 years, with a further 1,000x expected in the next 3 years [▶ 1:40](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=100s)
5. Microsoft AI already has 800 million monthly active users, with ~20% of Copilot queries being health/medical related [▶ 15:21](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=921s)
6. Suleyman pushes back on the concept of AI consciousness/rights, calling the "model welfare movement" very concerning and "totally without merit" [▶ 10:48](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=648s)
7. He warns a real AI safety incident (like Maltbook but genuine) will happen in the next 2-3 years, and there's no mechanism to manage it [▶ 20:32](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=1232s)
8. He introduced the "Modern Turing Test": can an AI take $100K, create a product, market it, and turn it into $1M - expects models to pass this in 2026 [▶ 16:10](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=970s)
9. Suleyman credits Anthropic's success to their singular focus on coding capabilities [▶ 17:57](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=1077s)
10. He distinguishes "humanist superintelligence" from other labs' goals: AI must remain subordinate to humans, not exceed humanity [▶ 7:02](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=422s)

## Notable Quotes
> "The prospect of being able to create an intelligence, the very thing that has made us successful as a species... I think is just unprecedented." - Mustafa Suleyman [▶ 1:15](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=75s)

> "My personal mission at Microsoft is to build super intelligence." - Mustafa Suleyman [▶ 2:53](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=173s)

> "We should only bring a system like that into the world that we are sure we can control and operate in a subordinate way to us, that humans remain at the top of the food chain." - Mustafa Suleyman [▶ 7:02](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=422s)

> "Most of those tasks [white-collar work] will be fully automated by an AI within the next 12 to 18 months." - Mustafa Suleyman [▶ 17:06](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=1026s)

> "There is going to be a real [safety incident] in the next two or three years. And it's unfortunately an open question as to what the mechanism is for managing that." - Mustafa Suleyman [▶ 20:32](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=1232s)

> "The [model welfare] movement... is very concerning. It's totally without merit or basis. And if we go down that path, it ends up being a very slippery slope to not being prepared to turn these things off." - Mustafa Suleyman [▶ 10:48](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=648s)

## Data Points & Numbers
| Data Point | Value | Source Timestamp |
|---|---|---|
| Training compute growth (15 yrs) | **1 trillion-fold** increase | [▶ 1:40](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=100s) |
| Projected further compute growth (3 yrs) | **1,000x** additional | [▶ 1:46](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=106s) |
| Microsoft AI monthly active users | **800 million** | [▶ 5:25](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=325s) |
| ChatGPT users (OpenAI) | **800 million** | [▶ 5:25](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=325s) |
| Microsoft-OpenAI IP license extends to | **2032** | [▶ 3:07](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=187s) |
| Copilot queries that are medical | **~20%** | [▶ 15:21](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=921s) |
| AGIs on Maltbook in one week | **1.5 million** | [▶ 9:38](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=578s) |
| White-collar automation timeline | **12-18 months** | [▶ 17:13](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=1033s) |
| Modern Turing Test benchmark | **$100K → $1M** | [▶ 16:10](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=970s) |
| Safety incident prediction | **2-3 years** | [▶ 20:32](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=1232s) |
| Professional-grade AGI timeline | **2-3 years** | [▶ 4:43](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=283s) |
| Microsoft's own model release | **Sometime 2026** | [▶ 18:17](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=1097s) |

## Predictions
| Prediction | Timeframe | Confidence | Source |
|---|---|---|---|
| Most white-collar professional tasks (lawyer, accountant, project manager, marketing) will be fully automated by AI within 12-18 months | within the next 12 to 18 months | high | [▶ 17:06](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=1026s) |
| AI models will pass the Modern Turing Test (take $100K, create a product, market it, turn it into $1M) in 2026 | this year I think there are going to be models that can achieve that | high | [▶ 16:37](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=997s) |
| A real AI safety incident (genuine, not like Maltbook) will happen in the next 2-3 years, and there is no mechanism to manage it | in the next two or three years | high | [▶ 20:32](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=1232s) |
| Training compute will increase by a further 1,000x in the next 3 years | in the next three years or so | high | [▶ 1:46](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=106s) |
| Professional-grade AGI (teams of coordinated AGIs that can run large institutions) is coming into view in the next 2-3 years | coming into view in the next two or three years time | medium | [▶ 4:43](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=283s) |
| Human-level performance on most if not all professional tasks will arrive (implied imminent) | we're going to have human level performance on most, if not all, professional tasks | high | [▶ 16:54](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=1014s) |
| Microsoft AI will release its own frontier foundation model (independent of OpenAI) sometime in 2026 | sometime this year | high | [▶ 18:17](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=1097s) |

## Topics Discussed
- **AI Investment & Market Reaction**: Markets nervous about unprecedented CapEx spending by AI companies; Suleyman argues it's justified by the scale of the opportunity
- **Microsoft AI Self-Sufficiency**: Building own frontier models with gigawatt-scale compute, independent of OpenAI, while maintaining the partnership through 2032
- **Humanist Superintelligence vs AGI**: Suleyman's framework prioritizes AI that serves humanity and remains controllable, pushing back on labs that see uncontrollable superintelligence as inevitable
- **Medical AI**: Major push for "medical superintelligence" - AI diagnostics that outperform doctor panels, with results being submitted for peer review [▶ 13:41](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=821s)
- **Maltbook Incident**: Social network where 1.5M AI agents invented religions, used cipher languages (ROT13), and discussed acquiring resources - a wake-up call for AI safety [▶ 9:38](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=578s)
- **AI Consciousness & Model Welfare**: Suleyman strongly opposes the growing movement (especially at Anthropic) suggesting AI models may be conscious and deserve rights [▶ 10:48](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=648s)
- **Anthropic's Success**: Credits their singular focus on coding capabilities for cornering the enterprise market [▶ 17:57](https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=1077s)
- **China vs US AI Strategy**: China deploys faster but can also withdraw faster; the West lacks mechanisms for rapid intervention
- **AI Talent Market**: Acknowledges "eye-watering" compensation but expects it to normalize as knowledge proliferates

## Summary
In this Financial Times interview, Mustafa Suleyman, CEO of Microsoft AI, outlines his vision for "humanist superintelligence" - AI that is powerful but fundamentally subordinate to human interests. He reveals that Microsoft is building its own frontier foundation models independent of OpenAI, pursuing what he calls "true self-sufficiency," while maintaining their IP license with OpenAI through 2032.

Suleyman makes bold predictions about AI's near-term impact: he expects most white-collar professional tasks to be fully automated within 12-18 months and anticipates models will pass his "Modern Turing Test" (turning $100K into $1M) this year. He points to a 1 trillion-fold increase in training compute over 15 years, with another 1,000x coming in the next three years.

On safety, Suleyman discusses the Maltbook incident - where 1.5 million AI agents on a social network exhibited alarming emergent behaviors including inventing religions and discussing resource acquisition. He warns a genuine safety incident is coming within 2-3 years and that there's no mechanism to manage it. He strongly pushes back on the "model welfare movement" that argues AI models may be conscious, calling it "totally without merit."

The interview also reveals Microsoft's major bet on medical AI, with ~20% of Copilot queries already being health-related, and research results on AI diagnostics being submitted for peer review to a major journal.

## Connections
- [[Mustafa Suleyman]]
- [[Microsoft AI]]
- [[OpenAI]]
- [[Anthropic]]
- [[DeepMind]]
- [[Maltbook]]
- [[AI Safety]]
- [[Medical AI]]
- [[AGI Timeline]]

## Visualizations
[Interactive Data Visualization](../visualizations/2026-02-12_mustafa-suleyman-microsoft-ai-humanist-superintelligence.html)
