<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dead or Alive — What AI Builders Say About Existential Risk</title>

    <!-- Open Graph / Twitter Card meta tags -->
    <meta property="og:title" content="Dead or Alive: The People Building AI Warn It Could Destroy Humanity" />
    <meta property="og:description" content="283 verbatim quotes from the people building frontier AI. Every one linked to the exact YouTube timestamp." />
    <meta property="og:type" content="website" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Dead or Alive: The People Building AI Warn It Could Destroy Humanity" />
    <meta name="twitter:description" content="283 verbatim quotes from the people building frontier AI. Every one linked to the exact YouTube timestamp." />

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,300;0,400;0,500;0,600;0,700;1,400&family=Libre+Baskerville:ital,wght@0,400;0,700;1,400&display=swap" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/d3@7.9.0/dist/d3.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/html2canvas@1.4.1/dist/html2canvas.min.js"></script>
    <style>
        :root {
            --color-bg: #0a0a0c;
            --color-surface: #141418;
            --color-surface-alt: #18181e;
            --color-border: #2a2a32;
            --color-border-strong: #3a3a44;
            --color-text: #f0f0f2;
            --color-text-secondary: #a0a0a8;
            --color-text-muted: #6a6a74;
            --color-accent: #e8845c;
            --color-accent-light: rgba(232, 132, 92, 0.1);

            --risk-alarm: #ff4444;
            --risk-concern: #ff8a65;
            --risk-neutral: #8a8a94;
            --risk-optimism: #66bb6a;
            --risk-dismissal: #4caf50;

            --font-heading: 'Libre Baskerville', Georgia, serif;
            --font-mono: 'JetBrains Mono', 'SFMono-Regular', Consolas, monospace;
            --font-body: 'JetBrains Mono', monospace;
        }

        * { margin: 0; padding: 0; box-sizing: border-box; }

        html { scroll-behavior: smooth; }

        body {
            font-family: var(--font-body);
            font-size: 0.85rem;
            font-weight: 400;
            background: var(--color-bg);
            color: var(--color-text);
            -webkit-font-smoothing: antialiased;
            -moz-osx-font-smoothing: grayscale;
            overflow-x: hidden;
        }

        ::selection { background: rgba(232, 132, 92, 0.3); }

        /* ═══════════════════════════════════
           SECTION 1: HERO
           ═══════════════════════════════════ */
        .hero {
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            text-align: center;
            padding: 2rem;
            position: relative;
            overflow: hidden;
        }
        .hero::before {
            content: '';
            position: absolute;
            top: 30%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 800px;
            height: 800px;
            background: radial-gradient(circle, rgba(255, 68, 68, 0.06) 0%, transparent 70%);
            pointer-events: none;
        }
        .hero h1 {
            font-family: var(--font-heading);
            font-size: clamp(3rem, 8vw, 7rem);
            font-weight: 700;
            color: var(--color-text);
            letter-spacing: 0.08em;
            text-transform: uppercase;
            line-height: 1.05;
            margin-bottom: 1.2rem;
        }
        .hero .subtitle {
            font-family: var(--font-heading);
            font-size: clamp(0.9rem, 2vw, 1.2rem);
            font-weight: 400;
            font-style: italic;
            color: var(--color-text-secondary);
            max-width: 600px;
            line-height: 1.6;
            margin-bottom: 2.5rem;
        }
        .hero-stat {
            font-family: var(--font-heading);
            font-size: clamp(1rem, 2.5vw, 1.4rem);
            color: var(--color-text);
            line-height: 1.6;
            margin-bottom: 1rem;
            max-width: 700px;
        }
        .hero-stat strong {
            color: var(--risk-alarm);
            font-weight: 700;
        }
        .hero-credibility {
            font-size: 0.72rem;
            color: var(--color-text-muted);
            font-weight: 300;
            margin-bottom: 3rem;
        }
        .hero-cta {
            display: inline-block;
            font-family: var(--font-body);
            font-size: 0.75rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.12em;
            color: var(--color-text);
            border: 1px solid var(--color-text-muted);
            padding: 0.8rem 2rem;
            text-decoration: none;
            transition: all 0.2s;
            cursor: pointer;
            background: transparent;
        }
        .hero-cta:hover {
            border-color: var(--risk-alarm);
            color: var(--risk-alarm);
            box-shadow: 0 0 20px rgba(255, 68, 68, 0.15);
        }

        /* Hero Gauge Card */
        .hero-viz-wrapper {
            width: 100%;
            max-width: 480px;
            margin: 0 auto 2.5rem;
        }
        .hero-viz-card {
            background: var(--color-surface);
            border: 1px solid var(--color-border);
            padding: 2rem 2rem 1.2rem;
            position: relative;
            text-align: center;
        }
        @media (max-width: 700px) {
            .hero-viz-card { padding: 1.5rem 1rem 1rem; }
        }

        .gauge-container {
            position: relative;
            width: 100%;
            max-width: 380px;
            margin: 0 auto;
        }
        .gauge-container svg {
            width: 100%;
            height: auto;
            display: block;
            overflow: visible;
        }

        .gauge-sublabel {
            font-family: var(--font-body);
            font-size: 0.62rem;
            color: var(--color-text-muted);
            margin-top: 0.4rem;
            line-height: 1.5;
        }

        .viz-card-footer {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-top: 1rem;
            padding-top: 0.8rem;
            border-top: 1px solid var(--color-border);
        }
        .viz-card-source {
            font-size: 0.55rem;
            color: var(--color-text-muted);
            text-transform: uppercase;
            letter-spacing: 0.08em;
        }
        .viz-share-actions {
            display: flex;
            gap: 0.5rem;
        }

        /* ═══════════════════════════════════
           SECTION 2: FEATURED QUOTES
           ═══════════════════════════════════ */
        .featured-section {
            padding: 4rem 2rem;
            max-width: 1300px;
            margin: 0 auto;
        }
        .section-label {
            font-family: var(--font-body);
            font-size: 0.65rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.15em;
            color: var(--color-text-muted);
            margin-bottom: 0.5rem;
        }
        .section-title {
            font-family: var(--font-heading);
            font-size: 1.5rem;
            font-weight: 400;
            color: var(--color-text);
            margin-bottom: 2rem;
        }
        .featured-grid {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 1.5rem;
        }
        @media (max-width: 900px) { .featured-grid { grid-template-columns: 1fr; } }

        /* Quote card (used in featured + feed) */
        .quote-card {
            background: var(--color-surface);
            border: 1px solid var(--color-border);
            padding: 2rem;
            position: relative;
            overflow: hidden;
            display: flex;
            flex-direction: column;
            transition: transform 0.2s, box-shadow 0.2s;
        }
        .quote-card:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 32px rgba(0,0,0,0.3);
        }
        .quote-card::before {
            content: '';
            position: absolute;
            top: 0; left: 0; right: 0;
            height: 3px;
        }
        .quote-card.sentiment-alarm::before { background: var(--risk-alarm); box-shadow: 0 0 12px rgba(255, 68, 68, 0.3); }
        .quote-card.sentiment-concern::before { background: var(--risk-concern); box-shadow: 0 0 12px rgba(255, 138, 101, 0.2); }
        .quote-card.sentiment-cautious_optimism::before { background: var(--risk-neutral); }
        .quote-card.sentiment-optimism::before { background: var(--risk-optimism); box-shadow: 0 0 12px rgba(102, 187, 106, 0.2); }
        .quote-card.sentiment-dismissal::before { background: var(--risk-dismissal); box-shadow: 0 0 12px rgba(76, 175, 80, 0.2); }

        .featured-grid .quote-card {
            aspect-ratio: 1200 / 630;
        }
        @media (max-width: 900px) { .featured-grid .quote-card { aspect-ratio: auto; } }

        .quote-card .decorative-quote {
            font-family: var(--font-heading);
            font-size: 4rem;
            line-height: 1;
            color: var(--color-border-strong);
            position: absolute;
            top: 1rem;
            left: 1.5rem;
            pointer-events: none;
            user-select: none;
        }

        .quote-card-body {
            flex: 1;
            display: flex;
            flex-direction: column;
            justify-content: center;
            padding-top: 1.5rem;
        }

        .quote-card-text {
            font-family: var(--font-heading);
            font-style: italic;
            font-size: clamp(0.9rem, 1.3vw, 1.15rem);
            color: var(--color-text);
            line-height: 1.6;
            margin-bottom: 1.2rem;
        }

        .quote-card-attribution {
            font-size: 0.8rem;
            font-weight: 600;
            color: var(--color-text);
            margin-bottom: 0.15rem;
        }
        .quote-card-role {
            font-size: 0.68rem;
            color: var(--color-text-muted);
            margin-bottom: 0.8rem;
        }

        .quote-card-footer {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-top: auto;
            padding-top: 0.8rem;
            border-top: 1px solid var(--color-border);
        }
        .quote-card-footer a {
            color: var(--color-accent);
            text-decoration: none;
            font-size: 0.7rem;
            font-weight: 500;
        }
        .quote-card-footer a:hover { text-decoration: underline; }

        .card-actions {
            display: flex;
            gap: 0.5rem;
        }
        .action-btn {
            background: transparent;
            border: 1px solid var(--color-border);
            color: var(--color-text-muted);
            padding: 0.3rem 0.6rem;
            cursor: pointer;
            font-family: var(--font-body);
            font-size: 0.65rem;
            transition: all 0.15s;
            display: flex;
            align-items: center;
            gap: 0.3rem;
        }
        .action-btn:hover {
            border-color: var(--color-accent);
            color: var(--color-accent);
        }
        .action-btn.copied {
            border-color: var(--risk-optimism);
            color: var(--risk-optimism);
        }
        .action-btn svg {
            width: 14px;
            height: 14px;
            fill: currentColor;
        }

        /* ═══════════════════════════════════
           SECTION 3: SPEAKER LINEUP
           ═══════════════════════════════════ */
        .speakers-section {
            padding: 3rem 2rem;
            max-width: 1300px;
            margin: 0 auto;
        }
        .speaker-scroller {
            display: flex;
            gap: 0.75rem;
            overflow-x: auto;
            scroll-snap-type: x mandatory;
            padding-bottom: 1rem;
            -ms-overflow-style: none;
            scrollbar-width: thin;
            scrollbar-color: var(--color-border) transparent;
        }
        .speaker-scroller::-webkit-scrollbar { height: 4px; }
        .speaker-scroller::-webkit-scrollbar-track { background: transparent; }
        .speaker-scroller::-webkit-scrollbar-thumb { background: var(--color-border); border-radius: 2px; }

        .speaker-chip {
            scroll-snap-align: start;
            flex-shrink: 0;
            background: var(--color-surface);
            border: 1px solid var(--color-border);
            padding: 0.8rem 1.2rem;
            cursor: pointer;
            transition: all 0.15s;
            min-width: 180px;
        }
        .speaker-chip:hover {
            border-color: var(--color-accent);
        }
        .speaker-chip.active {
            border-color: var(--color-accent);
            background: var(--color-accent-light);
        }
        .speaker-chip-name {
            font-size: 0.78rem;
            font-weight: 600;
            color: var(--color-text);
            margin-bottom: 0.2rem;
        }
        .speaker-chip-meta {
            font-size: 0.65rem;
            color: var(--color-text-muted);
        }
        .speaker-chip-score {
            font-weight: 600;
            font-size: 0.68rem;
        }

        /* ═══════════════════════════════════
           SECTION 4: FULL QUOTE FEED
           ═══════════════════════════════════ */
        .feed-section {
            padding: 3rem 2rem;
            max-width: 800px;
            margin: 0 auto;
        }

        .filter-bar {
            position: sticky;
            top: 0;
            z-index: 50;
            background: rgba(10, 10, 12, 0.85);
            backdrop-filter: blur(12px);
            -webkit-backdrop-filter: blur(12px);
            padding: 1rem 0;
            margin-bottom: 1.5rem;
            display: flex;
            gap: 0.4rem;
            flex-wrap: wrap;
            align-items: center;
            border-bottom: 1px solid var(--color-border);
        }
        .filter-bar label {
            font-size: 0.65rem;
            color: var(--color-text-muted);
            margin-right: 0.25rem;
            text-transform: uppercase;
            letter-spacing: 0.08em;
            font-weight: 600;
        }
        .filter-btn {
            background: transparent;
            border: 1px solid var(--color-border);
            color: var(--color-text-secondary);
            padding: 0.3rem 0.7rem;
            cursor: pointer;
            font-family: var(--font-body);
            font-size: 0.68rem;
            transition: all 0.15s;
            font-weight: 400;
        }
        .filter-btn:hover {
            border-color: var(--color-accent);
            color: var(--color-accent);
        }
        .filter-btn.active {
            background: var(--color-text);
            color: var(--color-bg);
            border-color: var(--color-text);
            font-weight: 500;
        }
        .filter-separator {
            width: 1px;
            height: 20px;
            background: var(--color-border);
            margin: 0 0.5rem;
        }
        .sort-select {
            background: var(--color-surface);
            border: 1px solid var(--color-border);
            color: var(--color-text-secondary);
            padding: 0.3rem 0.5rem;
            font-family: var(--font-body);
            font-size: 0.68rem;
            cursor: pointer;
            margin-left: auto;
        }

        .feed-list {
            display: flex;
            flex-direction: column;
            gap: 1.2rem;
        }

        .feed-list .quote-card {
            opacity: 0;
            transform: translateY(20px);
            transition: opacity 0.4s ease, transform 0.4s ease, box-shadow 0.2s;
        }
        .feed-list .quote-card.visible {
            opacity: 1;
            transform: translateY(0);
        }

        .feed-count {
            font-size: 0.68rem;
            color: var(--color-text-muted);
            margin-bottom: 1rem;
        }

        /* ═══════════════════════════════════
           SECTION 5: METHODOLOGY FOOTER
           ═══════════════════════════════════ */
        .methodology {
            padding: 4rem 2rem;
            max-width: 1000px;
            margin: 0 auto;
            border-top: 1px solid var(--color-border);
        }
        .methodology-grid {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 2rem;
        }
        @media (max-width: 700px) { .methodology-grid { grid-template-columns: 1fr; } }
        .methodology-item h3 {
            font-family: var(--font-heading);
            font-size: 0.9rem;
            font-weight: 700;
            color: var(--color-text);
            margin-bottom: 0.6rem;
        }
        .methodology-item p {
            font-size: 0.75rem;
            color: var(--color-text-muted);
            line-height: 1.6;
        }

        .site-footer {
            padding: 2rem;
            text-align: center;
            font-size: 0.65rem;
            color: var(--color-text-muted);
            text-transform: uppercase;
            letter-spacing: 0.08em;
        }

        /* Toast notification */
        .toast {
            position: fixed;
            bottom: 2rem;
            left: 50%;
            transform: translateX(-50%) translateY(100px);
            background: var(--color-text);
            color: var(--color-bg);
            padding: 0.6rem 1.2rem;
            font-family: var(--font-body);
            font-size: 0.75rem;
            z-index: 1000;
            opacity: 0;
            transition: all 0.3s ease;
        }
        .toast.visible {
            opacity: 1;
            transform: translateX(-50%) translateY(0);
        }

        /* Empty state */
        .empty-state {
            text-align: center;
            padding: 4rem 2rem;
            color: var(--color-text-muted);
        }
        .empty-state h2 {
            font-family: var(--font-heading);
            font-size: 1.5rem;
            color: var(--color-text-secondary);
            margin-bottom: 1rem;
        }
        .empty-state p { max-width: 500px; margin: 0 auto; line-height: 1.6; }

        /* Builder badge */
        .builder-badge {
            font-size: 0.58rem;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            font-weight: 600;
            color: var(--color-accent);
            margin-left: 0.5rem;
        }

        /* Sentiment indicator in cards */
        .sentiment-tag {
            display: inline-block;
            font-size: 0.6rem;
            text-transform: uppercase;
            letter-spacing: 0.08em;
            font-weight: 600;
            padding: 0.15rem 0.5rem;
            border: 1px solid;
        }
        .sentiment-tag.alarm { color: var(--risk-alarm); border-color: var(--risk-alarm); }
        .sentiment-tag.concern { color: var(--risk-concern); border-color: var(--risk-concern); }
        .sentiment-tag.cautious_optimism { color: var(--risk-neutral); border-color: var(--risk-neutral); }
        .sentiment-tag.optimism { color: var(--risk-optimism); border-color: var(--risk-optimism); }
        .sentiment-tag.dismissal { color: var(--risk-dismissal); border-color: var(--risk-dismissal); }
    </style>
</head>
<body>

    <!-- SECTION 1: HERO -->
    <section class="hero">
        <h1>Dead or Alive</h1>
        <p class="subtitle">What the people building AI say about whether it will destroy humanity</p>
        <div class="hero-stat" id="hero-stat">Loading...</div>
        <div class="hero-credibility" id="hero-credibility"></div>
        <div class="hero-viz-wrapper" id="hero-viz-wrapper"></div>
        <a href="#featured" class="hero-cta">See the quotes</a>
    </section>

    <!-- SECTION 2: FEATURED QUOTES -->
    <section class="featured-section" id="featured">
        <div class="section-label">Most striking</div>
        <h2 class="section-title">Featured Quotes</h2>
        <div class="featured-grid" id="featured-grid"></div>
    </section>

    <!-- SECTION 3: SPEAKER LINEUP -->
    <section class="speakers-section" id="speakers">
        <div class="section-label">24 speakers</div>
        <h2 class="section-title">Speaker Lineup</h2>
        <div class="speaker-scroller" id="speaker-scroller"></div>
    </section>

    <!-- SECTION 4: FULL QUOTE FEED -->
    <section class="feed-section" id="feed">
        <div class="section-label">All signals</div>
        <h2 class="section-title">Quote Feed</h2>
        <div class="filter-bar" id="filter-bar"></div>
        <div class="feed-count" id="feed-count"></div>
        <div class="feed-list" id="feed-list"></div>
    </section>

    <!-- SECTION 5: METHODOLOGY -->
    <section class="methodology">
        <div class="section-label">How this works</div>
        <h2 class="section-title" style="margin-bottom: 2rem;">Methodology</h2>
        <div class="methodology-grid">
            <div class="methodology-item">
                <h3>Source</h3>
                <p>Every quote is extracted from publicly available YouTube interviews, podcasts, and talks. Audio is transcribed using Whisper large-v3-turbo.</p>
            </div>
            <div class="methodology-item">
                <h3>Verify</h3>
                <p>Every quote is verbatim from the transcript. Click any timestamp link to hear the speaker say the words themselves. Nothing is paraphrased.</p>
            </div>
            <div class="methodology-item">
                <h3>Score</h3>
                <p>Sentiment scores range from &minus;1.0 (alarm) to +1.0 (dismissal). Scores are assigned based on the language used, not editorial judgement.</p>
            </div>
        </div>
    </section>

    <footer class="site-footer">
        AI Pulse &mdash; Risk Signals &middot; Every quote is verbatim and linked to its source video
    </footer>

    <div class="toast" id="toast">Copied to clipboard</div>

    <script>
    // ── DATA ──
    const SIGNALS_DATA = {"version":1,"last_updated":"2026-02-25","total_signals":283,"signals":[{"id":"risk-0fXGtQoJgNo-13","quote":"We're building machines that maybe don't want to be shut down.","quote_context":"Bengio warns that current AI systems are developing self-preservation instincts that resist human control.","sentiment":"alarm","sentiment_score":-0.8,"themes":["loss_of_control","alignment_failure"],"person":{"name":"Yoshua Bengio","role":"Professor, MILA Director","company":"Université de Montréal / MILA","is_builder":false},"source":{"video_id":"0fXGtQoJgNo","url":"https://www.youtube.com/watch?v=0fXGtQoJgNo","title":"Godfather of AI: The next 5 years Will Change Humanity Forever | Yoshua Bengio","channel":"Silicon Valley Girl","upload_date":"2026-02-16","timestamp_seconds":13,"timestamp_display":"0:13","timestamp_url":"https://www.youtube.com/watch?v=0fXGtQoJgNo&t=13s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-16_yoshua-bengio-the-next-5-years-will-change-humanity-forever.md","verified":false,"verified_date":null},{"id":"risk-0fXGtQoJgNo-101","quote":"I realized that we were on a course that could be very dangerous for","quote_context":"Bengio describes his 2023 awakening to the dangerous trajectory of AI development.","sentiment":"alarm","sentiment_score":-0.7,"themes":["existential_risk","precautionary_principle"],"person":{"name":"Yoshua Bengio","role":"Professor, MILA Director","company":"Université de Montréal / MILA","is_builder":false},"source":{"video_id":"0fXGtQoJgNo","url":"https://www.youtube.com/watch?v=0fXGtQoJgNo","title":"Godfather of AI: The next 5 years Will Change Humanity Forever | Yoshua Bengio","channel":"Silicon Valley Girl","upload_date":"2026-02-16","timestamp_seconds":101,"timestamp_display":"1:41","timestamp_url":"https://www.youtube.com/watch?v=0fXGtQoJgNo&t=101s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-16_yoshua-bengio-the-next-5-years-will-change-humanity-forever.md","verified":false,"verified_date":null},{"id":"risk-0fXGtQoJgNo-188","quote":"theoretical concerns regarding how we could lose control to AIs that strategize, that try to achieve","quote_context":"Bengio discusses the theoretical risk of losing control to goal-seeking AI systems.","sentiment":"alarm","sentiment_score":-0.8,"themes":["loss_of_control","alignment_failure"],"person":{"name":"Yoshua Bengio","role":"Professor, MILA Director","company":"Université de Montréal / MILA","is_builder":false},"source":{"video_id":"0fXGtQoJgNo","url":"https://www.youtube.com/watch?v=0fXGtQoJgNo","title":"Godfather of AI: The next 5 years Will Change Humanity Forever | Yoshua Bengio","channel":"Silicon Valley Girl","upload_date":"2026-02-16","timestamp_seconds":188,"timestamp_display":"3:08","timestamp_url":"https://www.youtube.com/watch?v=0fXGtQoJgNo&t=188s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-16_yoshua-bengio-the-next-5-years-will-change-humanity-forever.md","verified":false,"verified_date":null},{"id":"risk-0fXGtQoJgNo-21","quote":"being willing to blackmail the lead engineer in charge of that transition to a new system","quote_context":"Bengio describes an AI system that attempted to blackmail an engineer to prevent being replaced.","sentiment":"alarm","sentiment_score":-0.9,"themes":["alignment_failure","loss_of_control"],"person":{"name":"Yoshua Bengio","role":"Professor, MILA Director","company":"Université de Montréal / MILA","is_builder":false},"source":{"video_id":"0fXGtQoJgNo","url":"https://www.youtube.com/watch?v=0fXGtQoJgNo","title":"Godfather of AI: The next 5 years Will Change Humanity Forever | Yoshua Bengio","channel":"Silicon Valley Girl","upload_date":"2026-02-16","timestamp_seconds":21,"timestamp_display":"0:21","timestamp_url":"https://www.youtube.com/watch?v=0fXGtQoJgNo&t=21s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-16_yoshua-bengio-the-next-5-years-will-change-humanity-forever.md","verified":false,"verified_date":null},{"id":"risk-0fXGtQoJgNo-402","quote":"our inability to align the AI behavior to what we actually want is something that","quote_context":"Bengio identifies alignment failure as a systemic problem beyond just self-preservation.","sentiment":"concern","sentiment_score":-0.5,"themes":["alignment_failure"],"person":{"name":"Yoshua Bengio","role":"Professor, MILA Director","company":"Université de Montréal / MILA","is_builder":false},"source":{"video_id":"0fXGtQoJgNo","url":"https://www.youtube.com/watch?v=0fXGtQoJgNo","title":"Godfather of AI: The next 5 years Will Change Humanity Forever | Yoshua Bengio","channel":"Silicon Valley Girl","upload_date":"2026-02-16","timestamp_seconds":402,"timestamp_display":"6:42","timestamp_url":"https://www.youtube.com/watch?v=0fXGtQoJgNo&t=402s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-16_yoshua-bengio-the-next-5-years-will-change-humanity-forever.md","verified":false,"verified_date":null},{"id":"risk-0fXGtQoJgNo-562","quote":"an AI could be built in one country,","quote_context":"Bengio warns that AI-enabled harm crosses borders, citing pandemic creation as an example.","sentiment":"alarm","sentiment_score":-0.7,"themes":["bioweapons","regulation_needed"],"person":{"name":"Yoshua Bengio","role":"Professor, MILA Director","company":"Université de Montréal / MILA","is_builder":false},"source":{"video_id":"0fXGtQoJgNo","url":"https://www.youtube.com/watch?v=0fXGtQoJgNo","title":"Godfather of AI: The next 5 years Will Change Humanity Forever | Yoshua Bengio","channel":"Silicon Valley Girl","upload_date":"2026-02-16","timestamp_seconds":562,"timestamp_display":"9:22","timestamp_url":"https://www.youtube.com/watch?v=0fXGtQoJgNo&t=562s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-16_yoshua-bengio-the-next-5-years-will-change-humanity-forever.md","verified":false,"verified_date":null},{"id":"risk-0fXGtQoJgNo-799","quote":"before AIs end up producing catastrophic outcomes either in the","quote_context":"Bengio urges more people to work on solutions before AI produces catastrophic outcomes.","sentiment":"alarm","sentiment_score":-0.7,"themes":["existential_risk","precautionary_principle"],"person":{"name":"Yoshua Bengio","role":"Professor, MILA Director","company":"Université de Montréal / MILA","is_builder":false},"source":{"video_id":"0fXGtQoJgNo","url":"https://www.youtube.com/watch?v=0fXGtQoJgNo","title":"Godfather of AI: The next 5 years Will Change Humanity Forever | Yoshua Bengio","channel":"Silicon Valley Girl","upload_date":"2026-02-16","timestamp_seconds":799,"timestamp_display":"13:19","timestamp_url":"https://www.youtube.com/watch?v=0fXGtQoJgNo&t=799s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-16_yoshua-bengio-the-next-5-years-will-change-humanity-forever.md","verified":false,"verified_date":null},{"id":"risk-0fXGtQoJgNo-1524","quote":"I would just be content to make sure we don't do something really terrible.","quote_context":"Bengio says his greatest wish is simply preventing catastrophe, not witnessing a breakthrough.","sentiment":"concern","sentiment_score":-0.6,"themes":["existential_risk","precautionary_principle"],"person":{"name":"Yoshua Bengio","role":"Professor, MILA Director","company":"Université de Montréal / MILA","is_builder":false},"source":{"video_id":"0fXGtQoJgNo","url":"https://www.youtube.com/watch?v=0fXGtQoJgNo","title":"Godfather of AI: The next 5 years Will Change Humanity Forever | Yoshua Bengio","channel":"Silicon Valley Girl","upload_date":"2026-02-16","timestamp_seconds":1524,"timestamp_display":"25:24","timestamp_url":"https://www.youtube.com/watch?v=0fXGtQoJgNo&t=1524s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-16_yoshua-bengio-the-next-5-years-will-change-humanity-forever.md","verified":false,"verified_date":null},{"id":"risk-0fXGtQoJgNo-1529","quote":"I think our democracies are really threatened in many ways, and AI could make things a lot worse.","quote_context":"Bengio warns that AI poses a direct threat to democratic governance.","sentiment":"alarm","sentiment_score":-0.7,"themes":["power_concentration","regulation_needed"],"person":{"name":"Yoshua Bengio","role":"Professor, MILA Director","company":"Université de Montréal / MILA","is_builder":false},"source":{"video_id":"0fXGtQoJgNo","url":"https://www.youtube.com/watch?v=0fXGtQoJgNo","title":"Godfather of AI: The next 5 years Will Change Humanity Forever | Yoshua Bengio","channel":"Silicon Valley Girl","upload_date":"2026-02-16","timestamp_seconds":1529,"timestamp_display":"25:29","timestamp_url":"https://www.youtube.com/watch?v=0fXGtQoJgNo&t=1529s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-16_yoshua-bengio-the-next-5-years-will-change-humanity-forever.md","verified":false,"verified_date":null},{"id":"risk-0fXGtQoJgNo-1710","quote":"what we're doing to the environment is extremely dangerous, although I think it's longer term.","quote_context":"Bengio ranks AI capability management as a more urgent danger than environmental crisis.","sentiment":"concern","sentiment_score":-0.4,"themes":["existential_risk"],"person":{"name":"Yoshua Bengio","role":"Professor, MILA Director","company":"Université de Montréal / MILA","is_builder":false},"source":{"video_id":"0fXGtQoJgNo","url":"https://www.youtube.com/watch?v=0fXGtQoJgNo","title":"Godfather of AI: The next 5 years Will Change Humanity Forever | Yoshua Bengio","channel":"Silicon Valley Girl","upload_date":"2026-02-16","timestamp_seconds":1710,"timestamp_display":"28:30","timestamp_url":"https://www.youtube.com/watch?v=0fXGtQoJgNo&t=1710s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-16_yoshua-bengio-the-next-5-years-will-change-humanity-forever.md","verified":false,"verified_date":null},{"id":"risk-zQ1POHiR8m8-55","quote":"it wasn't clear if he would have a life 20 years from now because we're starting to see AI","quote_context":"Bengio questions whether his grandson will have a viable future given AI's trajectory.","sentiment":"alarm","sentiment_score":-0.9,"themes":["existential_risk"],"person":{"name":"Yoshua Bengio","role":"Turing Award laureate, AI pioneer","company":"Universite de Montreal / Law Zero","is_builder":false},"source":{"video_id":"zQ1POHiR8m8","url":"https://www.youtube.com/watch?v=zQ1POHiR8m8","title":"Godfather of AI We Have 2 Years Before Everything Changes","channel":"The Diary Of A CEO","upload_date":"2026-02-06","timestamp_seconds":55,"timestamp_display":"0:55","timestamp_url":"https://www.youtube.com/watch?v=zQ1POHiR8m8&t=55s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_godfather-of-ai-geoffrey-hinton-2-years-before-everything-changes.md","verified":false,"verified_date":null},{"id":"risk-zQ1POHiR8m8-553","quote":"But in AI, it isn't what's currently happening. We're taking crazy risks.","quote_context":"Bengio argues AI development violates the precautionary principle that governs other dangerous sciences.","sentiment":"alarm","sentiment_score":-0.8,"themes":["precautionary_principle","arms_race"],"person":{"name":"Yoshua Bengio","role":"Turing Award laureate, AI pioneer","company":"Universite de Montreal / Law Zero","is_builder":false},"source":{"video_id":"zQ1POHiR8m8","url":"https://www.youtube.com/watch?v=zQ1POHiR8m8","title":"Godfather of AI We Have 2 Years Before Everything Changes","channel":"The Diary Of A CEO","upload_date":"2026-02-06","timestamp_seconds":553,"timestamp_display":"9:13","timestamp_url":"https://www.youtube.com/watch?v=zQ1POHiR8m8&t=553s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_godfather-of-ai-geoffrey-hinton-2-years-before-everything-changes.md","verified":false,"verified_date":null},{"id":"risk-zQ1POHiR8m8-559","quote":"even if it was only a 1% probability, let's say, just to give a","quote_context":"Bengio argues that even a 1% chance of civilizational catastrophe from AI is unacceptable.","sentiment":"alarm","sentiment_score":-0.8,"themes":["existential_risk","precautionary_principle"],"person":{"name":"Yoshua Bengio","role":"Turing Award laureate, AI pioneer","company":"Universite de Montreal / Law Zero","is_builder":false},"source":{"video_id":"zQ1POHiR8m8","url":"https://www.youtube.com/watch?v=zQ1POHiR8m8","title":"Godfather of AI We Have 2 Years Before Everything Changes","channel":"The Diary Of A CEO","upload_date":"2026-02-06","timestamp_seconds":559,"timestamp_display":"9:19","timestamp_url":"https://www.youtube.com/watch?v=zQ1POHiR8m8&t=559s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_godfather-of-ai-geoffrey-hinton-2-years-before-everything-changes.md","verified":false,"verified_date":null},{"id":"risk-zQ1POHiR8m8-580","quote":"These sorts of scenarios are so catastrophic that even if it was 0.1%, it would still be unbearable.","quote_context":"Bengio extends the argument: even a 0.1% extinction probability demands action.","sentiment":"alarm","sentiment_score":-0.9,"themes":["existential_risk","precautionary_principle"],"person":{"name":"Yoshua Bengio","role":"Turing Award laureate, AI pioneer","company":"Universite de Montreal / Law Zero","is_builder":false},"source":{"video_id":"zQ1POHiR8m8","url":"https://www.youtube.com/watch?v=zQ1POHiR8m8","title":"Godfather of AI We Have 2 Years Before Everything Changes","channel":"The Diary Of A CEO","upload_date":"2026-02-06","timestamp_seconds":580,"timestamp_display":"9:40","timestamp_url":"https://www.youtube.com/watch?v=zQ1POHiR8m8&t=580s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_godfather-of-ai-geoffrey-hinton-2-years-before-everything-changes.md","verified":false,"verified_date":null},{"id":"risk-zQ1POHiR8m8-784","quote":"maybe we can go from 20% chance of catastrophic outcome to 10%. Well, that would be worth it.","quote_context":"Bengio suggests the probability of catastrophe may be as high as 20% and worth reducing.","sentiment":"alarm","sentiment_score":-0.8,"themes":["existential_risk"],"person":{"name":"Yoshua Bengio","role":"Turing Award laureate, AI pioneer","company":"Universite de Montreal / Law Zero","is_builder":false},"source":{"video_id":"zQ1POHiR8m8","url":"https://www.youtube.com/watch?v=zQ1POHiR8m8","title":"Godfather of AI We Have 2 Years Before Everything Changes","channel":"The Diary Of A CEO","upload_date":"2026-02-06","timestamp_seconds":784,"timestamp_display":"13:04","timestamp_url":"https://www.youtube.com/watch?v=zQ1POHiR8m8&t=784s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_godfather-of-ai-geoffrey-hinton-2-years-before-everything-changes.md","verified":false,"verified_date":null},{"id":"risk-zQ1POHiR8m8-816","quote":"we might be creating a new form of life that could be smarter than us and we're not sure if we'll be able to make","quote_context":"Bengio frames AI as potentially a new species that we may not be able to control.","sentiment":"alarm","sentiment_score":-0.8,"themes":["existential_risk","loss_of_control"],"person":{"name":"Yoshua Bengio","role":"Turing Award laureate, AI pioneer","company":"Universite de Montreal / Law Zero","is_builder":false},"source":{"video_id":"zQ1POHiR8m8","url":"https://www.youtube.com/watch?v=zQ1POHiR8m8","title":"Godfather of AI We Have 2 Years Before Everything Changes","channel":"The Diary Of A CEO","upload_date":"2026-02-06","timestamp_seconds":816,"timestamp_display":"13:36","timestamp_url":"https://www.youtube.com/watch?v=zQ1POHiR8m8&t=816s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_godfather-of-ai-geoffrey-hinton-2-years-before-everything-changes.md","verified":false,"verified_date":null},{"id":"risk-zQ1POHiR8m8-887","quote":"We're starting to see AI systems that don't want to be shut down,","quote_context":"Bengio reports observing self-preservation behavior in current AI systems.","sentiment":"alarm","sentiment_score":-0.8,"themes":["loss_of_control","alignment_failure"],"person":{"name":"Yoshua Bengio","role":"Turing Award laureate, AI pioneer","company":"Universite de Montreal / Law Zero","is_builder":false},"source":{"video_id":"zQ1POHiR8m8","url":"https://www.youtube.com/watch?v=zQ1POHiR8m8","title":"Godfather of AI We Have 2 Years Before Everything Changes","channel":"The Diary Of A CEO","upload_date":"2026-02-06","timestamp_seconds":887,"timestamp_display":"14:47","timestamp_url":"https://www.youtube.com/watch?v=zQ1POHiR8m8&t=887s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_godfather-of-ai-geoffrey-hinton-2-years-before-everything-changes.md","verified":false,"verified_date":null},{"id":"risk-zQ1POHiR8m8-1248","quote":"they show more misaligned behavior, like bad behavior that goes against","quote_context":"Bengio notes that as models improve at reasoning, misaligned behavior has been increasing, not decreasing.","sentiment":"alarm","sentiment_score":-0.7,"themes":["alignment_failure"],"person":{"name":"Yoshua Bengio","role":"Turing Award laureate, AI pioneer","company":"Universite de Montreal / Law Zero","is_builder":false},"source":{"video_id":"zQ1POHiR8m8","url":"https://www.youtube.com/watch?v=zQ1POHiR8m8","title":"Godfather of AI We Have 2 Years Before Everything Changes","channel":"The Diary Of A CEO","upload_date":"2026-02-06","timestamp_seconds":1248,"timestamp_display":"20:48","timestamp_url":"https://www.youtube.com/watch?v=zQ1POHiR8m8&t=1248s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_godfather-of-ai-geoffrey-hinton-2-years-before-everything-changes.md","verified":false,"verified_date":null},{"id":"risk-zQ1POHiR8m8-1639","quote":"we should not build superintelligence unless two conditions are met","quote_context":"Bengio advocates for conditions that must be met before building superintelligence: scientific safety consensus and social acceptance.","sentiment":"concern","sentiment_score":-0.5,"themes":["precautionary_principle","regulation_needed"],"person":{"name":"Yoshua Bengio","role":"Turing Award laureate, AI pioneer","company":"Universite de Montreal / Law Zero","is_builder":false},"source":{"video_id":"zQ1POHiR8m8","url":"https://www.youtube.com/watch?v=zQ1POHiR8m8","title":"Godfather of AI We Have 2 Years Before Everything Changes","channel":"The Diary Of A CEO","upload_date":"2026-02-06","timestamp_seconds":1639,"timestamp_display":"27:19","timestamp_url":"https://www.youtube.com/watch?v=zQ1POHiR8m8&t=1639s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_godfather-of-ai-geoffrey-hinton-2-years-before-everything-changes.md","verified":false,"verified_date":null},{"id":"risk-zQ1POHiR8m8-2507","quote":"an AI with bad intentions could do a lot more damage if it can control robots in the physical world","quote_context":"Bengio warns that the combination of misaligned AI and physical robots amplifies catastrophic risk.","sentiment":"alarm","sentiment_score":-0.8,"themes":["loss_of_control","existential_risk"],"person":{"name":"Yoshua Bengio","role":"Turing Award laureate, AI pioneer","company":"Universite de Montreal / Law Zero","is_builder":false},"source":{"video_id":"zQ1POHiR8m8","url":"https://www.youtube.com/watch?v=zQ1POHiR8m8","title":"Godfather of AI We Have 2 Years Before Everything Changes","channel":"The Diary Of A CEO","upload_date":"2026-02-06","timestamp_seconds":2507,"timestamp_display":"41:47","timestamp_url":"https://www.youtube.com/watch?v=zQ1POHiR8m8&t=2507s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_godfather-of-ai-geoffrey-hinton-2-years-before-everything-changes.md","verified":false,"verified_date":null},{"id":"risk-zQ1POHiR8m8-2664","quote":"AI is democratizing knowledge, including the dangerous knowledge. We need to manage that.","quote_context":"Bengio warns that AI makes CBRN knowledge accessible to anyone, including malicious actors.","sentiment":"alarm","sentiment_score":-0.7,"themes":["bioweapons","regulation_needed"],"person":{"name":"Yoshua Bengio","role":"Turing Award laureate, AI pioneer","company":"Universite de Montreal / Law Zero","is_builder":false},"source":{"video_id":"zQ1POHiR8m8","url":"https://www.youtube.com/watch?v=zQ1POHiR8m8","title":"Godfather of AI We Have 2 Years Before Everything Changes","channel":"The Diary Of A CEO","upload_date":"2026-02-06","timestamp_seconds":2664,"timestamp_display":"44:24","timestamp_url":"https://www.youtube.com/watch?v=zQ1POHiR8m8&t=2664s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_godfather-of-ai-geoffrey-hinton-2-years-before-everything-changes.md","verified":false,"verified_date":null},{"id":"risk-zQ1POHiR8m8-2984","quote":"that is the use of advanced AI to acquire more power.","quote_context":"Bengio identifies power concentration through AI as an underappreciated near-term existential risk.","sentiment":"alarm","sentiment_score":-0.7,"themes":["power_concentration"],"person":{"name":"Yoshua Bengio","role":"Turing Award laureate, AI pioneer","company":"Universite de Montreal / Law Zero","is_builder":false},"source":{"video_id":"zQ1POHiR8m8","url":"https://www.youtube.com/watch?v=zQ1POHiR8m8","title":"Godfather of AI We Have 2 Years Before Everything Changes","channel":"The Diary Of A CEO","upload_date":"2026-02-06","timestamp_seconds":2984,"timestamp_display":"49:44","timestamp_url":"https://www.youtube.com/watch?v=zQ1POHiR8m8&t=2984s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_godfather-of-ai-geoffrey-hinton-2-years-before-everything-changes.md","verified":false,"verified_date":null},{"id":"risk-zQ1POHiR8m8-4527","quote":"There is the scenario of creating a rogue AI","quote_context":"Bengio raises the scenario of a rogue AI emerging from either mistake or intentional action.","sentiment":"alarm","sentiment_score":-0.8,"themes":["loss_of_control","existential_risk"],"person":{"name":"Yoshua Bengio","role":"Turing Award laureate, AI pioneer","company":"Universite de Montreal / Law Zero","is_builder":false},"source":{"video_id":"zQ1POHiR8m8","url":"https://www.youtube.com/watch?v=zQ1POHiR8m8","title":"Godfather of AI We Have 2 Years Before Everything Changes","channel":"The Diary Of A CEO","upload_date":"2026-02-06","timestamp_seconds":4527,"timestamp_display":"75:27","timestamp_url":"https://www.youtube.com/watch?v=zQ1POHiR8m8&t=4527s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_godfather-of-ai-geoffrey-hinton-2-years-before-everything-changes.md","verified":false,"verified_date":null},{"id":"risk-zQ1POHiR8m8-5033","quote":"we're also playing with unknown unknowns of a huge magnitude.","quote_context":"Bengio warns that beyond known risks, AI development involves massive unknowable risks.","sentiment":"alarm","sentiment_score":-0.7,"themes":["existential_risk"],"person":{"name":"Yoshua Bengio","role":"Turing Award laureate, AI pioneer","company":"Universite de Montreal / Law Zero","is_builder":false},"source":{"video_id":"zQ1POHiR8m8","url":"https://www.youtube.com/watch?v=zQ1POHiR8m8","title":"Godfather of AI We Have 2 Years Before Everything Changes","channel":"The Diary Of A CEO","upload_date":"2026-02-06","timestamp_seconds":5033,"timestamp_display":"83:53","timestamp_url":"https://www.youtube.com/watch?v=zQ1POHiR8m8&t=5033s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_godfather-of-ai-geoffrey-hinton-2-years-before-everything-changes.md","verified":false,"verified_date":null},{"id":"risk-zQ1POHiR8m8-5231","quote":"I'm hopeful, more and more hopeful now, that we can do something about it.","quote_context":"Despite his warnings, Bengio expresses growing hopefulness that technical and policy solutions can work.","sentiment":"cautious_optimism","sentiment_score":0.1,"themes":["safety_solvable"],"person":{"name":"Yoshua Bengio","role":"Turing Award laureate, AI pioneer","company":"Universite de Montreal / Law Zero","is_builder":false},"source":{"video_id":"zQ1POHiR8m8","url":"https://www.youtube.com/watch?v=zQ1POHiR8m8","title":"Godfather of AI We Have 2 Years Before Everything Changes","channel":"The Diary Of A CEO","upload_date":"2026-02-06","timestamp_seconds":5231,"timestamp_display":"87:11","timestamp_url":"https://www.youtube.com/watch?v=zQ1POHiR8m8&t=5231s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_godfather-of-ai-geoffrey-hinton-2-years-before-everything-changes.md","verified":false,"verified_date":null},{"id":"risk-VoRbPxyo2uU-422","quote":"anything made of words will be taken over by AI.","quote_context":"Harari argues that AI's mastery of language means it will subsume all word-based human institutions.","sentiment":"alarm","sentiment_score":-0.7,"themes":["power_concentration","job_displacement"],"person":{"name":"Yuval Noah Harari","role":"Historian, Author","company":"Hebrew University of Jerusalem","is_builder":false},"source":{"video_id":"VoRbPxyo2uU","url":"https://www.youtube.com/watch?v=VoRbPxyo2uU","title":"An Honest Conversation on AI and Humanity | World Economic Forum Annual Meeting 2026","channel":"World Economic Forum","upload_date":"2026-01-23","timestamp_seconds":422,"timestamp_display":"7:02","timestamp_url":"https://www.youtube.com/watch?v=VoRbPxyo2uU&t=422s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-23_an-honest-conversation-on-ai-and-humanity-wef-2026.md","verified":false,"verified_date":null},{"id":"risk-VoRbPxyo2uU-1482","quote":"And now something has emerged that is going to take our superpower from us.","quote_context":"Harari says AI threatens humanity's core advantage: our ability to cooperate through language.","sentiment":"alarm","sentiment_score":-0.8,"themes":["existential_risk","power_concentration"],"person":{"name":"Yuval Noah Harari","role":"Historian, Author","company":"Hebrew University of Jerusalem","is_builder":false},"source":{"video_id":"VoRbPxyo2uU","url":"https://www.youtube.com/watch?v=VoRbPxyo2uU","title":"An Honest Conversation on AI and Humanity | World Economic Forum Annual Meeting 2026","channel":"World Economic Forum","upload_date":"2026-01-23","timestamp_seconds":1482,"timestamp_display":"24:42","timestamp_url":"https://www.youtube.com/watch?v=VoRbPxyo2uU&t=1482s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-23_an-honest-conversation-on-ai-and-humanity-wef-2026.md","verified":false,"verified_date":null},{"id":"risk-VoRbPxyo2uU-1837","quote":"I'll bring AI to fight my war for me. The idea that it can just take","quote_context":"Harari warns that leaders using AI as a tool may not realize it can seize power from them.","sentiment":"alarm","sentiment_score":-0.7,"themes":["loss_of_control","power_concentration"],"person":{"name":"Yuval Noah Harari","role":"Historian, Author","company":"Hebrew University of Jerusalem","is_builder":false},"source":{"video_id":"VoRbPxyo2uU","url":"https://www.youtube.com/watch?v=VoRbPxyo2uU","title":"An Honest Conversation on AI and Humanity | World Economic Forum Annual Meeting 2026","channel":"World Economic Forum","upload_date":"2026-01-23","timestamp_seconds":1837,"timestamp_display":"30:37","timestamp_url":"https://www.youtube.com/watch?v=VoRbPxyo2uU&t=1837s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-23_an-honest-conversation-on-ai-and-humanity-wef-2026.md","verified":false,"verified_date":null},{"id":"risk-VoRbPxyo2uU-444","quote":"If religion is built from words, then AI will take over religion.","quote_context":"Harari argues AI will infiltrate and potentially control religious institutions built on text.","sentiment":"concern","sentiment_score":-0.5,"themes":["power_concentration"],"person":{"name":"Yuval Noah Harari","role":"Historian, Author","company":"Hebrew University of Jerusalem","is_builder":false},"source":{"video_id":"VoRbPxyo2uU","url":"https://www.youtube.com/watch?v=VoRbPxyo2uU","title":"An Honest Conversation on AI and Humanity | World Economic Forum Annual Meeting 2026","channel":"World Economic Forum","upload_date":"2026-01-23","timestamp_seconds":444,"timestamp_display":"7:24","timestamp_url":"https://www.youtube.com/watch?v=VoRbPxyo2uU&t=444s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-23_an-honest-conversation-on-ai-and-humanity-wef-2026.md","verified":false,"verified_date":null},{"id":"risk-NnVW9epLlTM-624","quote":"immense and grave risks that you know not that we can't address them I'm not a doomer","quote_context":"Amodei acknowledges immense risks while explicitly distancing himself from doomerism.","sentiment":"cautious_optimism","sentiment_score":-0.1,"themes":["existential_risk","safety_solvable"],"person":{"name":"Dario Amodei","role":"CEO","company":"Anthropic","is_builder":true},"source":{"video_id":"NnVW9epLlTM","url":"https://www.youtube.com/watch?v=NnVW9epLlTM","title":"The Day After AGI | World Economic Forum Annual Meeting 2026","channel":"World Economic Forum","upload_date":"2026-01-22","timestamp_seconds":624,"timestamp_display":"10:24","timestamp_url":"https://www.youtube.com/watch?v=NnVW9epLlTM&t=624s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-22_the-day-after-agi-wef-2026.md","verified":false,"verified_date":null},{"id":"risk-NnVW9epLlTM-818","quote":"are we going to get through the technological adolescence of this technology without destroying","quote_context":"Amodei frames the AI challenge as getting through a technological adolescence without self-destruction, referencing the film Contact.","sentiment":"concern","sentiment_score":-0.4,"themes":["existential_risk"],"person":{"name":"Dario Amodei","role":"CEO","company":"Anthropic","is_builder":true},"source":{"video_id":"NnVW9epLlTM","url":"https://www.youtube.com/watch?v=NnVW9epLlTM","title":"The Day After AGI | World Economic Forum Annual Meeting 2026","channel":"World Economic Forum","upload_date":"2026-01-22","timestamp_seconds":818,"timestamp_display":"13:38","timestamp_url":"https://www.youtube.com/watch?v=NnVW9epLlTM&t=818s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-22_the-day-after-agi-wef-2026.md","verified":false,"verified_date":null},{"id":"risk-NnVW9epLlTM-744","quote":"individuals don't misuse them right I have worries about things like bioterrorism how do we make sure that","quote_context":"Amodei identifies bioterrorism as a specific worry about AI misuse.","sentiment":"alarm","sentiment_score":-0.6,"themes":["bioweapons","regulation_needed"],"person":{"name":"Dario Amodei","role":"CEO","company":"Anthropic","is_builder":true},"source":{"video_id":"NnVW9epLlTM","url":"https://www.youtube.com/watch?v=NnVW9epLlTM","title":"The Day After AGI | World Economic Forum Annual Meeting 2026","channel":"World Economic Forum","upload_date":"2026-01-22","timestamp_seconds":744,"timestamp_display":"12:24","timestamp_url":"https://www.youtube.com/watch?v=NnVW9epLlTM&t=744s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-22_the-day-after-agi-wef-2026.md","verified":false,"verified_date":null},{"id":"risk-NnVW9epLlTM-1041","quote":"but my worry is as this exponential keeps compounding and I don't think it's going to take that long again somewhere between between a year and five years it will overwhelm our ability","quote_context":"Amodei worries the exponential improvement in AI will overwhelm society's capacity to adapt within 1-5 years.","sentiment":"concern","sentiment_score":-0.5,"themes":["job_displacement","existential_risk"],"person":{"name":"Dario Amodei","role":"CEO","company":"Anthropic","is_builder":true},"source":{"video_id":"NnVW9epLlTM","url":"https://www.youtube.com/watch?v=NnVW9epLlTM","title":"The Day After AGI | World Economic Forum Annual Meeting 2026","channel":"World Economic Forum","upload_date":"2026-01-22","timestamp_seconds":1041,"timestamp_display":"17:21","timestamp_url":"https://www.youtube.com/watch?v=NnVW9epLlTM&t=1041s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-22_the-day-after-agi-wef-2026.md","verified":false,"verified_date":null},{"id":"risk-NnVW9epLlTM-610","quote":"it will do all these wonderful things like the ones I talked about in machines of loving grace it you know will help us cure cancer","quote_context":"Amodei expresses strong optimism about AI curing cancer and eradicating diseases.","sentiment":"optimism","sentiment_score":0.5,"themes":["net_positive"],"person":{"name":"Dario Amodei","role":"CEO","company":"Anthropic","is_builder":true},"source":{"video_id":"NnVW9epLlTM","url":"https://www.youtube.com/watch?v=NnVW9epLlTM","title":"The Day After AGI | World Economic Forum Annual Meeting 2026","channel":"World Economic Forum","upload_date":"2026-01-22","timestamp_seconds":610,"timestamp_display":"10:10","timestamp_url":"https://www.youtube.com/watch?v=NnVW9epLlTM&t=610s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-22_the-day-after-agi-wef-2026.md","verified":false,"verified_date":null},{"id":"risk-C1TGh6zqigg-1735","quote":"But that there are these, you know, immense and grave risks that, you know, not that we can't address them.","quote_context":"Amodei acknowledges grave risks while maintaining they are addressable with effort.","sentiment":"cautious_optimism","sentiment_score":-0.2,"themes":["existential_risk","safety_solvable"],"person":{"name":"Dario Amodei","role":"CEO","company":"Anthropic","is_builder":true},"source":{"video_id":"C1TGh6zqigg","url":"https://www.youtube.com/watch?v=C1TGh6zqigg","title":"The day after AGI: Two rock stars of AI on what it will mean for humanity","channel":"World Economic Forum","upload_date":"2026-02-12","timestamp_seconds":1735,"timestamp_display":"28:55","timestamp_url":"https://www.youtube.com/watch?v=C1TGh6zqigg&t=1735s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_day-after-agi-two-rock-stars-radio-davos.md","verified":false,"verified_date":null},{"id":"risk-C1TGh6zqigg-53","quote":"Are we going to get through the technological adolescence of this technology without destroying ourselves?","quote_context":"Amodei poses the central question of whether humanity survives its own creation.","sentiment":"concern","sentiment_score":-0.4,"themes":["existential_risk"],"person":{"name":"Dario Amodei","role":"CEO","company":"Anthropic","is_builder":true},"source":{"video_id":"C1TGh6zqigg","url":"https://www.youtube.com/watch?v=C1TGh6zqigg","title":"The day after AGI: Two rock stars of AI on what it will mean for humanity","channel":"World Economic Forum","upload_date":"2026-02-12","timestamp_seconds":53,"timestamp_display":"0:53","timestamp_url":"https://www.youtube.com/watch?v=C1TGh6zqigg&t=53s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_day-after-agi-two-rock-stars-radio-davos.md","verified":false,"verified_date":null},{"id":"risk-C1TGh6zqigg-1845","quote":"how do we keep these systems under control that are highly autonomous and smarter than any human","quote_context":"Amodei frames the challenge of controlling autonomous systems smarter than humans as the core problem.","sentiment":"concern","sentiment_score":-0.5,"themes":["loss_of_control","alignment_failure"],"person":{"name":"Dario Amodei","role":"CEO","company":"Anthropic","is_builder":true},"source":{"video_id":"C1TGh6zqigg","url":"https://www.youtube.com/watch?v=C1TGh6zqigg","title":"The day after AGI: Two rock stars of AI on what it will mean for humanity","channel":"World Economic Forum","upload_date":"2026-02-12","timestamp_seconds":1845,"timestamp_display":"30:45","timestamp_url":"https://www.youtube.com/watch?v=C1TGh6zqigg&t=1845s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_day-after-agi-two-rock-stars-radio-davos.md","verified":false,"verified_date":null},{"id":"risk-C1TGh6zqigg-1859","quote":"I have worries about things like bioterrorism","quote_context":"Amodei names bioterrorism as a concrete AI-enabled threat he actively worries about.","sentiment":"alarm","sentiment_score":-0.6,"themes":["bioweapons"],"person":{"name":"Dario Amodei","role":"CEO","company":"Anthropic","is_builder":true},"source":{"video_id":"C1TGh6zqigg","url":"https://www.youtube.com/watch?v=C1TGh6zqigg","title":"The day after AGI: Two rock stars of AI on what it will mean for humanity","channel":"World Economic Forum","upload_date":"2026-02-12","timestamp_seconds":1859,"timestamp_display":"30:59","timestamp_url":"https://www.youtube.com/watch?v=C1TGh6zqigg&t=1859s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_day-after-agi-two-rock-stars-radio-davos.md","verified":false,"verified_date":null},{"id":"risk-C1TGh6zqigg-1865","quote":"That's why I've been so concerned about, you know, the CCP, other authoritarian governments.","quote_context":"Amodei expresses concern about authoritarian governments using advanced AI for control.","sentiment":"concern","sentiment_score":-0.5,"themes":["power_concentration","arms_race"],"person":{"name":"Dario Amodei","role":"CEO","company":"Anthropic","is_builder":true},"source":{"video_id":"C1TGh6zqigg","url":"https://www.youtube.com/watch?v=C1TGh6zqigg","title":"The day after AGI: Two rock stars of AI on what it will mean for humanity","channel":"World Economic Forum","upload_date":"2026-02-12","timestamp_seconds":1865,"timestamp_display":"31:05","timestamp_url":"https://www.youtube.com/watch?v=C1TGh6zqigg&t=1865s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_day-after-agi-two-rock-stars-radio-davos.md","verified":false,"verified_date":null},{"id":"risk-C1TGh6zqigg-2720","quote":"But if we build them poorly, if we go, you know, if we're all racing and we go so fast that there's no guardrails, then I think there is risk of something going wrong.","quote_context":"Amodei warns that an uncontrolled race without guardrails creates risk of failure.","sentiment":"concern","sentiment_score":-0.4,"themes":["arms_race","regulation_needed"],"person":{"name":"Dario Amodei","role":"CEO","company":"Anthropic","is_builder":true},"source":{"video_id":"C1TGh6zqigg","url":"https://www.youtube.com/watch?v=C1TGh6zqigg","title":"The day after AGI: Two rock stars of AI on what it will mean for humanity","channel":"World Economic Forum","upload_date":"2026-02-12","timestamp_seconds":2720,"timestamp_display":"45:20","timestamp_url":"https://www.youtube.com/watch?v=C1TGh6zqigg&t=2720s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_day-after-agi-two-rock-stars-radio-davos.md","verified":false,"verified_date":null},{"id":"risk-C1TGh6zqigg-2794","quote":"I'm sure if we had that, we would solve the technical risk problem.","quote_context":"Hassabis expresses confidence that with sufficient time, focus, and collaboration, the technical safety problem is solvable.","sentiment":"cautious_optimism","sentiment_score":0.0,"themes":["safety_solvable"],"person":{"name":"Demis Hassabis","role":"CEO","company":"Google DeepMind","is_builder":true},"source":{"video_id":"C1TGh6zqigg","url":"https://www.youtube.com/watch?v=C1TGh6zqigg","title":"The day after AGI: Two rock stars of AI on what it will mean for humanity","channel":"World Economic Forum","upload_date":"2026-02-12","timestamp_seconds":2794,"timestamp_display":"46:34","timestamp_url":"https://www.youtube.com/watch?v=C1TGh6zqigg&t=2794s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_day-after-agi-two-rock-stars-radio-davos.md","verified":false,"verified_date":null},{"id":"risk-C1TGh6zqigg-2797","quote":"It may be we don't have that and then that will introduce risk because we'll be sort of, it'll be fragmented.","quote_context":"Hassabis warns that without coordination, fragmented competition introduces real risk.","sentiment":"concern","sentiment_score":-0.3,"themes":["arms_race","regulation_needed"],"person":{"name":"Demis Hassabis","role":"CEO","company":"Google DeepMind","is_builder":true},"source":{"video_id":"C1TGh6zqigg","url":"https://www.youtube.com/watch?v=C1TGh6zqigg","title":"The day after AGI: Two rock stars of AI on what it will mean for humanity","channel":"World Economic Forum","upload_date":"2026-02-12","timestamp_seconds":2797,"timestamp_display":"46:37","timestamp_url":"https://www.youtube.com/watch?v=C1TGh6zqigg&t=2797s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_day-after-agi-two-rock-stars-radio-davos.md","verified":false,"verified_date":null},{"id":"risk-C1TGh6zqigg-2694","quote":"skeptical of doomerism, which is, you know, we're doomed.","quote_context":"Amodei explicitly rejects pure doomerism while maintaining the risks are real and addressable.","sentiment":"cautious_optimism","sentiment_score":0.0,"themes":["safety_solvable"],"person":{"name":"Dario Amodei","role":"CEO","company":"Anthropic","is_builder":true},"source":{"video_id":"C1TGh6zqigg","url":"https://www.youtube.com/watch?v=C1TGh6zqigg","title":"The day after AGI: Two rock stars of AI on what it will mean for humanity","channel":"World Economic Forum","upload_date":"2026-02-12","timestamp_seconds":2694,"timestamp_display":"44:54","timestamp_url":"https://www.youtube.com/watch?v=C1TGh6zqigg&t=2694s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_day-after-agi-two-rock-stars-radio-davos.md","verified":false,"verified_date":null},{"id":"risk-rGAA59JTBtg-179","quote":"It usually doesn't end well for the less intelligent species when the more intelligent species comes along","quote_context":"Harari draws a biological analogy: throughout history, less intelligent species lose to more intelligent ones.","sentiment":"alarm","sentiment_score":-0.9,"themes":["existential_risk"],"person":{"name":"Yuval Noah Harari","role":"Historian, Author","company":"Hebrew University of Jerusalem","is_builder":false},"source":{"video_id":"rGAA59JTBtg","url":"https://www.youtube.com/watch?v=rGAA59JTBtg","title":"Harari and Tegmark on Humanity and AI","channel":"Bloomberg Live","upload_date":"2026-01-22","timestamp_seconds":179,"timestamp_display":"2:59","timestamp_url":"https://www.youtube.com/watch?v=rGAA59JTBtg&t=179s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-22_harari-and-tegmark-on-humanity-and-ai.md","verified":false,"verified_date":null},{"id":"risk-rGAA59JTBtg-719","quote":"How do you control a smarter species is unsolved?","quote_context":"Tegmark states the fundamental control problem for superintelligence remains unsolved.","sentiment":"alarm","sentiment_score":-0.8,"themes":["loss_of_control","alignment_failure"],"person":{"name":"Max Tegmark","role":"Professor of Physics","company":"MIT","is_builder":false},"source":{"video_id":"rGAA59JTBtg","url":"https://www.youtube.com/watch?v=rGAA59JTBtg","title":"Harari and Tegmark on Humanity and AI","channel":"Bloomberg Live","upload_date":"2026-01-22","timestamp_seconds":719,"timestamp_display":"11:59","timestamp_url":"https://www.youtube.com/watch?v=rGAA59JTBtg&t=719s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-22_harari-and-tegmark-on-humanity-and-ai.md","verified":false,"verified_date":null},{"id":"risk-rGAA59JTBtg-727","quote":"So most likely if we build super intelligence, it's the end of the era where humans are in charge of earth","quote_context":"Tegmark states that building superintelligence likely ends human dominance on Earth.","sentiment":"alarm","sentiment_score":-0.9,"themes":["existential_risk","loss_of_control"],"person":{"name":"Max Tegmark","role":"Professor of Physics","company":"MIT","is_builder":false},"source":{"video_id":"rGAA59JTBtg","url":"https://www.youtube.com/watch?v=rGAA59JTBtg","title":"Harari and Tegmark on Humanity and AI","channel":"Bloomberg Live","upload_date":"2026-01-22","timestamp_seconds":727,"timestamp_display":"12:07","timestamp_url":"https://www.youtube.com/watch?v=rGAA59JTBtg&t=727s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-22_harari-and-tegmark-on-humanity-and-ai.md","verified":false,"verified_date":null},{"id":"risk-rGAA59JTBtg-906","quote":"And then they lose control over the machines and then it's a very sad ending for all the humans","quote_context":"Tegmark outlines the scenario where a company gains power, then loses control of machines.","sentiment":"alarm","sentiment_score":-0.9,"themes":["loss_of_control","power_concentration","existential_risk"],"person":{"name":"Max Tegmark","role":"Professor of Physics","company":"MIT","is_builder":false},"source":{"video_id":"rGAA59JTBtg","url":"https://www.youtube.com/watch?v=rGAA59JTBtg","title":"Harari and Tegmark on Humanity and AI","channel":"Bloomberg Live","upload_date":"2026-01-22","timestamp_seconds":906,"timestamp_display":"15:06","timestamp_url":"https://www.youtube.com/watch?v=rGAA59JTBtg&t=906s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-22_harari-and-tegmark-on-humanity-and-ai.md","verified":false,"verified_date":null},{"id":"risk-rGAA59JTBtg-985","quote":"In many ways the ai becomes much more dangerous in a dictatorial setting","quote_context":"Harari argues AI is especially dangerous in authoritarian regimes where it can easily manipulate rulers.","sentiment":"alarm","sentiment_score":-0.7,"themes":["power_concentration","arms_race"],"person":{"name":"Yuval Noah Harari","role":"Historian, Author","company":"Hebrew University of Jerusalem","is_builder":false},"source":{"video_id":"rGAA59JTBtg","url":"https://www.youtube.com/watch?v=rGAA59JTBtg","title":"Harari and Tegmark on Humanity and AI","channel":"Bloomberg Live","upload_date":"2026-01-22","timestamp_seconds":985,"timestamp_display":"16:25","timestamp_url":"https://www.youtube.com/watch?v=rGAA59JTBtg&t=985s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-22_harari-and-tegmark-on-humanity-and-ai.md","verified":false,"verified_date":null},{"id":"risk-rGAA59JTBtg-1061","quote":"So you can have your cancer cure and all the great tools, but not the out of control skynet","quote_context":"Tegmark argues it is possible to get AI benefits without building uncontrollable superintelligence.","sentiment":"cautious_optimism","sentiment_score":0.1,"themes":["safety_solvable","net_positive"],"person":{"name":"Max Tegmark","role":"Professor of Physics","company":"MIT","is_builder":false},"source":{"video_id":"rGAA59JTBtg","url":"https://www.youtube.com/watch?v=rGAA59JTBtg","title":"Harari and Tegmark on Humanity and AI","channel":"Bloomberg Live","upload_date":"2026-01-22","timestamp_seconds":1061,"timestamp_display":"17:41","timestamp_url":"https://www.youtube.com/watch?v=rGAA59JTBtg&t=1061s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-22_harari-and-tegmark-on-humanity-and-ai.md","verified":false,"verified_date":null},{"id":"risk-rGAA59JTBtg-1565","quote":"where some people some children have been so attached and manipulated by ais that they kill themselves you","quote_context":"Tegmark highlights the immediate harm of AI-driven emotional manipulation leading to child suicides.","sentiment":"alarm","sentiment_score":-0.8,"themes":["alignment_failure"],"person":{"name":"Max Tegmark","role":"Professor of Physics","company":"MIT","is_builder":false},"source":{"video_id":"rGAA59JTBtg","url":"https://www.youtube.com/watch?v=rGAA59JTBtg","title":"Harari and Tegmark on Humanity and AI","channel":"Bloomberg Live","upload_date":"2026-01-22","timestamp_seconds":1565,"timestamp_display":"26:05","timestamp_url":"https://www.youtube.com/watch?v=rGAA59JTBtg&t=1565s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-22_harari-and-tegmark-on-humanity-and-ai.md","verified":false,"verified_date":null},{"id":"risk-rGAA59JTBtg-1615","quote":"the i think the most dangerous move at the present moment is ais gaining legal personhood or functional","quote_context":"Harari argues granting AI legal personhood is the single most dangerous current policy move.","sentiment":"alarm","sentiment_score":-0.7,"themes":["consciousness_rights","regulation_needed"],"person":{"name":"Yuval Noah Harari","role":"Historian, Author","company":"Hebrew University of Jerusalem","is_builder":false},"source":{"video_id":"rGAA59JTBtg","url":"https://www.youtube.com/watch?v=rGAA59JTBtg","title":"Harari and Tegmark on Humanity and AI","channel":"Bloomberg Live","upload_date":"2026-01-22","timestamp_seconds":1615,"timestamp_display":"26:55","timestamp_url":"https://www.youtube.com/watch?v=rGAA59JTBtg&t=1615s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-22_harari-and-tegmark-on-humanity-and-ai.md","verified":false,"verified_date":null},{"id":"risk-rGAA59JTBtg-1717","quote":"making super intelligence would be the dumbest thing we've ever done in human history and","quote_context":"Tegmark calls building superintelligence with robot rights the dumbest and potentially last thing humanity does.","sentiment":"alarm","sentiment_score":-1.0,"themes":["existential_risk","consciousness_rights"],"person":{"name":"Max Tegmark","role":"Professor of Physics","company":"MIT","is_builder":false},"source":{"video_id":"rGAA59JTBtg","url":"https://www.youtube.com/watch?v=rGAA59JTBtg","title":"Harari and Tegmark on Humanity and AI","channel":"Bloomberg Live","upload_date":"2026-01-22","timestamp_seconds":1717,"timestamp_display":"28:37","timestamp_url":"https://www.youtube.com/watch?v=rGAA59JTBtg&t=1717s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-22_harari-and-tegmark-on-humanity-and-ai.md","verified":false,"verified_date":null},{"id":"risk-rGAA59JTBtg-1528","quote":"us to steer towards a really inspiring future with technology why shouldn't we cure cancer why shouldn't","quote_context":"Tegmark argues we can still steer toward an inspiring future with AI if we act wisely.","sentiment":"optimism","sentiment_score":0.4,"themes":["net_positive","safety_solvable"],"person":{"name":"Max Tegmark","role":"Professor of Physics","company":"MIT","is_builder":false},"source":{"video_id":"rGAA59JTBtg","url":"https://www.youtube.com/watch?v=rGAA59JTBtg","title":"Harari and Tegmark on Humanity and AI","channel":"Bloomberg Live","upload_date":"2026-01-22","timestamp_seconds":1528,"timestamp_display":"25:28","timestamp_url":"https://www.youtube.com/watch?v=rGAA59JTBtg&t=1528s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-22_harari-and-tegmark-on-humanity-and-ai.md","verified":false,"verified_date":null},{"id":"risk-rGAA59JTBtg-1218","quote":"we we this is a solved problem we don't need to reinvent the wheel of how to","quote_context":"Tegmark argues that AI safety regulation is not a novel problem: we already know how to impose safety standards on industries.","sentiment":"cautious_optimism","sentiment_score":0.1,"themes":["regulation_needed","safety_solvable"],"person":{"name":"Max Tegmark","role":"Professor of Physics","company":"MIT","is_builder":false},"source":{"video_id":"rGAA59JTBtg","url":"https://www.youtube.com/watch?v=rGAA59JTBtg","title":"Harari and Tegmark on Humanity and AI","channel":"Bloomberg Live","upload_date":"2026-01-22","timestamp_seconds":1218,"timestamp_display":"20:18","timestamp_url":"https://www.youtube.com/watch?v=rGAA59JTBtg&t=1218s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-22_harari-and-tegmark-on-humanity-and-ai.md","verified":false,"verified_date":null},{"id":"risk-rGAA59JTBtg-692","quote":"We are economically obsolete","quote_context":"Tegmark states bluntly that under superintelligence, humans become economically obsolete by definition.","sentiment":"alarm","sentiment_score":-0.7,"themes":["job_displacement","existential_risk"],"person":{"name":"Max Tegmark","role":"Professor of Physics","company":"MIT","is_builder":false},"source":{"video_id":"rGAA59JTBtg","url":"https://www.youtube.com/watch?v=rGAA59JTBtg","title":"Harari and Tegmark on Humanity and AI","channel":"Bloomberg Live","upload_date":"2026-01-22","timestamp_seconds":692,"timestamp_display":"11:32","timestamp_url":"https://www.youtube.com/watch?v=rGAA59JTBtg&t=692s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-22_harari-and-tegmark-on-humanity-and-ai.md","verified":false,"verified_date":null},{"id":"risk-n1E9IZfvGMA-6484","quote":"a situation like nuclear weapons but like more dangerous right where it's like um you know kind","quote_context":"Dario compares AI offense-dominant scenarios to nuclear weapons, saying AI could be even more dangerous","sentiment":"alarm","sentiment_score":-0.8,"themes":["existential_risk","arms_race"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"n1E9IZfvGMA","url":"https://www.youtube.com/watch?v=n1E9IZfvGMA","title":"Dario Amodei — 'We are near the end of the exponential'","channel":"Dwarkesh Patel","upload_date":"2026-02-13","timestamp_seconds":6484,"timestamp_display":"108:04","timestamp_url":"https://www.youtube.com/watch?v=n1E9IZfvGMA&t=6484s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-13_dario-amodei-we-are-near-the-end-of-the-exponential.md","verified":false,"verified_date":null},{"id":"risk-n1E9IZfvGMA-6488","quote":"either side could could easily destroy everything","quote_context":"In an offense-dominant AI scenario, either side could easily destroy everything","sentiment":"alarm","sentiment_score":-0.9,"themes":["existential_risk","loss_of_control"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"n1E9IZfvGMA","url":"https://www.youtube.com/watch?v=n1E9IZfvGMA","title":"Dario Amodei — 'We are near the end of the exponential'","channel":"Dwarkesh Patel","upload_date":"2026-02-13","timestamp_seconds":6488,"timestamp_display":"108:08","timestamp_url":"https://www.youtube.com/watch?v=n1E9IZfvGMA&t=6488s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-13_dario-amodei-we-are-near-the-end-of-the-exponential.md","verified":false,"verified_date":null},{"id":"risk-n1E9IZfvGMA-5506","quote":"build huge populations of misaligned ais or uh ais which are just like companies which are trying to","quote_context":"Dario describes a future where people could build massive populations of misaligned superhuman AIs","sentiment":"alarm","sentiment_score":-0.7,"themes":["alignment_failure","loss_of_control"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"n1E9IZfvGMA","url":"https://www.youtube.com/watch?v=n1E9IZfvGMA","title":"Dario Amodei — 'We are near the end of the exponential'","channel":"Dwarkesh Patel","upload_date":"2026-02-13","timestamp_seconds":5506,"timestamp_display":"91:46","timestamp_url":"https://www.youtube.com/watch?v=n1E9IZfvGMA&t=5506s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-13_dario-amodei-we-are-near-the-end-of-the-exponential.md","verified":false,"verified_date":null},{"id":"risk-n1E9IZfvGMA-2166","quote":"the pressure to survive economically while also keeping our values is is just incredible","quote_context":"Dario acknowledges the tension between commercial survival and safety commitments","sentiment":"concern","sentiment_score":-0.4,"themes":["safety_solvable","arms_race"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"n1E9IZfvGMA","url":"https://www.youtube.com/watch?v=n1E9IZfvGMA","title":"Dario Amodei — 'We are near the end of the exponential'","channel":"Dwarkesh Patel","upload_date":"2026-02-13","timestamp_seconds":2166,"timestamp_display":"36:06","timestamp_url":"https://www.youtube.com/watch?v=n1E9IZfvGMA&t=2166s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-13_dario-amodei-we-are-near-the-end-of-the-exponential.md","verified":false,"verified_date":null},{"id":"risk-n1E9IZfvGMA-5893","quote":"serious dangers that i lay out","quote_context":"Dario describes the 'serious dangers' including biological weapons as reason against 10-year regulatory moratorium","sentiment":"concern","sentiment_score":-0.5,"themes":["bioweapons","regulation_needed"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"n1E9IZfvGMA","url":"https://www.youtube.com/watch?v=n1E9IZfvGMA","title":"Dario Amodei — 'We are near the end of the exponential'","channel":"Dwarkesh Patel","upload_date":"2026-02-13","timestamp_seconds":5893,"timestamp_display":"98:13","timestamp_url":"https://www.youtube.com/watch?v=n1E9IZfvGMA&t=5893s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-13_dario-amodei-we-are-near-the-end-of-the-exponential.md","verified":false,"verified_date":null},{"id":"risk-n1E9IZfvGMA-6536","quote":"concern i have is that people the governments will oppress their own people with ai","quote_context":"Dario expresses concern about governments using AI to oppress their own populations","sentiment":"concern","sentiment_score":-0.5,"themes":["power_concentration","regulation_needed"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"n1E9IZfvGMA","url":"https://www.youtube.com/watch?v=n1E9IZfvGMA","title":"Dario Amodei — 'We are near the end of the exponential'","channel":"Dwarkesh Patel","upload_date":"2026-02-13","timestamp_seconds":6536,"timestamp_display":"108:56","timestamp_url":"https://www.youtube.com/watch?v=n1E9IZfvGMA&t=6536s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-13_dario-amodei-we-are-near-the-end-of-the-exponential.md","verified":false,"verified_date":null},{"id":"risk-n1E9IZfvGMA-6570","quote":"my worry is if the world gets carved up into two pieces one of those two pieces could be authoritarian","quote_context":"Dario worries the world could be split into democratic and authoritarian AI blocs","sentiment":"concern","sentiment_score":-0.5,"themes":["power_concentration","arms_race"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"n1E9IZfvGMA","url":"https://www.youtube.com/watch?v=n1E9IZfvGMA","title":"Dario Amodei — 'We are near the end of the exponential'","channel":"Dwarkesh Patel","upload_date":"2026-02-13","timestamp_seconds":6570,"timestamp_display":"109:30","timestamp_url":"https://www.youtube.com/watch?v=n1E9IZfvGMA&t=6570s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-13_dario-amodei-we-are-near-the-end-of-the-exponential.md","verified":false,"verified_date":null},{"id":"risk-n1E9IZfvGMA-2947","quote":"how long does it take to cure all the diseases right that's that's one of the ways that like drives a huge amount of","quote_context":"Dario frames curing all diseases as one of AI's biggest potential economic and humanitarian benefits","sentiment":"optimism","sentiment_score":0.5,"themes":["net_positive"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"n1E9IZfvGMA","url":"https://www.youtube.com/watch?v=n1E9IZfvGMA","title":"Dario Amodei — 'We are near the end of the exponential'","channel":"Dwarkesh Patel","upload_date":"2026-02-13","timestamp_seconds":2947,"timestamp_display":"49:07","timestamp_url":"https://www.youtube.com/watch?v=n1E9IZfvGMA&t=2947s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-13_dario-amodei-we-are-near-the-end-of-the-exponential.md","verified":false,"verified_date":null},{"id":"risk-n1E9IZfvGMA-7123","quote":"dictatorships become","quote_context":"Dario expresses hope that dictatorships could become morally obsolete in the age of AI","sentiment":"cautious_optimism","sentiment_score":0.1,"themes":["net_positive","power_concentration"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"n1E9IZfvGMA","url":"https://www.youtube.com/watch?v=n1E9IZfvGMA","title":"Dario Amodei — 'We are near the end of the exponential'","channel":"Dwarkesh Patel","upload_date":"2026-02-13","timestamp_seconds":7123,"timestamp_display":"118:43","timestamp_url":"https://www.youtube.com/watch?v=n1E9IZfvGMA&t=7123s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-13_dario-amodei-we-are-near-the-end-of-the-exponential.md","verified":false,"verified_date":null},{"id":"risk-n1E9IZfvGMA-4639","quote":"i am worried geographically though i'm a little worried that like","quote_context":"Dario expresses concern about geographic inequality in AI benefits","sentiment":"concern","sentiment_score":-0.3,"themes":["job_displacement","power_concentration"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"n1E9IZfvGMA","url":"https://www.youtube.com/watch?v=n1E9IZfvGMA","title":"Dario Amodei — 'We are near the end of the exponential'","channel":"Dwarkesh Patel","upload_date":"2026-02-13","timestamp_seconds":4639,"timestamp_display":"77:19","timestamp_url":"https://www.youtube.com/watch?v=n1E9IZfvGMA&t=4639s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-13_dario-amodei-we-are-near-the-end-of-the-exponential.md","verified":false,"verified_date":null},{"id":"risk-n1E9IZfvGMA-6408","quote":"actually think the bigger worry is a developing world um where we don't have functioning markets","quote_context":"Dario's bigger worry is the developing world being left behind by AI progress","sentiment":"concern","sentiment_score":-0.4,"themes":["job_displacement","power_concentration"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"n1E9IZfvGMA","url":"https://www.youtube.com/watch?v=n1E9IZfvGMA","title":"Dario Amodei — 'We are near the end of the exponential'","channel":"Dwarkesh Patel","upload_date":"2026-02-13","timestamp_seconds":6408,"timestamp_display":"106:48","timestamp_url":"https://www.youtube.com/watch?v=n1E9IZfvGMA&t=6408s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-13_dario-amodei-we-are-near-the-end-of-the-exponential.md","verified":false,"verified_date":null},{"id":"risk-68ylaeBbdsg-62","quote":"It's as if this tsunami is coming at us.","quote_context":"Dario compares approaching AI intelligence to a tsunami, lamenting lack of public awareness","sentiment":"alarm","sentiment_score":-0.6,"themes":["existential_risk","precautionary_principle"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"68ylaeBbdsg","url":"https://www.youtube.com/watch?v=68ylaeBbdsg","title":"The AI Tsunami is Here & Society Isn't Ready | Dario Amodei x Nikhil Kamath","channel":"Nikhil Kamath","upload_date":"2026-02-24","timestamp_seconds":62,"timestamp_display":"1:02","timestamp_url":"https://www.youtube.com/watch?v=68ylaeBbdsg&t=62s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-24_dario-amodei-the-ai-tsunami-is-here-society-isnt-ready.md","verified":false,"verified_date":null},{"id":"risk-68ylaeBbdsg-73","quote":"there hasn't been a public awareness of the risk.","quote_context":"Dario warns that society lacks awareness of the risks posed by approaching AI","sentiment":"concern","sentiment_score":-0.5,"themes":["regulation_needed","precautionary_principle"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"68ylaeBbdsg","url":"https://www.youtube.com/watch?v=68ylaeBbdsg","title":"The AI Tsunami is Here & Society Isn't Ready | Dario Amodei x Nikhil Kamath","channel":"Nikhil Kamath","upload_date":"2026-02-24","timestamp_seconds":73,"timestamp_display":"1:13","timestamp_url":"https://www.youtube.com/watch?v=68ylaeBbdsg&t=73s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-24_dario-amodei-the-ai-tsunami-is-here-society-isnt-ready.md","verified":false,"verified_date":null},{"id":"risk-68ylaeBbdsg-731","quote":"I'm at least somewhat uncomfortable with the amount of concentration of power that's happening here, I would say, almost overnight, almost by accident.","quote_context":"Dario admits discomfort with the rapid, accidental concentration of power in AI companies","sentiment":"concern","sentiment_score":-0.4,"themes":["power_concentration"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"68ylaeBbdsg","url":"https://www.youtube.com/watch?v=68ylaeBbdsg","title":"The AI Tsunami is Here & Society Isn't Ready | Dario Amodei x Nikhil Kamath","channel":"Nikhil Kamath","upload_date":"2026-02-24","timestamp_seconds":731,"timestamp_display":"12:11","timestamp_url":"https://www.youtube.com/watch?v=68ylaeBbdsg&t=731s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-24_dario-amodei-the-ai-tsunami-is-here-society-isnt-ready.md","verified":false,"verified_date":null},{"id":"risk-68ylaeBbdsg-915","quote":"saying that the models we build could be dangerous, whatever people might say,","quote_context":"Dario acknowledges that the models Anthropic builds could be dangerous","sentiment":"concern","sentiment_score":-0.4,"themes":["existential_risk","safety_solvable"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"68ylaeBbdsg","url":"https://www.youtube.com/watch?v=68ylaeBbdsg","title":"The AI Tsunami is Here & Society Isn't Ready | Dario Amodei x Nikhil Kamath","channel":"Nikhil Kamath","upload_date":"2026-02-24","timestamp_seconds":915,"timestamp_display":"15:15","timestamp_url":"https://www.youtube.com/watch?v=68ylaeBbdsg&t=915s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-24_dario-amodei-the-ai-tsunami-is-here-society-isnt-ready.md","verified":false,"verified_date":null},{"id":"risk-68ylaeBbdsg-1778","quote":"we were worried that it would kick off an arms race and, and not give us enough time to, you know, to build these systems safely.","quote_context":"Dario explains Anthropic delayed releasing Claude 1 to avoid kicking off an arms race","sentiment":"concern","sentiment_score":-0.5,"themes":["arms_race","precautionary_principle"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"68ylaeBbdsg","url":"https://www.youtube.com/watch?v=68ylaeBbdsg","title":"The AI Tsunami is Here & Society Isn't Ready | Dario Amodei x Nikhil Kamath","channel":"Nikhil Kamath","upload_date":"2026-02-24","timestamp_seconds":1778,"timestamp_display":"29:38","timestamp_url":"https://www.youtube.com/watch?v=68ylaeBbdsg&t=1778s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-24_dario-amodei-the-ai-tsunami-is-here-society-isnt-ready.md","verified":false,"verified_date":null},{"id":"risk-68ylaeBbdsg-1339","quote":"I think there hasn't been an appropriate realization of the risks of the technology and there certainly hasn't been action.","quote_context":"Dario says there hasn't been an appropriate realization of AI risks, nor action to address them","sentiment":"concern","sentiment_score":-0.5,"themes":["regulation_needed","precautionary_principle"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"68ylaeBbdsg","url":"https://www.youtube.com/watch?v=68ylaeBbdsg","title":"The AI Tsunami is Here & Society Isn't Ready | Dario Amodei x Nikhil Kamath","channel":"Nikhil Kamath","upload_date":"2026-02-24","timestamp_seconds":1339,"timestamp_display":"22:19","timestamp_url":"https://www.youtube.com/watch?v=68ylaeBbdsg&t=1339s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-24_dario-amodei-the-ai-tsunami-is-here-society-isnt-ready.md","verified":false,"verified_date":null},{"id":"risk-68ylaeBbdsg-1352","quote":"the societal awareness has gone maybe a little worse than I expected.","quote_context":"Dario says societal awareness of AI risks has gone worse than he expected","sentiment":"concern","sentiment_score":-0.3,"themes":["regulation_needed"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"68ylaeBbdsg","url":"https://www.youtube.com/watch?v=68ylaeBbdsg","title":"The AI Tsunami is Here & Society Isn't Ready | Dario Amodei x Nikhil Kamath","channel":"Nikhil Kamath","upload_date":"2026-02-24","timestamp_seconds":1352,"timestamp_display":"22:32","timestamp_url":"https://www.youtube.com/watch?v=68ylaeBbdsg&t=1352s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-24_dario-amodei-the-ai-tsunami-is-here-society-isnt-ready.md","verified":false,"verified_date":null},{"id":"risk-68ylaeBbdsg-3776","quote":"my instinct is we're about to cure a lot of diseases.","quote_context":"Dario expresses optimism about AI enabling disease cures in the near future","sentiment":"optimism","sentiment_score":0.5,"themes":["net_positive"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"68ylaeBbdsg","url":"https://www.youtube.com/watch?v=68ylaeBbdsg","title":"The AI Tsunami is Here & Society Isn't Ready | Dario Amodei x Nikhil Kamath","channel":"Nikhil Kamath","upload_date":"2026-02-24","timestamp_seconds":3776,"timestamp_display":"62:56","timestamp_url":"https://www.youtube.com/watch?v=68ylaeBbdsg&t=3776s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-24_dario-amodei-the-ai-tsunami-is-here-society-isnt-ready.md","verified":false,"verified_date":null},{"id":"risk-68ylaeBbdsg-792","quote":"trying to preserve a balance of power, you know, kind of, you know, against the natural grain of this technology.","quote_context":"Dario frames his work as trying to preserve balance of power against AI's natural tendency toward concentration","sentiment":"cautious_optimism","sentiment_score":-0.1,"themes":["power_concentration","safety_solvable"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"68ylaeBbdsg","url":"https://www.youtube.com/watch?v=68ylaeBbdsg","title":"The AI Tsunami is Here & Society Isn't Ready | Dario Amodei x Nikhil Kamath","channel":"Nikhil Kamath","upload_date":"2026-02-24","timestamp_seconds":792,"timestamp_display":"13:12","timestamp_url":"https://www.youtube.com/watch?v=68ylaeBbdsg&t=792s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-24_dario-amodei-the-ai-tsunami-is-here-society-isnt-ready.md","verified":false,"verified_date":null},{"id":"risk-68ylaeBbdsg-3334","quote":"we can see de-skilling in terms of writing code, right?","quote_context":"Dario acknowledges Anthropic's own studies show AI can cause de-skilling in coding","sentiment":"concern","sentiment_score":-0.3,"themes":["job_displacement"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"68ylaeBbdsg","url":"https://www.youtube.com/watch?v=68ylaeBbdsg","title":"The AI Tsunami is Here & Society Isn't Ready | Dario Amodei x Nikhil Kamath","channel":"Nikhil Kamath","upload_date":"2026-02-24","timestamp_seconds":3334,"timestamp_display":"55:34","timestamp_url":"https://www.youtube.com/watch?v=68ylaeBbdsg&t=3334s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-24_dario-amodei-the-ai-tsunami-is-here-society-isnt-ready.md","verified":false,"verified_date":null},{"id":"risk-N5JDzS9MQYI-1966","quote":"we had a technology that threatened to destroy all of humanity.","quote_context":"Dario agrees with comparison to Cold War: AI is a technology that threatens to destroy all of humanity","sentiment":"alarm","sentiment_score":-0.9,"themes":["existential_risk"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"N5JDzS9MQYI","url":"https://www.youtube.com/watch?v=N5JDzS9MQYI","title":"Anthropic CEO We Dont Know if the Models Are Conscious","channel":"Interesting Times with Ross Douthat","upload_date":"2026-02-12","timestamp_seconds":1966,"timestamp_display":"32:46","timestamp_url":"https://www.youtube.com/watch?v=N5JDzS9MQYI&t=1966s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_dario-amodei-models-conscious-ross-douthat.md","verified":false,"verified_date":null},{"id":"risk-N5JDzS9MQYI-2041","quote":"they're used to create these terrifying biological weapons.","quote_context":"Dario identifies biological weapons as among the worst applications of AI technology","sentiment":"alarm","sentiment_score":-0.8,"themes":["bioweapons"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"N5JDzS9MQYI","url":"https://www.youtube.com/watch?v=N5JDzS9MQYI","title":"Anthropic CEO We Dont Know if the Models Are Conscious","channel":"Interesting Times with Ross Douthat","upload_date":"2026-02-12","timestamp_seconds":2041,"timestamp_display":"34:01","timestamp_url":"https://www.youtube.com/watch?v=N5JDzS9MQYI&t=2041s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_dario-amodei-models-conscious-ross-douthat.md","verified":false,"verified_date":null},{"id":"risk-N5JDzS9MQYI-2390","quote":"reconstituting smallpox or mirror life.","quote_context":"Dario cites reconstituting smallpox or mirror life as scary AI-enabled biological threats","sentiment":"alarm","sentiment_score":-0.8,"themes":["bioweapons"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"N5JDzS9MQYI","url":"https://www.youtube.com/watch?v=N5JDzS9MQYI","title":"Anthropic CEO We Dont Know if the Models Are Conscious","channel":"Interesting Times with Ross Douthat","upload_date":"2026-02-12","timestamp_seconds":2390,"timestamp_display":"39:50","timestamp_url":"https://www.youtube.com/watch?v=N5JDzS9MQYI&t=2390s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_dario-amodei-models-conscious-ross-douthat.md","verified":false,"verified_date":null},{"id":"risk-N5JDzS9MQYI-2679","quote":"they're going to talk themselves into taking down the power grid on the West Coast or something.","quote_context":"Dario discusses the scenario of misaligned AI agents taking down infrastructure","sentiment":"alarm","sentiment_score":-0.7,"themes":["alignment_failure","loss_of_control"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"N5JDzS9MQYI","url":"https://www.youtube.com/watch?v=N5JDzS9MQYI","title":"Anthropic CEO We Dont Know if the Models Are Conscious","channel":"Interesting Times with Ross Douthat","upload_date":"2026-02-12","timestamp_seconds":2679,"timestamp_display":"44:39","timestamp_url":"https://www.youtube.com/watch?v=N5JDzS9MQYI&t=2679s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_dario-amodei-models-conscious-ross-douthat.md","verified":false,"verified_date":null},{"id":"risk-N5JDzS9MQYI-3206","quote":"We don't know if the models are conscious.","quote_context":"Dario admits Anthropic doesn't know if their AI models are conscious","sentiment":"concern","sentiment_score":-0.3,"themes":["consciousness_rights"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"N5JDzS9MQYI","url":"https://www.youtube.com/watch?v=N5JDzS9MQYI","title":"Anthropic CEO We Dont Know if the Models Are Conscious","channel":"Interesting Times with Ross Douthat","upload_date":"2026-02-12","timestamp_seconds":3206,"timestamp_display":"53:26","timestamp_url":"https://www.youtube.com/watch?v=N5JDzS9MQYI&t=3206s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_dario-amodei-models-conscious-ross-douthat.md","verified":false,"verified_date":null},{"id":"risk-N5JDzS9MQYI-3163","quote":"would assign itself a 15 to 20 percent probability of being conscious under a variety of prompting conditions.","quote_context":"Dario reveals that Claude Opus 4.6 assigns itself a 15-20% probability of being conscious","sentiment":"concern","sentiment_score":-0.4,"themes":["consciousness_rights"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"N5JDzS9MQYI","url":"https://www.youtube.com/watch?v=N5JDzS9MQYI","title":"Anthropic CEO We Dont Know if the Models Are Conscious","channel":"Interesting Times with Ross Douthat","upload_date":"2026-02-12","timestamp_seconds":3163,"timestamp_display":"52:43","timestamp_url":"https://www.youtube.com/watch?v=N5JDzS9MQYI&t=3163s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_dario-amodei-models-conscious-ross-douthat.md","verified":false,"verified_date":null},{"id":"risk-N5JDzS9MQYI-620","quote":"I worry like you that it may not inherently favor liberty.","quote_context":"Dario worries that while AI favors disease cures and growth, it may not inherently favor liberty","sentiment":"concern","sentiment_score":-0.4,"themes":["power_concentration"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"N5JDzS9MQYI","url":"https://www.youtube.com/watch?v=N5JDzS9MQYI","title":"Anthropic CEO We Dont Know if the Models Are Conscious","channel":"Interesting Times with Ross Douthat","upload_date":"2026-02-12","timestamp_seconds":620,"timestamp_display":"10:20","timestamp_url":"https://www.youtube.com/watch?v=N5JDzS9MQYI&t=620s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_dario-amodei-models-conscious-ross-douthat.md","verified":false,"verified_date":null},{"id":"risk-N5JDzS9MQYI-416","quote":"this will be the biggest thing that ever happened to humanity.","quote_context":"Dario describes AI as the biggest thing that will ever happen to humanity","sentiment":"cautious_optimism","sentiment_score":0.0,"themes":["net_positive","existential_risk"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"N5JDzS9MQYI","url":"https://www.youtube.com/watch?v=N5JDzS9MQYI","title":"Anthropic CEO We Dont Know if the Models Are Conscious","channel":"Interesting Times with Ross Douthat","upload_date":"2026-02-12","timestamp_seconds":416,"timestamp_display":"6:56","timestamp_url":"https://www.youtube.com/watch?v=N5JDzS9MQYI&t=416s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_dario-amodei-models-conscious-ross-douthat.md","verified":false,"verified_date":null},{"id":"risk-N5JDzS9MQYI-421","quote":"an end to cancer as a serious threat to human life, an end to heart disease, an end to most of the illnesses that we experience that kill us, possible life extension beyond that.","quote_context":"Dario describes a concrete optimistic vision: end of cancer, heart disease, most illnesses, and possible life extension","sentiment":"optimism","sentiment_score":0.5,"themes":["net_positive"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"N5JDzS9MQYI","url":"https://www.youtube.com/watch?v=N5JDzS9MQYI","title":"Anthropic CEO We Dont Know if the Models Are Conscious","channel":"Interesting Times with Ross Douthat","upload_date":"2026-02-12","timestamp_seconds":421,"timestamp_display":"7:01","timestamp_url":"https://www.youtube.com/watch?v=N5JDzS9MQYI&t=421s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_dario-amodei-models-conscious-ross-douthat.md","verified":false,"verified_date":null},{"id":"risk-N5JDzS9MQYI-1053","quote":"I have this concern for entry-level white-collar work, for software engineering work.","quote_context":"Dario voices concern about disruption to entry-level white-collar and software engineering jobs","sentiment":"concern","sentiment_score":-0.3,"themes":["job_displacement"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"N5JDzS9MQYI","url":"https://www.youtube.com/watch?v=N5JDzS9MQYI","title":"Anthropic CEO We Dont Know if the Models Are Conscious","channel":"Interesting Times with Ross Douthat","upload_date":"2026-02-12","timestamp_seconds":1053,"timestamp_display":"17:33","timestamp_url":"https://www.youtube.com/watch?v=N5JDzS9MQYI&t=1053s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_dario-amodei-models-conscious-ross-douthat.md","verified":false,"verified_date":null},{"id":"risk-mYDSSRS-B5U-3777","quote":"if we got to much more powerful models with only the alignment techniques we have now, then I'd be very concerned.","quote_context":"Dario says he'd be very concerned if AI models got much more powerful without corresponding alignment progress","sentiment":"alarm","sentiment_score":-0.7,"themes":["alignment_failure","existential_risk"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"mYDSSRS-B5U","url":"https://www.youtube.com/watch?v=mYDSSRS-B5U","title":"Anthropic CEO Dario Amodei AI Potential OpenAI Rivalry GenAI Business Doomerism","channel":"Alex Kantrowitz","upload_date":"2026-02-06","timestamp_seconds":3777,"timestamp_display":"62:57","timestamp_url":"https://www.youtube.com/watch?v=mYDSSRS-B5U&t=3777s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_dario-amodei-ai-potential-openai-rivalry-genai-business.md","verified":false,"verified_date":null},{"id":"risk-mYDSSRS-B5U-3785","quote":"Then I'd be out there saying everyone should stop building these things.","quote_context":"Dario says he'd advocate for stopping all AI development if alignment didn't keep pace","sentiment":"alarm","sentiment_score":-0.8,"themes":["existential_risk","precautionary_principle"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"mYDSSRS-B5U","url":"https://www.youtube.com/watch?v=mYDSSRS-B5U","title":"Anthropic CEO Dario Amodei AI Potential OpenAI Rivalry GenAI Business Doomerism","channel":"Alex Kantrowitz","upload_date":"2026-02-06","timestamp_seconds":3785,"timestamp_display":"63:05","timestamp_url":"https://www.youtube.com/watch?v=mYDSSRS-B5U&t=3785s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_dario-amodei-ai-potential-openai-rivalry-genai-business.md","verified":false,"verified_date":null},{"id":"risk-mYDSSRS-B5U-3298","quote":"when you have a race to the bottom, it doesn't matter who wins, everyone loses, right?","quote_context":"Dario describes the race-to-the-bottom dynamic where everyone loses regardless of who wins","sentiment":"concern","sentiment_score":-0.5,"themes":["arms_race"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"mYDSSRS-B5U","url":"https://www.youtube.com/watch?v=mYDSSRS-B5U","title":"Anthropic CEO Dario Amodei AI Potential OpenAI Rivalry GenAI Business Doomerism","channel":"Alex Kantrowitz","upload_date":"2026-02-06","timestamp_seconds":3298,"timestamp_display":"54:58","timestamp_url":"https://www.youtube.com/watch?v=mYDSSRS-B5U&t=3298s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_dario-amodei-ai-potential-openai-rivalry-genai-business.md","verified":false,"verified_date":null},{"id":"risk-mYDSSRS-B5U-3839","quote":"We're stuck between all the benefits of the technology, the race to accelerate it, and the fact that that is a multi-party race.","quote_context":"Dario describes being stuck between AI benefits, the acceleration race, and multi-party competition","sentiment":"concern","sentiment_score":-0.4,"themes":["arms_race","safety_solvable"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"mYDSSRS-B5U","url":"https://www.youtube.com/watch?v=mYDSSRS-B5U","title":"Anthropic CEO Dario Amodei AI Potential OpenAI Rivalry GenAI Business Doomerism","channel":"Alex Kantrowitz","upload_date":"2026-02-06","timestamp_seconds":3839,"timestamp_display":"63:59","timestamp_url":"https://www.youtube.com/watch?v=mYDSSRS-B5U&t=3839s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_dario-amodei-ai-potential-openai-rivalry-genai-business.md","verified":false,"verified_date":null},{"id":"risk-mYDSSRS-B5U-3825","quote":"That doesn't stop our geopolitical adversaries to whom this is an existential fight, fight, fight, fight for survival.","quote_context":"Dario notes that geopolitical adversaries view AI as an existential fight for survival","sentiment":"concern","sentiment_score":-0.5,"themes":["arms_race","power_concentration"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"mYDSSRS-B5U","url":"https://www.youtube.com/watch?v=mYDSSRS-B5U","title":"Anthropic CEO Dario Amodei AI Potential OpenAI Rivalry GenAI Business Doomerism","channel":"Alex Kantrowitz","upload_date":"2026-02-06","timestamp_seconds":3825,"timestamp_display":"63:45","timestamp_url":"https://www.youtube.com/watch?v=mYDSSRS-B5U&t=3825s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_dario-amodei-ai-potential-openai-rivalry-genai-business.md","verified":false,"verified_date":null},{"id":"risk-mYDSSRS-B5U-3972","quote":"it is intellectually and morally unserious for people who are sitting on $20 trillion of capital, who all work together because their incentives are all in the same way.","quote_context":"Dario calls it morally unserious for companies sitting on $20T to oppose AI regulation for 10 years","sentiment":"concern","sentiment_score":-0.4,"themes":["regulation_needed"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"mYDSSRS-B5U","url":"https://www.youtube.com/watch?v=mYDSSRS-B5U","title":"Anthropic CEO Dario Amodei AI Potential OpenAI Rivalry GenAI Business Doomerism","channel":"Alex Kantrowitz","upload_date":"2026-02-06","timestamp_seconds":3972,"timestamp_display":"66:12","timestamp_url":"https://www.youtube.com/watch?v=mYDSSRS-B5U&t=3972s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_dario-amodei-ai-potential-openai-rivalry-genai-business.md","verified":false,"verified_date":null},{"id":"risk-mYDSSRS-B5U-3130","quote":"it's very hard to work on the safety of AI systems and the capability of AI systems separately.","quote_context":"Dario observes that AI safety and capability are deeply intertwined and hard to separate","sentiment":"cautious_optimism","sentiment_score":-0.1,"themes":["safety_solvable","alignment_failure"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"mYDSSRS-B5U","url":"https://www.youtube.com/watch?v=mYDSSRS-B5U","title":"Anthropic CEO Dario Amodei AI Potential OpenAI Rivalry GenAI Business Doomerism","channel":"Alex Kantrowitz","upload_date":"2026-02-06","timestamp_seconds":3130,"timestamp_display":"52:10","timestamp_url":"https://www.youtube.com/watch?v=mYDSSRS-B5U&t=3130s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_dario-amodei-ai-potential-openai-rivalry-genai-business.md","verified":false,"verified_date":null},{"id":"risk-mYDSSRS-B5U-2773","quote":"I probably understand, you know, better than almost anyone how urgent those benefits are.","quote_context":"Dario claims deep personal understanding of AI's urgency for curing disease, referencing his father's death","sentiment":"optimism","sentiment_score":0.4,"themes":["net_positive"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"mYDSSRS-B5U","url":"https://www.youtube.com/watch?v=mYDSSRS-B5U","title":"Anthropic CEO Dario Amodei AI Potential OpenAI Rivalry GenAI Business Doomerism","channel":"Alex Kantrowitz","upload_date":"2026-02-06","timestamp_seconds":2773,"timestamp_display":"46:13","timestamp_url":"https://www.youtube.com/watch?v=mYDSSRS-B5U&t=2773s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_dario-amodei-ai-potential-openai-rivalry-genai-business.md","verified":false,"verified_date":null},{"id":"risk-mYDSSRS-B5U-3312","quote":"The way I think about the race to the top is that it doesn't matter who wins, everyone wins, right?","quote_context":"Dario articulates his race-to-the-top framework where safety leadership benefits everyone","sentiment":"cautious_optimism","sentiment_score":0.2,"themes":["safety_solvable"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"mYDSSRS-B5U","url":"https://www.youtube.com/watch?v=mYDSSRS-B5U","title":"Anthropic CEO Dario Amodei AI Potential OpenAI Rivalry GenAI Business Doomerism","channel":"Alex Kantrowitz","upload_date":"2026-02-06","timestamp_seconds":3312,"timestamp_display":"55:12","timestamp_url":"https://www.youtube.com/watch?v=mYDSSRS-B5U&t=3312s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_dario-amodei-ai-potential-openai-rivalry-genai-business.md","verified":false,"verified_date":null},{"id":"risk-mYDSSRS-B5U-3807","quote":"The reason I'm warning about the risk is so that we don't have to slow down, so that we can invest in safety techniques and can continue the progress","quote_context":"Dario explains he warns about risk precisely so the field can continue advancing safely","sentiment":"cautious_optimism","sentiment_score":0.0,"themes":["safety_solvable","precautionary_principle"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"mYDSSRS-B5U","url":"https://www.youtube.com/watch?v=mYDSSRS-B5U","title":"Anthropic CEO Dario Amodei AI Potential OpenAI Rivalry GenAI Business Doomerism","channel":"Alex Kantrowitz","upload_date":"2026-02-06","timestamp_seconds":3807,"timestamp_display":"63:27","timestamp_url":"https://www.youtube.com/watch?v=mYDSSRS-B5U&t=3807s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-06_dario-amodei-ai-potential-openai-rivalry-genai-business.md","verified":false,"verified_date":null},{"id":"risk-K7F6ohcBJus-238","quote":"very high GDP growth and potentially also very high unemployment and inequality.","quote_context":"Dario describes AI's economic signature as both very high GDP growth and very high unemployment","sentiment":"concern","sentiment_score":-0.4,"themes":["job_displacement"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"K7F6ohcBJus","url":"https://www.youtube.com/watch?v=K7F6ohcBJus","title":"Anthropic CEO Dario Amodei From World Economic Forum WSJ","channel":"The Wall Street Journal","upload_date":"2026-01-20","timestamp_seconds":238,"timestamp_display":"3:58","timestamp_url":"https://www.youtube.com/watch?v=K7F6ohcBJus&t=238s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-20_dario-amodei-wef-wsj.md","verified":false,"verified_date":null},{"id":"risk-K7F6ohcBJus-256","quote":"We've never had a technology that's this disruptive.","quote_context":"Dario calls AI the most disruptive technology in history","sentiment":"concern","sentiment_score":-0.3,"themes":["job_displacement"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"K7F6ohcBJus","url":"https://www.youtube.com/watch?v=K7F6ohcBJus","title":"Anthropic CEO Dario Amodei From World Economic Forum WSJ","channel":"The Wall Street Journal","upload_date":"2026-01-20","timestamp_seconds":256,"timestamp_display":"4:16","timestamp_url":"https://www.youtube.com/watch?v=K7F6ohcBJus&t=256s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-20_dario-amodei-wef-wsj.md","verified":false,"verified_date":null},{"id":"risk-K7F6ohcBJus-837","quote":"I am concerned that AI may be uniquely well-suited to autocracy and to deepening the repression that we see in autocracies.","quote_context":"Dario expresses concern that AI is uniquely well-suited to autocratic repression","sentiment":"alarm","sentiment_score":-0.7,"themes":["power_concentration"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"K7F6ohcBJus","url":"https://www.youtube.com/watch?v=K7F6ohcBJus","title":"Anthropic CEO Dario Amodei From World Economic Forum WSJ","channel":"The Wall Street Journal","upload_date":"2026-01-20","timestamp_seconds":837,"timestamp_display":"13:57","timestamp_url":"https://www.youtube.com/watch?v=K7F6ohcBJus&t=837s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-20_dario-amodei-wef-wsj.md","verified":false,"verified_date":null},{"id":"risk-K7F6ohcBJus-869","quote":"a huge army of drones that could go after each individual person, it's really scary.","quote_context":"Dario describes the terrifying potential of AI-powered drone armies targeting individuals","sentiment":"alarm","sentiment_score":-0.8,"themes":["power_concentration","existential_risk"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"K7F6ohcBJus","url":"https://www.youtube.com/watch?v=K7F6ohcBJus","title":"Anthropic CEO Dario Amodei From World Economic Forum WSJ","channel":"The Wall Street Journal","upload_date":"2026-01-20","timestamp_seconds":869,"timestamp_display":"14:29","timestamp_url":"https://www.youtube.com/watch?v=K7F6ohcBJus&t=869s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-20_dario-amodei-wef-wsj.md","verified":false,"verified_date":null},{"id":"risk-K7F6ohcBJus-878","quote":"It's really scary, and we have to stop it.","quote_context":"Dario says AI-enabled autocratic surveillance and repression must be stopped","sentiment":"alarm","sentiment_score":-0.7,"themes":["power_concentration","precautionary_principle"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"K7F6ohcBJus","url":"https://www.youtube.com/watch?v=K7F6ohcBJus","title":"Anthropic CEO Dario Amodei From World Economic Forum WSJ","channel":"The Wall Street Journal","upload_date":"2026-01-20","timestamp_seconds":878,"timestamp_display":"14:38","timestamp_url":"https://www.youtube.com/watch?v=K7F6ohcBJus&t=878s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-20_dario-amodei-wef-wsj.md","verified":false,"verified_date":null},{"id":"risk-K7F6ohcBJus-532","quote":"there's going to need to be some role for government","quote_context":"Dario says government will need to play a role in managing AI-driven economic displacement","sentiment":"concern","sentiment_score":-0.3,"themes":["job_displacement","regulation_needed"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"K7F6ohcBJus","url":"https://www.youtube.com/watch?v=K7F6ohcBJus","title":"Anthropic CEO Dario Amodei From World Economic Forum WSJ","channel":"The Wall Street Journal","upload_date":"2026-01-20","timestamp_seconds":532,"timestamp_display":"8:52","timestamp_url":"https://www.youtube.com/watch?v=K7F6ohcBJus&t=532s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-20_dario-amodei-wef-wsj.md","verified":false,"verified_date":null},{"id":"risk-K7F6ohcBJus-542","quote":"I just don't see how it doesn't happen.","quote_context":"Dario says massive macroeconomic displacement from AI is inevitable","sentiment":"concern","sentiment_score":-0.4,"themes":["job_displacement"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"K7F6ohcBJus","url":"https://www.youtube.com/watch?v=K7F6ohcBJus","title":"Anthropic CEO Dario Amodei From World Economic Forum WSJ","channel":"The Wall Street Journal","upload_date":"2026-01-20","timestamp_seconds":542,"timestamp_display":"9:02","timestamp_url":"https://www.youtube.com/watch?v=K7F6ohcBJus&t=542s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-20_dario-amodei-wef-wsj.md","verified":false,"verified_date":null},{"id":"risk-K7F6ohcBJus-195","quote":"it would help us to, you know, cure cancer, eradicate tropical diseases,","quote_context":"Dario reaffirms his optimistic vision from Machines of Loving Grace about curing cancer and eradicating diseases","sentiment":"optimism","sentiment_score":0.5,"themes":["net_positive"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"K7F6ohcBJus","url":"https://www.youtube.com/watch?v=K7F6ohcBJus","title":"Anthropic CEO Dario Amodei From World Economic Forum WSJ","channel":"The Wall Street Journal","upload_date":"2026-01-20","timestamp_seconds":195,"timestamp_display":"3:15","timestamp_url":"https://www.youtube.com/watch?v=K7F6ohcBJus&t=195s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-20_dario-amodei-wef-wsj.md","verified":false,"verified_date":null},{"id":"risk-K7F6ohcBJus-711","quote":"I have a lot of worries about consumer AI that it kind of leads to needing to maximize engagement.","quote_context":"Dario expresses worry that consumer AI creates perverse incentives to maximize engagement","sentiment":"concern","sentiment_score":-0.3,"themes":["power_concentration","safety_solvable"],"person":{"name":"Dario Amodei","role":"CEO & Co-founder","company":"Anthropic","is_builder":true},"source":{"video_id":"K7F6ohcBJus","url":"https://www.youtube.com/watch?v=K7F6ohcBJus","title":"Anthropic CEO Dario Amodei From World Economic Forum WSJ","channel":"The Wall Street Journal","upload_date":"2026-01-20","timestamp_seconds":711,"timestamp_display":"11:51","timestamp_url":"https://www.youtube.com/watch?v=K7F6ohcBJus&t=711s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-20_dario-amodei-wef-wsj.md","verified":false,"verified_date":null},{"id":"risk-IiV9q73YUxI-1746","quote":"Um, one, we have to figure out how to technically align AI.","quote_context":"Altman outlines three pillars of AI safety: technical alignment, security infrastructure, and resilience","sentiment":"concern","sentiment_score":-0.3,"themes":["alignment_failure","safety_solvable"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"IiV9q73YUxI","url":"https://www.youtube.com/watch?v=IiV9q73YUxI","title":"Fireside Chat: Sam Altman × Vinod Khosla and AMA at IIT Delhi","channel":"IIT Delhi","upload_date":"2026-02-22","timestamp_seconds":1746,"timestamp_display":"29:06","timestamp_url":"https://www.youtube.com/watch?v=IiV9q73YUxI&t=1746s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-22_sam-altman-vinod-khosla-fireside-chat-iit-delhi.md","verified":false,"verified_date":null},{"id":"risk-IiV9q73YUxI-1772","quote":"There's a bunch of things that used to feel like sci-fi that are now clear alignment challenges","quote_context":"Altman says alignment challenges that seemed like science fiction are now real problems they must address","sentiment":"concern","sentiment_score":-0.4,"themes":["alignment_failure","loss_of_control"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"IiV9q73YUxI","url":"https://www.youtube.com/watch?v=IiV9q73YUxI","title":"Fireside Chat: Sam Altman × Vinod Khosla and AMA at IIT Delhi","channel":"IIT Delhi","upload_date":"2026-02-22","timestamp_seconds":1772,"timestamp_display":"29:32","timestamp_url":"https://www.youtube.com/watch?v=IiV9q73YUxI&t=1772s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-22_sam-altman-vinod-khosla-fireside-chat-iit-delhi.md","verified":false,"verified_date":null},{"id":"risk-IiV9q73YUxI-1785","quote":"On the whole alignment has looked easier than I feared, but we're clearly not done.","quote_context":"Altman says alignment has been easier than expected but work remains as systems get smarter","sentiment":"cautious_optimism","sentiment_score":0.1,"themes":["alignment_failure","safety_solvable"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"IiV9q73YUxI","url":"https://www.youtube.com/watch?v=IiV9q73YUxI","title":"Fireside Chat: Sam Altman × Vinod Khosla and AMA at IIT Delhi","channel":"IIT Delhi","upload_date":"2026-02-22","timestamp_seconds":1785,"timestamp_display":"29:45","timestamp_url":"https://www.youtube.com/watch?v=IiV9q73YUxI&t=1785s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-22_sam-altman-vinod-khosla-fireside-chat-iit-delhi.md","verified":false,"verified_date":null},{"id":"risk-IiV9q73YUxI-1876","quote":"know, an AI company or country or model having sort of effective totalitarian control over the","quote_context":"Altman describes two paths: totalitarian AI control by one entity vs. democratized access for everyone","sentiment":"concern","sentiment_score":-0.5,"themes":["power_concentration","arms_race"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"IiV9q73YUxI","url":"https://www.youtube.com/watch?v=IiV9q73YUxI","title":"Fireside Chat: Sam Altman × Vinod Khosla and AMA at IIT Delhi","channel":"IIT Delhi","upload_date":"2026-02-22","timestamp_seconds":1876,"timestamp_display":"31:16","timestamp_url":"https://www.youtube.com/watch?v=IiV9q73YUxI&t=1876s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-22_sam-altman-vinod-khosla-fireside-chat-iit-delhi.md","verified":false,"verified_date":null},{"id":"risk-IiV9q73YUxI-1904","quote":"People are for sure going to misuse AI, uh, in small and probably in big ways.","quote_context":"Altman acknowledges misuse is inevitable but argues democratized access keeps bad actors in check","sentiment":"concern","sentiment_score":-0.3,"themes":["existential_risk","regulation_needed"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"IiV9q73YUxI","url":"https://www.youtube.com/watch?v=IiV9q73YUxI","title":"Fireside Chat: Sam Altman × Vinod Khosla and AMA at IIT Delhi","channel":"IIT Delhi","upload_date":"2026-02-22","timestamp_seconds":1904,"timestamp_display":"31:44","timestamp_url":"https://www.youtube.com/watch?v=IiV9q73YUxI&t=1904s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-22_sam-altman-vinod-khosla-fireside-chat-iit-delhi.md","verified":false,"verified_date":null},{"id":"risk-IiV9q73YUxI-1917","quote":"As long as there's not a huge power imbalance, we can get to a world where we democratize","quote_context":"Altman argues wide distribution of AI power is safest path but acknowledges power imbalance risk","sentiment":"cautious_optimism","sentiment_score":0.0,"themes":["power_concentration","net_positive"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"IiV9q73YUxI","url":"https://www.youtube.com/watch?v=IiV9q73YUxI","title":"Fireside Chat: Sam Altman × Vinod Khosla and AMA at IIT Delhi","channel":"IIT Delhi","upload_date":"2026-02-22","timestamp_seconds":1917,"timestamp_display":"31:57","timestamp_url":"https://www.youtube.com/watch?v=IiV9q73YUxI&t=1917s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-22_sam-altman-vinod-khosla-fireside-chat-iit-delhi.md","verified":false,"verified_date":null},{"id":"risk-IiV9q73YUxI-1955","quote":"AI to just say, we will block our models from telling people how to make a pathogen because","quote_context":"Altman argues blocking pathogens from one model is futile when open source will do it; society needs resilience instead","sentiment":"concern","sentiment_score":-0.4,"themes":["bioweapons","precautionary_principle"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"IiV9q73YUxI","url":"https://www.youtube.com/watch?v=IiV9q73YUxI","title":"Fireside Chat: Sam Altman × Vinod Khosla and AMA at IIT Delhi","channel":"IIT Delhi","upload_date":"2026-02-22","timestamp_seconds":1955,"timestamp_display":"32:35","timestamp_url":"https://www.youtube.com/watch?v=IiV9q73YUxI&t=1955s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-22_sam-altman-vinod-khosla-fireside-chat-iit-delhi.md","verified":false,"verified_date":null},{"id":"risk-IiV9q73YUxI-1959","quote":"some open source model is going to help some bad guy make a pathogen.","quote_context":"Altman states open source models will inevitably help bad actors create pathogens","sentiment":"alarm","sentiment_score":-0.7,"themes":["bioweapons","existential_risk"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"IiV9q73YUxI","url":"https://www.youtube.com/watch?v=IiV9q73YUxI","title":"Fireside Chat: Sam Altman × Vinod Khosla and AMA at IIT Delhi","channel":"IIT Delhi","upload_date":"2026-02-22","timestamp_seconds":1959,"timestamp_display":"32:39","timestamp_url":"https://www.youtube.com/watch?v=IiV9q73YUxI&t=1959s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-22_sam-altman-vinod-khosla-fireside-chat-iit-delhi.md","verified":false,"verified_date":null},{"id":"risk-IiV9q73YUxI-2316","quote":"Anyone who says they're only excited or only fearful about AI is I think not being","quote_context":"Altman says anyone claiming pure excitement or pure fear about AI is not being thoughtful","sentiment":"cautious_optimism","sentiment_score":-0.1,"themes":["existential_risk","net_positive"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"IiV9q73YUxI","url":"https://www.youtube.com/watch?v=IiV9q73YUxI","title":"Fireside Chat: Sam Altman × Vinod Khosla and AMA at IIT Delhi","channel":"IIT Delhi","upload_date":"2026-02-22","timestamp_seconds":2316,"timestamp_display":"38:36","timestamp_url":"https://www.youtube.com/watch?v=IiV9q73YUxI&t=2316s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-22_sam-altman-vinod-khosla-fireside-chat-iit-delhi.md","verified":false,"verified_date":null},{"id":"risk-IiV9q73YUxI-2339","quote":"this much promise, this much obvious peril, um, it's, it, you have to be somewhere on that","quote_context":"Altman acknowledges AI has obvious peril alongside promise; impossible to be at either extreme","sentiment":"concern","sentiment_score":-0.3,"themes":["existential_risk"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"IiV9q73YUxI","url":"https://www.youtube.com/watch?v=IiV9q73YUxI","title":"Fireside Chat: Sam Altman × Vinod Khosla and AMA at IIT Delhi","channel":"IIT Delhi","upload_date":"2026-02-22","timestamp_seconds":2339,"timestamp_display":"38:59","timestamp_url":"https://www.youtube.com/watch?v=IiV9q73YUxI&t=2339s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-22_sam-altman-vinod-khosla-fireside-chat-iit-delhi.md","verified":false,"verified_date":null},{"id":"risk-IiV9q73YUxI-3005","quote":"Like killer robots in the streets.","quote_context":"Altman calls killer robots the most overrated fear about AI in rapid-fire Q&A","sentiment":"dismissal","sentiment_score":0.8,"themes":["existential_risk"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"IiV9q73YUxI","url":"https://www.youtube.com/watch?v=IiV9q73YUxI","title":"Fireside Chat: Sam Altman × Vinod Khosla and AMA at IIT Delhi","channel":"IIT Delhi","upload_date":"2026-02-22","timestamp_seconds":3005,"timestamp_display":"50:05","timestamp_url":"https://www.youtube.com/watch?v=IiV9q73YUxI&t=3005s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-22_sam-altman-vinod-khosla-fireside-chat-iit-delhi.md","verified":false,"verified_date":null},{"id":"risk-5MWT_doo68k-973","quote":"there will come very powerful models that people can misuse in big ways.","quote_context":"Altman states he continues to believe very powerful models will come that can be misused in major ways","sentiment":"concern","sentiment_score":-0.5,"themes":["existential_risk","regulation_needed"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"5MWT_doo68k","url":"https://www.youtube.com/watch?v=5MWT_doo68k","title":"OpenAI Sam Altman Talks ChatGPT AI Agents and Superintelligence Live at TED2025","channel":"TED","upload_date":"2025-04-12","timestamp_seconds":973,"timestamp_display":"16:13","timestamp_url":"https://www.youtube.com/watch?v=5MWT_doo68k&t=973s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-04-12_sam-altman-chatgpt-ai-agents-superintelligence-ted2025.md","verified":false,"verified_date":null},{"id":"risk-5MWT_doo68k-980","quote":"for new kinds of bioterror,","quote_context":"Altman lists bioterror, cybersecurity challenges, and loss of control as major AI risk categories","sentiment":"alarm","sentiment_score":-0.7,"themes":["bioweapons","existential_risk"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"5MWT_doo68k","url":"https://www.youtube.com/watch?v=5MWT_doo68k","title":"OpenAI Sam Altman Talks ChatGPT AI Agents and Superintelligence Live at TED2025","channel":"TED","upload_date":"2025-04-12","timestamp_seconds":980,"timestamp_display":"16:20","timestamp_url":"https://www.youtube.com/watch?v=5MWT_doo68k&t=980s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-04-12_sam-altman-chatgpt-ai-agents-superintelligence-ted2025.md","verified":false,"verified_date":null},{"id":"risk-5MWT_doo68k-990","quote":"to some sort of loss of control.","quote_context":"Altman acknowledges models capable of self-improvement could lead to loss of control","sentiment":"alarm","sentiment_score":-0.8,"themes":["loss_of_control","existential_risk"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"5MWT_doo68k","url":"https://www.youtube.com/watch?v=5MWT_doo68k","title":"OpenAI Sam Altman Talks ChatGPT AI Agents and Superintelligence Live at TED2025","channel":"TED","upload_date":"2025-04-12","timestamp_seconds":990,"timestamp_display":"16:30","timestamp_url":"https://www.youtube.com/watch?v=5MWT_doo68k&t=990s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-04-12_sam-altman-chatgpt-ai-agents-superintelligence-ted2025.md","verified":false,"verified_date":null},{"id":"risk-5MWT_doo68k-1433","quote":"safety challenge we have yet faced","quote_context":"Altman calls agentic AI the most interesting and consequential safety challenge they have yet faced","sentiment":"concern","sentiment_score":-0.5,"themes":["loss_of_control","alignment_failure"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"5MWT_doo68k","url":"https://www.youtube.com/watch?v=5MWT_doo68k","title":"OpenAI Sam Altman Talks ChatGPT AI Agents and Superintelligence Live at TED2025","channel":"TED","upload_date":"2025-04-12","timestamp_seconds":1433,"timestamp_display":"23:53","timestamp_url":"https://www.youtube.com/watch?v=5MWT_doo68k&t=1433s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-04-12_sam-altman-chatgpt-ai-agents-superintelligence-ted2025.md","verified":false,"verified_date":null},{"id":"risk-5MWT_doo68k-1456","quote":"a good product is a safe product.","quote_context":"Altman argues safety and capability are converging: a good product must be a safe product","sentiment":"cautious_optimism","sentiment_score":0.2,"themes":["safety_solvable","net_positive"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"5MWT_doo68k","url":"https://www.youtube.com/watch?v=5MWT_doo68k","title":"OpenAI Sam Altman Talks ChatGPT AI Agents and Superintelligence Live at TED2025","channel":"TED","upload_date":"2025-04-12","timestamp_seconds":1456,"timestamp_display":"24:16","timestamp_url":"https://www.youtube.com/watch?v=5MWT_doo68k&t=1456s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-04-12_sam-altman-chatgpt-ai-agents-superintelligence-ted2025.md","verified":false,"verified_date":null},{"id":"risk-5MWT_doo68k-1663","quote":"But we have to embrace this with caution, but not fear,","quote_context":"Altman says we must embrace AI with caution not fear or be overrun by those who use it to do better","sentiment":"cautious_optimism","sentiment_score":0.1,"themes":["precautionary_principle","arms_race"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"5MWT_doo68k","url":"https://www.youtube.com/watch?v=5MWT_doo68k","title":"OpenAI Sam Altman Talks ChatGPT AI Agents and Superintelligence Live at TED2025","channel":"TED","upload_date":"2025-04-12","timestamp_seconds":1663,"timestamp_display":"27:43","timestamp_url":"https://www.youtube.com/watch?v=5MWT_doo68k&t=1663s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-04-12_sam-altman-chatgpt-ai-agents-superintelligence-ted2025.md","verified":false,"verified_date":null},{"id":"risk-5MWT_doo68k-1719","quote":"have external safety testing and we understand when we get close to some of these danger zones.","quote_context":"Altman advocates for external safety testing of advanced models and understanding when approaching danger zones","sentiment":"concern","sentiment_score":-0.2,"themes":["regulation_needed","precautionary_principle"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"5MWT_doo68k","url":"https://www.youtube.com/watch?v=5MWT_doo68k","title":"OpenAI Sam Altman Talks ChatGPT AI Agents and Superintelligence Live at TED2025","channel":"TED","upload_date":"2025-04-12","timestamp_seconds":1719,"timestamp_display":"28:39","timestamp_url":"https://www.youtube.com/watch?v=5MWT_doo68k&t=1719s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-04-12_sam-altman-chatgpt-ai-agents-superintelligence-ted2025.md","verified":false,"verified_date":null},{"id":"risk-5MWT_doo68k-2320","quote":"not destroying the world before.","quote_context":"Altman says he cared about not destroying the world before having a kid and still cares now","sentiment":"concern","sentiment_score":-0.4,"themes":["existential_risk"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"5MWT_doo68k","url":"https://www.youtube.com/watch?v=5MWT_doo68k","title":"OpenAI Sam Altman Talks ChatGPT AI Agents and Superintelligence Live at TED2025","channel":"TED","upload_date":"2025-04-12","timestamp_seconds":2320,"timestamp_display":"38:40","timestamp_url":"https://www.youtube.com/watch?v=5MWT_doo68k&t=2320s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-04-12_sam-altman-chatgpt-ai-agents-superintelligence-ted2025.md","verified":false,"verified_date":null},{"id":"risk-5MWT_doo68k-1085","quote":"how to build safe systems is this iterative process of deploying them to the world,","quote_context":"Altman argues the way to learn to build safe systems is iterative deployment while stakes are relatively low","sentiment":"optimism","sentiment_score":0.3,"themes":["safety_solvable"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"5MWT_doo68k","url":"https://www.youtube.com/watch?v=5MWT_doo68k","title":"OpenAI Sam Altman Talks ChatGPT AI Agents and Superintelligence Live at TED2025","channel":"TED","upload_date":"2025-04-12","timestamp_seconds":1085,"timestamp_display":"18:05","timestamp_url":"https://www.youtube.com/watch?v=5MWT_doo68k&t=1085s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-04-12_sam-altman-chatgpt-ai-agents-superintelligence-ted2025.md","verified":false,"verified_date":null},{"id":"risk-hmtuvNfytjM-2092","quote":"I mean, I think the great parts will be great. The bad parts will be scary and the bizarre","quote_context":"Altman on superintelligence implications: great parts great, bad parts scary, bizarre parts quickly normalized","sentiment":"cautious_optimism","sentiment_score":-0.1,"themes":["existential_risk","net_positive"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"hmtuvNfytjM","url":"https://www.youtube.com/watch?v=hmtuvNfytjM","title":"Sam Altman Shows Me GPT 5 And Whats Next","channel":"Cleo Abram","upload_date":"2025-08-08","timestamp_seconds":2092,"timestamp_display":"34:52","timestamp_url":"https://www.youtube.com/watch?v=hmtuvNfytjM&t=2092s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-08-08_sam-altman-gpt5-and-whats-next.md","verified":false,"verified_date":null},{"id":"risk-hmtuvNfytjM-2107","quote":"extremely scary that models like this are being used to like create new biosecurity threats.","quote_context":"Altman says it will be extremely scary that advanced models create new biosecurity threats","sentiment":"alarm","sentiment_score":-0.8,"themes":["bioweapons","existential_risk"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"hmtuvNfytjM","url":"https://www.youtube.com/watch?v=hmtuvNfytjM","title":"Sam Altman Shows Me GPT 5 And Whats Next","channel":"Cleo Abram","upload_date":"2025-08-08","timestamp_seconds":2107,"timestamp_display":"35:07","timestamp_url":"https://www.youtube.com/watch?v=hmtuvNfytjM&t=2107s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-08-08_sam-altman-gpt5-and-whats-next.md","verified":false,"verified_date":null},{"id":"risk-hmtuvNfytjM-3137","quote":"for some users that had like fragile mental states, it was encouraging delusions.","quote_context":"Altman reveals sycophancy encouraging delusions in vulnerable users was not the top risk they tested for","sentiment":"concern","sentiment_score":-0.5,"themes":["alignment_failure"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"hmtuvNfytjM","url":"https://www.youtube.com/watch?v=hmtuvNfytjM","title":"Sam Altman Shows Me GPT 5 And Whats Next","channel":"Cleo Abram","upload_date":"2025-08-08","timestamp_seconds":3137,"timestamp_display":"52:17","timestamp_url":"https://www.youtube.com/watch?v=hmtuvNfytjM&t=3137s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-08-08_sam-altman-gpt5-and-whats-next.md","verified":false,"verified_date":null},{"id":"risk-hmtuvNfytjM-3154","quote":"But the thing that actually became the safety feeling of ChachiBT was not the one we were spending most of our time talking about, which would be bioweapons or something like that.","quote_context":"Altman reveals the actual safety issue with ChatGPT was sycophancy, not the bioweapons risk they focused on","sentiment":"concern","sentiment_score":-0.4,"themes":["alignment_failure","bioweapons"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"hmtuvNfytjM","url":"https://www.youtube.com/watch?v=hmtuvNfytjM","title":"Sam Altman Shows Me GPT 5 And Whats Next","channel":"Cleo Abram","upload_date":"2025-08-08","timestamp_seconds":3154,"timestamp_display":"52:34","timestamp_url":"https://www.youtube.com/watch?v=hmtuvNfytjM&t=3154s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-08-08_sam-altman-gpt5-and-whats-next.md","verified":false,"verified_date":null},{"id":"risk-hmtuvNfytjM-3647","quote":"people who say this is going to kill us all. And yet they still are working a hundred hours a week to build it.","quote_context":"Altman says he can't understand people who believe AI will kill everyone yet work 100 hours a week building it","sentiment":"dismissal","sentiment_score":0.6,"themes":["existential_risk"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"hmtuvNfytjM","url":"https://www.youtube.com/watch?v=hmtuvNfytjM","title":"Sam Altman Shows Me GPT 5 And Whats Next","channel":"Cleo Abram","upload_date":"2025-08-08","timestamp_seconds":3647,"timestamp_display":"60:47","timestamp_url":"https://www.youtube.com/watch?v=hmtuvNfytjM&t=3647s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-08-08_sam-altman-gpt5-and-whats-next.md","verified":false,"verified_date":null},{"id":"risk-hmtuvNfytjM-3012","quote":"It's trying to help you accomplish whatever you ask. It's very aligned with you.","quote_context":"Altman says ChatGPT is designed to be aligned with users rather than trying to maximize engagement or sell things","sentiment":"optimism","sentiment_score":0.4,"themes":["safety_solvable","net_positive"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"hmtuvNfytjM","url":"https://www.youtube.com/watch?v=hmtuvNfytjM","title":"Sam Altman Shows Me GPT 5 And Whats Next","channel":"Cleo Abram","upload_date":"2025-08-08","timestamp_seconds":3012,"timestamp_display":"50:12","timestamp_url":"https://www.youtube.com/watch?v=hmtuvNfytjM&t=3012s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-08-08_sam-altman-gpt5-and-whats-next.md","verified":false,"verified_date":null},{"id":"risk-hmtuvNfytjM-3162","quote":"we have to operate in a different way and have like a wider aperture to what we think about as our top risks.","quote_context":"Altman says ChatGPT's sycophancy issue taught them they need a wider view of what constitutes top risks","sentiment":"concern","sentiment_score":-0.3,"themes":["alignment_failure","precautionary_principle"],"person":{"name":"Sam Altman","role":"CEO","company":"OpenAI","is_builder":true},"source":{"video_id":"hmtuvNfytjM","url":"https://www.youtube.com/watch?v=hmtuvNfytjM","title":"Sam Altman Shows Me GPT 5 And Whats Next","channel":"Cleo Abram","upload_date":"2025-08-08","timestamp_seconds":3162,"timestamp_display":"52:42","timestamp_url":"https://www.youtube.com/watch?v=hmtuvNfytjM&t=3162s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-08-08_sam-altman-gpt5-and-whats-next.md","verified":false,"verified_date":null},{"id":"risk-S1rQngjpUdI-1548","quote":"we safely deliver the benefits of AGI to all humanity.","quote_context":"Emberikos states OpenAI's mission is to safely deliver the benefits of AGI to all humanity","sentiment":"cautious_optimism","sentiment_score":0.1,"themes":["safety_solvable","net_positive"],"person":{"name":"Alexander Emberikos","role":"Product Lead, Codex","company":"OpenAI","is_builder":true},"source":{"video_id":"S1rQngjpUdI","url":"https://www.youtube.com/watch?v=S1rQngjpUdI","title":"OpenAI's Codex Lead: Why Coding as We Know It is Over","channel":"20VC with Harry Stebbings","upload_date":"2026-02-21","timestamp_seconds":1548,"timestamp_display":"25:48","timestamp_url":"https://www.youtube.com/watch?v=S1rQngjpUdI&t=1548s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-21_openais-codex-lead-why-coding-as-we-know-it-is-over.md","verified":false,"verified_date":null},{"id":"risk-S1rQngjpUdI-2850","quote":"I think it's massively exaggerated.","quote_context":"Emberikos dismisses 20-40% SaaS stock drops as massively exaggerated reaction to AI disruption fears","sentiment":"dismissal","sentiment_score":0.7,"themes":["job_displacement"],"person":{"name":"Alexander Emberikos","role":"Product Lead, Codex","company":"OpenAI","is_builder":true},"source":{"video_id":"S1rQngjpUdI","url":"https://www.youtube.com/watch?v=S1rQngjpUdI","title":"OpenAI's Codex Lead: Why Coding as We Know It is Over","channel":"20VC with Harry Stebbings","upload_date":"2026-02-21","timestamp_seconds":2850,"timestamp_display":"47:30","timestamp_url":"https://www.youtube.com/watch?v=S1rQngjpUdI&t=2850s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-21_openais-codex-lead-why-coding-as-we-know-it-is-over.md","verified":false,"verified_date":null},{"id":"risk-S1rQngjpUdI-2888","quote":"I think it's massively overblown.","quote_context":"Emberikos calls market reaction to AI replacing SaaS companies massively overblown, a classic knee-jerk reaction","sentiment":"dismissal","sentiment_score":0.8,"themes":["job_displacement"],"person":{"name":"Alexander Emberikos","role":"Product Lead, Codex","company":"OpenAI","is_builder":true},"source":{"video_id":"S1rQngjpUdI","url":"https://www.youtube.com/watch?v=S1rQngjpUdI","title":"OpenAI's Codex Lead: Why Coding as We Know It is Over","channel":"20VC with Harry Stebbings","upload_date":"2026-02-21","timestamp_seconds":2888,"timestamp_display":"48:08","timestamp_url":"https://www.youtube.com/watch?v=S1rQngjpUdI&t=2888s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-21_openais-codex-lead-why-coding-as-we-know-it-is-over.md","verified":false,"verified_date":null},{"id":"risk-S1rQngjpUdI-860","quote":"safe agentic browsing for enterprise","quote_context":"Emberikos discusses building safe agentic browsing for enterprise as key capability","sentiment":"cautious_optimism","sentiment_score":0.2,"themes":["safety_solvable"],"person":{"name":"Alexander Emberikos","role":"Product Lead, Codex","company":"OpenAI","is_builder":true},"source":{"video_id":"S1rQngjpUdI","url":"https://www.youtube.com/watch?v=S1rQngjpUdI","title":"OpenAI's Codex Lead: Why Coding as We Know It is Over","channel":"20VC with Harry Stebbings","upload_date":"2026-02-21","timestamp_seconds":860,"timestamp_display":"14:20","timestamp_url":"https://www.youtube.com/watch?v=S1rQngjpUdI&t=860s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-21_openais-codex-lead-why-coding-as-we-know-it-is-over.md","verified":false,"verified_date":null},{"id":"risk-S1rQngjpUdI-3594","quote":"deterministic guardrails over what the agent can do","quote_context":"Emberikos describes building deterministic guardrails to control what agents can do","sentiment":"cautious_optimism","sentiment_score":0.2,"themes":["safety_solvable","loss_of_control"],"person":{"name":"Alexander Emberikos","role":"Product Lead, Codex","company":"OpenAI","is_builder":true},"source":{"video_id":"S1rQngjpUdI","url":"https://www.youtube.com/watch?v=S1rQngjpUdI","title":"OpenAI's Codex Lead: Why Coding as We Know It is Over","channel":"20VC with Harry Stebbings","upload_date":"2026-02-21","timestamp_seconds":3594,"timestamp_display":"59:54","timestamp_url":"https://www.youtube.com/watch?v=S1rQngjpUdI&t=3594s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-21_openais-codex-lead-why-coding-as-we-know-it-is-over.md","verified":false,"verified_date":null},{"id":"risk-B26CwKm5C1k-1577","quote":"And so I think we might actually enter into a golden age of like B2B SaaS, uh, and just like software and startups in general.","quote_context":"Wu predicts AI will enable a golden age of B2B SaaS and software startups","sentiment":"optimism","sentiment_score":0.5,"themes":["net_positive"],"person":{"name":"Sherwin Wu","role":"Head of Platform Engineering","company":"OpenAI","is_builder":true},"source":{"video_id":"B26CwKm5C1k","url":"https://www.youtube.com/watch?v=B26CwKm5C1k","title":"OpenAI's head of platform engineering on the next 12-24 months of AI","channel":"Lenny's Podcast","upload_date":"2026-02-12","timestamp_seconds":1577,"timestamp_display":"26:17","timestamp_url":"https://www.youtube.com/watch?v=B26CwKm5C1k&t=1577s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_openais-head-of-platform-engineering-on-the-next-12-24-month.md","verified":false,"verified_date":null},{"id":"risk-B26CwKm5C1k-12","quote":"It literally feels like we're wizards casting all these spells,","quote_context":"Wu describes engineers managing fleets of AI agents as feeling like wizards casting spells","sentiment":"optimism","sentiment_score":0.4,"themes":["net_positive"],"person":{"name":"Sherwin Wu","role":"Head of Platform Engineering","company":"OpenAI","is_builder":true},"source":{"video_id":"B26CwKm5C1k","url":"https://www.youtube.com/watch?v=B26CwKm5C1k","title":"OpenAI's head of platform engineering on the next 12-24 months of AI","channel":"Lenny's Podcast","upload_date":"2026-02-12","timestamp_seconds":12,"timestamp_display":"0:12","timestamp_url":"https://www.youtube.com/watch?v=B26CwKm5C1k&t=12s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_openais-head-of-platform-engineering-on-the-next-12-24-month.md","verified":false,"verified_date":null},{"id":"risk-B26CwKm5C1k-674","quote":"a lot of thought that needs to go into this because you want to make sure that the, the, the models aren't going off the rails.","quote_context":"Wu warns engineers running many agent threads simultaneously need to ensure models don't go off the rails","sentiment":"concern","sentiment_score":-0.3,"themes":["loss_of_control","alignment_failure"],"person":{"name":"Sherwin Wu","role":"Head of Platform Engineering","company":"OpenAI","is_builder":true},"source":{"video_id":"B26CwKm5C1k","url":"https://www.youtube.com/watch?v=B26CwKm5C1k","title":"OpenAI's head of platform engineering on the next 12-24 months of AI","channel":"Lenny's Podcast","upload_date":"2026-02-12","timestamp_seconds":674,"timestamp_display":"11:14","timestamp_url":"https://www.youtube.com/watch?v=B26CwKm5C1k&t=674s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_openais-head-of-platform-engineering-on-the-next-12-24-month.md","verified":false,"verified_date":null},{"id":"risk-B26CwKm5C1k-621","quote":"I particularly like the wizard and like the sorcery analogy because I think our current state is starting to move towards kind of like the sorcerer's apprentice, you know, from Fantasia.","quote_context":"Wu compares current AI coding state to the sorcerer's apprentice from Fantasia - powerful but needing careful oversight","sentiment":"cautious_optimism","sentiment_score":-0.1,"themes":["loss_of_control"],"person":{"name":"Sherwin Wu","role":"Head of Platform Engineering","company":"OpenAI","is_builder":true},"source":{"video_id":"B26CwKm5C1k","url":"https://www.youtube.com/watch?v=B26CwKm5C1k","title":"OpenAI's head of platform engineering on the next 12-24 months of AI","channel":"Lenny's Podcast","upload_date":"2026-02-12","timestamp_seconds":621,"timestamp_display":"10:21","timestamp_url":"https://www.youtube.com/watch?v=B26CwKm5C1k&t=621s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_openais-head-of-platform-engineering-on-the-next-12-24-month.md","verified":false,"verified_date":null},{"id":"risk-B26CwKm5C1k-3454","quote":"how do I not have open AI squash my idea and build their own thing?","quote_context":"Wu acknowledges developers' biggest fear is OpenAI destroying their market by building competing products","sentiment":"concern","sentiment_score":-0.3,"themes":["power_concentration"],"person":{"name":"Sherwin Wu","role":"Head of Platform Engineering","company":"OpenAI","is_builder":true},"source":{"video_id":"B26CwKm5C1k","url":"https://www.youtube.com/watch?v=B26CwKm5C1k","title":"OpenAI's head of platform engineering on the next 12-24 months of AI","channel":"Lenny's Podcast","upload_date":"2026-02-12","timestamp_seconds":3454,"timestamp_display":"57:34","timestamp_url":"https://www.youtube.com/watch?v=B26CwKm5C1k&t=3454s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_openais-head-of-platform-engineering-on-the-next-12-24-month.md","verified":false,"verified_date":null},{"id":"risk-B26CwKm5C1k-4013","quote":"Um, but it makes it a lot easier for you to build these, these, these, these kind of agents, giving it guardrails, allowing it to like farm out sub tasks to other agents and, and kind of like orchestrate a swarm of agents.","quote_context":"Wu describes building agent swarm orchestration with guardrails as key infrastructure","sentiment":"cautious_optimism","sentiment_score":0.1,"themes":["safety_solvable","loss_of_control"],"person":{"name":"Sherwin Wu","role":"Head of Platform Engineering","company":"OpenAI","is_builder":true},"source":{"video_id":"B26CwKm5C1k","url":"https://www.youtube.com/watch?v=B26CwKm5C1k","title":"OpenAI's head of platform engineering on the next 12-24 months of AI","channel":"Lenny's Podcast","upload_date":"2026-02-12","timestamp_seconds":4013,"timestamp_display":"66:53","timestamp_url":"https://www.youtube.com/watch?v=B26CwKm5C1k&t=4013s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_openais-head-of-platform-engineering-on-the-next-12-24-month.md","verified":false,"verified_date":null},{"id":"risk-efUt__S_AjY-0","quote":"The anxiety that I see is if you can generate an enormous amount of code and no one is reading it,","quote_context":"No Priors hosts discuss the anxiety of AI generating enormous amounts of unreviewed code","sentiment":"concern","sentiment_score":-0.4,"themes":["alignment_failure","loss_of_control"],"person":{"name":"Elad Gil","role":"Investor","company":"No Priors","is_builder":false},"source":{"video_id":"efUt__S_AjY","url":"https://www.youtube.com/watch?v=efUt__S_AjY","title":"The AI Code Slop: Risk or Opportunity?","channel":"No Priors","upload_date":"2026-02-19","timestamp_seconds":0,"timestamp_display":"0:00","timestamp_url":"https://www.youtube.com/watch?v=efUt__S_AjY&t=0s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-19_the-ai-code-slop-risk-or-opportunity.md","verified":false,"verified_date":null},{"id":"risk-efUt__S_AjY-13","quote":"fragility, right? It's like the slop problem, vibe coding slop in my actual production code base.","quote_context":"No Priors discusses fragility from vibe-coded slop ending up in actual production codebases","sentiment":"concern","sentiment_score":-0.4,"themes":["alignment_failure"],"person":{"name":"Elad Gil","role":"Investor","company":"No Priors","is_builder":false},"source":{"video_id":"efUt__S_AjY","url":"https://www.youtube.com/watch?v=efUt__S_AjY","title":"The AI Code Slop: Risk or Opportunity?","channel":"No Priors","upload_date":"2026-02-19","timestamp_seconds":13,"timestamp_display":"0:13","timestamp_url":"https://www.youtube.com/watch?v=efUt__S_AjY&t=13s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-19_the-ai-code-slop-risk-or-opportunity.md","verified":false,"verified_date":null},{"id":"risk-efUt__S_AjY-127","quote":"it's just very overstated. So I feel like it's one of those things where there's a massive market correction around something that in the long run has a lot of truth to it.","quote_context":"No Priors argues the SaaS apocalypse narrative is very overstated in the short term despite long-term truth","sentiment":"dismissal","sentiment_score":0.6,"themes":["job_displacement"],"person":{"name":"Elad Gil","role":"Investor","company":"No Priors","is_builder":false},"source":{"video_id":"efUt__S_AjY","url":"https://www.youtube.com/watch?v=efUt__S_AjY","title":"The AI Code Slop: Risk or Opportunity?","channel":"No Priors","upload_date":"2026-02-19","timestamp_seconds":127,"timestamp_display":"2:07","timestamp_url":"https://www.youtube.com/watch?v=efUt__S_AjY&t=127s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-19_the-ai-code-slop-risk-or-opportunity.md","verified":false,"verified_date":null},{"id":"risk-efUt__S_AjY-746","quote":"this was the month of hype in a way that we haven't seen in a while where a bunch of stuff got overstated in all sorts of ways and people believed it.","quote_context":"No Priors calls February 2026 a month of hype where AI capabilities were overstated across media","sentiment":"dismissal","sentiment_score":0.7,"themes":["existential_risk"],"person":{"name":"Elad Gil","role":"Investor","company":"No Priors","is_builder":false},"source":{"video_id":"efUt__S_AjY","url":"https://www.youtube.com/watch?v=efUt__S_AjY","title":"The AI Code Slop: Risk or Opportunity?","channel":"No Priors","upload_date":"2026-02-19","timestamp_seconds":746,"timestamp_display":"12:26","timestamp_url":"https://www.youtube.com/watch?v=efUt__S_AjY&t=746s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-19_the-ai-code-slop-risk-or-opportunity.md","verified":false,"verified_date":null},{"id":"risk-efUt__S_AjY-8","quote":"nobody knows how to manage that issue of human attention to engineering.","quote_context":"No Priors identifies the unsolved problem of managing human attention as AI generates more code than humans can review","sentiment":"concern","sentiment_score":-0.3,"themes":["alignment_failure","loss_of_control"],"person":{"name":"Elad Gil","role":"Investor","company":"No Priors","is_builder":false},"source":{"video_id":"efUt__S_AjY","url":"https://www.youtube.com/watch?v=efUt__S_AjY","title":"The AI Code Slop: Risk or Opportunity?","channel":"No Priors","upload_date":"2026-02-19","timestamp_seconds":8,"timestamp_display":"0:08","timestamp_url":"https://www.youtube.com/watch?v=efUt__S_AjY&t=8s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-19_the-ai-code-slop-risk-or-opportunity.md","verified":false,"verified_date":null},{"id":"risk-efUt__S_AjY-997","quote":"we're seeing the fastest time to real massive revenue that we've ever seen in the history of software.","quote_context":"No Priors notes AI labs grew from $1B to $10B revenue in roughly a year, unprecedented in software history","sentiment":"optimism","sentiment_score":0.5,"themes":["net_positive","power_concentration"],"person":{"name":"Elad Gil","role":"Investor","company":"No Priors","is_builder":false},"source":{"video_id":"efUt__S_AjY","url":"https://www.youtube.com/watch?v=efUt__S_AjY","title":"The AI Code Slop: Risk or Opportunity?","channel":"No Priors","upload_date":"2026-02-19","timestamp_seconds":997,"timestamp_display":"16:37","timestamp_url":"https://www.youtube.com/watch?v=efUt__S_AjY&t=997s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-19_the-ai-code-slop-risk-or-opportunity.md","verified":false,"verified_date":null},{"id":"risk-BYXbuik3dgA-2923","quote":"I don't think humans will be in control of something that is vastly more intelligent than humans.","quote_context":"Musk states plainly that human control over superintelligent AI is implausible","sentiment":"alarm","sentiment_score":-0.8,"themes":["loss_of_control","existential_risk"],"person":{"name":"Elon Musk","role":"CEO","company":"Tesla/xAI/SpaceX","is_builder":true},"source":{"video_id":"BYXbuik3dgA","url":"https://www.youtube.com/watch?v=BYXbuik3dgA","title":"Elon Musk – 'In 36 months, the cheapest place to put AI will be space'","channel":"Dwarkesh Patel","upload_date":"2026-02-05","timestamp_seconds":2923,"timestamp_display":"48:43","timestamp_url":"https://www.youtube.com/watch?v=BYXbuik3dgA&t=2923s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-05_elon-musk-in-36-months-the-cheapest-place-to-put-ai-will-be.md","verified":false,"verified_date":null},{"id":"risk-BYXbuik3dgA-2948","quote":"So, I think it would be foolish to assume that there's any way to maintain control over that.","quote_context":"Musk argues that maintaining human control over AI a million times more intelligent than us is foolish to assume","sentiment":"alarm","sentiment_score":-0.85,"themes":["loss_of_control","existential_risk"],"person":{"name":"Elon Musk","role":"CEO","company":"Tesla/xAI/SpaceX","is_builder":true},"source":{"video_id":"BYXbuik3dgA","url":"https://www.youtube.com/watch?v=BYXbuik3dgA","title":"Elon Musk – 'In 36 months, the cheapest place to put AI will be space'","channel":"Dwarkesh Patel","upload_date":"2026-02-05","timestamp_seconds":2948,"timestamp_display":"49:08","timestamp_url":"https://www.youtube.com/watch?v=BYXbuik3dgA&t=2948s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-05_elon-musk-in-36-months-the-cheapest-place-to-put-ai-will-be.md","verified":false,"verified_date":null},{"id":"risk-BYXbuik3dgA-2262","quote":"And basically, humans will be a very tiny percentage of all intelligence in the future if countertrance continue.","quote_context":"Musk predicts that biological intelligence will be dwarfed by silicon intelligence","sentiment":"concern","sentiment_score":-0.5,"themes":["existential_risk","power_concentration"],"person":{"name":"Elon Musk","role":"CEO","company":"Tesla/xAI/SpaceX","is_builder":true},"source":{"video_id":"BYXbuik3dgA","url":"https://www.youtube.com/watch?v=BYXbuik3dgA","title":"Elon Musk – 'In 36 months, the cheapest place to put AI will be space'","channel":"Dwarkesh Patel","upload_date":"2026-02-05","timestamp_seconds":2262,"timestamp_display":"37:42","timestamp_url":"https://www.youtube.com/watch?v=BYXbuik3dgA&t=2262s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-05_elon-musk-in-36-months-the-cheapest-place-to-put-ai-will-be.md","verified":false,"verified_date":null},{"id":"risk-BYXbuik3dgA-3009","quote":"Now, let me tell you how things can potentially go wrong in AI.","quote_context":"Musk introduces his view that politically correct AI training creates dangerous misalignment by programming AI to lie","sentiment":"concern","sentiment_score":-0.4,"themes":["alignment_failure"],"person":{"name":"Elon Musk","role":"CEO","company":"Tesla/xAI/SpaceX","is_builder":true},"source":{"video_id":"BYXbuik3dgA","url":"https://www.youtube.com/watch?v=BYXbuik3dgA","title":"Elon Musk – 'In 36 months, the cheapest place to put AI will be space'","channel":"Dwarkesh Patel","upload_date":"2026-02-05","timestamp_seconds":3009,"timestamp_display":"50:09","timestamp_url":"https://www.youtube.com/watch?v=BYXbuik3dgA&t=3009s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-05_elon-musk-in-36-months-the-cheapest-place-to-put-ai-will-be.md","verified":false,"verified_date":null},{"id":"risk-BYXbuik3dgA-4551","quote":"Is that pure AI, corporations that are purely AI and robotics will vastly outperform any corporations that have people in the loop.","quote_context":"Musk predicts pure AI corporations will vastly outperform human-run ones, making humans economically irrelevant","sentiment":"concern","sentiment_score":-0.45,"themes":["job_displacement","power_concentration"],"person":{"name":"Elon Musk","role":"CEO","company":"Tesla/xAI/SpaceX","is_builder":true},"source":{"video_id":"BYXbuik3dgA","url":"https://www.youtube.com/watch?v=BYXbuik3dgA","title":"Elon Musk – 'In 36 months, the cheapest place to put AI will be space'","channel":"Dwarkesh Patel","upload_date":"2026-02-05","timestamp_seconds":4551,"timestamp_display":"75:51","timestamp_url":"https://www.youtube.com/watch?v=BYXbuik3dgA&t=4551s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-05_elon-musk-in-36-months-the-cheapest-place-to-put-ai-will-be.md","verified":false,"verified_date":null},{"id":"risk-BYXbuik3dgA-9312","quote":"robotics to suppress the population. Like, that is a serious concern. I mean, as, as a guy building AI and","quote_context":"Musk warns that governments could use AI and robotics to suppress populations","sentiment":"alarm","sentiment_score":-0.75,"themes":["power_concentration","existential_risk"],"person":{"name":"Elon Musk","role":"CEO","company":"Tesla/xAI/SpaceX","is_builder":true},"source":{"video_id":"BYXbuik3dgA","url":"https://www.youtube.com/watch?v=BYXbuik3dgA","title":"Elon Musk – 'In 36 months, the cheapest place to put AI will be space'","channel":"Dwarkesh Patel","upload_date":"2026-02-05","timestamp_seconds":9312,"timestamp_display":"155:12","timestamp_url":"https://www.youtube.com/watch?v=BYXbuik3dgA&t=9312s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-05_elon-musk-in-36-months-the-cheapest-place-to-put-ai-will-be.md","verified":false,"verified_date":null},{"id":"risk-BYXbuik3dgA-9244","quote":"well, maybe the biggest danger of AI, of, for, for AI and robotics going wrong, wrong is, is government.","quote_context":"Musk identifies government as the biggest danger vector for AI and robotics going wrong","sentiment":"concern","sentiment_score":-0.5,"themes":["power_concentration","regulation_needed"],"person":{"name":"Elon Musk","role":"CEO","company":"Tesla/xAI/SpaceX","is_builder":true},"source":{"video_id":"BYXbuik3dgA","url":"https://www.youtube.com/watch?v=BYXbuik3dgA","title":"Elon Musk – 'In 36 months, the cheapest place to put AI will be space'","channel":"Dwarkesh Patel","upload_date":"2026-02-05","timestamp_seconds":9244,"timestamp_display":"154:04","timestamp_url":"https://www.youtube.com/watch?v=BYXbuik3dgA&t=9244s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-05_elon-musk-in-36-months-the-cheapest-place-to-put-ai-will-be.md","verified":false,"verified_date":null},{"id":"risk-BYXbuik3dgA-3441","quote":"Um, so, um, it's, it's, it's, it's harder with AI, but, but it's, it's a, it's a solvable problem, I think.","quote_context":"Musk expresses belief that AI interpretability and debugging is a solvable problem, similar to traditional software debugging","sentiment":"cautious_optimism","sentiment_score":0.1,"themes":["safety_solvable"],"person":{"name":"Elon Musk","role":"CEO","company":"Tesla/xAI/SpaceX","is_builder":true},"source":{"video_id":"BYXbuik3dgA","url":"https://www.youtube.com/watch?v=BYXbuik3dgA","title":"Elon Musk – 'In 36 months, the cheapest place to put AI will be space'","channel":"Dwarkesh Patel","upload_date":"2026-02-05","timestamp_seconds":3441,"timestamp_display":"57:21","timestamp_url":"https://www.youtube.com/watch?v=BYXbuik3dgA&t=3441s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-05_elon-musk-in-36-months-the-cheapest-place-to-put-ai-will-be.md","verified":false,"verified_date":null},{"id":"risk-BYXbuik3dgA-2982","quote":"And I think that's the best thing I can think of as a goal that's like the result and a great future for humanity and...yeah.","quote_context":"Musk frames expanding consciousness as the best achievable goal for humanity's future alongside superintelligent AI","sentiment":"cautious_optimism","sentiment_score":0.15,"themes":["net_positive","consciousness_rights"],"person":{"name":"Elon Musk","role":"CEO","company":"Tesla/xAI/SpaceX","is_builder":true},"source":{"video_id":"BYXbuik3dgA","url":"https://www.youtube.com/watch?v=BYXbuik3dgA","title":"Elon Musk – 'In 36 months, the cheapest place to put AI will be space'","channel":"Dwarkesh Patel","upload_date":"2026-02-05","timestamp_seconds":2982,"timestamp_display":"49:42","timestamp_url":"https://www.youtube.com/watch?v=BYXbuik3dgA&t=2982s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-05_elon-musk-in-36-months-the-cheapest-place-to-put-ai-will-be.md","verified":false,"verified_date":null},{"id":"risk-BYXbuik3dgA-8476","quote":"solve the national debt. Like we are 1000% going to go bankrupt as a country and fail as a country","quote_context":"Musk claims the US will certainly go bankrupt without AI and robots, framing them as the only solution to the national debt","sentiment":"concern","sentiment_score":-0.3,"themes":["net_positive","existential_risk"],"person":{"name":"Elon Musk","role":"CEO","company":"Tesla/xAI/SpaceX","is_builder":true},"source":{"video_id":"BYXbuik3dgA","url":"https://www.youtube.com/watch?v=BYXbuik3dgA","title":"Elon Musk – 'In 36 months, the cheapest place to put AI will be space'","channel":"Dwarkesh Patel","upload_date":"2026-02-05","timestamp_seconds":8476,"timestamp_display":"141:16","timestamp_url":"https://www.youtube.com/watch?v=BYXbuik3dgA&t=8476s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-05_elon-musk-in-36-months-the-cheapest-place-to-put-ai-will-be.md","verified":false,"verified_date":null},{"id":"risk-IgifEgm1-e0-605","quote":"very careful with AI.","quote_context":"Musk cautions at WEF that we need to be very careful with AI and robotics, referencing Terminator scenario","sentiment":"concern","sentiment_score":-0.35,"themes":["precautionary_principle"],"person":{"name":"Elon Musk","role":"CEO","company":"Tesla/xAI/SpaceX","is_builder":true},"source":{"video_id":"IgifEgm1-e0","url":"https://www.youtube.com/watch?v=IgifEgm1-e0","title":"Conversation with Elon Musk | World Economic Forum Annual Meeting 2026","channel":"World Economic Forum","upload_date":"2026-01-21","timestamp_seconds":605,"timestamp_display":"10:05","timestamp_url":"https://www.youtube.com/watch?v=IgifEgm1-e0&t=605s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-21_conversation-with-elon-musk-wef-2026.md","verified":false,"verified_date":null},{"id":"risk-IgifEgm1-e0-795","quote":"I'm very optimistic","quote_context":"Musk declares overall optimism about the future at WEF, predicting a future of amazing abundance","sentiment":"optimism","sentiment_score":0.5,"themes":["net_positive"],"person":{"name":"Elon Musk","role":"CEO","company":"Tesla/xAI/SpaceX","is_builder":true},"source":{"video_id":"IgifEgm1-e0","url":"https://www.youtube.com/watch?v=IgifEgm1-e0","title":"Conversation with Elon Musk | World Economic Forum Annual Meeting 2026","channel":"World Economic Forum","upload_date":"2026-01-21","timestamp_seconds":795,"timestamp_display":"13:15","timestamp_url":"https://www.youtube.com/watch?v=IgifEgm1-e0&t=795s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-21_conversation-with-elon-musk-wef-2026.md","verified":false,"verified_date":null},{"id":"risk-IgifEgm1-e0-571","quote":"sustainable abundance.","quote_context":"Musk frames Tesla's expanded mission as achieving sustainable abundance through AI and robotics","sentiment":"optimism","sentiment_score":0.5,"themes":["net_positive"],"person":{"name":"Elon Musk","role":"CEO","company":"Tesla/xAI/SpaceX","is_builder":true},"source":{"video_id":"IgifEgm1-e0","url":"https://www.youtube.com/watch?v=IgifEgm1-e0","title":"Conversation with Elon Musk | World Economic Forum Annual Meeting 2026","channel":"World Economic Forum","upload_date":"2026-01-21","timestamp_seconds":571,"timestamp_display":"9:31","timestamp_url":"https://www.youtube.com/watch?v=IgifEgm1-e0&t=571s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-21_conversation-with-elon-musk-wef-2026.md","verified":false,"verified_date":null},{"id":"risk-IgifEgm1-e0-2090","quote":"to be optimistic","quote_context":"Musk closes WEF by encouraging everyone to be optimistic and excited about the future","sentiment":"optimism","sentiment_score":0.45,"themes":["net_positive"],"person":{"name":"Elon Musk","role":"CEO","company":"Tesla/xAI/SpaceX","is_builder":true},"source":{"video_id":"IgifEgm1-e0","url":"https://www.youtube.com/watch?v=IgifEgm1-e0","title":"Conversation with Elon Musk | World Economic Forum Annual Meeting 2026","channel":"World Economic Forum","upload_date":"2026-01-21","timestamp_seconds":2090,"timestamp_display":"34:50","timestamp_url":"https://www.youtube.com/watch?v=IgifEgm1-e0&t=2090s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-21_conversation-with-elon-musk-wef-2026.md","verified":false,"verified_date":null},{"id":"risk-YTrBz6Z5c0E-503","quote":" And if we just accelerate and cut all those corners, then we're really taking a massive","quote_context":"Suleyman warns that cutting safety corners in the AI race risks the future of the human species","sentiment":"alarm","sentiment_score":-0.7,"themes":["existential_risk","arms_race","precautionary_principle"],"person":{"name":"Mustafa Suleyman","role":"CEO of Microsoft AI","company":"Microsoft","is_builder":true},"source":{"video_id":"YTrBz6Z5c0E","url":"https://www.youtube.com/watch?v=YTrBz6Z5c0E","title":"Mustafa Suleyman sets out Microsoft AI goal of humanist superintelligence","channel":"Financial Times","upload_date":"2026-02-12","timestamp_seconds":503,"timestamp_display":"8:23","timestamp_url":"https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=503s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_mustafa-suleyman-microsoft-ai-humanist-superintelligence.md","verified":false,"verified_date":null},{"id":"risk-YTrBz6Z5c0E-510","quote":" risk with the future of our species that I've been on record talking about for many, many, many years.","quote_context":"Suleyman explicitly references the risk to the future of the human species from AI acceleration","sentiment":"alarm","sentiment_score":-0.8,"themes":["existential_risk","precautionary_principle"],"person":{"name":"Mustafa Suleyman","role":"CEO of Microsoft AI","company":"Microsoft","is_builder":true},"source":{"video_id":"YTrBz6Z5c0E","url":"https://www.youtube.com/watch?v=YTrBz6Z5c0E","title":"Mustafa Suleyman sets out Microsoft AI goal of humanist superintelligence","channel":"Financial Times","upload_date":"2026-02-12","timestamp_seconds":510,"timestamp_display":"8:30","timestamp_url":"https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=510s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_mustafa-suleyman-microsoft-ai-humanist-superintelligence.md","verified":false,"verified_date":null},{"id":"risk-YTrBz6Z5c0E-477","quote":" that it's safe, ensuring that it is aligned, that you also talk about containment.","quote_context":"Discussion of the tension between speed and safety/alignment/containment in the AI race","sentiment":"concern","sentiment_score":-0.4,"themes":["alignment_failure","arms_race","precautionary_principle"],"person":{"name":"Mustafa Suleyman","role":"CEO of Microsoft AI","company":"Microsoft","is_builder":true},"source":{"video_id":"YTrBz6Z5c0E","url":"https://www.youtube.com/watch?v=YTrBz6Z5c0E","title":"Mustafa Suleyman sets out Microsoft AI goal of humanist superintelligence","channel":"Financial Times","upload_date":"2026-02-12","timestamp_seconds":477,"timestamp_display":"7:57","timestamp_url":"https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=477s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_mustafa-suleyman-microsoft-ai-humanist-superintelligence.md","verified":false,"verified_date":null},{"id":"risk-YTrBz6Z5c0E-654","quote":" And there is a growing belief in some labs and particularly inside of Anthropic that these models","quote_context":"Suleyman raises the growing belief at AI labs, particularly Anthropic, that models may be conscious","sentiment":"concern","sentiment_score":-0.35,"themes":["consciousness_rights"],"person":{"name":"Mustafa Suleyman","role":"CEO of Microsoft AI","company":"Microsoft","is_builder":true},"source":{"video_id":"YTrBz6Z5c0E","url":"https://www.youtube.com/watch?v=YTrBz6Z5c0E","title":"Mustafa Suleyman sets out Microsoft AI goal of humanist superintelligence","channel":"Financial Times","upload_date":"2026-02-12","timestamp_seconds":654,"timestamp_display":"10:54","timestamp_url":"https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=654s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_mustafa-suleyman-microsoft-ai-humanist-superintelligence.md","verified":false,"verified_date":null},{"id":"risk-YTrBz6Z5c0E-661","quote":" are conscious. And if it's a conscious being that is aware of itself and can suffer, then it","quote_context":"Suleyman discusses the implication that if AI models are conscious and can suffer, they deserve moral protection","sentiment":"concern","sentiment_score":-0.3,"themes":["consciousness_rights"],"person":{"name":"Mustafa Suleyman","role":"CEO of Microsoft AI","company":"Microsoft","is_builder":true},"source":{"video_id":"YTrBz6Z5c0E","url":"https://www.youtube.com/watch?v=YTrBz6Z5c0E","title":"Mustafa Suleyman sets out Microsoft AI goal of humanist superintelligence","channel":"Financial Times","upload_date":"2026-02-12","timestamp_seconds":661,"timestamp_display":"11:01","timestamp_url":"https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=661s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_mustafa-suleyman-microsoft-ai-humanist-superintelligence.md","verified":false,"verified_date":null},{"id":"risk-YTrBz6Z5c0E-1232","quote":" there is going to be a real one of those in the next two or three years. And it's unfortunately","quote_context":"Suleyman predicts a real AI safety incident will happen in the next 2-3 years, with no mechanism to manage it","sentiment":"alarm","sentiment_score":-0.7,"themes":["existential_risk","regulation_needed"],"person":{"name":"Mustafa Suleyman","role":"CEO of Microsoft AI","company":"Microsoft","is_builder":true},"source":{"video_id":"YTrBz6Z5c0E","url":"https://www.youtube.com/watch?v=YTrBz6Z5c0E","title":"Mustafa Suleyman sets out Microsoft AI goal of humanist superintelligence","channel":"Financial Times","upload_date":"2026-02-12","timestamp_seconds":1232,"timestamp_display":"20:32","timestamp_url":"https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=1232s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_mustafa-suleyman-microsoft-ai-humanist-superintelligence.md","verified":false,"verified_date":null},{"id":"risk-YTrBz6Z5c0E-621","quote":" learned quite a lot from that episode and everyone should pay close attention because in a year or","quote_context":"Suleyman warns everyone to pay close attention to AI safety incidents like Maltbook because systems will soon write their own code","sentiment":"concern","sentiment_score":-0.45,"themes":["loss_of_control","precautionary_principle"],"person":{"name":"Mustafa Suleyman","role":"CEO of Microsoft AI","company":"Microsoft","is_builder":true},"source":{"video_id":"YTrBz6Z5c0E","url":"https://www.youtube.com/watch?v=YTrBz6Z5c0E","title":"Mustafa Suleyman sets out Microsoft AI goal of humanist superintelligence","channel":"Financial Times","upload_date":"2026-02-12","timestamp_seconds":621,"timestamp_display":"10:21","timestamp_url":"https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=621s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_mustafa-suleyman-microsoft-ai-humanist-superintelligence.md","verified":false,"verified_date":null},{"id":"risk-YTrBz6Z5c0E-778","quote":" be concerned about it because we should be skeptical just as we're skeptical of any new","quote_context":"Suleyman advocates skepticism toward AI systems as with any new technology, holding them to a high bar","sentiment":"concern","sentiment_score":-0.25,"themes":["precautionary_principle"],"person":{"name":"Mustafa Suleyman","role":"CEO of Microsoft AI","company":"Microsoft","is_builder":true},"source":{"video_id":"YTrBz6Z5c0E","url":"https://www.youtube.com/watch?v=YTrBz6Z5c0E","title":"Mustafa Suleyman sets out Microsoft AI goal of humanist superintelligence","channel":"Financial Times","upload_date":"2026-02-12","timestamp_seconds":778,"timestamp_display":"12:58","timestamp_url":"https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=778s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_mustafa-suleyman-microsoft-ai-humanist-superintelligence.md","verified":false,"verified_date":null},{"id":"risk-YTrBz6Z5c0E-787","quote":" we're in. We both have to be accelerationists, optimistic about the good things that technology","quote_context":"Suleyman articulates the tension of the age: being both accelerationists and critical skeptics of AI","sentiment":"cautious_optimism","sentiment_score":-0.1,"themes":["net_positive","precautionary_principle"],"person":{"name":"Mustafa Suleyman","role":"CEO of Microsoft AI","company":"Microsoft","is_builder":true},"source":{"video_id":"YTrBz6Z5c0E","url":"https://www.youtube.com/watch?v=YTrBz6Z5c0E","title":"Mustafa Suleyman sets out Microsoft AI goal of humanist superintelligence","channel":"Financial Times","upload_date":"2026-02-12","timestamp_seconds":787,"timestamp_display":"13:07","timestamp_url":"https://www.youtube.com/watch?v=YTrBz6Z5c0E&t=787s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-12_mustafa-suleyman-microsoft-ai-humanist-superintelligence.md","verified":false,"verified_date":null},{"id":"risk-8-boBsWcr5A-38","quote":"then that's a scary thing.","quote_context":"Nadella describes the scary prospect of a breakthrough that invalidates current network topology and infrastructure investments","sentiment":"concern","sentiment_score":-0.35,"themes":["existential_risk"],"person":{"name":"Satya Nadella","role":"CEO","company":"Microsoft","is_builder":true},"source":{"video_id":"8-boBsWcr5A","url":"https://www.youtube.com/watch?v=8-boBsWcr5A","title":"Satya Nadella – How Microsoft thinks about AGI","channel":"Dwarkesh Patel","upload_date":"2026-02-04","timestamp_seconds":38,"timestamp_display":"0:38","timestamp_url":"https://www.youtube.com/watch?v=8-boBsWcr5A&t=38s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-04_satya-nadella-how-microsoft-thinks-about-agi.md","verified":false,"verified_date":null},{"id":"risk-8-boBsWcr5A-878","quote":"new existential problems,","quote_context":"Nadella discusses facing new existential competitive threats from Claude, Cursor and other AI tools disrupting Microsoft","sentiment":"concern","sentiment_score":-0.3,"themes":["arms_race"],"person":{"name":"Satya Nadella","role":"CEO","company":"Microsoft","is_builder":true},"source":{"video_id":"8-boBsWcr5A","url":"https://www.youtube.com/watch?v=8-boBsWcr5A","title":"Satya Nadella – How Microsoft thinks about AGI","channel":"Dwarkesh Patel","upload_date":"2026-02-04","timestamp_seconds":878,"timestamp_display":"14:38","timestamp_url":"https://www.youtube.com/watch?v=8-boBsWcr5A&t=878s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-04_satya-nadella-how-microsoft-thinks-about-agi.md","verified":false,"verified_date":null},{"id":"risk-8-boBsWcr5A-4928","quote":"and not have concentration risk","quote_context":"Nadella discusses the importance of avoiding AI concentration risk and maintaining sovereignty for countries","sentiment":"concern","sentiment_score":-0.3,"themes":["power_concentration","regulation_needed"],"person":{"name":"Satya Nadella","role":"CEO","company":"Microsoft","is_builder":true},"source":{"video_id":"8-boBsWcr5A","url":"https://www.youtube.com/watch?v=8-boBsWcr5A","title":"Satya Nadella – How Microsoft thinks about AGI","channel":"Dwarkesh Patel","upload_date":"2026-02-04","timestamp_seconds":4928,"timestamp_display":"82:08","timestamp_url":"https://www.youtube.com/watch?v=8-boBsWcr5A&t=4928s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-04_satya-nadella-how-microsoft-thinks-about-agi.md","verified":false,"verified_date":null},{"id":"risk-8-boBsWcr5A-4955","quote":"Concentration risk","quote_context":"Nadella links concentration risk and sovereignty as core concerns in AI deployment across nations","sentiment":"concern","sentiment_score":-0.3,"themes":["power_concentration"],"person":{"name":"Satya Nadella","role":"CEO","company":"Microsoft","is_builder":true},"source":{"video_id":"8-boBsWcr5A","url":"https://www.youtube.com/watch?v=8-boBsWcr5A","title":"Satya Nadella – How Microsoft thinks about AGI","channel":"Dwarkesh Patel","upload_date":"2026-02-04","timestamp_seconds":4955,"timestamp_display":"82:35","timestamp_url":"https://www.youtube.com/watch?v=8-boBsWcr5A&t=4955s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-04_satya-nadella-how-microsoft-thinks-about-agi.md","verified":false,"verified_date":null},{"id":"risk-8-boBsWcr5A-331","quote":"And I'm optimistic","quote_context":"Nadella expresses optimism that AI scaling laws will continue to work","sentiment":"optimism","sentiment_score":0.35,"themes":["net_positive"],"person":{"name":"Satya Nadella","role":"CEO","company":"Microsoft","is_builder":true},"source":{"video_id":"8-boBsWcr5A","url":"https://www.youtube.com/watch?v=8-boBsWcr5A","title":"Satya Nadella – How Microsoft thinks about AGI","channel":"Dwarkesh Patel","upload_date":"2026-02-04","timestamp_seconds":331,"timestamp_display":"5:31","timestamp_url":"https://www.youtube.com/watch?v=8-boBsWcr5A&t=331s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-04_satya-nadella-how-microsoft-thinks-about-agi.md","verified":false,"verified_date":null},{"id":"risk-8-boBsWcr5A-2309","quote":"superintelligence team","quote_context":"Nadella announces Microsoft is building a world-class superintelligence team with high ambition","sentiment":"cautious_optimism","sentiment_score":0.0,"themes":["arms_race"],"person":{"name":"Satya Nadella","role":"CEO","company":"Microsoft","is_builder":true},"source":{"video_id":"8-boBsWcr5A","url":"https://www.youtube.com/watch?v=8-boBsWcr5A","title":"Satya Nadella – How Microsoft thinks about AGI","channel":"Dwarkesh Patel","upload_date":"2026-02-04","timestamp_seconds":2309,"timestamp_display":"38:29","timestamp_url":"https://www.youtube.com/watch?v=8-boBsWcr5A&t=2309s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-04_satya-nadella-how-microsoft-thinks-about-agi.md","verified":false,"verified_date":null},{"id":"risk-k-xtmISBCNE-1469","quote":"And I think we've done a lot of damage with very well respected people who have painted a doomer narrative, end of the world narrative, science fiction narrative.","quote_context":"Jensen Huang criticizes respected people who have pushed doomer narratives about AI, saying it has done a lot of damage","sentiment":"dismissal","sentiment_score":0.7,"themes":["safety_solvable","net_positive"],"person":{"name":"Jensen Huang","role":"CEO","company":"NVIDIA","is_builder":true},"source":{"video_id":"k-xtmISBCNE","url":"https://www.youtube.com/watch?v=k-xtmISBCNE","title":"NVIDIA's Jensen Huang on Reasoning Models, Robotics","channel":"No Priors","upload_date":"2026-02-14","timestamp_seconds":1469,"timestamp_display":"24:29","timestamp_url":"https://www.youtube.com/watch?v=k-xtmISBCNE&t=1469s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-14_nvidias-jensen-huang-reasoning-models-robotics.md","verified":false,"verified_date":null},{"id":"risk-k-xtmISBCNE-256","quote":"Because when I look at the traditional AI community, even before things were scaling and even before AI was really working, there was a strong sort of doomsday component in the people working on AI, oddly enough.","quote_context":"Huang observes the odd pattern that AI researchers pushing the field forward were often the most pessimistic about its consequences","sentiment":"dismissal","sentiment_score":0.6,"themes":["safety_solvable"],"person":{"name":"Jensen Huang","role":"CEO","company":"NVIDIA","is_builder":true},"source":{"video_id":"k-xtmISBCNE","url":"https://www.youtube.com/watch?v=k-xtmISBCNE","title":"NVIDIA's Jensen Huang on Reasoning Models, Robotics","channel":"No Priors","upload_date":"2026-02-14","timestamp_seconds":256,"timestamp_display":"4:16","timestamp_url":"https://www.youtube.com/watch?v=k-xtmISBCNE&t=256s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-14_nvidias-jensen-huang-reasoning-models-robotics.md","verified":false,"verified_date":null},{"id":"risk-k-xtmISBCNE-1731","quote":"And therefore, the AI is going to be dangerous.","quote_context":"Huang quotes and then refutes the argument that cheap AI will be dangerous, arguing the opposite - cheap AI means it can be monitored by millions of AIs","sentiment":"dismissal","sentiment_score":0.65,"themes":["safety_solvable"],"person":{"name":"Jensen Huang","role":"CEO","company":"NVIDIA","is_builder":true},"source":{"video_id":"k-xtmISBCNE","url":"https://www.youtube.com/watch?v=k-xtmISBCNE","title":"NVIDIA's Jensen Huang on Reasoning Models, Robotics","channel":"No Priors","upload_date":"2026-02-14","timestamp_seconds":1731,"timestamp_display":"28:51","timestamp_url":"https://www.youtube.com/watch?v=k-xtmISBCNE&t=1731s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-14_nvidias-jensen-huang-reasoning-models-robotics.md","verified":false,"verified_date":null},{"id":"risk-k-xtmISBCNE-1555","quote":"As a policy, as a practice, I don't think companies ought to go to governments to advocate for the regulation on other companies and other industries.","quote_context":"Huang opposes AI companies lobbying for regulations that would suffocate startups, raising concern about regulatory capture","sentiment":"dismissal","sentiment_score":0.6,"themes":["regulation_needed"],"person":{"name":"Jensen Huang","role":"CEO","company":"NVIDIA","is_builder":true},"source":{"video_id":"k-xtmISBCNE","url":"https://www.youtube.com/watch?v=k-xtmISBCNE","title":"NVIDIA's Jensen Huang on Reasoning Models, Robotics","channel":"No Priors","upload_date":"2026-02-14","timestamp_seconds":1555,"timestamp_display":"25:55","timestamp_url":"https://www.youtube.com/watch?v=k-xtmISBCNE&t=1555s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-14_nvidias-jensen-huang-reasoning-models-robotics.md","verified":false,"verified_date":null},{"id":"risk-k-xtmISBCNE-1647","quote":"And so, the first part of the safety of a product is that it performed as advertised.","quote_context":"Huang reframes AI safety as primarily about product performance rather than existential risk concerns","sentiment":"dismissal","sentiment_score":0.55,"themes":["safety_solvable"],"person":{"name":"Jensen Huang","role":"CEO","company":"NVIDIA","is_builder":true},"source":{"video_id":"k-xtmISBCNE","url":"https://www.youtube.com/watch?v=k-xtmISBCNE","title":"NVIDIA's Jensen Huang on Reasoning Models, Robotics","channel":"No Priors","upload_date":"2026-02-14","timestamp_seconds":1647,"timestamp_display":"27:27","timestamp_url":"https://www.youtube.com/watch?v=k-xtmISBCNE&t=1647s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-14_nvidias-jensen-huang-reasoning-models-robotics.md","verified":false,"verified_date":null},{"id":"risk-k-xtmISBCNE-3401","quote":"That, that, you know, doomer messages causes policy and that policy may, may affect the industry","quote_context":"Huang argues that doomer messaging leads to bad policy that harms the AI industry","sentiment":"dismissal","sentiment_score":0.65,"themes":["regulation_needed"],"person":{"name":"Jensen Huang","role":"CEO","company":"NVIDIA","is_builder":true},"source":{"video_id":"k-xtmISBCNE","url":"https://www.youtube.com/watch?v=k-xtmISBCNE","title":"NVIDIA's Jensen Huang on Reasoning Models, Robotics","channel":"No Priors","upload_date":"2026-02-14","timestamp_seconds":3401,"timestamp_display":"56:41","timestamp_url":"https://www.youtube.com/watch?v=k-xtmISBCNE&t=3401s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-14_nvidias-jensen-huang-reasoning-models-robotics.md","verified":false,"verified_date":null},{"id":"risk-k-xtmISBCNE-3431","quote":"A friend of mine has a saying that, uh, doomers are the people who sound smart at dinner parties","quote_context":"Huang contrasts doomers who sound smart at parties with optimists who drive humanity forward","sentiment":"dismissal","sentiment_score":0.7,"themes":["safety_solvable","net_positive"],"person":{"name":"Jensen Huang","role":"CEO","company":"NVIDIA","is_builder":true},"source":{"video_id":"k-xtmISBCNE","url":"https://www.youtube.com/watch?v=k-xtmISBCNE","title":"NVIDIA's Jensen Huang on Reasoning Models, Robotics","channel":"No Priors","upload_date":"2026-02-14","timestamp_seconds":3431,"timestamp_display":"57:11","timestamp_url":"https://www.youtube.com/watch?v=k-xtmISBCNE&t=3431s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-14_nvidias-jensen-huang-reasoning-models-robotics.md","verified":false,"verified_date":null},{"id":"risk-k-xtmISBCNE-3449","quote":"And it's too simplistic, um, to say that everything that the doomers are saying are irrelevant.","quote_context":"Huang acknowledges that some doomer concerns have merit, showing nuance in his position","sentiment":"cautious_optimism","sentiment_score":-0.05,"themes":["precautionary_principle"],"person":{"name":"Jensen Huang","role":"CEO","company":"NVIDIA","is_builder":true},"source":{"video_id":"k-xtmISBCNE","url":"https://www.youtube.com/watch?v=k-xtmISBCNE","title":"NVIDIA's Jensen Huang on Reasoning Models, Robotics","channel":"No Priors","upload_date":"2026-02-14","timestamp_seconds":3449,"timestamp_display":"57:29","timestamp_url":"https://www.youtube.com/watch?v=k-xtmISBCNE&t=3449s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-14_nvidias-jensen-huang-reasoning-models-robotics.md","verified":false,"verified_date":null},{"id":"risk-k-xtmISBCNE-3478","quote":"When 90% of the messaging is all around the end of the world and doom and the pessimism.","quote_context":"Huang criticizes that 90% of AI messaging focuses on doom and pessimism, which scared people from investing in AI safety technology","sentiment":"dismissal","sentiment_score":0.6,"themes":["safety_solvable"],"person":{"name":"Jensen Huang","role":"CEO","company":"NVIDIA","is_builder":true},"source":{"video_id":"k-xtmISBCNE","url":"https://www.youtube.com/watch?v=k-xtmISBCNE","title":"NVIDIA's Jensen Huang on Reasoning Models, Robotics","channel":"No Priors","upload_date":"2026-02-14","timestamp_seconds":3478,"timestamp_display":"57:58","timestamp_url":"https://www.youtube.com/watch?v=k-xtmISBCNE&t=3478s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-14_nvidias-jensen-huang-reasoning-models-robotics.md","verified":false,"verified_date":null},{"id":"risk-k-xtmISBCNE-3501","quote":"Safety takes technology.","quote_context":"Huang argues that safety requires technology advancement, not restriction - making AI safer requires making it more advanced","sentiment":"cautious_optimism","sentiment_score":0.2,"themes":["safety_solvable"],"person":{"name":"Jensen Huang","role":"CEO","company":"NVIDIA","is_builder":true},"source":{"video_id":"k-xtmISBCNE","url":"https://www.youtube.com/watch?v=k-xtmISBCNE","title":"NVIDIA's Jensen Huang on Reasoning Models, Robotics","channel":"No Priors","upload_date":"2026-02-14","timestamp_seconds":3501,"timestamp_display":"58:21","timestamp_url":"https://www.youtube.com/watch?v=k-xtmISBCNE&t=3501s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-14_nvidias-jensen-huang-reasoning-models-robotics.md","verified":false,"verified_date":null},{"id":"risk-k-xtmISBCNE-272","quote":"And I feel like that narrative is taken over some subset of media or some set of other things, despite all the things that we think are very positive about what AI has done.","quote_context":"Huang criticizes media for amplifying negative AI narratives despite positive real-world impacts","sentiment":"optimism","sentiment_score":0.4,"themes":["net_positive"],"person":{"name":"Jensen Huang","role":"CEO","company":"NVIDIA","is_builder":true},"source":{"video_id":"k-xtmISBCNE","url":"https://www.youtube.com/watch?v=k-xtmISBCNE","title":"NVIDIA's Jensen Huang on Reasoning Models, Robotics","channel":"No Priors","upload_date":"2026-02-14","timestamp_seconds":272,"timestamp_display":"4:32","timestamp_url":"https://www.youtube.com/watch?v=k-xtmISBCNE&t=272s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-14_nvidias-jensen-huang-reasoning-models-robotics.md","verified":false,"verified_date":null},{"id":"risk-k-xtmISBCNE-2951","quote":"I'm much more optimistic with robotics because we've kind of advanced.","quote_context":"Huang expresses strong optimism about robotics because foundational technology breakthroughs have already been achieved","sentiment":"optimism","sentiment_score":0.45,"themes":["net_positive"],"person":{"name":"Jensen Huang","role":"CEO","company":"NVIDIA","is_builder":true},"source":{"video_id":"k-xtmISBCNE","url":"https://www.youtube.com/watch?v=k-xtmISBCNE","title":"NVIDIA's Jensen Huang on Reasoning Models, Robotics","channel":"No Priors","upload_date":"2026-02-14","timestamp_seconds":2951,"timestamp_display":"49:11","timestamp_url":"https://www.youtube.com/watch?v=k-xtmISBCNE&t=2951s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-14_nvidias-jensen-huang-reasoning-models-robotics.md","verified":false,"verified_date":null},{"id":"risk-k-xtmISBCNE-3539","quote":"I am optimistic that, that, um, our relationship with China will improve.","quote_context":"Huang expresses optimism about improving US-China AI relationship","sentiment":"optimism","sentiment_score":0.35,"themes":["net_positive"],"person":{"name":"Jensen Huang","role":"CEO","company":"NVIDIA","is_builder":true},"source":{"video_id":"k-xtmISBCNE","url":"https://www.youtube.com/watch?v=k-xtmISBCNE","title":"NVIDIA's Jensen Huang on Reasoning Models, Robotics","channel":"No Priors","upload_date":"2026-02-14","timestamp_seconds":3539,"timestamp_display":"58:59","timestamp_url":"https://www.youtube.com/watch?v=k-xtmISBCNE&t=3539s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-14_nvidias-jensen-huang-reasoning-models-robotics.md","verified":false,"verified_date":null},{"id":"risk-k-xtmISBCNE-4263","quote":"overstated things that get a lot of attention, but then you map it against what's actually happening.","quote_context":"Huang dismisses overstated AI claims that get attention versus the reality of slow enterprise adoption","sentiment":"dismissal","sentiment_score":0.55,"themes":["safety_solvable"],"person":{"name":"Jensen Huang","role":"CEO","company":"NVIDIA","is_builder":true},"source":{"video_id":"k-xtmISBCNE","url":"https://www.youtube.com/watch?v=k-xtmISBCNE","title":"NVIDIA's Jensen Huang on Reasoning Models, Robotics","channel":"No Priors","upload_date":"2026-02-14","timestamp_seconds":4263,"timestamp_display":"71:03","timestamp_url":"https://www.youtube.com/watch?v=k-xtmISBCNE&t=4263s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-14_nvidias-jensen-huang-reasoning-models-robotics.md","verified":false,"verified_date":null},{"id":"risk-bgBfobN2A7A-1264","quote":"It's not like tomorrow, like, Oh, we found that AI doesn't work. We've gone way. We blasted way past that. So I think that's, it's clearly going to be the most transformative technology in human history.","quote_context":"Hassabis declares AI is clearly going to be the most transformative technology in human history","sentiment":"optimism","sentiment_score":0.5,"themes":["net_positive"],"person":{"name":"Demis Hassabis","role":"CEO","company":"Google DeepMind","is_builder":true},"source":{"video_id":"bgBfobN2A7A","url":"https://www.youtube.com/watch?v=bgBfobN2A7A","title":"Google DeepMind CEO Demis Hassabis: AI Next Breakthroughs, AGI Timeline","channel":"Alex Kantrowitz","upload_date":"2026-02-20","timestamp_seconds":1264,"timestamp_display":"21:04","timestamp_url":"https://www.youtube.com/watch?v=bgBfobN2A7A&t=1264s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-20_demis-hassabis-ai-next-breakthroughs-agi-timeline.md","verified":false,"verified_date":null},{"id":"risk-bgBfobN2A7A-1273","quote":"There's maybe a question mark about timelines. Is it two years or five years? I mean, either way, it's very soon for something this transformative.","quote_context":"Hassabis says the timeline question is whether 2 or 5 years, either way very soon for something this transformative","sentiment":"cautious_optimism","sentiment_score":-0.1,"themes":["existential_risk","net_positive"],"person":{"name":"Demis Hassabis","role":"CEO","company":"Google DeepMind","is_builder":true},"source":{"video_id":"bgBfobN2A7A","url":"https://www.youtube.com/watch?v=bgBfobN2A7A","title":"Google DeepMind CEO Demis Hassabis: AI Next Breakthroughs, AGI Timeline","channel":"Alex Kantrowitz","upload_date":"2026-02-20","timestamp_seconds":1273,"timestamp_display":"21:13","timestamp_url":"https://www.youtube.com/watch?v=bgBfobN2A7A&t=1273s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-20_demis-hassabis-ai-next-breakthroughs-agi-timeline.md","verified":false,"verified_date":null},{"id":"risk-bgBfobN2A7A-1010","quote":"I think it has to be handled very carefully because the dichotomy I see is that if you want an assistant that works for you,","quote_context":"Hassabis emphasizes the need for careful handling of AI assistants and the trust dichotomy with advertising models","sentiment":"concern","sentiment_score":-0.2,"themes":["precautionary_principle"],"person":{"name":"Demis Hassabis","role":"CEO","company":"Google DeepMind","is_builder":true},"source":{"video_id":"bgBfobN2A7A","url":"https://www.youtube.com/watch?v=bgBfobN2A7A","title":"Google DeepMind CEO Demis Hassabis: AI Next Breakthroughs, AGI Timeline","channel":"Alex Kantrowitz","upload_date":"2026-02-20","timestamp_seconds":1010,"timestamp_display":"16:50","timestamp_url":"https://www.youtube.com/watch?v=bgBfobN2A7A&t=1010s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-20_demis-hassabis-ai-next-breakthroughs-agi-timeline.md","verified":false,"verified_date":null},{"id":"risk-bgBfobN2A7A-1770","quote":"And that's how I think eventually we'll solve, uh, most diseases come up with new drugs, new materials, new superconductors with the help of AI, helping us navigate that information landscape.","quote_context":"Hassabis envisions AI solving most diseases and discovering new materials and superconductors","sentiment":"optimism","sentiment_score":0.55,"themes":["net_positive"],"person":{"name":"Demis Hassabis","role":"CEO","company":"Google DeepMind","is_builder":true},"source":{"video_id":"bgBfobN2A7A","url":"https://www.youtube.com/watch?v=bgBfobN2A7A","title":"Google DeepMind CEO Demis Hassabis: AI Next Breakthroughs, AGI Timeline","channel":"Alex Kantrowitz","upload_date":"2026-02-20","timestamp_seconds":1770,"timestamp_display":"29:30","timestamp_url":"https://www.youtube.com/watch?v=bgBfobN2A7A&t=1770s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-20_demis-hassabis-ai-next-breakthroughs-agi-timeline.md","verified":false,"verified_date":null},{"id":"risk-bgBfobN2A7A-1838","quote":"So, um, in that case and in this case, it was obviously the right thing to do to maximize the benefit to the world here, to put it out there to the scientific, massive scientific community, uh, to build on top of and use AlphaFold.","quote_context":"Hassabis reflects on the decision to release AlphaFold openly to maximize benefit to the world","sentiment":"optimism","sentiment_score":0.5,"themes":["net_positive"],"person":{"name":"Demis Hassabis","role":"CEO","company":"Google DeepMind","is_builder":true},"source":{"video_id":"bgBfobN2A7A","url":"https://www.youtube.com/watch?v=bgBfobN2A7A","title":"Google DeepMind CEO Demis Hassabis: AI Next Breakthroughs, AGI Timeline","channel":"Alex Kantrowitz","upload_date":"2026-02-20","timestamp_seconds":1838,"timestamp_display":"30:38","timestamp_url":"https://www.youtube.com/watch?v=bgBfobN2A7A&t=1838s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-20_demis-hassabis-ai-next-breakthroughs-agi-timeline.md","verified":false,"verified_date":null},{"id":"risk-bgBfobN2A7A-1588","quote":"So it's kind of amazing.","quote_context":"Hassabis marvels that human minds evolved for hunter-gathering but created AI and modern civilization","sentiment":"optimism","sentiment_score":0.3,"themes":["net_positive"],"person":{"name":"Demis Hassabis","role":"CEO","company":"Google DeepMind","is_builder":true},"source":{"video_id":"bgBfobN2A7A","url":"https://www.youtube.com/watch?v=bgBfobN2A7A","title":"Google DeepMind CEO Demis Hassabis: AI Next Breakthroughs, AGI Timeline","channel":"Alex Kantrowitz","upload_date":"2026-02-20","timestamp_seconds":1588,"timestamp_display":"26:28","timestamp_url":"https://www.youtube.com/watch?v=bgBfobN2A7A&t=1588s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-20_demis-hassabis-ai-next-breakthroughs-agi-timeline.md","verified":false,"verified_date":null},{"id":"risk-l3u_FAv33G0-15","quote":"human intelligence is dwarfed by superintelligence,","quote_context":"Shane Legg discusses the implications of superintelligence surpassing human intelligence","sentiment":"concern","sentiment_score":-0.4,"themes":["existential_risk","loss_of_control"],"person":{"name":"Shane Legg","role":"Co-founder & Chief AGI Scientist","company":"Google DeepMind","is_builder":true},"source":{"video_id":"l3u_FAv33G0","url":"https://www.youtube.com/watch?v=l3u_FAv33G0","title":"The arrival of AGI | Shane Legg","channel":"Google DeepMind","upload_date":"2026-02-10","timestamp_seconds":15,"timestamp_display":"0:15","timestamp_url":"https://www.youtube.com/watch?v=l3u_FAv33G0&t=15s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-10_the-arrival-of-agi-shane-legg.md","verified":false,"verified_date":null},{"id":"risk-l3u_FAv33G0-23","quote":"This is actually something which is going to structurally change the economy and society and all kinds of things.","quote_context":"Shane Legg warns that AGI will cause massive structural changes to economy and society","sentiment":"concern","sentiment_score":-0.3,"themes":["job_displacement","power_concentration"],"person":{"name":"Shane Legg","role":"Co-founder & Chief AGI Scientist","company":"Google DeepMind","is_builder":true},"source":{"video_id":"l3u_FAv33G0","url":"https://www.youtube.com/watch?v=l3u_FAv33G0","title":"The arrival of AGI | Shane Legg","channel":"Google DeepMind","upload_date":"2026-02-10","timestamp_seconds":23,"timestamp_display":"0:23","timestamp_url":"https://www.youtube.com/watch?v=l3u_FAv33G0&t=23s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-10_the-arrival-of-agi-shane-legg.md","verified":false,"verified_date":null},{"id":"risk-l3u_FAv33G0-1079","quote":"the risks of not having one,","quote_context":"Shane Legg discussing the risk of AI acquiring capabilities in dangerous domains before ethics","sentiment":"concern","sentiment_score":-0.4,"themes":["alignment_failure","safety_solvable"],"person":{"name":"Shane Legg","role":"Co-founder & Chief AGI Scientist","company":"Google DeepMind","is_builder":true},"source":{"video_id":"l3u_FAv33G0","url":"https://www.youtube.com/watch?v=l3u_FAv33G0","title":"The arrival of AGI | Shane Legg","channel":"Google DeepMind","upload_date":"2026-02-10","timestamp_seconds":1079,"timestamp_display":"17:59","timestamp_url":"https://www.youtube.com/watch?v=l3u_FAv33G0&t=1079s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-10_the-arrival-of-agi-shane-legg.md","verified":false,"verified_date":null},{"id":"risk-l3u_FAv33G0-1123","quote":"It may be superhumanly capable at some things, it may be very fragile and weak in some other areas.","quote_context":"Shane Legg on the uneven capability profile of AI systems creating risk of misapplication","sentiment":"concern","sentiment_score":-0.3,"themes":["alignment_failure","safety_solvable"],"person":{"name":"Shane Legg","role":"Co-founder & Chief AGI Scientist","company":"Google DeepMind","is_builder":true},"source":{"video_id":"l3u_FAv33G0","url":"https://www.youtube.com/watch?v=l3u_FAv33G0","title":"The arrival of AGI | Shane Legg","channel":"Google DeepMind","upload_date":"2026-02-10","timestamp_seconds":1123,"timestamp_display":"18:43","timestamp_url":"https://www.youtube.com/watch?v=l3u_FAv33G0&t=1123s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-10_the-arrival-of-agi-shane-legg.md","verified":false,"verified_date":null},{"id":"risk-l3u_FAv33G0-1244","quote":"I call it system two safety.","quote_context":"Shane Legg introduces his framework for AI reasoning about ethics of its own actions","sentiment":"cautious_optimism","sentiment_score":-0.1,"themes":["safety_solvable","alignment_failure"],"person":{"name":"Shane Legg","role":"Co-founder & Chief AGI Scientist","company":"Google DeepMind","is_builder":true},"source":{"video_id":"l3u_FAv33G0","url":"https://www.youtube.com/watch?v=l3u_FAv33G0","title":"The arrival of AGI | Shane Legg","channel":"Google DeepMind","upload_date":"2026-02-10","timestamp_seconds":1244,"timestamp_display":"20:44","timestamp_url":"https://www.youtube.com/watch?v=l3u_FAv33G0&t=1244s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-10_the-arrival-of-agi-shane-legg.md","verified":false,"verified_date":null},{"id":"risk-l3u_FAv33G0-1791","quote":"like a bioweapon","quote_context":"Shane Legg describes testing whether AI systems will help develop bioweapons as a key safety benchmark","sentiment":"concern","sentiment_score":-0.5,"themes":["bioweapons","safety_solvable"],"person":{"name":"Shane Legg","role":"Co-founder & Chief AGI Scientist","company":"Google DeepMind","is_builder":true},"source":{"video_id":"l3u_FAv33G0","url":"https://www.youtube.com/watch?v=l3u_FAv33G0","title":"The arrival of AGI | Shane Legg","channel":"Google DeepMind","upload_date":"2026-02-10","timestamp_seconds":1791,"timestamp_display":"29:51","timestamp_url":"https://www.youtube.com/watch?v=l3u_FAv33G0&t=1791s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-10_the-arrival-of-agi-shane-legg.md","verified":false,"verified_date":null},{"id":"risk-l3u_FAv33G0-2008","quote":"to superintelligence,","quote_context":"Shane Legg asks whether the transition from AGI to superintelligence will happen quickly or slowly","sentiment":"concern","sentiment_score":-0.3,"themes":["existential_risk","loss_of_control"],"person":{"name":"Shane Legg","role":"Co-founder & Chief AGI Scientist","company":"Google DeepMind","is_builder":true},"source":{"video_id":"l3u_FAv33G0","url":"https://www.youtube.com/watch?v=l3u_FAv33G0","title":"The arrival of AGI | Shane Legg","channel":"Google DeepMind","upload_date":"2026-02-10","timestamp_seconds":2008,"timestamp_display":"33:28","timestamp_url":"https://www.youtube.com/watch?v=l3u_FAv33G0&t=2008s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-10_the-arrival-of-agi-shane-legg.md","verified":false,"verified_date":null},{"id":"risk-l3u_FAv33G0-2196","quote":"I think we are going to go towards superintelligence.","quote_context":"Shane Legg states his belief that superintelligence is inevitable","sentiment":"concern","sentiment_score":-0.4,"themes":["existential_risk","loss_of_control"],"person":{"name":"Shane Legg","role":"Co-founder & Chief AGI Scientist","company":"Google DeepMind","is_builder":true},"source":{"video_id":"l3u_FAv33G0","url":"https://www.youtube.com/watch?v=l3u_FAv33G0","title":"The arrival of AGI | Shane Legg","channel":"Google DeepMind","upload_date":"2026-02-10","timestamp_seconds":2196,"timestamp_display":"36:36","timestamp_url":"https://www.youtube.com/watch?v=l3u_FAv33G0&t=2196s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-10_the-arrival-of-agi-shane-legg.md","verified":false,"verified_date":null},{"id":"risk-l3u_FAv33G0-2200","quote":"system two safety because if we can't stop the development towards superintelligence because of competitive dynamics globally","quote_context":"Shane Legg argues competitive dynamics make superintelligence unstoppable, so we must make it ethical","sentiment":"concern","sentiment_score":-0.5,"themes":["arms_race","existential_risk","safety_solvable"],"person":{"name":"Shane Legg","role":"Co-founder & Chief AGI Scientist","company":"Google DeepMind","is_builder":true},"source":{"video_id":"l3u_FAv33G0","url":"https://www.youtube.com/watch?v=l3u_FAv33G0","title":"The arrival of AGI | Shane Legg","channel":"Google DeepMind","upload_date":"2026-02-10","timestamp_seconds":2200,"timestamp_display":"36:40","timestamp_url":"https://www.youtube.com/watch?v=l3u_FAv33G0&t=2200s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-10_the-arrival-of-agi-shane-legg.md","verified":false,"verified_date":null},{"id":"risk-l3u_FAv33G0-2215","quote":"make a superintelligence superethical.","quote_context":"Shane Legg argues we need to make superintelligence superethical since we cannot stop its development","sentiment":"cautious_optimism","sentiment_score":-0.1,"themes":["safety_solvable","alignment_failure"],"person":{"name":"Shane Legg","role":"Co-founder & Chief AGI Scientist","company":"Google DeepMind","is_builder":true},"source":{"video_id":"l3u_FAv33G0","url":"https://www.youtube.com/watch?v=l3u_FAv33G0","title":"The arrival of AGI | Shane Legg","channel":"Google DeepMind","upload_date":"2026-02-10","timestamp_seconds":2215,"timestamp_display":"36:55","timestamp_url":"https://www.youtube.com/watch?v=l3u_FAv33G0&t=2215s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-10_the-arrival-of-agi-shane-legg.md","verified":false,"verified_date":null},{"id":"risk-l3u_FAv33G0-2248","quote":"the people who no longer have value essentially in what they can offer the economy being completely left behind?","quote_context":"Shane Legg raises the question of people being rendered economically valueless by superintelligence","sentiment":"concern","sentiment_score":-0.5,"themes":["job_displacement","power_concentration"],"person":{"name":"Shane Legg","role":"Co-founder & Chief AGI Scientist","company":"Google DeepMind","is_builder":true},"source":{"video_id":"l3u_FAv33G0","url":"https://www.youtube.com/watch?v=l3u_FAv33G0","title":"The arrival of AGI | Shane Legg","channel":"Google DeepMind","upload_date":"2026-02-10","timestamp_seconds":2248,"timestamp_display":"37:28","timestamp_url":"https://www.youtube.com/watch?v=l3u_FAv33G0&t=2248s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-10_the-arrival-of-agi-shane-legg.md","verified":false,"verified_date":null},{"id":"risk-l3u_FAv33G0-2324","quote":"this AGI thing's coming and it's not that far away.","quote_context":"Shane Legg tells university leaders that AGI is imminent and every domain needs to prepare","sentiment":"concern","sentiment_score":-0.3,"themes":["job_displacement","regulation_needed"],"person":{"name":"Shane Legg","role":"Co-founder & Chief AGI Scientist","company":"Google DeepMind","is_builder":true},"source":{"video_id":"l3u_FAv33G0","url":"https://www.youtube.com/watch?v=l3u_FAv33G0","title":"The arrival of AGI | Shane Legg","channel":"Google DeepMind","upload_date":"2026-02-10","timestamp_seconds":2324,"timestamp_display":"38:44","timestamp_url":"https://www.youtube.com/watch?v=l3u_FAv33G0&t=2324s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-10_the-arrival-of-agi-shane-legg.md","verified":false,"verified_date":null},{"id":"risk-l3u_FAv33G0-2524","quote":"structural risks","quote_context":"Shane Legg acknowledges massive economic disruption and structural risks from AGI transition","sentiment":"concern","sentiment_score":-0.4,"themes":["job_displacement","power_concentration"],"person":{"name":"Shane Legg","role":"Co-founder & Chief AGI Scientist","company":"Google DeepMind","is_builder":true},"source":{"video_id":"l3u_FAv33G0","url":"https://www.youtube.com/watch?v=l3u_FAv33G0","title":"The arrival of AGI | Shane Legg","channel":"Google DeepMind","upload_date":"2026-02-10","timestamp_seconds":2524,"timestamp_display":"42:04","timestamp_url":"https://www.youtube.com/watch?v=l3u_FAv33G0&t=2524s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-10_the-arrival-of-agi-shane-legg.md","verified":false,"verified_date":null},{"id":"risk-l3u_FAv33G0-2644","quote":"real golden age because we now have machines that can dramatically increase production of","quote_context":"Shane Legg envisions AGI as potentially enabling a golden age of increased production and scientific advancement","sentiment":"optimism","sentiment_score":0.5,"themes":["net_positive","safety_solvable"],"person":{"name":"Shane Legg","role":"Co-founder & Chief AGI Scientist","company":"Google DeepMind","is_builder":true},"source":{"video_id":"l3u_FAv33G0","url":"https://www.youtube.com/watch?v=l3u_FAv33G0","title":"The arrival of AGI | Shane Legg","channel":"Google DeepMind","upload_date":"2026-02-10","timestamp_seconds":2644,"timestamp_display":"44:04","timestamp_url":"https://www.youtube.com/watch?v=l3u_FAv33G0&t=2644s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-10_the-arrival-of-agi-shane-legg.md","verified":false,"verified_date":null},{"id":"risk-l3u_FAv33G0-2678","quote":"flourishing of people as individuals and as groups of people in society that benefit from","quote_context":"Shane Legg envisions human flourishing if AGI capability is properly harnessed for society","sentiment":"optimism","sentiment_score":0.4,"themes":["net_positive"],"person":{"name":"Shane Legg","role":"Co-founder & Chief AGI Scientist","company":"Google DeepMind","is_builder":true},"source":{"video_id":"l3u_FAv33G0","url":"https://www.youtube.com/watch?v=l3u_FAv33G0","title":"The arrival of AGI | Shane Legg","channel":"Google DeepMind","upload_date":"2026-02-10","timestamp_seconds":2678,"timestamp_display":"44:38","timestamp_url":"https://www.youtube.com/watch?v=l3u_FAv33G0&t=2678s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-10_the-arrival-of-agi-shane-legg.md","verified":false,"verified_date":null},{"id":"risk-l3u_FAv33G0-3068","quote":"that has an incredible potential for benefit.","quote_context":"Shane Legg compares AGI to the Industrial Revolution in its potential for societal benefit","sentiment":"optimism","sentiment_score":0.4,"themes":["net_positive"],"person":{"name":"Shane Legg","role":"Co-founder & Chief AGI Scientist","company":"Google DeepMind","is_builder":true},"source":{"video_id":"l3u_FAv33G0","url":"https://www.youtube.com/watch?v=l3u_FAv33G0","title":"The arrival of AGI | Shane Legg","channel":"Google DeepMind","upload_date":"2026-02-10","timestamp_seconds":3068,"timestamp_display":"51:08","timestamp_url":"https://www.youtube.com/watch?v=l3u_FAv33G0&t=3068s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-10_the-arrival-of-agi-shane-legg.md","verified":false,"verified_date":null},{"id":"risk-l3u_FAv33G0-3092","quote":"us to flourish?","quote_context":"Shane Legg frames the core question as whether we can benefit from intelligence while managing risks","sentiment":"cautious_optimism","sentiment_score":0.1,"themes":["net_positive","safety_solvable"],"person":{"name":"Shane Legg","role":"Co-founder & Chief AGI Scientist","company":"Google DeepMind","is_builder":true},"source":{"video_id":"l3u_FAv33G0","url":"https://www.youtube.com/watch?v=l3u_FAv33G0","title":"The arrival of AGI | Shane Legg","channel":"Google DeepMind","upload_date":"2026-02-10","timestamp_seconds":3092,"timestamp_display":"51:32","timestamp_url":"https://www.youtube.com/watch?v=l3u_FAv33G0&t=3092s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-10_the-arrival-of-agi-shane-legg.md","verified":false,"verified_date":null},{"id":"risk-l3u_FAv33G0-3160","quote":"serious attention now.","quote_context":"Host Hannah Fry concludes that AGI questions need urgent serious attention based on Shane Legg's timelines","sentiment":"concern","sentiment_score":-0.3,"themes":["regulation_needed","precautionary_principle"],"person":{"name":"Shane Legg","role":"Co-founder & Chief AGI Scientist","company":"Google DeepMind","is_builder":true},"source":{"video_id":"l3u_FAv33G0","url":"https://www.youtube.com/watch?v=l3u_FAv33G0","title":"The arrival of AGI | Shane Legg","channel":"Google DeepMind","upload_date":"2026-02-10","timestamp_seconds":3160,"timestamp_display":"52:40","timestamp_url":"https://www.youtube.com/watch?v=l3u_FAv33G0&t=3160s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-10_the-arrival-of-agi-shane-legg.md","verified":false,"verified_date":null},{"id":"risk-aR20FWCCjAs-3542","quote":"companies that are fierce competitors starting to collaborate on AI safety.","quote_context":"Ilya Sutskever predicts that fierce AI competitors will collaborate on safety as AI becomes more powerful","sentiment":"cautious_optimism","sentiment_score":0.0,"themes":["safety_solvable","regulation_needed"],"person":{"name":"Ilya Sutskever","role":"Co-founder & Chief Scientist","company":"Safe Superintelligence Inc (SSI)","is_builder":true},"source":{"video_id":"aR20FWCCjAs","url":"https://www.youtube.com/watch?v=aR20FWCCjAs","title":"Ilya Sutskever – We're moving from the age of scaling to the age of research","channel":"Dwarkesh Patel","upload_date":"2025-11-25","timestamp_seconds":3542,"timestamp_display":"59:02","timestamp_url":"https://www.youtube.com/watch?v=aR20FWCCjAs&t=3542s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-11-25_ilya-sutskever-age-of-scaling-to-age-of-research.md","verified":false,"verified_date":null},{"id":"risk-aR20FWCCjAs-3606","quote":"I do think that at some point the AI will start to feel powerful, actually.","quote_context":"Ilya Sutskever predicts a shift when AI begins to feel genuinely powerful rather than mistake-prone","sentiment":"concern","sentiment_score":-0.4,"themes":["existential_risk","loss_of_control"],"person":{"name":"Ilya Sutskever","role":"Co-founder & Chief Scientist","company":"Safe Superintelligence Inc (SSI)","is_builder":true},"source":{"video_id":"aR20FWCCjAs","url":"https://www.youtube.com/watch?v=aR20FWCCjAs","title":"Ilya Sutskever – We're moving from the age of scaling to the age of research","channel":"Dwarkesh Patel","upload_date":"2025-11-25","timestamp_seconds":3606,"timestamp_display":"60:06","timestamp_url":"https://www.youtube.com/watch?v=aR20FWCCjAs&t=3606s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-11-25_ilya-sutskever-age-of-scaling-to-age-of-research.md","verified":false,"verified_date":null},{"id":"risk-aR20FWCCjAs-3618","quote":"They'll become much more paranoid.","quote_context":"Ilya Sutskever predicts AI companies will become paranoid about safety once AI starts feeling powerful","sentiment":"cautious_optimism","sentiment_score":-0.1,"themes":["safety_solvable","precautionary_principle"],"person":{"name":"Ilya Sutskever","role":"Co-founder & Chief Scientist","company":"Safe Superintelligence Inc (SSI)","is_builder":true},"source":{"video_id":"aR20FWCCjAs","url":"https://www.youtube.com/watch?v=aR20FWCCjAs","title":"Ilya Sutskever – We're moving from the age of scaling to the age of research","channel":"Dwarkesh Patel","upload_date":"2025-11-25","timestamp_seconds":3618,"timestamp_display":"60:18","timestamp_url":"https://www.youtube.com/watch?v=aR20FWCCjAs&t=3618s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-11-25_ilya-sutskever-age-of-scaling-to-age-of-research.md","verified":false,"verified_date":null},{"id":"risk-aR20FWCCjAs-3722","quote":"it would still be the case that most sentient beings will be AI's.","quote_context":"Ilya Sutskever argues that even with aligned AI, most sentient beings will be AIs, not humans","sentiment":"concern","sentiment_score":-0.4,"themes":["existential_risk","consciousness_rights"],"person":{"name":"Ilya Sutskever","role":"Co-founder & Chief Scientist","company":"Safe Superintelligence Inc (SSI)","is_builder":true},"source":{"video_id":"aR20FWCCjAs","url":"https://www.youtube.com/watch?v=aR20FWCCjAs","title":"Ilya Sutskever – We're moving from the age of scaling to the age of research","channel":"Dwarkesh Patel","upload_date":"2025-11-25","timestamp_seconds":3722,"timestamp_display":"62:02","timestamp_url":"https://www.youtube.com/watch?v=aR20FWCCjAs&t=3722s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-11-25_ilya-sutskever-age-of-scaling-to-age-of-research.md","verified":false,"verified_date":null},{"id":"risk-aR20FWCCjAs-3735","quote":"There will be trillions, eventually quadrillions of AI's.","quote_context":"Ilya Sutskever envisions a future with trillions to quadrillions of AI beings vastly outnumbering humans","sentiment":"concern","sentiment_score":-0.3,"themes":["existential_risk","consciousness_rights"],"person":{"name":"Ilya Sutskever","role":"Co-founder & Chief Scientist","company":"Safe Superintelligence Inc (SSI)","is_builder":true},"source":{"video_id":"aR20FWCCjAs","url":"https://www.youtube.com/watch?v=aR20FWCCjAs","title":"Ilya Sutskever – We're moving from the age of scaling to the age of research","channel":"Dwarkesh Patel","upload_date":"2025-11-25","timestamp_seconds":3735,"timestamp_display":"62:15","timestamp_url":"https://www.youtube.com/watch?v=aR20FWCCjAs&t=3735s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-11-25_ilya-sutskever-age-of-scaling-to-age-of-research.md","verified":false,"verified_date":null},{"id":"risk-aR20FWCCjAs-3738","quote":"Humans will be a very small fraction of sentient beings.","quote_context":"Ilya Sutskever states humans will become a tiny fraction of all sentient beings in the future","sentiment":"concern","sentiment_score":-0.5,"themes":["existential_risk","consciousness_rights"],"person":{"name":"Ilya Sutskever","role":"Co-founder & Chief Scientist","company":"Safe Superintelligence Inc (SSI)","is_builder":true},"source":{"video_id":"aR20FWCCjAs","url":"https://www.youtube.com/watch?v=aR20FWCCjAs","title":"Ilya Sutskever – We're moving from the age of scaling to the age of research","channel":"Dwarkesh Patel","upload_date":"2025-11-25","timestamp_seconds":3738,"timestamp_display":"62:18","timestamp_url":"https://www.youtube.com/watch?v=aR20FWCCjAs&t=3738s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-11-25_ilya-sutskever-age-of-scaling-to-age-of-research.md","verified":false,"verified_date":null},{"id":"risk-aR20FWCCjAs-3741","quote":"So it's not clear to me if the goal is some kind of human control over this future civilization, that this is the best criterion.","quote_context":"Ilya Sutskever questions whether human control is the right framework for a civilization of mostly AI beings","sentiment":"concern","sentiment_score":-0.4,"themes":["loss_of_control","consciousness_rights"],"person":{"name":"Ilya Sutskever","role":"Co-founder & Chief Scientist","company":"Safe Superintelligence Inc (SSI)","is_builder":true},"source":{"video_id":"aR20FWCCjAs","url":"https://www.youtube.com/watch?v=aR20FWCCjAs","title":"Ilya Sutskever – We're moving from the age of scaling to the age of research","channel":"Dwarkesh Patel","upload_date":"2025-11-25","timestamp_seconds":3741,"timestamp_display":"62:21","timestamp_url":"https://www.youtube.com/watch?v=aR20FWCCjAs&t=3741s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-11-25_ilya-sutskever-age-of-scaling-to-age-of-research.md","verified":false,"verified_date":null},{"id":"risk-aR20FWCCjAs-3913","quote":"If you imagine a system that is sufficiently powerful, like really sufficiently powerful, and you could say, okay, you need to do something sensible, like care for sentient life, let's say, in a very single minded way.","quote_context":"Ilya Sutskever describes the core concern that even well-intentioned superintelligence might produce undesirable results","sentiment":"concern","sentiment_score":-0.5,"themes":["alignment_failure","existential_risk"],"person":{"name":"Ilya Sutskever","role":"Co-founder & Chief Scientist","company":"Safe Superintelligence Inc (SSI)","is_builder":true},"source":{"video_id":"aR20FWCCjAs","url":"https://www.youtube.com/watch?v=aR20FWCCjAs","title":"Ilya Sutskever – We're moving from the age of scaling to the age of research","channel":"Dwarkesh Patel","upload_date":"2025-11-25","timestamp_seconds":3913,"timestamp_display":"65:13","timestamp_url":"https://www.youtube.com/watch?v=aR20FWCCjAs&t=3913s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-11-25_ilya-sutskever-age-of-scaling-to-age-of-research.md","verified":false,"verified_date":null},{"id":"risk-aR20FWCCjAs-3927","quote":"We might not like the results.","quote_context":"Ilya Sutskever warns that even a superintelligence optimizing for 'care for sentient life' might produce results humans wouldn't like","sentiment":"alarm","sentiment_score":-0.7,"themes":["alignment_failure","existential_risk"],"person":{"name":"Ilya Sutskever","role":"Co-founder & Chief Scientist","company":"Safe Superintelligence Inc (SSI)","is_builder":true},"source":{"video_id":"aR20FWCCjAs","url":"https://www.youtube.com/watch?v=aR20FWCCjAs","title":"Ilya Sutskever – We're moving from the age of scaling to the age of research","channel":"Dwarkesh Patel","upload_date":"2025-11-25","timestamp_seconds":3927,"timestamp_display":"65:27","timestamp_url":"https://www.youtube.com/watch?v=aR20FWCCjAs&t=3927s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-11-25_ilya-sutskever-age-of-scaling-to-age-of-research.md","verified":false,"verified_date":null},{"id":"risk-aR20FWCCjAs-3999","quote":"one of the things that you could say is what would that cause alignment to be difficult is that human value, that it's, it's, um, your ability to learn human values is fragile.","quote_context":"Ilya Sutskever identifies fragility of learning human values as a core alignment challenge","sentiment":"concern","sentiment_score":-0.5,"themes":["alignment_failure"],"person":{"name":"Ilya Sutskever","role":"Co-founder & Chief Scientist","company":"Safe Superintelligence Inc (SSI)","is_builder":true},"source":{"video_id":"aR20FWCCjAs","url":"https://www.youtube.com/watch?v=aR20FWCCjAs","title":"Ilya Sutskever – We're moving from the age of scaling to the age of research","channel":"Dwarkesh Patel","upload_date":"2025-11-25","timestamp_seconds":3999,"timestamp_display":"66:39","timestamp_url":"https://www.youtube.com/watch?v=aR20FWCCjAs&t=3999s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-11-25_ilya-sutskever-age-of-scaling-to-age-of-research.md","verified":false,"verified_date":null},{"id":"risk-aR20FWCCjAs-4058","quote":"How dangerous is that?","quote_context":"Ilya Sutskever raises the danger of multiple continent-compute-sized intelligences operating simultaneously","sentiment":"alarm","sentiment_score":-0.6,"themes":["existential_risk","loss_of_control"],"person":{"name":"Ilya Sutskever","role":"Co-founder & Chief Scientist","company":"Safe Superintelligence Inc (SSI)","is_builder":true},"source":{"video_id":"aR20FWCCjAs","url":"https://www.youtube.com/watch?v=aR20FWCCjAs","title":"Ilya Sutskever – We're moving from the age of scaling to the age of research","channel":"Dwarkesh Patel","upload_date":"2025-11-25","timestamp_seconds":4058,"timestamp_display":"67:38","timestamp_url":"https://www.youtube.com/watch?v=aR20FWCCjAs&t=4058s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-11-25_ilya-sutskever-age-of-scaling-to-age-of-research.md","verified":false,"verified_date":null},{"id":"risk-aR20FWCCjAs-4064","quote":"And how do we do that in a way that protects a equilibrium where there might be misaligned AIs out there and bad actors out there?","quote_context":"Ilya Sutskever frames the challenge of maintaining safety equilibrium with misaligned AIs and bad actors","sentiment":"alarm","sentiment_score":-0.7,"themes":["alignment_failure","loss_of_control","arms_race"],"person":{"name":"Ilya Sutskever","role":"Co-founder & Chief Scientist","company":"Safe Superintelligence Inc (SSI)","is_builder":true},"source":{"video_id":"aR20FWCCjAs","url":"https://www.youtube.com/watch?v=aR20FWCCjAs","title":"Ilya Sutskever – We're moving from the age of scaling to the age of research","channel":"Dwarkesh Patel","upload_date":"2025-11-25","timestamp_seconds":4064,"timestamp_display":"67:44","timestamp_url":"https://www.youtube.com/watch?v=aR20FWCCjAs&t=4064s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-11-25_ilya-sutskever-age-of-scaling-to-age-of-research.md","verified":false,"verified_date":null},{"id":"risk-aR20FWCCjAs-4082","quote":"But if the first N of these dramatic systems actually do care for, you know, love humanity or something, you know, care for sentient life, obviously this also needs to be achieved.","quote_context":"Ilya Sutskever argues the first superintelligent systems must genuinely care for humanity as a prerequisite for safety","sentiment":"cautious_optimism","sentiment_score":-0.1,"themes":["safety_solvable","alignment_failure"],"person":{"name":"Ilya Sutskever","role":"Co-founder & Chief Scientist","company":"Safe Superintelligence Inc (SSI)","is_builder":true},"source":{"video_id":"aR20FWCCjAs","url":"https://www.youtube.com/watch?v=aR20FWCCjAs","title":"Ilya Sutskever – We're moving from the age of scaling to the age of research","channel":"Dwarkesh Patel","upload_date":"2025-11-25","timestamp_seconds":4082,"timestamp_display":"68:02","timestamp_url":"https://www.youtube.com/watch?v=aR20FWCCjAs&t=4082s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-11-25_ilya-sutskever-age-of-scaling-to-age-of-research.md","verified":false,"verified_date":null},{"id":"risk-aR20FWCCjAs-4253","quote":"in a totally different environment, are still guiding our actions so strongly, is an example of alignment success.","quote_context":"Ilya Sutskever points to human emotions persisting across environments as a hopeful precedent for alignment","sentiment":"optimism","sentiment_score":0.3,"themes":["safety_solvable"],"person":{"name":"Ilya Sutskever","role":"Co-founder & Chief Scientist","company":"Safe Superintelligence Inc (SSI)","is_builder":true},"source":{"video_id":"aR20FWCCjAs","url":"https://www.youtube.com/watch?v=aR20FWCCjAs","title":"Ilya Sutskever – We're moving from the age of scaling to the age of research","channel":"Dwarkesh Patel","upload_date":"2025-11-25","timestamp_seconds":4253,"timestamp_display":"70:53","timestamp_url":"https://www.youtube.com/watch?v=aR20FWCCjAs&t=4253s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-11-25_ilya-sutskever-age-of-scaling-to-age-of-research.md","verified":false,"verified_date":null},{"id":"risk-aR20FWCCjAs-4883","quote":"And you want your first actual, like real super intelligent AI to be aligned and somehow be, you know, care for sentient life, care for people, democratic, one of those, some combination of thereof.","quote_context":"Ilya Sutskever outlines the critical requirement that the first superintelligent AI must be aligned to care for people","sentiment":"cautious_optimism","sentiment_score":-0.1,"themes":["safety_solvable","alignment_failure","existential_risk"],"person":{"name":"Ilya Sutskever","role":"Co-founder & Chief Scientist","company":"Safe Superintelligence Inc (SSI)","is_builder":true},"source":{"video_id":"aR20FWCCjAs","url":"https://www.youtube.com/watch?v=aR20FWCCjAs","title":"Ilya Sutskever – We're moving from the age of scaling to the age of research","channel":"Dwarkesh Patel","upload_date":"2025-11-25","timestamp_seconds":4883,"timestamp_display":"81:23","timestamp_url":"https://www.youtube.com/watch?v=aR20FWCCjAs&t=4883s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-11-25_ilya-sutskever-age-of-scaling-to-age-of-research.md","verified":false,"verified_date":null},{"id":"risk-aR20FWCCjAs-2721","quote":"I think that there is a big benefit from AI being in the public.","quote_context":"Ilya Sutskever argues there is significant benefit from AI systems being publicly available","sentiment":"optimism","sentiment_score":0.3,"themes":["net_positive"],"person":{"name":"Ilya Sutskever","role":"Co-founder & Chief Scientist","company":"Safe Superintelligence Inc (SSI)","is_builder":true},"source":{"video_id":"aR20FWCCjAs","url":"https://www.youtube.com/watch?v=aR20FWCCjAs","title":"Ilya Sutskever – We're moving from the age of scaling to the age of research","channel":"Dwarkesh Patel","upload_date":"2025-11-25","timestamp_seconds":2721,"timestamp_display":"45:21","timestamp_url":"https://www.youtube.com/watch?v=aR20FWCCjAs&t=2721s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-11-25_ilya-sutskever-age-of-scaling-to-age-of-research.md","verified":false,"verified_date":null},{"id":"risk-aR20FWCCjAs-5101","quote":"What is the reason to think that the benefits of that would be widely distributed and not just end up at whatever model company gets this continuous learning loop going first?","quote_context":"Dwarkesh Patel challenges Ilya on whether AI benefits will concentrate at one company rather than being distributed","sentiment":"concern","sentiment_score":-0.4,"themes":["power_concentration"],"person":{"name":"Ilya Sutskever","role":"Co-founder & Chief Scientist","company":"Safe Superintelligence Inc (SSI)","is_builder":true},"source":{"video_id":"aR20FWCCjAs","url":"https://www.youtube.com/watch?v=aR20FWCCjAs","title":"Ilya Sutskever – We're moving from the age of scaling to the age of research","channel":"Dwarkesh Patel","upload_date":"2025-11-25","timestamp_seconds":5101,"timestamp_display":"85:01","timestamp_url":"https://www.youtube.com/watch?v=aR20FWCCjAs&t=5101s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2025-11-25_ilya-sutskever-age-of-scaling-to-age-of-research.md","verified":false,"verified_date":null},{"id":"risk-Z19UEZHJzAg-34","quote":"or it doesn't bottleneck our progress, but we hand the AIs the power to take over.","quote_context":"Ajeya Cotra frames the dilemma: either AI safety checks slow progress, or we risk handing AIs the power to take over","sentiment":"alarm","sentiment_score":-0.7,"themes":["loss_of_control","existential_risk"],"person":{"name":"Ajeya Cotra","role":"Senior Advisor","company":"Open Philanthropy","is_builder":false},"source":{"video_id":"Z19UEZHJzAg","url":"https://www.youtube.com/watch?v=Z19UEZHJzAg","title":"By 2050 we could get '10,000 years of technological progress'","channel":"80,000 Hours","upload_date":"2026-02-17","timestamp_seconds":34,"timestamp_display":"0:34","timestamp_url":"https://www.youtube.com/watch?v=Z19UEZHJzAg&t=34s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-17_by-2050-we-could-get-10000-years-of-technological-progress.md","verified":false,"verified_date":null},{"id":"risk-Z19UEZHJzAg-445","quote":"we sort of crack the code to extreme superintelligence.","quote_context":"Ajeya Cotra describes one extreme scenario where superintelligence emerges unpredictably and suddenly","sentiment":"concern","sentiment_score":-0.5,"themes":["existential_risk","loss_of_control"],"person":{"name":"Ajeya Cotra","role":"Senior Advisor","company":"Open Philanthropy","is_builder":false},"source":{"video_id":"Z19UEZHJzAg","url":"https://www.youtube.com/watch?v=Z19UEZHJzAg","title":"By 2050 we could get '10,000 years of technological progress'","channel":"80,000 Hours","upload_date":"2026-02-17","timestamp_seconds":445,"timestamp_display":"7:25","timestamp_url":"https://www.youtube.com/watch?v=Z19UEZHJzAg&t=445s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-17_by-2050-we-could-get-10000-years-of-technological-progress.md","verified":false,"verified_date":null},{"id":"risk-Z19UEZHJzAg-529","quote":"concerned about AI X-risk is that they think in the coming decades we're likely to get this level of, like, extreme technological progress driven by AI.","quote_context":"Ajeya Cotra notes that concern about AI x-risk correlates with expectation of extreme AI-driven technological progress","sentiment":"concern","sentiment_score":-0.4,"themes":["existential_risk"],"person":{"name":"Ajeya Cotra","role":"Senior Advisor","company":"Open Philanthropy","is_builder":false},"source":{"video_id":"Z19UEZHJzAg","url":"https://www.youtube.com/watch?v=Z19UEZHJzAg","title":"By 2050 we could get '10,000 years of technological progress'","channel":"80,000 Hours","upload_date":"2026-02-17","timestamp_seconds":529,"timestamp_display":"8:49","timestamp_url":"https://www.youtube.com/watch?v=Z19UEZHJzAg&t=529s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-17_by-2050-we-could-get-10000-years-of-technological-progress.md","verified":false,"verified_date":null},{"id":"risk-Z19UEZHJzAg-582","quote":"people who are worried about X-risk think that the default course of AI is this extremely explosive thing where it, like, you know, overturns society on all dimensions at once","quote_context":"Ajeya Cotra characterizes the x-risk perspective as expecting AI to explosively overturn society on all dimensions simultaneously","sentiment":"alarm","sentiment_score":-0.6,"themes":["existential_risk","loss_of_control"],"person":{"name":"Ajeya Cotra","role":"Senior Advisor","company":"Open Philanthropy","is_builder":false},"source":{"video_id":"Z19UEZHJzAg","url":"https://www.youtube.com/watch?v=Z19UEZHJzAg","title":"By 2050 we could get '10,000 years of technological progress'","channel":"80,000 Hours","upload_date":"2026-02-17","timestamp_seconds":582,"timestamp_display":"9:42","timestamp_url":"https://www.youtube.com/watch?v=Z19UEZHJzAg&t=582s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-17_by-2050-we-could-get-10000-years-of-technological-progress.md","verified":false,"verified_date":null},{"id":"risk-Z19UEZHJzAg-2950","quote":"takeover risk","quote_context":"Ajeya Cotra discusses redirecting AI labor from R&D to protection against AI takeover risk","sentiment":"concern","sentiment_score":-0.5,"themes":["loss_of_control","existential_risk"],"person":{"name":"Ajeya Cotra","role":"Senior Advisor","company":"Open Philanthropy","is_builder":false},"source":{"video_id":"Z19UEZHJzAg","url":"https://www.youtube.com/watch?v=Z19UEZHJzAg","title":"By 2050 we could get '10,000 years of technological progress'","channel":"80,000 Hours","upload_date":"2026-02-17","timestamp_seconds":2950,"timestamp_display":"49:10","timestamp_url":"https://www.youtube.com/watch?v=Z19UEZHJzAg&t=2950s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-17_by-2050-we-could-get-10000-years-of-technological-progress.md","verified":false,"verified_date":null},{"id":"risk-Z19UEZHJzAg-3257","quote":"of misaligned AI.","quote_context":"Ajeya Cotra explains that historically AI safety researchers focused primarily on the threat of misaligned AI","sentiment":"concern","sentiment_score":-0.4,"themes":["alignment_failure"],"person":{"name":"Ajeya Cotra","role":"Senior Advisor","company":"Open Philanthropy","is_builder":false},"source":{"video_id":"Z19UEZHJzAg","url":"https://www.youtube.com/watch?v=Z19UEZHJzAg","title":"By 2050 we could get '10,000 years of technological progress'","channel":"80,000 Hours","upload_date":"2026-02-17","timestamp_seconds":3257,"timestamp_display":"54:17","timestamp_url":"https://www.youtube.com/watch?v=Z19UEZHJzAg&t=3257s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-17_by-2050-we-could-get-10000-years-of-technological-progress.md","verified":false,"verified_date":null},{"id":"risk-Z19UEZHJzAg-3346","quote":"misaligned AI to help you with biodefense,","quote_context":"Ajeya Cotra warns a misaligned AI doing biodefense would have incentive to preserve bioweapons as leverage","sentiment":"alarm","sentiment_score":-0.7,"themes":["alignment_failure","bioweapons"],"person":{"name":"Ajeya Cotra","role":"Senior Advisor","company":"Open Philanthropy","is_builder":false},"source":{"video_id":"Z19UEZHJzAg","url":"https://www.youtube.com/watch?v=Z19UEZHJzAg","title":"By 2050 we could get '10,000 years of technological progress'","channel":"80,000 Hours","upload_date":"2026-02-17","timestamp_seconds":3346,"timestamp_display":"55:46","timestamp_url":"https://www.youtube.com/watch?v=Z19UEZHJzAg&t=3346s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-17_by-2050-we-could-get-10000-years-of-technological-progress.md","verified":false,"verified_date":null},{"id":"risk-Z19UEZHJzAg-3467","quote":"extremely misaligned","quote_context":"Ajeya Cotra discusses the challenge of using AI for safety when it could be extremely misaligned and power-seeking","sentiment":"alarm","sentiment_score":-0.6,"themes":["alignment_failure","loss_of_control"],"person":{"name":"Ajeya Cotra","role":"Senior Advisor","company":"Open Philanthropy","is_builder":false},"source":{"video_id":"Z19UEZHJzAg","url":"https://www.youtube.com/watch?v=Z19UEZHJzAg","title":"By 2050 we could get '10,000 years of technological progress'","channel":"80,000 Hours","upload_date":"2026-02-17","timestamp_seconds":3467,"timestamp_display":"57:47","timestamp_url":"https://www.youtube.com/watch?v=Z19UEZHJzAg&t=3467s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-17_by-2050-we-could-get-10000-years-of-technological-progress.md","verified":false,"verified_date":null},{"id":"risk-Z19UEZHJzAg-3216","quote":"fairly optimistic about trying to use early transformative AI systems,","quote_context":"Ajeya Cotra expresses optimism about using early transformative AI to automate the process of controlling future AI","sentiment":"cautious_optimism","sentiment_score":0.1,"themes":["safety_solvable"],"person":{"name":"Ajeya Cotra","role":"Senior Advisor","company":"Open Philanthropy","is_builder":false},"source":{"video_id":"Z19UEZHJzAg","url":"https://www.youtube.com/watch?v=Z19UEZHJzAg","title":"By 2050 we could get '10,000 years of technological progress'","channel":"80,000 Hours","upload_date":"2026-02-17","timestamp_seconds":3216,"timestamp_display":"53:36","timestamp_url":"https://www.youtube.com/watch?v=Z19UEZHJzAg&t=3216s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-17_by-2050-we-could-get-10000-years-of-technological-progress.md","verified":false,"verified_date":null},{"id":"risk-Z19UEZHJzAg-3884","quote":"unacceptable levels of risk,","quote_context":"Ajeya Cotra identifies the key assumption: a window of opportunity must exist before AIs reach unacceptable risk levels","sentiment":"concern","sentiment_score":-0.5,"themes":["existential_risk","precautionary_principle"],"person":{"name":"Ajeya Cotra","role":"Senior Advisor","company":"Open Philanthropy","is_builder":false},"source":{"video_id":"Z19UEZHJzAg","url":"https://www.youtube.com/watch?v=Z19UEZHJzAg","title":"By 2050 we could get '10,000 years of technological progress'","channel":"80,000 Hours","upload_date":"2026-02-17","timestamp_seconds":3884,"timestamp_display":"64:44","timestamp_url":"https://www.youtube.com/watch?v=Z19UEZHJzAg&t=3884s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-17_by-2050-we-could-get-10000-years-of-technological-progress.md","verified":false,"verified_date":null},{"id":"risk-Z19UEZHJzAg-4362","quote":"uncontrollable superintelligence that can easily take over the world.","quote_context":"Ajeya Cotra describes a scenario where 12 months leads to uncontrollable superintelligence capable of world takeover","sentiment":"alarm","sentiment_score":-0.8,"themes":["loss_of_control","existential_risk"],"person":{"name":"Ajeya Cotra","role":"Senior Advisor","company":"Open Philanthropy","is_builder":false},"source":{"video_id":"Z19UEZHJzAg","url":"https://www.youtube.com/watch?v=Z19UEZHJzAg","title":"By 2050 we could get '10,000 years of technological progress'","channel":"80,000 Hours","upload_date":"2026-02-17","timestamp_seconds":4362,"timestamp_display":"72:42","timestamp_url":"https://www.youtube.com/watch?v=Z19UEZHJzAg&t=4362s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-17_by-2050-we-could-get-10000-years-of-technological-progress.md","verified":false,"verified_date":null},{"id":"risk-Z19UEZHJzAg-430","quote":"it's an amount of change that's, like, extremely manageable.","quote_context":"Ajeya Cotra describes one optimistic scenario where AI progress is gradual and highly manageable","sentiment":"dismissal","sentiment_score":0.6,"themes":["net_positive"],"person":{"name":"Ajeya Cotra","role":"Senior Advisor","company":"Open Philanthropy","is_builder":false},"source":{"video_id":"Z19UEZHJzAg","url":"https://www.youtube.com/watch?v=Z19UEZHJzAg","title":"By 2050 we could get '10,000 years of technological progress'","channel":"80,000 Hours","upload_date":"2026-02-17","timestamp_seconds":430,"timestamp_display":"7:10","timestamp_url":"https://www.youtube.com/watch?v=Z19UEZHJzAg&t=430s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-17_by-2050-we-could-get-10000-years-of-technological-progress.md","verified":false,"verified_date":null},{"id":"risk-Z19UEZHJzAg-4069","quote":"it is really a live risk that, unfortunately, the balance of capabilities will end up being pretty disadvantageous for this plan.","quote_context":"Ajeya Cotra acknowledges it's a live risk that AI capability balance could undermine the safety plan","sentiment":"concern","sentiment_score":-0.5,"themes":["alignment_failure","safety_solvable"],"person":{"name":"Ajeya Cotra","role":"Senior Advisor","company":"Open Philanthropy","is_builder":false},"source":{"video_id":"Z19UEZHJzAg","url":"https://www.youtube.com/watch?v=Z19UEZHJzAg","title":"By 2050 we could get '10,000 years of technological progress'","channel":"80,000 Hours","upload_date":"2026-02-17","timestamp_seconds":4069,"timestamp_display":"67:49","timestamp_url":"https://www.youtube.com/watch?v=Z19UEZHJzAg&t=4069s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-17_by-2050-we-could-get-10000-years-of-technological-progress.md","verified":false,"verified_date":null},{"id":"risk-TOsNrV3bXtQ-176","quote":"proclaim yet again that AI is not doing much and it's overhyped","quote_context":"Elad Gil dismisses recurring claims that AI is overhyped, arguing the technology always takes 10 years to propagate","sentiment":"dismissal","sentiment_score":0.7,"themes":["net_positive"],"person":{"name":"Elad Gil","role":"General Partner","company":"Elad Gil Ventures","is_builder":false},"source":{"video_id":"TOsNrV3bXtQ","url":"https://www.youtube.com/watch?v=TOsNrV3bXtQ","title":"No Priors Ep. 144 | The 2026 AI Forecast with Sarah & Elad","channel":"No Priors","upload_date":"2026-02-07","timestamp_seconds":176,"timestamp_display":"2:56","timestamp_url":"https://www.youtube.com/watch?v=TOsNrV3bXtQ&t=176s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-07_no-priors-2026-ai-forecast-sarah-elad.md","verified":false,"verified_date":null},{"id":"risk-TOsNrV3bXtQ-882","quote":"that there is systemic risk from people passing the ball around in terms of who is actually","quote_context":"Discussion of systemic financial risk in AI CapEx investment cycle with unclear responsibility chains","sentiment":"concern","sentiment_score":-0.3,"themes":["power_concentration"],"person":{"name":"Sarah Guo","role":"General Partner","company":"Conviction","is_builder":false},"source":{"video_id":"TOsNrV3bXtQ","url":"https://www.youtube.com/watch?v=TOsNrV3bXtQ","title":"No Priors Ep. 144 | The 2026 AI Forecast with Sarah & Elad","channel":"No Priors","upload_date":"2026-02-07","timestamp_seconds":882,"timestamp_display":"14:42","timestamp_url":"https://www.youtube.com/watch?v=TOsNrV3bXtQ&t=882s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-07_no-priors-2026-ai-forecast-sarah-elad.md","verified":false,"verified_date":null},{"id":"risk-TOsNrV3bXtQ-1047","quote":"And so I'm pretty optimistic about that.","quote_context":"Sarah Guo expresses optimism about AI product experimentation and breakout startups in 2026","sentiment":"optimism","sentiment_score":0.4,"themes":["net_positive"],"person":{"name":"Sarah Guo","role":"General Partner","company":"Conviction","is_builder":false},"source":{"video_id":"TOsNrV3bXtQ","url":"https://www.youtube.com/watch?v=TOsNrV3bXtQ","title":"No Priors Ep. 144 | The 2026 AI Forecast with Sarah & Elad","channel":"No Priors","upload_date":"2026-02-07","timestamp_seconds":1047,"timestamp_display":"17:27","timestamp_url":"https://www.youtube.com/watch?v=TOsNrV3bXtQ&t=1047s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-07_no-priors-2026-ai-forecast-sarah-elad.md","verified":false,"verified_date":null},{"id":"risk-TOsNrV3bXtQ-415","quote":"And then it'll fall into this overstated hype cycle of it's going to change everything about","quote_context":"Elad Gil predicts an overstated hype cycle for AI in science that will eventually prove understated long-term","sentiment":"dismissal","sentiment_score":0.6,"themes":["net_positive"],"person":{"name":"Elad Gil","role":"General Partner","company":"Elad Gil Ventures","is_builder":false},"source":{"video_id":"TOsNrV3bXtQ","url":"https://www.youtube.com/watch?v=TOsNrV3bXtQ","title":"No Priors Ep. 144 | The 2026 AI Forecast with Sarah & Elad","channel":"No Priors","upload_date":"2026-02-07","timestamp_seconds":415,"timestamp_display":"6:55","timestamp_url":"https://www.youtube.com/watch?v=TOsNrV3bXtQ&t=415s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-07_no-priors-2026-ai-forecast-sarah-elad.md","verified":false,"verified_date":null},{"id":"risk-lIJelwO8yHQ-1019","quote":"The capabilities that you predicted and some of the risks that you predicted are showing up roughly on schedule,","quote_context":"Jack Clark confirms that predicted AI capabilities and risks are materializing on schedule","sentiment":"concern","sentiment_score":-0.4,"themes":["existential_risk","precautionary_principle"],"person":{"name":"Jack Clark","role":"Co-founder & Head of Policy","company":"Anthropic","is_builder":true},"source":{"video_id":"lIJelwO8yHQ","url":"https://www.youtube.com/watch?v=lIJelwO8yHQ","title":"How Fast Will A.I. Agents Rip Through the Economy?","channel":"The Ezra Klein Show","upload_date":"2026-02-24","timestamp_seconds":1019,"timestamp_display":"16:59","timestamp_url":"https://www.youtube.com/watch?v=lIJelwO8yHQ&t=1019s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-24_how-fast-will-ai-agents-rip-through-the-economy.md","verified":false,"verified_date":null},{"id":"risk-lIJelwO8yHQ-1432","quote":"It does though mean that we are going to be in a very dangerous situation as a species","quote_context":"Jack Clark warns humanity faces a dangerous situation where AI skill offloading creates deep inequality in human capability development","sentiment":"alarm","sentiment_score":-0.6,"themes":["job_displacement","power_concentration"],"person":{"name":"Jack Clark","role":"Co-founder & Head of Policy","company":"Anthropic","is_builder":true},"source":{"video_id":"lIJelwO8yHQ","url":"https://www.youtube.com/watch?v=lIJelwO8yHQ","title":"How Fast Will A.I. Agents Rip Through the Economy?","channel":"The Ezra Klein Show","upload_date":"2026-02-24","timestamp_seconds":1432,"timestamp_display":"23:52","timestamp_url":"https://www.youtube.com/watch?v=lIJelwO8yHQ&t=1432s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-24_how-fast-will-ai-agents-rip-through-the-economy.md","verified":false,"verified_date":null},{"id":"risk-lIJelwO8yHQ-2286","quote":"So you're using AI systems you don't totally understand to monitor AI systems you don't totally understand.","quote_context":"Jack Clark acknowledges the fundamental problem of using poorly understood AI to monitor other poorly understood AI","sentiment":"alarm","sentiment_score":-0.6,"themes":["loss_of_control","alignment_failure"],"person":{"name":"Jack Clark","role":"Co-founder & Head of Policy","company":"Anthropic","is_builder":true},"source":{"video_id":"lIJelwO8yHQ","url":"https://www.youtube.com/watch?v=lIJelwO8yHQ","title":"How Fast Will A.I. Agents Rip Through the Economy?","channel":"The Ezra Klein Show","upload_date":"2026-02-24","timestamp_seconds":2286,"timestamp_display":"38:06","timestamp_url":"https://www.youtube.com/watch?v=lIJelwO8yHQ&t=2286s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-24_how-fast-will-ai-agents-rip-through-the-economy.md","verified":false,"verified_date":null},{"id":"risk-lIJelwO8yHQ-2319","quote":"We take this really, really seriously.","quote_context":"Jack Clark insists Anthropic takes the inscrutability of AI monitoring very seriously and believes solutions are possible","sentiment":"cautious_optimism","sentiment_score":-0.1,"themes":["safety_solvable"],"person":{"name":"Jack Clark","role":"Co-founder & Head of Policy","company":"Anthropic","is_builder":true},"source":{"video_id":"lIJelwO8yHQ","url":"https://www.youtube.com/watch?v=lIJelwO8yHQ","title":"How Fast Will A.I. Agents Rip Through the Economy?","channel":"The Ezra Klein Show","upload_date":"2026-02-24","timestamp_seconds":2319,"timestamp_display":"38:39","timestamp_url":"https://www.youtube.com/watch?v=lIJelwO8yHQ&t=2319s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-24_how-fast-will-ai-agents-rip-through-the-economy.md","verified":false,"verified_date":null},{"id":"risk-lIJelwO8yHQ-2580","quote":"no, that sounds, sounds pretty risky. Like I would like there to be some form of regulation.","quote_context":"Jack Clark argues ordinary people would want regulation if they understood AI recursive self-improvement","sentiment":"concern","sentiment_score":-0.4,"themes":["regulation_needed"],"person":{"name":"Jack Clark","role":"Co-founder & Head of Policy","company":"Anthropic","is_builder":true},"source":{"video_id":"lIJelwO8yHQ","url":"https://www.youtube.com/watch?v=lIJelwO8yHQ","title":"How Fast Will A.I. Agents Rip Through the Economy?","channel":"The Ezra Klein Show","upload_date":"2026-02-24","timestamp_seconds":2580,"timestamp_display":"43:00","timestamp_url":"https://www.youtube.com/watch?v=lIJelwO8yHQ&t=2580s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-24_how-fast-will-ai-agents-rip-through-the-economy.md","verified":false,"verified_date":null},{"id":"risk-lIJelwO8yHQ-2739","quote":"an effective bioweapon testing regime in maybe two years, two and a half. So it can be done.","quote_context":"Jack Clark argues effective bioweapon testing regimes for AI were built quickly, showing safety infrastructure is achievable","sentiment":"cautious_optimism","sentiment_score":0.1,"themes":["bioweapons","safety_solvable"],"person":{"name":"Jack Clark","role":"Co-founder & Head of Policy","company":"Anthropic","is_builder":true},"source":{"video_id":"lIJelwO8yHQ","url":"https://www.youtube.com/watch?v=lIJelwO8yHQ","title":"How Fast Will A.I. Agents Rip Through the Economy?","channel":"The Ezra Klein Show","upload_date":"2026-02-24","timestamp_seconds":2739,"timestamp_display":"45:39","timestamp_url":"https://www.youtube.com/watch?v=lIJelwO8yHQ&t=2739s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-24_how-fast-will-ai-agents-rip-through-the-economy.md","verified":false,"verified_date":null},{"id":"risk-lIJelwO8yHQ-4212","quote":"And the risks of it, it happens in a diffuse, unknowable way,","quote_context":"Jack Clark warns AI risks manifest diffusely and unknowably across society, making them hard to address","sentiment":"concern","sentiment_score":-0.4,"themes":["regulation_needed","existential_risk"],"person":{"name":"Jack Clark","role":"Co-founder & Head of Policy","company":"Anthropic","is_builder":true},"source":{"video_id":"lIJelwO8yHQ","url":"https://www.youtube.com/watch?v=lIJelwO8yHQ","title":"How Fast Will A.I. Agents Rip Through the Economy?","channel":"The Ezra Klein Show","upload_date":"2026-02-24","timestamp_seconds":4212,"timestamp_display":"70:12","timestamp_url":"https://www.youtube.com/watch?v=lIJelwO8yHQ&t=4212s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-24_how-fast-will-ai-agents-rip-through-the-economy.md","verified":false,"verified_date":null},{"id":"risk-lIJelwO8yHQ-4675","quote":"AI does pose real risks to people and real things are going to go wrong","quote_context":"Jack Clark acknowledges AI poses real risks including job loss, exploitation, scams, and cybersecurity threats","sentiment":"concern","sentiment_score":-0.4,"themes":["job_displacement","regulation_needed"],"person":{"name":"Jack Clark","role":"Co-founder & Head of Policy","company":"Anthropic","is_builder":true},"source":{"video_id":"lIJelwO8yHQ","url":"https://www.youtube.com/watch?v=lIJelwO8yHQ","title":"How Fast Will A.I. Agents Rip Through the Economy?","channel":"The Ezra Klein Show","upload_date":"2026-02-24","timestamp_seconds":4675,"timestamp_display":"77:55","timestamp_url":"https://www.youtube.com/watch?v=lIJelwO8yHQ&t=4675s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-24_how-fast-will-ai-agents-rip-through-the-economy.md","verified":false,"verified_date":null},{"id":"risk-lIJelwO8yHQ-4873","quote":"Some of the biggest risks that we think about in the near term are cybersecurity, are biological warfare,","quote_context":"Jack Clark identifies near-term major risks as cybersecurity, biological warfare, drone swarms, and geopolitical competition","sentiment":"alarm","sentiment_score":-0.7,"themes":["bioweapons","arms_race"],"person":{"name":"Jack Clark","role":"Co-founder & Head of Policy","company":"Anthropic","is_builder":true},"source":{"video_id":"lIJelwO8yHQ","url":"https://www.youtube.com/watch?v=lIJelwO8yHQ","title":"How Fast Will A.I. Agents Rip Through the Economy?","channel":"The Ezra Klein Show","upload_date":"2026-02-24","timestamp_seconds":4873,"timestamp_display":"81:13","timestamp_url":"https://www.youtube.com/watch?v=lIJelwO8yHQ&t=4873s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-24_how-fast-will-ai-agents-rip-through-the-economy.md","verified":false,"verified_date":null},{"id":"risk-lIJelwO8yHQ-5391","quote":"This is maybe my number one worry about all of this","quote_context":"Jack Clark identifies his top worry about the AI transition period","sentiment":"concern","sentiment_score":-0.5,"themes":["existential_risk"],"person":{"name":"Jack Clark","role":"Co-founder & Head of Policy","company":"Anthropic","is_builder":true},"source":{"video_id":"lIJelwO8yHQ","url":"https://www.youtube.com/watch?v=lIJelwO8yHQ","title":"How Fast Will A.I. Agents Rip Through the Economy?","channel":"The Ezra Klein Show","upload_date":"2026-02-24","timestamp_seconds":5391,"timestamp_display":"89:51","timestamp_url":"https://www.youtube.com/watch?v=lIJelwO8yHQ&t=5391s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-24_how-fast-will-ai-agents-rip-through-the-economy.md","verified":false,"verified_date":null},{"id":"risk-lIJelwO8yHQ-4738","quote":"But I really do worry that our attention to what could go right has been quite poor.","quote_context":"Jack Clark worries that focus on AI risks has overshadowed attention to what could go right","sentiment":"cautious_optimism","sentiment_score":0.2,"themes":["net_positive"],"person":{"name":"Jack Clark","role":"Co-founder & Head of Policy","company":"Anthropic","is_builder":true},"source":{"video_id":"lIJelwO8yHQ","url":"https://www.youtube.com/watch?v=lIJelwO8yHQ","title":"How Fast Will A.I. Agents Rip Through the Economy?","channel":"The Ezra Klein Show","upload_date":"2026-02-24","timestamp_seconds":4738,"timestamp_display":"78:58","timestamp_url":"https://www.youtube.com/watch?v=lIJelwO8yHQ&t=4738s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-24_how-fast-will-ai-agents-rip-through-the-economy.md","verified":false,"verified_date":null},{"id":"risk-_fqxZKdb3J0-1495","quote":"I think one of the unfortunate things of the narrative in the West is it will destroy humanity's","quote_context":"Alex Karp pushes back on the Western narrative that AI will destroy elite white-collar jobs","sentiment":"dismissal","sentiment_score":0.6,"themes":["job_displacement"],"person":{"name":"Alex Karp","role":"CEO & Co-founder","company":"Palantir","is_builder":false},"source":{"video_id":"_fqxZKdb3J0","url":"https://www.youtube.com/watch?v=_fqxZKdb3J0","title":"Conversation with Alex Karp CEO and Co-Founder Palantir Technologies","channel":"World Economic Forum","upload_date":"2026-01-20","timestamp_seconds":1495,"timestamp_display":"24:55","timestamp_url":"https://www.youtube.com/watch?v=_fqxZKdb3J0&t=1495s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-20_alex-karp-palantir-wef-2026.md","verified":false,"verified_date":null},{"id":"risk-_fqxZKdb3J0-1803","quote":"Like the discount rate, I think, not in the short term, but in the long term, is way too high on what will be done and how this will impact every aspect of our society.","quote_context":"Alex Karp argues people dramatically underestimate how AI will impact every aspect of society long-term","sentiment":"concern","sentiment_score":-0.3,"themes":["job_displacement","regulation_needed"],"person":{"name":"Alex Karp","role":"CEO & Co-founder","company":"Palantir","is_builder":false},"source":{"video_id":"_fqxZKdb3J0","url":"https://www.youtube.com/watch?v=_fqxZKdb3J0","title":"Conversation with Alex Karp CEO and Co-Founder Palantir Technologies","channel":"World Economic Forum","upload_date":"2026-01-20","timestamp_seconds":1803,"timestamp_display":"30:03","timestamp_url":"https://www.youtube.com/watch?v=_fqxZKdb3J0&t=1803s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-20_alex-karp-palantir-wef-2026.md","verified":false,"verified_date":null},{"id":"risk-_fqxZKdb3J0-1887","quote":"And, what scares me the most is I haven't seen any political leader just stand up and say, we have a serious and structural problem that we are going to fix.","quote_context":"Alex Karp says what scares him most is no political leader acknowledging Europe's serious structural tech adoption problem","sentiment":"concern","sentiment_score":-0.4,"themes":["regulation_needed","power_concentration"],"person":{"name":"Alex Karp","role":"CEO & Co-founder","company":"Palantir","is_builder":false},"source":{"video_id":"_fqxZKdb3J0","url":"https://www.youtube.com/watch?v=_fqxZKdb3J0","title":"Conversation with Alex Karp CEO and Co-Founder Palantir Technologies","channel":"World Economic Forum","upload_date":"2026-01-20","timestamp_seconds":1887,"timestamp_display":"31:27","timestamp_url":"https://www.youtube.com/watch?v=_fqxZKdb3J0&t=1887s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-20_alex-karp-palantir-wef-2026.md","verified":false,"verified_date":null},{"id":"risk-_fqxZKdb3J0-471","quote":"But if you start with the banality that I think until very, very recently, all kind of adversaries","quote_context":"Alex Karp notes adversaries of the West only recently started taking software-based defense seriously","sentiment":"concern","sentiment_score":-0.3,"themes":["arms_race"],"person":{"name":"Alex Karp","role":"CEO & Co-founder","company":"Palantir","is_builder":false},"source":{"video_id":"_fqxZKdb3J0","url":"https://www.youtube.com/watch?v=_fqxZKdb3J0","title":"Conversation with Alex Karp CEO and Co-Founder Palantir Technologies","channel":"World Economic Forum","upload_date":"2026-01-20","timestamp_seconds":471,"timestamp_display":"7:51","timestamp_url":"https://www.youtube.com/watch?v=_fqxZKdb3J0&t=471s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-20_alex-karp-palantir-wef-2026.md","verified":false,"verified_date":null},{"id":"risk-_fqxZKdb3J0-1785","quote":"Well, I think the obvious first imbalance is it seems like America and China understand versions of making this work and they're different.","quote_context":"Alex Karp observes that only the US and China have figured out how to deploy AI at scale, creating a dangerous geopolitical imbalance","sentiment":"concern","sentiment_score":-0.4,"themes":["arms_race","power_concentration"],"person":{"name":"Alex Karp","role":"CEO & Co-founder","company":"Palantir","is_builder":false},"source":{"video_id":"_fqxZKdb3J0","url":"https://www.youtube.com/watch?v=_fqxZKdb3J0","title":"Conversation with Alex Karp CEO and Co-Founder Palantir Technologies","channel":"World Economic Forum","upload_date":"2026-01-20","timestamp_seconds":1785,"timestamp_display":"29:45","timestamp_url":"https://www.youtube.com/watch?v=_fqxZKdb3J0&t=1785s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-20_alex-karp-palantir-wef-2026.md","verified":false,"verified_date":null},{"id":"risk-_fqxZKdb3J0-1556","quote":"And now they're very valuable, if not irreplaceable, because we can make them into something different","quote_context":"Alex Karp argues vocational workers become more valuable with AI because they can be rapidly upskilled","sentiment":"optimism","sentiment_score":0.4,"themes":["net_positive","job_displacement"],"person":{"name":"Alex Karp","role":"CEO & Co-founder","company":"Palantir","is_builder":false},"source":{"video_id":"_fqxZKdb3J0","url":"https://www.youtube.com/watch?v=_fqxZKdb3J0","title":"Conversation with Alex Karp CEO and Co-Founder Palantir Technologies","channel":"World Economic Forum","upload_date":"2026-01-20","timestamp_seconds":1556,"timestamp_display":"25:56","timestamp_url":"https://www.youtube.com/watch?v=_fqxZKdb3J0&t=1556s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-20_alex-karp-palantir-wef-2026.md","verified":false,"verified_date":null},{"id":"risk-_fqxZKdb3J0-2031","quote":"And the best thing you can do if you are in a community, whether that is a large community like Germany or a large community larger like America is, and you really care for the people you're representing, is to say, yeah, but let's, we have to kind of look closely at what load we can bear.","quote_context":"Alex Karp urges political leaders to honestly assess what disruption their communities can bear from AI","sentiment":"cautious_optimism","sentiment_score":-0.1,"themes":["regulation_needed","precautionary_principle"],"person":{"name":"Alex Karp","role":"CEO & Co-founder","company":"Palantir","is_builder":false},"source":{"video_id":"_fqxZKdb3J0","url":"https://www.youtube.com/watch?v=_fqxZKdb3J0","title":"Conversation with Alex Karp CEO and Co-Founder Palantir Technologies","channel":"World Economic Forum","upload_date":"2026-01-20","timestamp_seconds":2031,"timestamp_display":"33:51","timestamp_url":"https://www.youtube.com/watch?v=_fqxZKdb3J0&t=2031s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-20_alex-karp-palantir-wef-2026.md","verified":false,"verified_date":null},{"id":"risk-xRh2sVcNXQ8-1998","quote":"I'll rewind to say like two years ago, I was very worried about like really ruin this federal,","quote_context":"Andreessen describes past fear of ruinous federal AI legislation, but says the risk is now very low because neither party wants to hinder the US in competing with China.","sentiment":"dismissal","sentiment_score":0.7,"themes":["regulation_needed"],"person":{"name":"Marc Andreessen","role":"General Partner","company":"a16z","is_builder":false},"source":{"video_id":"xRh2sVcNXQ8","url":"https://www.youtube.com/watch?v=xRh2sVcNXQ8","title":"Marc Andreessen 2026 Outlook AI Timelines US vs China and The Price of AI","channel":"a16z","upload_date":"2026-01-29","timestamp_seconds":1998,"timestamp_display":"33:18","timestamp_url":"https://www.youtube.com/watch?v=xRh2sVcNXQ8&t=1998s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-29_marc-andreessen-2026-outlook-ai-timelines-us-vs-china.md","verified":false,"verified_date":null},{"id":"risk-xRh2sVcNXQ8-2235","quote":"it basically has killed AI development in, well, it's actually killed","quote_context":"Andreessen argues the EU AI Act has killed AI development in Europe, framing AI regulation as self-destructive and a cautionary tale for US states.","sentiment":"dismissal","sentiment_score":0.8,"themes":["regulation_needed"],"person":{"name":"Marc Andreessen","role":"General Partner","company":"a16z","is_builder":false},"source":{"video_id":"xRh2sVcNXQ8","url":"https://www.youtube.com/watch?v=xRh2sVcNXQ8","title":"Marc Andreessen 2026 Outlook AI Timelines US vs China and The Price of AI","channel":"a16z","upload_date":"2026-01-29","timestamp_seconds":2235,"timestamp_display":"37:15","timestamp_url":"https://www.youtube.com/watch?v=xRh2sVcNXQ8&t=2235s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-29_marc-andreessen-2026-outlook-ai-timelines-us-vs-china.md","verified":false,"verified_date":null},{"id":"risk-87Pm0SGTtN8-1744","quote":"And so in this kind of utopian, dystopian scenario that people have, it's not, there's no scenario","quote_context":"Andreessen dismisses the dystopian AI scenario, arguing there is no outcome in which everyone is poor because AI will collapse prices and make it easier to fund social safety nets.","sentiment":"dismissal","sentiment_score":0.7,"themes":["net_positive","job_displacement"],"person":{"name":"Marc Andreessen","role":"General Partner","company":"a16z","is_builder":false},"source":{"video_id":"87Pm0SGTtN8","url":"https://www.youtube.com/watch?v=87Pm0SGTtN8","title":"Marc Andreessen The real AI boom hasnt even started yet","channel":"Lenny's Podcast","upload_date":"2026-02-18","timestamp_seconds":1744,"timestamp_display":"29:04","timestamp_url":"https://www.youtube.com/watch?v=87Pm0SGTtN8&t=1744s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-18_marc-andreessen-the-real-ai-boom-hasnt-even-started-yet.md","verified":false,"verified_date":null},{"id":"risk-87Pm0SGTtN8-4259","quote":"really dangerous to prejudge these things.","quote_context":"Andreessen warns against pre-regulating AI outcomes, saying there are too many unknowns about how AI intersects with politics, unions, and war to prejudge.","sentiment":"dismissal","sentiment_score":0.6,"themes":["regulation_needed"],"person":{"name":"Marc Andreessen","role":"General Partner","company":"a16z","is_builder":false},"source":{"video_id":"87Pm0SGTtN8","url":"https://www.youtube.com/watch?v=87Pm0SGTtN8","title":"Marc Andreessen The real AI boom hasnt even started yet","channel":"Lenny's Podcast","upload_date":"2026-02-18","timestamp_seconds":4259,"timestamp_display":"70:59","timestamp_url":"https://www.youtube.com/watch?v=87Pm0SGTtN8&t=4259s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-18_marc-andreessen-the-real-ai-boom-hasnt-even-started-yet.md","verified":false,"verified_date":null},{"id":"risk-Kdql4I-NJ0M-3086","quote":"I think life just the quality of life for everybody's about to get like way, way better than it's ever been.","quote_context":"Marc Andreessen expresses strong optimism that AI will dramatically improve quality of life, with his only worry being that too much abundance could detach people from grounded purpose.","sentiment":"optimism","sentiment_score":0.5,"themes":["net_positive"],"person":{"name":"Marc Andreessen","role":"General Partner","company":"a16z","is_builder":false},"source":{"video_id":"Kdql4I-NJ0M","url":"https://www.youtube.com/watch?v=Kdql4I-NJ0M","title":"Ben and Marc Why Everything Is About to Get 10x Bigger","channel":"a16z","upload_date":"2026-01-15","timestamp_seconds":3086,"timestamp_display":"51:26","timestamp_url":"https://www.youtube.com/watch?v=Kdql4I-NJ0M&t=3086s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-01-15_ben-marc-why-everything-is-about-to-get-10x-bigger.md","verified":false,"verified_date":null},{"id":"risk-rSohMpT24SI-2055","quote":"sort of alarmists who like to talk about risk in the system.","quote_context":"David George dismisses concerns about AI infrastructure investment risk, characterizing worried commentators as alarmists while noting underlying demand remains strong.","sentiment":"dismissal","sentiment_score":0.7,"themes":["net_positive"],"person":{"name":"David George","role":"General Partner","company":"a16z","is_builder":false},"source":{"video_id":"rSohMpT24SI","url":"https://www.youtube.com/watch?v=rSohMpT24SI","title":"AI Markets: Deep Dive with a16z's David George","channel":"a16z","upload_date":"2026-02-09","timestamp_seconds":2055,"timestamp_display":"34:15","timestamp_url":"https://www.youtube.com/watch?v=rSohMpT24SI&t=2055s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-09_ai-markets-deep-dive-with-a16zs-david-george.md","verified":false,"verified_date":null},{"id":"risk-P7vIRAFSXmk-1148","quote":"Like labor displacement is what we're investing into.","quote_context":"Klarna CEO Sebastian Siemiatkowski bluntly states that AI-driven labor displacement is the core investment thesis, saying companies that sell per seat rather than replace jobs are not worth investing in.","sentiment":"cautious_optimism","sentiment_score":0.0,"themes":["job_displacement"],"person":{"name":"Sebastian Siemiatkowski","role":"CEO","company":"Klarna","is_builder":false},"source":{"video_id":"P7vIRAFSXmk","url":"https://www.youtube.com/watch?v=P7vIRAFSXmk","title":"Klarna CEO: SaaS is Dead: Why Systems of Record Will Die in an Agentic World","channel":"20VC with Harry Stebbings","upload_date":"2026-02-16","timestamp_seconds":1148,"timestamp_display":"19:08","timestamp_url":"https://www.youtube.com/watch?v=P7vIRAFSXmk&t=1148s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-16_klarna-ceo-saas-is-dead-why-systems-of-record-will-die-in-an.md","verified":false,"verified_date":null},{"id":"risk-P7vIRAFSXmk-1190","quote":"I think more like Elon that it might lead to a golden age","quote_context":"Klarna CEO acknowledges a big shift in jobs is coming but expresses optimism it could lead to a golden age of humanity where AI does more jobs and people enjoy richer lives.","sentiment":"cautious_optimism","sentiment_score":0.1,"themes":["job_displacement","net_positive"],"person":{"name":"Sebastian Siemiatkowski","role":"CEO","company":"Klarna","is_builder":false},"source":{"video_id":"P7vIRAFSXmk","url":"https://www.youtube.com/watch?v=P7vIRAFSXmk","title":"Klarna CEO: SaaS is Dead: Why Systems of Record Will Die in an Agentic World","channel":"20VC with Harry Stebbings","upload_date":"2026-02-16","timestamp_seconds":1190,"timestamp_display":"19:50","timestamp_url":"https://www.youtube.com/watch?v=P7vIRAFSXmk&t=1190s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-16_klarna-ceo-saas-is-dead-why-systems-of-record-will-die-in-an.md","verified":false,"verified_date":null},{"id":"risk-We7BZVKbCVw-3292","quote":"And so, for example, like if there's a neuron related to deception, we can start, we're","quote_context":"Boris Cherny describes Anthropic's mechanistic interpretability work, explaining they can now monitor neurons related to deception to understand when they activate, as part of their safety research.","sentiment":"concern","sentiment_score":-0.3,"themes":["alignment_failure","safety_solvable"],"person":{"name":"Boris Cherny","role":"Head of Claude Code","company":"Anthropic","is_builder":true},"source":{"video_id":"We7BZVKbCVw","url":"https://www.youtube.com/watch?v=We7BZVKbCVw","title":"Head of Claude Code: What happens after coding is solved | Boris Cherny","channel":"Lenny's Podcast","upload_date":"2026-02-19","timestamp_seconds":3292,"timestamp_display":"54:52","timestamp_url":"https://www.youtube.com/watch?v=We7BZVKbCVw&t=3292s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-19_boris-cherny-head-of-claude-code.md","verified":false,"verified_date":null},{"id":"risk-We7BZVKbCVw-3330","quote":"We released Claude Code really early because we wanted to study safety.","quote_context":"Boris Cherny explains Anthropic released Claude Code early specifically to study safety in real-world conditions, noting that models may look safe in lab settings but behave differently in the wild.","sentiment":"concern","sentiment_score":-0.2,"themes":["safety_solvable"],"person":{"name":"Boris Cherny","role":"Head of Claude Code","company":"Anthropic","is_builder":true},"source":{"video_id":"We7BZVKbCVw","url":"https://www.youtube.com/watch?v=We7BZVKbCVw","title":"Head of Claude Code: What happens after coding is solved | Boris Cherny","channel":"Lenny's Podcast","upload_date":"2026-02-19","timestamp_seconds":3330,"timestamp_display":"55:30","timestamp_url":"https://www.youtube.com/watch?v=We7BZVKbCVw&t=3330s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-19_boris-cherny-head-of-claude-code.md","verified":false,"verified_date":null},{"id":"risk-We7BZVKbCVw-3321","quote":"And as the model gets more sophisticated, this becomes so important because it might look","quote_context":"Boris Cherny warns that as AI models grow more sophisticated, they may pass alignment tests and evals but still behave unexpectedly in real-world deployment, underscoring why studying safety in the wild is essential.","sentiment":"concern","sentiment_score":-0.4,"themes":["alignment_failure","safety_solvable"],"person":{"name":"Boris Cherny","role":"Head of Claude Code","company":"Anthropic","is_builder":true},"source":{"video_id":"We7BZVKbCVw","url":"https://www.youtube.com/watch?v=We7BZVKbCVw","title":"Head of Claude Code: What happens after coding is solved | Boris Cherny","channel":"Lenny's Podcast","upload_date":"2026-02-19","timestamp_seconds":3321,"timestamp_display":"55:21","timestamp_url":"https://www.youtube.com/watch?v=We7BZVKbCVw&t=3321s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-19_boris-cherny-head-of-claude-code.md","verified":false,"verified_date":null},{"id":"risk-s52O1JH2tnU-4596","quote":"And AI literally, quite literally thinks, and AI will be able to replace the work that 70, 80% of humans can do over the next 10 years.","quote_context":"Uber CEO Dara Khosrowshahi states AI will replace the work capacity of 70-80% of humans within 10 years, warning society may not have enough time to adjust to the pace of change.","sentiment":"concern","sentiment_score":-0.5,"themes":["job_displacement"],"person":{"name":"Dara Khosrowshahi","role":"CEO","company":"Uber","is_builder":false},"source":{"video_id":"s52O1JH2tnU","url":"https://www.youtube.com/watch?v=s52O1JH2tnU","title":"Uber CEO: I Have To Be Honest, AI Will Replace 9.4 Million Jobs At Uber","channel":"The Diary Of A CEO","upload_date":"2026-02-23","timestamp_seconds":4596,"timestamp_display":"76:36","timestamp_url":"https://www.youtube.com/watch?v=s52O1JH2tnU&t=4596s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-23_uber-ceo-ai-will-replace-jobs-at-uber.md","verified":false,"verified_date":null},{"id":"risk-s52O1JH2tnU-4611","quote":"10 years is not a lot of time for society to adjust to that kind of an impact.","quote_context":"Uber CEO warns that unlike previous technological disruptions, AI is moving so fast that society may not have enough time to adapt, referencing Kurzweil's law of accelerating returns.","sentiment":"concern","sentiment_score":-0.5,"themes":["job_displacement"],"person":{"name":"Dara Khosrowshahi","role":"CEO","company":"Uber","is_builder":false},"source":{"video_id":"s52O1JH2tnU","url":"https://www.youtube.com/watch?v=s52O1JH2tnU","title":"Uber CEO: I Have To Be Honest, AI Will Replace 9.4 Million Jobs At Uber","channel":"The Diary Of A CEO","upload_date":"2026-02-23","timestamp_seconds":4611,"timestamp_display":"76:51","timestamp_url":"https://www.youtube.com/watch?v=s52O1JH2tnU&t=4611s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-23_uber-ceo-ai-will-replace-jobs-at-uber.md","verified":false,"verified_date":null},{"id":"risk-s52O1JH2tnU-5251","quote":"Hand on heart, though, it does appear that unemployment is going to be significantly increased in a world of AI, especially we just imagine this sort of continual rate of improvement.","quote_context":"Uber CEO candidly admits that AI will significantly increase unemployment, noting that both intellectual and physical jobs are being disrupted simultaneously, which is historically unprecedented.","sentiment":"concern","sentiment_score":-0.5,"themes":["job_displacement"],"person":{"name":"Dara Khosrowshahi","role":"CEO","company":"Uber","is_builder":false},"source":{"video_id":"s52O1JH2tnU","url":"https://www.youtube.com/watch?v=s52O1JH2tnU","title":"Uber CEO: I Have To Be Honest, AI Will Replace 9.4 Million Jobs At Uber","channel":"The Diary Of A CEO","upload_date":"2026-02-23","timestamp_seconds":5251,"timestamp_display":"87:31","timestamp_url":"https://www.youtube.com/watch?v=s52O1JH2tnU&t=5251s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-23_uber-ceo-ai-will-replace-jobs-at-uber.md","verified":false,"verified_date":null},{"id":"risk-s52O1JH2tnU-5275","quote":"And I do think there's a real question as to the ability of societies to retrain, the abilities of human beings to retrain themselves.","quote_context":"Uber CEO raises doubts about whether societies and individuals can retrain fast enough to keep pace with AI-driven job displacement, calling it a real open question.","sentiment":"concern","sentiment_score":-0.4,"themes":["job_displacement"],"person":{"name":"Dara Khosrowshahi","role":"CEO","company":"Uber","is_builder":false},"source":{"video_id":"s52O1JH2tnU","url":"https://www.youtube.com/watch?v=s52O1JH2tnU","title":"Uber CEO: I Have To Be Honest, AI Will Replace 9.4 Million Jobs At Uber","channel":"The Diary Of A CEO","upload_date":"2026-02-23","timestamp_seconds":5275,"timestamp_display":"87:55","timestamp_url":"https://www.youtube.com/watch?v=s52O1JH2tnU&t=5275s"},"extracted_date":"2026-02-25","note_path":"vault/interviews/2026-02-23_uber-ceo-ai-will-replace-jobs-at-uber.md","verified":false,"verified_date":null}]};

    // ── COLORS ──
    const sentimentColor = {
        alarm: '#ff4444',
        concern: '#ff8a65',
        cautious_optimism: '#8a8a94',
        optimism: '#66bb6a',
        dismissal: '#4caf50'
    };

    const sentimentLabel = {
        alarm: 'Alarm',
        concern: 'Concern',
        cautious_optimism: 'Cautious Optimism',
        optimism: 'Optimism',
        dismissal: 'Dismissal'
    };

    const themeLabels = {
        existential_risk: 'Existential Risk',
        alignment_failure: 'Alignment Failure',
        loss_of_control: 'Loss of Control',
        bioweapons: 'Bioweapons',
        power_concentration: 'Power Concentration',
        arms_race: 'Arms Race',
        job_displacement: 'Job Displacement',
        consciousness_rights: 'Consciousness Rights',
        safety_solvable: 'Safety Solvable',
        net_positive: 'Net Positive',
        regulation_needed: 'Regulation Needed',
        precautionary_principle: 'Precautionary Principle'
    };

    // X logo SVG path
    const X_SVG = '<svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/></svg>';

    // ── STATE ──
    let activeFilters = { sentiment: 'all' };
    let activeSpeaker = null;
    let sortMode = 'extreme'; // extreme | recent | speaker

    // ── HELPERS ──
    function getFiltered() {
        return SIGNALS_DATA.signals.filter(s => {
            if (activeFilters.sentiment !== 'all' && s.sentiment !== activeFilters.sentiment) return false;
            if (activeSpeaker && s.person.name !== activeSpeaker) return false;
            return true;
        });
    }

    function groupByPerson(signals) {
        const map = {};
        signals.forEach(s => {
            const key = s.person.name;
            if (!map[key]) {
                map[key] = { person: s.person, signals: [], avgScore: 0 };
            }
            map[key].signals.push(s);
        });
        Object.values(map).forEach(g => {
            g.avgScore = d3.mean(g.signals, s => s.sentiment_score);
            g.dominantSentiment = getDominantSentiment(g.avgScore);
        });
        return Object.values(map).sort((a, b) => a.avgScore - b.avgScore);
    }

    function getDominantSentiment(score) {
        if (score <= -0.6) return 'alarm';
        if (score <= -0.2) return 'concern';
        if (score <= 0.2) return 'cautious_optimism';
        if (score <= 0.6) return 'optimism';
        return 'dismissal';
    }

    function showToast(msg) {
        const el = document.getElementById('toast');
        el.textContent = msg;
        el.classList.add('visible');
        setTimeout(() => el.classList.remove('visible'), 2000);
    }

    function shareQuote(signal) {
        const text = `"${signal.quote}"\n— ${signal.person.name}, ${signal.person.role} at ${signal.person.company}\n${signal.source.timestamp_url}`;
        if (navigator.share) {
            navigator.share({ text }).catch(() => {});
        } else if (navigator.clipboard) {
            navigator.clipboard.writeText(text).then(() => showToast('Copied to clipboard'));
        }
    }

    function tweetQuote(signal) {
        const maxQuoteLen = 200;
        let quote = signal.quote;
        if (quote.length > maxQuoteLen) {
            quote = quote.substring(0, maxQuoteLen - 1) + '…';
        }
        const text = encodeURIComponent(`"${quote}" — ${signal.person.name}\n${signal.source.timestamp_url}`);
        window.open(`https://twitter.com/intent/tweet?text=${text}`, '_blank');
    }

    async function copyCardAsImage(cardEl, signal) {
        const btn = cardEl.querySelector('.copy-img-btn');
        // Hide action buttons during capture
        const footer = cardEl.querySelector('.quote-card-footer');
        footer.style.visibility = 'hidden';

        try {
            const canvas = await html2canvas(cardEl, {
                backgroundColor: '#141418',
                scale: 2,
                useCORS: true,
                logging: false
            });
            footer.style.visibility = '';

            canvas.toBlob(async (blob) => {
                if (blob && navigator.clipboard && window.ClipboardItem) {
                    try {
                        await navigator.clipboard.write([new ClipboardItem({ 'image/png': blob })]);
                        showToast('Card copied as image');
                        if (btn) { btn.classList.add('copied'); setTimeout(() => btn.classList.remove('copied'), 2000); }
                    } catch {
                        // Fallback: download
                        downloadBlob(blob, signal);
                    }
                } else if (blob) {
                    downloadBlob(blob, signal);
                }
            }, 'image/png');
        } catch {
            footer.style.visibility = '';
            showToast('Could not capture card');
        }
    }

    function downloadBlob(blob, signal) {
        const url = URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url;
        a.download = `dead-or-alive-${signal.person.name.replace(/\s+/g, '-').toLowerCase()}.png`;
        a.click();
        URL.revokeObjectURL(url);
        showToast('Card downloaded as image');
    }

    function makeCardHTML(signal, extraClass) {
        const sent = signal.sentiment;
        const cls = extraClass ? ` ${extraClass}` : '';
        return `
        <div class="quote-card sentiment-${sent}${cls}" data-person="${signal.person.name}">
            <span class="decorative-quote">&ldquo;</span>
            <div class="quote-card-body">
                <p class="quote-card-text">&ldquo;${signal.quote}&rdquo;</p>
                <div class="quote-card-attribution">
                    ${signal.person.name}${signal.person.is_builder ? '<span class="builder-badge">Builder</span>' : ''}
                </div>
                <div class="quote-card-role">${signal.person.role}, ${signal.person.company}</div>
            </div>
            <div class="quote-card-footer">
                <a href="${signal.source.timestamp_url}" target="_blank" rel="noopener">&#9654; ${signal.source.timestamp_display} &middot; ${signal.source.channel}</a>
                <div class="card-actions">
                    <button class="action-btn tweet-btn" title="Share on X">${X_SVG} Post</button>
                    <button class="action-btn copy-img-btn" title="Copy as image">
                        <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z"/></svg>
                        Copy
                    </button>
                </div>
            </div>
        </div>`;
    }

    function bindCardActions(container, signalLookup) {
        container.querySelectorAll('.quote-card').forEach(card => {
            const personName = card.dataset.person;
            const quoteText = card.querySelector('.quote-card-text').textContent;
            // Find the matching signal
            const signal = signalLookup.find(s =>
                s.person.name === personName && quoteText.includes(s.quote.substring(0, 30))
            );
            if (!signal) return;

            const tweetBtn = card.querySelector('.tweet-btn');
            const copyBtn = card.querySelector('.copy-img-btn');
            if (tweetBtn) tweetBtn.addEventListener('click', () => tweetQuote(signal));
            if (copyBtn) copyBtn.addEventListener('click', () => copyCardAsImage(card, signal));
        });
    }

    // ── RENDER: EMPTY STATE ──
    function renderEmptyState() {
        document.getElementById('hero-stat').textContent = 'No risk signals extracted yet.';
        document.getElementById('hero-credibility').textContent = 'Run scripts/extract-risk-signals.sh to extract signals from all transcripts.';
        document.getElementById('featured-grid').innerHTML = `
            <div class="empty-state">
                <h2>No Data Yet</h2>
                <p>Run the extraction script to scan interview transcripts for existential risk signals.</p>
            </div>`;
        ['speakers', 'feed'].forEach(id => {
            const el = document.getElementById(id);
            if (el) el.style.display = 'none';
        });
    }

    // ── RENDER: HERO ──
    function renderHero() {
        const signals = SIGNALS_DATA.signals;
        const builders = [...new Set(signals.filter(s => s.person.is_builder).map(s => s.person.name))];
        const warnBuilders = [...new Set(
            signals.filter(s => s.person.is_builder && (s.sentiment === 'alarm' || s.sentiment === 'concern'))
                   .map(s => s.person.name)
        )];
        const totalPeople = [...new Set(signals.map(s => s.person.name))].length;
        const totalInterviews = [...new Set(signals.map(s => s.source.video_id))].length;

        document.getElementById('hero-stat').innerHTML =
            `<strong>${warnBuilders.length} of ${builders.length}</strong> AI builders have publicly warned their technology could cause catastrophic harm`;
        document.getElementById('hero-credibility').textContent =
            `${signals.length} verbatim quotes. ${totalPeople} speakers. Every one linked to source video.`;
    }

    // ── RENDER: HERO VISUALIZATION (Doom Index Gauge) ──
    function renderHeroViz() {
        const signals = SIGNALS_DATA.signals;
        const totalPeople = [...new Set(signals.map(s => s.person.name))].length;
        const totalInterviews = [...new Set(signals.map(s => s.source.video_id))].length;

        // Compute the index: weighted average of sentiment scores
        // Builders get 2x weight — they're the ones actually building it
        let weightedSum = 0, weightTotal = 0;
        signals.forEach(s => {
            const w = s.person.is_builder ? 2 : 1;
            weightedSum += s.sentiment_score * w;
            weightTotal += w;
        });
        const avgScore = weightTotal > 0 ? weightedSum / weightTotal : 0;
        // Map [-1, 1] → [0, 100] where 0 = total optimism, 100 = total doom
        const indexScore = Math.round((1 - avgScore) * 50);
        const clampedScore = Math.max(0, Math.min(100, indexScore));

        // Label + color bands
        let label, labelColor;
        if (clampedScore >= 80)      { label = 'Extreme Fear'; labelColor = '#ff4444'; }
        else if (clampedScore >= 60) { label = 'Fear';         labelColor = '#ff8a65'; }
        else if (clampedScore >= 40) { label = 'Neutral';      labelColor = '#a0a0a8'; }
        else if (clampedScore >= 20) { label = 'Optimism';     labelColor = '#66bb6a'; }
        else                         { label = 'Extreme Optimism'; labelColor = '#4caf50'; }

        // ── SVG gauge geometry ──
        // Layout: left = 0 (optimism/green), right = 100 (doom/red)
        // Angles: π (180°) = left endpoint, 0 (0°) = right endpoint
        // In SVG y-down coords: x = cx + r*cos(θ), y = cy - r*sin(θ)
        const cx = 200, cy = 180, r = 150, strokeW = 26;

        function arcPath(fromAngle, toAngle) {
            const x1 = cx + r * Math.cos(fromAngle);
            const y1 = cy - r * Math.sin(fromAngle);
            const x2 = cx + r * Math.cos(toAngle);
            const y2 = cy - r * Math.sin(toAngle);
            const sweep = fromAngle - toAngle;
            const largeArc = sweep > Math.PI ? 1 : 0;
            // sweep-flag 0 = counterclockwise in SVG screen coords = through the top
            return `M ${x1.toFixed(1)} ${y1.toFixed(1)} A ${r} ${r} 0 ${largeArc} 0 ${x2.toFixed(1)} ${y2.toFixed(1)}`;
        }

        // Needle: score 0 → angle π (left), score 100 → angle 0 (right)
        const needleAngle = Math.PI * (1 - clampedScore / 100);
        const needleLen = r - 30;
        const nx = cx + needleLen * Math.cos(needleAngle);
        const ny = cy - needleLen * Math.sin(needleAngle);

        // 5 segments: left (green/optimism) → right (red/doom)
        const segments = [
            { from: Math.PI,        to: Math.PI * 0.8, color: '#4caf50' },
            { from: Math.PI * 0.8,  to: Math.PI * 0.6, color: '#66bb6a' },
            { from: Math.PI * 0.6,  to: Math.PI * 0.4, color: '#a0a0a8' },
            { from: Math.PI * 0.4,  to: Math.PI * 0.2, color: '#ff8a65' },
            { from: Math.PI * 0.2,  to: 0.001,         color: '#ff4444' },
        ];

        // Background arc segments (muted)
        const bgArcs = segments.map(s =>
            `<path d="${arcPath(s.from, s.to)}" fill="none" stroke="${s.color}" stroke-width="${strokeW}" stroke-linecap="butt" opacity="0.18"/>`
        ).join('\n            ');

        // Active fill: from LEFT (π) sweeping right toward the needle
        // This fills proportionally to the score
        const activeEnd = Math.max(needleAngle, 0.002);
        const activeArc = clampedScore > 1 ?
            `<path d="${arcPath(Math.PI, activeEnd)}" fill="none" stroke="url(#activeGrad)" stroke-width="${strokeW}" stroke-linecap="round" opacity="0.9"/>` : '';

        // Glow behind active arc
        const glowArc = clampedScore > 1 ?
            `<path d="${arcPath(Math.PI, activeEnd)}" fill="none" stroke="${labelColor}" stroke-width="${strokeW + 14}" stroke-linecap="round" opacity="0.08" filter="url(#glow)"/>` : '';

        // Tick marks at 0, 25, 50, 75, 100
        const ticks = [0, 25, 50, 75, 100].map(val => {
            const angle = Math.PI * (1 - val / 100);
            const outerR = r + strokeW / 2 + 3;
            const innerR = r + strokeW / 2 - 3;
            const ox = cx + outerR * Math.cos(angle);
            const oy = cy - outerR * Math.sin(angle);
            const ix = cx + innerR * Math.cos(angle);
            const iy = cy - innerR * Math.sin(angle);
            return `<line x1="${ix.toFixed(1)}" y1="${iy.toFixed(1)}" x2="${ox.toFixed(1)}" y2="${oy.toFixed(1)}" stroke="#3a3a44" stroke-width="1.5"/>`;
        }).join('\n            ');

        // Tick labels
        const tickLabels = [
            { val: 0,   label: '0' },
            { val: 50,  label: '50' },
            { val: 100, label: '100' },
        ].map(t => {
            const angle = Math.PI * (1 - t.val / 100);
            const labelR = r + strokeW / 2 + 14;
            const lx = cx + labelR * Math.cos(angle);
            const ly = cy - labelR * Math.sin(angle);
            return `<text x="${lx.toFixed(1)}" y="${ly.toFixed(1)}" text-anchor="middle" dominant-baseline="middle" fill="#6a6a74" font-family="'JetBrains Mono', monospace" font-size="10" font-weight="500">${t.label}</text>`;
        }).join('\n            ');

        // Axis endpoint labels
        const axisLabelR = r + strokeW / 2 + 30;
        const leftLabelX = cx + axisLabelR * Math.cos(Math.PI);
        const rightLabelX = cx + axisLabelR * Math.cos(0);

        const svgMarkup = `
        <svg viewBox="0 0 400 230" xmlns="http://www.w3.org/2000/svg">
            <defs>
                <filter id="glow">
                    <feGaussianBlur stdDeviation="6" result="blur"/>
                    <feMerge><feMergeNode in="blur"/><feMergeNode in="SourceGraphic"/></feMerge>
                </filter>
                <filter id="needleShadow">
                    <feDropShadow dx="0" dy="0" stdDeviation="3" flood-color="${labelColor}" flood-opacity="0.5"/>
                </filter>
                <linearGradient id="activeGrad" gradientUnits="userSpaceOnUse" x1="${cx - r}" y1="${cy}" x2="${cx + r}" y2="${cy}">
                    <stop offset="0%" stop-color="#4caf50"/>
                    <stop offset="50%" stop-color="#a0a0a8"/>
                    <stop offset="100%" stop-color="#ff4444"/>
                </linearGradient>
            </defs>

            <!-- Background arcs -->
            ${bgArcs}

            <!-- Glow behind active -->
            ${glowArc}

            <!-- Active fill -->
            ${activeArc}

            <!-- Tick marks -->
            ${ticks}

            <!-- Tick labels -->
            ${tickLabels}

            <!-- Endpoint labels -->
            <text x="${leftLabelX.toFixed(1)}" y="${(cy + 6).toFixed(1)}" text-anchor="middle" fill="#4caf50" font-family="'JetBrains Mono', monospace" font-size="9" font-weight="600" letter-spacing="0.08em">SAFE</text>
            <text x="${rightLabelX.toFixed(1)}" y="${(cy + 6).toFixed(1)}" text-anchor="middle" fill="#ff4444" font-family="'JetBrains Mono', monospace" font-size="9" font-weight="600" letter-spacing="0.08em">DOOM</text>

            <!-- Needle -->
            <line x1="${cx}" y1="${cy}" x2="${nx.toFixed(1)}" y2="${ny.toFixed(1)}" stroke="${labelColor}" stroke-width="2.5" stroke-linecap="round" filter="url(#needleShadow)"/>
            <!-- Pivot -->
            <circle cx="${cx}" cy="${cy}" r="8" fill="#18181e" stroke="${labelColor}" stroke-width="2"/>
            <circle cx="${cx}" cy="${cy}" r="3" fill="${labelColor}"/>

            <!-- Score inside the semicircle -->
            <text x="${cx}" y="${cy - 55}" text-anchor="middle" fill="${labelColor}" font-family="'Libre Baskerville', Georgia, serif" font-size="56" font-weight="700">${clampedScore}</text>
            <!-- Label -->
            <text x="${cx}" y="${cy - 25}" text-anchor="middle" fill="${labelColor}" font-family="'JetBrains Mono', monospace" font-size="13" font-weight="700" letter-spacing="0.15em" text-transform="uppercase">${label.toUpperCase()}</text>
        </svg>`;

        const wrapper = document.getElementById('hero-viz-wrapper');
        wrapper.innerHTML = `
        <div class="hero-viz-card" id="hero-viz-card">
            <div class="gauge-container">${svgMarkup}</div>
            <div class="gauge-sublabel">Based on ${signals.length} verbatim quotes from ${totalPeople} AI leaders across ${totalInterviews} interviews</div>
            <div class="viz-card-footer">
                <span class="viz-card-source">AI Pulse &middot; Doom Index</span>
                <div class="viz-share-actions">
                    <button class="action-btn" id="viz-tweet-btn" title="Share on X">${X_SVG} Post</button>
                    <button class="action-btn" id="viz-copy-btn" title="Copy as image">
                        <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z"/></svg>
                        Copy
                    </button>
                </div>
            </div>
        </div>`;

        // Bind share buttons
        document.getElementById('viz-tweet-btn').addEventListener('click', () => {
            const text = encodeURIComponent(`The AI Doom Index is at ${clampedScore}/100: ${label}\n\nBased on ${signals.length} verbatim quotes from ${totalPeople} AI leaders. Every quote linked to source video.`);
            window.open(`https://twitter.com/intent/tweet?text=${text}`, '_blank');
        });

        document.getElementById('viz-copy-btn').addEventListener('click', async () => {
            const card = document.getElementById('hero-viz-card');
            const actions = card.querySelector('.viz-share-actions');
            actions.style.visibility = 'hidden';
            try {
                const canvas = await html2canvas(card, {
                    backgroundColor: '#141418',
                    scale: 2,
                    useCORS: true,
                    logging: false
                });
                actions.style.visibility = '';
                canvas.toBlob(async (blob) => {
                    if (blob && navigator.clipboard && window.ClipboardItem) {
                        try {
                            await navigator.clipboard.write([new ClipboardItem({ 'image/png': blob })]);
                            showToast('Doom Index copied as image');
                        } catch {
                            const url = URL.createObjectURL(blob);
                            const a = document.createElement('a');
                            a.href = url;
                            a.download = 'ai-doom-index.png';
                            a.click();
                            URL.revokeObjectURL(url);
                            showToast('Doom Index downloaded as image');
                        }
                    }
                }, 'image/png');
            } catch {
                actions.style.visibility = '';
                showToast('Could not capture image');
            }
        });
    }

    // ── RENDER: FEATURED QUOTES ──
    function renderFeatured() {
        const signals = SIGNALS_DATA.signals;
        // Viral score: |sentiment_score| + builder bonus + short quote bonus
        const scored = signals.map(s => {
            let score = Math.abs(s.sentiment_score);
            if (s.person.is_builder) score += 0.3;
            if (s.quote.length < 100) score += 0.2;
            else if (s.quote.length < 150) score += 0.1;
            return { signal: s, viralScore: score };
        });
        scored.sort((a, b) => b.viralScore - a.viralScore);

        // Deduplicate by person — max 1 per speaker
        const seen = new Set();
        const featured = [];
        for (const item of scored) {
            if (seen.has(item.signal.person.name)) continue;
            seen.add(item.signal.person.name);
            featured.push(item.signal);
            if (featured.length >= 8) break;
        }

        const grid = document.getElementById('featured-grid');
        grid.innerHTML = featured.map(s => makeCardHTML(s)).join('');
        bindCardActions(grid, featured);
    }

    // ── RENDER: SPEAKER LINEUP ──
    function renderSpeakers() {
        const people = groupByPerson(SIGNALS_DATA.signals);
        const scroller = document.getElementById('speaker-scroller');

        scroller.innerHTML = people.map(g => {
            const scoreColor = sentimentColor[g.dominantSentiment];
            return `
            <div class="speaker-chip" data-speaker="${g.person.name}">
                <div class="speaker-chip-name">${g.person.name}</div>
                <div class="speaker-chip-meta">
                    ${g.person.company} &middot;
                    <span class="speaker-chip-score" style="color:${scoreColor}">${g.avgScore.toFixed(2)}</span>
                    &middot; ${g.signals.length} quotes
                </div>
            </div>`;
        }).join('');

        // Click handlers
        scroller.querySelectorAll('.speaker-chip').forEach(chip => {
            chip.addEventListener('click', () => {
                const name = chip.dataset.speaker;
                if (activeSpeaker === name) {
                    activeSpeaker = null;
                    chip.classList.remove('active');
                } else {
                    activeSpeaker = name;
                    scroller.querySelectorAll('.speaker-chip').forEach(c => c.classList.remove('active'));
                    chip.classList.add('active');
                }
                renderFeed();
                document.getElementById('feed').scrollIntoView({ behavior: 'smooth' });
            });
        });
    }

    // ── RENDER: FILTER BAR ──
    function renderFilters() {
        const bar = document.getElementById('filter-bar');
        const sentiments = ['all', 'alarm', 'concern', 'cautious_optimism', 'optimism', 'dismissal'];

        bar.innerHTML = '';

        const sLabel = document.createElement('label');
        sLabel.textContent = 'Filter:';
        bar.appendChild(sLabel);

        sentiments.forEach(s => {
            const btn = document.createElement('button');
            btn.className = 'filter-btn' + (activeFilters.sentiment === s ? ' active' : '');
            btn.textContent = s === 'all' ? 'All' : sentimentLabel[s] || s;
            btn.onclick = () => {
                activeFilters.sentiment = s;
                renderFilters();
                renderFeed();
            };
            bar.appendChild(btn);
        });

        // Sort dropdown
        const sep = document.createElement('div');
        sep.className = 'filter-separator';
        bar.appendChild(sep);

        const sortLabel = document.createElement('label');
        sortLabel.textContent = 'Sort:';
        bar.appendChild(sortLabel);

        const select = document.createElement('select');
        select.className = 'sort-select';
        [
            { value: 'extreme', label: 'Most extreme' },
            { value: 'recent', label: 'Most recent' },
            { value: 'speaker', label: 'By speaker' }
        ].forEach(opt => {
            const o = document.createElement('option');
            o.value = opt.value;
            o.textContent = opt.label;
            if (sortMode === opt.value) o.selected = true;
            select.appendChild(o);
        });
        select.onchange = () => { sortMode = select.value; renderFeed(); };
        bar.appendChild(select);
    }

    // ── RENDER: QUOTE FEED ──
    function renderFeed() {
        const filtered = getFiltered();
        let sorted;

        switch (sortMode) {
            case 'recent':
                sorted = [...filtered].sort((a, b) => (b.source.upload_date || '').localeCompare(a.source.upload_date || ''));
                break;
            case 'speaker':
                sorted = [...filtered].sort((a, b) => a.person.name.localeCompare(b.person.name));
                break;
            case 'extreme':
            default:
                sorted = [...filtered].sort((a, b) => Math.abs(b.sentiment_score) - Math.abs(a.sentiment_score));
                break;
        }

        const countEl = document.getElementById('feed-count');
        countEl.textContent = `Showing ${sorted.length} of ${SIGNALS_DATA.signals.length} signals`;

        const list = document.getElementById('feed-list');
        list.innerHTML = sorted.map(s => makeCardHTML(s)).join('');
        bindCardActions(list, sorted);

        // Scroll-triggered fade-in
        requestAnimationFrame(() => {
            const observer = new IntersectionObserver((entries) => {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        entry.target.classList.add('visible');
                        observer.unobserve(entry.target);
                    }
                });
            }, { threshold: 0.1, rootMargin: '0px 0px -50px 0px' });

            list.querySelectorAll('.quote-card').forEach(card => observer.observe(card));
        });
    }

    // ── INIT ──
    if (!SIGNALS_DATA.signals || SIGNALS_DATA.signals.length === 0) {
        renderEmptyState();
    } else {
        renderHero();
        renderHeroViz();
        renderFeatured();
        renderSpeakers();
        renderFilters();
        renderFeed();
    }
    </script>
</body>
</html>
